[{"title":"The title is: Optimizing Energy Consumption in Milk Evaporators using In-Silico Models","description":"\u2699\ufe0f\ud83c\udf10 Optimizing Energy Consumption in Milk Evaporators using In-Silico Models \ud83e\udd5b\ud83d\udca1\n\nIn today's food industry, manufacturing processes share commonalities with Pharma and Biotechnology, allowing the application of similar Digital Models. Evaporation units, crucial for concentrating milk and reducing energy needs in subsequent spray drying, exemplify this versatility.\n\n\ud83c\udf21 This study by Artemis Tsochatzidi, Achilleas Arvanitidis and Michael Georgiadis delves into the optimization of the evaporation process, exploring five different layouts through global system analysis (GSA) and advanced optimization techniques.\n\nKey Highlights:\n\u2699\ufe0f MVR and TVR Technologies: Investigated Mechanical Vapor Recompression (MVR) and Thermal Vapor Recompression as primary energy-saving technologies.\n\ud83d\udcc8 Pressure and Ratio Impact: Explored the effects of higher TVR pressures, MVR ratios, and increased feed temperatures on evaporation and operational costs.\n\ud83d\udcb0 Economical Configurations: Identified cost-effective setups for different product dry mass contents using TVR and MVR.\n\ud83d\udcca Cost Sensitivity: Analyzed the impact of electricity prices, steam costs, and product transitions on overall costs.\n\ud83c\udf3f Biomass-Based Steam: Explored the significant impact of reductions in biomass-based steam costs on annual expenditures.\n\ud83d\udcc9 Total Annualized Cost: Implemented optimization strategies for new plant designs, resulting in substantial cost reductions.\n\n\ud83d\udcda Link to Publication: https:\/\/lnkd.in\/dKfV33MP\n\n#EnergyOptimization #MilkEvaporators #DynamicOptimization #ResearchHighlight #PolyModelsHub","linkedinURL":"https:\/\/www.linkedin.com\/feed\/update\/urn:li:activity:7155529639560425473","githubURL":null,"paperURL":null,"author":"Antonio Benedetti","createdDate":"01\/23\/2024"},{"title":"The title is: Learning Programming & Python as a ChemEng: Essentials of Chemical Engineering","description":"\u2699\ufe0f\ud83d\udcda Learning Programming & Python as a ChemEng: Essentials of Chemical Engineering (essentials-ChEng) \ud83d\udd2c\ud83d\udc0d\n\n\ud83c\udf10 We've emphasized the importance of online educational resources for learning programming in a relevant context. If you're interested in modeling and study ChemEng, check out this exceptional work by Amvrosios G. Georgiadis.\n\n\ud83c\udf1f What sets this repository apart?\n\ud83d\udc0d Python-Centric: Delve into comprehensive examples exclusively focused on using Python for Chemical Engineering applications.\n\ud83d\udce6 Essential Tools: Explore fundamental tools and techniques crucial for mastering Chemical Engineering concepts.\n\ud83e\udd1d Community-Driven: Open to contributions and collaboration, shaping this repository into a thriving resource hub for the community.\n\ud83d\ude80 Why was this repository created?\nIdentifying a gap in GitHub's comprehensive Python-centric Chemical Engineering tutorials, essentials-ChEng was born. This repository aims to fill that void, providing a dedicated space for learning and collaboration.\n\n\ud83d\udc49 Dive in, contribute, and let's build a strong community of Python-savvy Chemical Engineers!\n\n\ud83d\udd17 GitHub Repository: https:\/\/lnkd.in\/d2AywMtW\n\n#ChemicalEngineering #PythonInEngineering #GitHubRepository #Education #PolyModelsHub","linkedinURL":"https:\/\/www.linkedin.com\/feed\/update\/urn:li:activity:7155210686791352321","githubURL":null,"paperURL":null,"author":"Antonio Benedetti","createdDate":"01\/22\/2024"},{"title":"The title is: Innovating Continuous Dry Granulation: Hybrid Model Development and Nonlinear Model Predictive Control","description":"\u2699\ufe0f\ud83d\udd04 Innovating Continuous Dry Granulation: Hybrid Model Development and Nonlinear Model Predictive Control \ud83c\udf10\ud83d\udc8a\n\nThe pharmaceutical industry relies significantly on the dry granulation process for manufacturing solid dosage forms like tablets, capsules, and sachets. Dry granulation is preferred over wet granulation, especially when materials exhibit sensitivity to heat and moisture.\n\n\ud83d\udcbb This research is centered on creating a hybrid model that seamlessly combines roll compaction and ribbon milling operations. The objective is to intricately design and control a continuous dry granulation process.\n\nKey Highlights:\n\ud83d\ude80 First Experimental NMPC Implementation in a Roller Compactor.\n\ud83c\udf9a\ufe0f Controlled Bimodal Size Distribution Using NMPC.\n\ud83d\udcca Bimodal Weibull Distribution for Granule Size Description.\n\ud83d\udd0d Innovative NIR Spectra Analysis for Ribbon Solid Fraction Measurement.\n\ud83d\udd04 Development of a Hybrid Model Integrating Roll Compaction and Ribbon Milling Processes.\n\n\ud83d\udcda Link to Publication: https:\/\/lnkd.in\/dRdprq-C\n\n#ContinuousGranulation #ModelPredictiveControl #PharmaceuticalProcesses #Innovation #PolyModelsHub","linkedinURL":"https:\/\/www.linkedin.com\/feed\/update\/urn:li:activity:7154826672649756672","githubURL":null,"paperURL":null,"author":"Antonio Benedetti","createdDate":"01\/21\/2024"},{"title":"The title is: \"Reduce Drug Development Time by 80%: A Thriving Reality?\"","description":"\u2753\ud83d\udc8a Is Reducing Drug Development Time by 80% Just Science Fiction, or a Thriving Reality\u2753\ud83d\udc8a\n\nCan drug development be accelerated by 80% compared to the current average? We firmly believe that this is not only feasible but can become a reality by undergoing a profound transformation in the R&D paradigm. This shift is driven by leveraging cutting-edge technologies and efficiently managing prior expertise.\n\n\ud83d\udd0e Today, we're glad to share this great example by Pfizer, showcasing an 80% time reduction in the development of Nirmatrelvir (Paxlovid).\n\nKey Highlights:\n\ud83e\udda0 Lightspeed Development: An aggressive development paradigm and \"lightspeed\" approach fueled by the urgency to address the global crisis.\n\ud83c\udfc6 Unprecedented Achievement: The chemical synthesis of Nirmatrelvir set a new record, progressing from laboratory synthesis in July 2020 to FDA emergency use authorization in just 17 months.\n\ud83d\udd2c Efficient Synthesis: Development and scale-up of an efficient chemical synthesis, providing hundreds of metric tons of the API across multiple vendor sites.\n\ud83d\udcc8 Leveraging Prior Research: The project underscores the importance of prior research, laying the groundwork for future commercial breakthroughs.\n\ud83c\udf0d Global Supply Chains: Overcoming logistical challenges and supply chain complexities to meet unprecedented material demands.\n\n\ud83d\udcda Link to Publication: https:\/\/lnkd.in\/dzxsxuM9\n\n#DrugDevelopment #researchanddevelopment  #CuttingEdgeTechnologies #PolyModelsHub","linkedinURL":"https:\/\/www.linkedin.com\/feed\/update\/urn:li:activity:7154469049148620800","githubURL":null,"paperURL":null,"author":"Antonio Benedetti","createdDate":"01\/20\/2024"},{"title":"The title is: ParMOO: Python Library for Parallel Multiobjective Simulation Optimization","description":"\u2699\ufe0f \ud83d\udd04 ParMOO: Python Library for Parallel Multiobjective Simulation Optimization\n\nParMOO stands as a parallel multiobjective optimization solver designed to harness the simulation-based structure within objective and constraint functions.\n\n\ud83d\udd0d To exploit this structure, ParMOO separates simulations from objectives and constraints, which means:\n\ud83d\udccc A design variable is a directly controllable input.\n\ud83d\udd04 A simulation is an expensive or time-consuming process, treated as a blackbox function of design variables and evaluated sparingly.\n\ud83d\udcca An objective is an algebraic function of design variables and\/or simulation outputs, aiming for optimization.\n\ud83d\udd12 A constraint is an algebraic function with a specified bound that cannot be exceeded.\n\n\ud83d\udcc8 Designs, Simulations, and Objectives: To tackle multiobjective optimization problems (MOOP), ParMOO utilizes surrogate models of simulation outputs, combined with algebraic definitions of objectives and constraints.\n\n\ud83d\udc0d Implemented in Python and employing libEnsemble for scalable parallelism, ParMOO distributes batches of simulation evaluations across parallel resources.\n\n\ud83d\ude80 Explore ParMOO: https:\/\/lnkd.in\/d2tNtHzS\n\ud83d\udcc4 Documentation: https:\/\/lnkd.in\/dE8yGUJ5\n\ud83d\udcfa Link to Youtube Tutorial: https:\/\/lnkd.in\/dYGf7yJG\n\n#MultiobjectiveOptimization #SimulationOptimization #PythonLibrary #ParallelComputing #PolyModelsHub","linkedinURL":"https:\/\/www.linkedin.com\/feed\/update\/urn:li:activity:7154095759041212416","githubURL":null,"paperURL":null,"author":"Antonio Benedetti","createdDate":"01\/19\/2024"},{"title":"The title is: M\u00b2E\u00b3D: Multiphase Materials Exploration via Evolutionary Equation Discovery","description":"\ud83e\udd16 M\u00b2E\u00b3D: Multiphase Materials Exploration via Evolutionary Equation Discovery \ud83d\udca1 \n\nFocused on simulational and experimental discovery from micro to macro scales, M\u00b2E\u00b3D uncovers equations, models, and correlations inherent in experimental data. It utilizes the PySR and fvGP libraries, providing a comprehensive toolkit for users.\n\n\ud83d\udce6 M\u00b2E\u00b3D is designed to unveil physical laws and correlations in chemical engineering. However, it is data-agnostic, seamlessly working with simulated and experimental results across diverse domains.\n\nKey Highlights:\n\ud83d\udcca Discovery of symbolic closed-form equations for modeling multiple responses.\n\ud83d\udd04 Efficient parameter sampling for planning experimental\/simulational campaigns.\n\ud83c\udf10 System multi-response uncertainty quantification, targeting high-variance parameter regions.\n\ud83d\ude80 Automatic parallelization of intricate user simulation scripts on OS Processes and distributed supercomputers.\n\ud83d\udcc8 Interactive plotting of responses, uncertainties, and discovered model outputs.\n\ud83d\udcbe Language-agnostic saving of results.\n\n\ud83d\ude80 Link to Github: https:\/\/lnkd.in\/dsadUF4Z\n\n#AI #Modelling #ExperimentalDiscovery #DataScience #PythonPackage #PolyModelsHub","linkedinURL":"https:\/\/www.linkedin.com\/feed\/update\/urn:li:activity:7153721879218827265","githubURL":null,"paperURL":null,"author":"Antonio Benedetti","createdDate":"01\/18\/2024"},{"title":"The title is: Decoding Stability in Continuous Mixed Suspension Crystallizers","description":"\u2699\ufe0f \u2744  Decoding Stability in Continuous Mixed Suspension Crystallizers \ud83e\uddca\ud83d\udd0d\n\nContinuous mixed suspension crystallizers find extensive use in various industries, facilitating the controlled production of crystalline materials. \n\n\ud83d\udc8e This study revisits the mathematical depiction of the mixed suspension crystallizer, introducing a comprehensive framework for identifying potential steady states and evaluating their stability.\n\nKey Highlights:\n\ud83d\udcca Birth Rate Framework: Novel use of birth rate for assessing steady state stability.\n\ud83d\udd0d Stability Conditions: Criteria include birth rate of one, positive derivative, and sustained positive suspension density.\n\ud83d\udd04 General Applicability: Framework accommodates diverse conditions, allowing analysis under various expressions and growth scenarios.\n\ud83c\udf10 Polymorphic and Chiral Exploration: Insights into polymorphic steady states and challenges in enantiopure crystallization.\n\n\ud83d\udcda Link to Publication: https:\/\/lnkd.in\/gpwFuXQ5\n\n#Crystallization #SteadyStateAnalysis #MaterialScience #MathematicalModeling #PolyModelsHub","linkedinURL":"https:\/\/www.linkedin.com\/feed\/update\/urn:li:activity:7153365402931073025","githubURL":null,"paperURL":null,"author":"Antonio Benedetti","createdDate":"01\/17\/2024"},{"title":"The title is: MolFlux - Molecular Predictive Modeling Made Easier and Accessible","description":"\u2699\ufe0f Molecular Predictive Modeling Made Easier and Accessible with MolFlux  \ud83e\uddec\ud83d\udd0d\n\nMolecular Predictive Modeling is garnering attention for its practical insights derived from computational techniques that understand and predict molecular behavior. \n\n\ud83d\ude80 Amidst various projects, we spotlight MolFlux today\u2014an interesting open-source package that wants to simplify the use of molecular predictive modeling. The package covers:\n\n\ud83d\uddc2\ufe0f Datasets: Access and handle data effortlessly.\n\ud83c\udf08 Features: Compute and extract features for insightful model training.\n\ud83d\udd00 Splits: Partition data effectively for robust model evaluation.\n\ud83e\udd16 Modelzoo: Efficiently handle and train models.\n\ud83d\udcc8 Metrics: Compute comprehensive metrics for model performance.\n\nMolFlux's Key Features:\n\ud83d\udd04 Standard API: Unifying principle for consistent model usage.\n\ud83c\udf10 Modular Design: Flexibility without overwhelming users.\n\ud83d\udd17 Smooth Interaction: Seamless workflow in building machine learning models.\n\n\ud83d\udce6 GitHub: https:\/\/lnkd.in\/dMUhM739\n\ud83d\udd17 Documentation: https:\/\/lnkd.in\/dXPErVeY\n \n#MolecularModeling #MachineLearning #OpenSource #DataScience #PythonPackage #PolyModelsHub","linkedinURL":"https:\/\/www.linkedin.com\/feed\/update\/urn:li:activity:7152992916083269633","githubURL":null,"paperURL":null,"author":"Antonio Benedetti","createdDate":"01\/16\/2024"},{"title":"The title is: Surrogate Modeling Made Easy: the Open-Source Surrogate Modeling Toolbox","description":"\u23e9 Surrogate Modeling Made Easy: the Open-Source Surrogate Modeling Toolbox \ud83d\udee0 \ud83d\udc0d \n\nSurrogate modeling involves the creation of simplified approximations for intricate mathematical models, providing a practical means to swiftly analyze and predict system behavior without the computational burden of the original model.\n\n\ud83d\udce6 The Surrogate Modeling Toolbox (SMT) emerges as a Python open-source gem, offering a rich collection of surrogate modeling methods, sampling techniques, and benchmarking functions. With a user-friendly design, it not only simplifies the utilization of existing surrogate models but also encourages the seamless implementation of new methods.\n\nKey Insights:\n\ud83d\udd0d Differentiation Emphasis: What sets SMT apart is its unique focus on derivatives. This includes training derivatives for gradient-enhanced modeling, prediction derivatives, and derivatives concerning the training data. \n\ud83c\udf10 Novel Models: SMT introduces novel surrogate models not found elsewhere, including kriging by partial-least squares reduction and energy-minimizing spline interpolation. \n\ud83d\udcda Documentation Excellence: SMT stands out with its well-documented structure. Custom tools embedded within the documentation process ensure automatically-tested code and dynamically-generated plots. \n\n\ud83d\udce6 GitHub: https:\/\/lnkd.in\/eC59icm\n\ud83d\udd17 Documentation: https:\/\/lnkd.in\/dAKpwCNg\n\ud83d\udcda Publication: https:\/\/lnkd.in\/e-K-7qF2\n\n#SurrogateModeling #PythonPackage #DerivativeEmphasis #NovelModels #DocumentationExcellence \ud83d\ude80 ","linkedinURL":"https:\/\/www.linkedin.com\/feed\/update\/urn:li:activity:7152630511478177793","githubURL":null,"paperURL":null,"author":"Antonio Benedetti","createdDate":"01\/14\/2024"},{"title":"The title is: Unlocking Efficiency: Iterative Real-Time Optimization in Reductive Amination.","description":" \ud83c\udfaf Unlocking Efficiency: Iterative Real-Time Optimization in Reductive Amination \ud83d\udcbb  \n\nReal-time optimization (RTO) in processing plants holds the key to enhancing economic and environmental performance. Anwesh Reddy Gottu Mukkula, Tim Riemer, Alexander K\u00fchl, Dieter Vogt, and Sebastian Engell delve into the practical application of RTO, specifically in the complex realm of a reductive amination process within a thermomorphic multiphase system.\n\n\ud83d\udcc8 Real-time optimization in processing plants aims to maximize economic and environmental performance by adjusting set-points or batch trajectories. However, the challenge lies in imperfect mathematical plant models, leading to discrepancies between computed and actual optimums. \n\nKey Insights:\n\ud83d\udd0d Algorithmic Innovations: The paper combines recent algorithmic innovations to achieve rapid and smooth convergence to the optimum. This includes an iterative real-time optimization method\u2014modifier adaptation with quadratic approximation.\n\ud83c\udf3f Model Uncertainty Management: The study focuses on online optimization of a reductive amination process, acknowledging and tackling model uncertainty. The iterative real-time optimization method employs modifier adaptation to correct the optimization problem, ensuring convergence to the true plant optimum.\n\u2699\ufe0f Undesired Input Oscillations: By guaranteeing model adequacy in Model Adequacy with Quadratic Approximation (MAWQA), the research team successfully avoids undesired input oscillations. This contributes to the method's applicability at an industrial scale, where medium-quality models prove sufficient for RTO.\n\ud83d\udcca Experimental Validation: The experimental results highlight the effectiveness of the approach, showcasing a smooth convergence to the process optimum in the presence of model uncertainty.\n\n\ud83d\udcda Link to Publication: https:\/\/lnkd.in\/dz8_JwNU\n\n#ChemicalEngineering #RealTimeOptimization #ReductiveAmination #AlgorithmicInnovations #ModelUncertainty #ProcessOptimization","linkedinURL":"https:\/\/www.linkedin.com\/feed\/update\/urn:li:activity:7152280826003496961","githubURL":null,"paperURL":null,"author":"Antonio Benedetti","createdDate":"01\/14\/2024"},{"title":"The title is: Navigating Model Uncertainty: A Deep Dive into Uncertainty Analysis Methods","description":"\ud83d\udc40  Navigating Model Uncertainty: A Deep Dive into Uncertainty Analysis Methods \ud83d\ude46\u200d\u2642\ufe0f  \n\nUnderstanding the reliability of model predictions hinges on a thorough exploration of model parameter uncertainty. Haiting Wang, Eduardo Iraola de Acevedo, Cleo Kontoravdi, and Ehecatl Antonio del Rio Chanona shed light on various uncertainty analysis methods in this enlightening chapter.\n\nKey Insights:\n\ud83d\udcca Chemical Engineering Focus: A comprehensive exploration of uncertainty analysis methods with a special emphasis on their applications and implications in chemical engineering.\n\ud83d\udd04 Frequentist vs Bayesian Approaches: Delving into two schools of thought in uncertainty quantification, comparing the widely used frequentist approaches with intuitive constructions of confidence intervals, and ellipsoids for parameter pairs. However, the chapter cautions about their limitations in high dimensions.\n\ud83c\udf10 Bayesian Sampling for Chemical Models: Introducing advanced Bayesian sampling methods like Markov chain Monte Carlo, offering superior performance in handling complex, nonlinear chemical engineering models. This approach unveils the nonlinear relationships between kinetic parameters, though it comes with a higher computational cost.\n\n\ud83d\udcda Link to Book Chapter: https:\/\/lnkd.in\/dPcMgtBe\n\n#ChemicalEngineering #UncertaintyAnalysis #BayesianApproaches #ChemicalProcessModeling #ModelUncertainty","linkedinURL":"https:\/\/www.linkedin.com\/feed\/update\/urn:li:activity:7151951491635851264","githubURL":null,"paperURL":null,"author":"Antonio Benedetti","createdDate":"01\/13\/2024"},{"title":"The title is: Optimizing Energy and Performance Metrics in Pharmaceutical Manufacturing","description":"\ud83d\ude80 Optimizing Energy and Performance Metrics in Pharmaceutical Manufacturing \ud83d\udc8a\ud83d\udc8a\ud83d\udc8a\n\n\ud83c\udf3f\u00a0In pharmaceutical manufacturing, maintaining critical quality attributes within specific ranges is essential for product performance. However, integrating sustainability practices remains underreported. \n\n\ud83c\udfaf Building upon a comprehensive modeling and techno-economic analysis framework previously crafted by Sampat et al. in 2022, this study introduces a combined sensitivity analysis and optimization approach. The aim is to reduce energy consumption, uphold product quality, and meet operational constraints within pharmaceutical processes.\n\nKey Insights:\n\ud83d\udcc8 Developed a sensitivity analysis and optimization approach using an integrated modeling and techno-economic analysis framework.\n\ud83c\udf0d Minimized energy consumption while preserving product quality and meeting operational constraints.\n\ud83d\udcca Validated optimal input conditions against experiments, showing good agreement between simulated and experimental data.\n\ud83d\udcb0 Compared costs for batch and continuous manufacturing under nominal and optimized conditions.\n\ud83d\udd04 Achieved a 71.7% reduction in energy consumption for optimized batch operations and an 83.3% energy saving for optimized continuous manufacturing.\n\n\ud83d\udcda Link to Publication: https:\/\/lnkd.in\/drffVgbs\n\n#PharmaceuticalEngineering #SustainabilityInPharma #Optimization #EnergyEfficiency #ContinuousManufacturing \ud83c\udf31\n","linkedinURL":"https:\/\/www.linkedin.com\/feed\/update\/urn:li:activity:7151600423689187328","githubURL":null,"paperURL":null,"author":"Antonio Benedetti","createdDate":"01\/12\/2024"},{"title":"The title is: Multi-objective Bayesian Optimization to Optimize Conditions for Green Amide Bond Formation.","description":"\ud83e\udd16 Multi-objective Bayesian Optimisation\u00a0to Optimize Conditions for Green Amide Bond Formation\ud83e\uddea\n\nAmide bond formation is integral to pharmaceutical processes, with the Schotten\u2013Baumann reaction holding promise for green amide synthesis. Challenges arise, particularly in the presence of water, leading to undesired hydrolysis and the formation of multiphase systems. \n\n\ud83d\ude80 This study investigates the Schotten\u2013Baumann reaction in continuous flow, optimizing it through a Bayesian algorithm employing the q-noisy expected hypervolume improvement (qNEHVI) acquisition function. \n\nKey Insights:\n\ud83c\udf10 Successfully addressed undesired hydrolysis challenges for greener amide formation.\n\ud83e\uddea Efficiently identified optimal solutions with the qNEHVI algorithm, revealing a Pareto front of possibilities.\n\ud83d\udd04 Compared reactions under flow and batch conditions, showcasing the effective suppression of undesired hydrolysis in continuous flow.\n\ud83d\udce6 Utilized Open-source BoTorch and Summit packages to compare TSEMO and qNEHVI algorithms \n\n\ud83c\udfd4 GitHub Summit: https:\/\/lnkd.in\/dVj2v_Rz\n\ud83d\udd25 GitHub BoTorch: https:\/\/lnkd.in\/d7sChS8z\n\ud83d\udcda Publication: https:\/\/lnkd.in\/dq5rMQZi\n\n#ChemicalEngineering #GreenChemistry #BayesianOptimization #AmideFormation #SchottenBaumann","linkedinURL":"https:\/\/www.linkedin.com\/feed\/update\/urn:li:activity:7151193879877201921","githubURL":null,"paperURL":null,"author":"Antonio Benedetti","createdDate":"01\/11\/2024"},{"title":"The title is: Advancing Molecular Simulations: Unveiling py-MCMD for Hybrid Monte Carlo\/Molecular Dynamics","description":"\ud83d\udd2c Advancing Molecular Simulations: Unveiling py-MCMD for Hybrid Monte Carlo\/Molecular Dynamics \ud83c\udf10\n\nEmbark on a journey into the realm of molecular simulations with py-MCMD, an open-source Python software developed by Mohammad Soroush Barhaghi, Brad Crawford , Gregory Schwing, David Hardy, John Stone, Loren Schwiebert, Jeffrey Potoff, and Emad Tajkhorshid. \n\n\ud83d\udce6 This robust software introduces a workflow layer that orchestrates seamless communication of critical system information between NAMD and GOMC simulation engines. The result? Coherent thermodynamic properties and trajectories ready for in-depth analysis.\n\n\ud83d\udd04 To showcase its prowess, py-MCMD orchestrates hybrid Monte Carlo\/molecular dynamics (MC\/MD) simulations for SPC\/E water in diverse ensembles, including isobaric\u2013isothermal (NPT) and grand canonical (GC). The simulations, validated against reference MC simulations, reveal computational efficiency gains ranging from 2 to a staggering 136 times compared to traditional Monte Carlo approaches.\n\n\ud83d\udca7 Delving into the specifics, simulations of water in a graphene slit pore demonstrate the remarkable sampling efficiency of the coupled\u2013decoupled configurational-bias MC (CD\u2013CBMC) algorithm. Equilibrium is reached with 25 times fewer cycles, showcasing a significant boost in efficiency with only a modest increase in computational cost.\n\n\ud83d\udcbc In a more intricate application, py-MCMD tackles hybrid grand canonical Monte Carlo\/molecular dynamics (GCMC\/MD) simulations, hydrating a buried binding pocket in bovine pancreatic trypsin inhibitor. The water occupancies align closely with crystallographically identified positions, highlighting a computational efficiency 5 times better than conventional MD simulations.\n\n\ud83d\ude80 Explore Our Hub!\nExciting news! We've just launched our\u00a0#Hub\u00a0at\u00a0PolyModelsHub.com, and we're eager to showcase exceptional packages like this one! If you've developed or discovered remarkable work, sign up, upload, or connect with us. With just a click, you can seamlessly link to your GitHub repository \ud83d\ude0a.\n\n \ud83d\udd17 Link to GitHub: https:\/\/lnkd.in\/d2j5Ka7W \n\ud83d\udcc4 Link to Publication: https:\/\/lnkd.in\/dGS4xmzF\n\n#MolecularSimulations #PythonSoftware #MCMD #MonteCarlo #MolecularDynamics #OpenSource \ud83c\udf10\ud83d\udd17","linkedinURL":"https:\/\/www.linkedin.com\/feed\/update\/urn:li:activity:7150818568371179520","githubURL":null,"paperURL":null,"author":"Antonio Benedetti","createdDate":"01\/08\/2024"},{"title":"The title is: Elevate Your Pharma Experience","description":"\ud83d\ude80 We just launched our brand new landing page! \ud83c\udf10\u2728 Explore the latest in our expanded range of services tailored for the Pharma industry at https:\/\/lnkd.in\/gM-TRds7.\n\n\ud83d\udd0d Dive into a world of possibilities and discover how we can elevate your Pharma experience. But wait, there's more! Don't miss out on exclusive insights and resources \u2013 sign up for our open-source sharing hub for FREE! \n\ud83d\udc8a\u2728\n\n#LifeScienceInnovation #PharmaInnovation #NewWebsiteLaunch  #OpenSourceHub #PharmaServices","linkedinURL":"https:\/\/www.linkedin.com\/feed\/update\/urn:li:activity:7150803462962720768","githubURL":null,"paperURL":null,"author":"Antonio Benedetti","createdDate":"01\/09\/2024"},{"title":"The title is: Improving Blending Performance using AI\/ML Approaches for Continuous Direct Compression.","description":"\ud83e\udd16 Improving Blending Performance using AI\/ML Approaches for Continuous Direct Compression (CDC) \ud83d\udd04\n\nUnlocking the potential of Artificial Intelligence and Machine Learning (AI\/ML), Owen Jones-Salkey, Kit Windows-Yule, Andrew Ingram, Lois Stahler, Andrei Leonard Nicusan, Sean Clifford, Luis Martin de Juan, & Gavin Reynolds just published an exciting study. The focus? Predicting blending performance and process sensitivity for Continuous Direct Compression (CDC).\n\n\ud83e\udde0 Through three AI\/ML tools, the study aims to predict fill levels in inclined linear blenders at steady state. This predictive approach relies on correlating a variety of bulk powder characteristics with processing parameters, specifically targeting the calculation of blade passes (strain) for improved content uniformity. The models, trained and introduced in the study, showcase distinct capabilities in predicting fill levels.\n\n\ud83c\udf10 Key features like RPM, Mixing Blade Region (MB) size, Wall Friction Angle (WFA), and Feed Rate (FR) are identified collectively by the models. The study utilizes Random Forest Regression, an algorithm constructing decision trees, for data interpretation.\n\n\ud83d\udcca A novel tool incorporating smart optimization and symbolic regression contributes to modeling complex systems into simple, closed-form equations, offering an accurate reduced-order model. In the realm of AI\/ML, an Artificial Neural Network (ANN) emerges as a reliable fill level predictor.\n\n\ud83d\udd2cImportantly, the study leverages several open-source libraries such as PyTorch, OpTuna, SHAP, and MED, emphasizing the role that open-source modelling can have on innovative approaches like this one.\n\n\ud83d\ude80 Explore Our Hub!\nExciting news! We've recently launched our\u00a0#Hub\u00a0at\u00a0PolyModelsHub.com, and we're eager to showcase exceptional packages like this one! If you've developed or discovered remarkable work, sign up, upload, or connect with us. With just a click, you can seamlessly link to your GitHub repository \ud83d\ude0a.\n\n\ud83d\udcda Link to Publication: https:\/\/lnkd.in\/da22wvXf\n\n#AIInPharmaceuticals #MachineLearning #ContinuousDirectCompression #BlendingPerformance #PharmaceuticalFormulation \ud83d\udd0d\ud83c\udf10","linkedinURL":"https:\/\/www.linkedin.com\/feed\/update\/urn:li:activity:7150448404085608448","githubURL":null,"paperURL":null,"author":"Antonio Benedetti","createdDate":"01\/09\/2024"},{"title":"The title is: Chemotools","description":"\ud83d\udd0d Learning more about Chemotools: Run Your Spectral Data Analysis with Python! \ud83d\udc0d \n\n\ud83d\udce2 Calling all Python enthusiasts engaged in spectral data work! Join this upcoming webinar organized by Rasmus Bro next week. Pau Caba\u00f1eros L\u00f3pez will take a deep dive into #Chemotools, a great Python spectral data analysis tool he meticulously crafted. This tool is tailored to empower Process Analytical Technology (PAT) scientists and chemometricians dealing with spectral data.\n\nBenefits of #Chemotools:\n\u2728 Preprocessing: Offers tools for effective spectral manipulation, including baseline correction, smoothing, scaling, derivatization, and scattering correction.\n\ud83e\udde9 Modular Design: Highly modular and user-friendly, seamlessly integrates with Scikit-learn transformers.\n\ud83d\udce6 Open Source: Embrace collaboration! Open source and available on PyPI.\n\nApplications of #Chemotools:\n\ud83e\uddec Scientific Exploration: Ideal for detailed analysis and processing of spectral data in diverse fields like chemistry and biology.\n\ud83e\udd16 Machine Learning: Build robust ML models, predicting properties or classifying samples based on intricate spectral data.\n\ud83c\udf93 Education: An invaluable tool for teaching and learning about chemometrics and data preprocessing in Python.\n\n\ud83d\ude80 Explore Our Hub!\nExciting news! We've just launched our\u00a0#Hub\u00a0at\u00a0PolyModelsHub.com, and we're eager to showcase exceptional packages like this one! If you've developed or discovered remarkable work, sign up, upload, or connect with us. With just a click, you can seamlessly link to your GitHub repository \ud83d\ude0a.\n\n\ud83d\udcc5 Link to Event: https:\/\/lnkd.in\/dScthnX2\n\ud83d\udd17 Link to Github: https:\/\/lnkd.in\/eMiMJZM8\n\n#Chemotools #PythonPackage #Chemometrics #SpectralDataAnalysis #OpenSourceScience \ud83c\udf10\ud83e\uddea","linkedinURL":"https:\/\/www.linkedin.com\/feed\/update\/urn:li:activity:7150091589984444416","githubURL":null,"paperURL":null,"author":"Antonio Benedetti","createdDate":"01\/08\/2024"},{"title":"The title is: Event-Driven Data Management for Materials Acceleration Platforms: A Paradigm Shift","description":"\ud83c\udf10 Innovating Materials Acceleration Platform: A Dive into Event-Driven Data Management \ud83d\ude80\n\nIn the dynamic field of materials research, automation and artificial intelligence (AI) are becoming catalysts for accelerated development. Michael Statt, Brian Rohr, Dan Guevarra, Santosh S., and John Gregoire explore the paradigm shift with Event-Driven Data Management, offering a glimpse into the future of materials acceleration platforms (MAPs).\n\n\ud83d\udee0\ufe0f A typical MAP encompasses a range of experimental techniques, creating a synthesis-characterization-evaluation workflow. With advancements in workflow orchestration and AI experiment design, MAPs are evolving in scope and complexity.\n\n\ud83d\ude80 However, each MAP traditionally functions as an independent entity, with dedicated experiment, compute, and database resources. This siloed approach often hinders seamless data integration until later efforts attempt to merge it into complex schemas like knowledge graphs.\n\n\ud83d\udd17 To overcome these challenges and establish a collaborative community of MAPs, the focus must extend to decoupling data handling from individual MAP resources.\n\n\ud83d\udcbb Enter event-driven pipelines\u2014a proven approach in the computational community for building decoupled data processing systems. While implementing such pipelines can be intricate, cloud services offer a lifeline.\n\n\ud83d\udd17 Link to Publication: https:\/\/lnkd.in\/e3-ZZkXr\n\n#MaterialsAcceleration #EventDrivenDataManagement #CloudComputing #AutomationInResearch #AIInMaterialsScience \ud83c\udf10\ud83d\udd2c","linkedinURL":"https:\/\/www.linkedin.com\/feed\/update\/urn:li:activity:7149748624787247105","githubURL":null,"paperURL":null,"author":"Antonio Benedetti","createdDate":"01\/07\/2024"},{"title":"The title is: Extensive Review on the Status of Quality-by-Design for Pharmaceutical Development","description":"\ud83c\udfaf Extensive Review on the Status of Quality-by-Design for Pharmaceutical Development\ud83e\uddea\n\nIn the ever-evolving landscape of the pharmaceutical industry, quality assurance remains a persistent challenge. In this paper, Ana Isabel Sim\u00f5es , Francisco Veiga, and Carla Vitorino extensively review the status of the Quality by Design (QbD) paradigm implementation\u2014a systematic methodology that has reshaped pharmaceutical quality.\n\n\ud83d\udca1 While QbD has become a cornerstone strategy, its roots lie in addressing longstanding challenges. Over the years, the pharmaceutical industry has embraced QbD as a systematic, scientific, and risk-based approach to enhance the development of high-quality drug products.\n\n\ud83d\udcc8 QbD is not just a concept but a dynamic strategy designed to maximize efficiency, saving time and costs throughout the drug development process. This approach demands an in-depth understanding of formulation and manufacturing processes, ensuring optimization of safety, efficacy, and quality at every development stage.\n\n\ud83d\ude80 Despite the undeniable advantages of the QbD approach and the widespread information on QbD regulatory expectations, its full implementation in the pharmaceutical field is still a work in progress. The review provides a crosswise overview of the current application status of QbD within the framework of ICH guidelines (ICH Q8(R2) - Q14 and ICH Q2(R2).\n\n\ud83d\udd17 Link to Publication: https:\/\/lnkd.in\/dyc367qB\n\n#PharmaceuticalDevelopment #QualityAssurance #QbD #ICHGuidelines #RnDInnovation \ud83c\udf10\ud83d\udc8a","linkedinURL":"https:\/\/www.linkedin.com\/feed\/update\/urn:li:activity:7149434870350471168","githubURL":null,"paperURL":null,"author":"Antonio Benedetti","createdDate":"01\/06\/2024"},{"title":"The title is: Advancing Drug Delivery: A Practical Exploration of Data-Driven Design in Oral Lipid-Based Nanoparticles","description":"\ud83c\udf10 Advancing Drug Delivery: A Practical Exploration of Data-Driven Design in Oral Lipid-Based Nanoparticles \ud83e\uddea\n\nOral drug administration remains a cost-effective and patient-preferred method, yet the effective delivery of hydrophobic drugs faces challenges like limited water solubility. To address these hurdles, Zeqing Bao, Fion Yung, Riley Hickman, Al\u00e1n Aspuru-Guzik, Pauric Bannigan, and Dr. Christine Allen employ solid lipid nanoparticles (SLNs) and nanostructured lipid carriers (NLCs) for enhanced bioavailability.\n\n\ud83d\udca1 Traditional design approaches often grapple with complexities within a narrow design space. In response, the authors introduce a pragmatic data-driven approach, focusing on cannabidiol as a model hydrophobic drug. This method combines experimental automation and machine learning for efficiency.\n\n\ud83d\udc8a  A select subset of formulations, just 10% of the design space, is meticulously prepared using miniaturized experimental automation, optimizing throughput and minimizing resource use. Machine learning models are then trained on this data, predicting properties for all SLNs\/NLCs within the extensive design space.\n\n\ud83d\udcca Results are compelling. High-performing formulations identified through this data-driven approach significantly enhance drug solubility, preventing degradation. Importantly, these formulations elevate the oral bioavailability of the drug compared to its free form and an over-the-counter version. This bioavailability closely matches that of an FDA-approved product, Epidiolex\u00ae.\n\n\ud83d\ude80 Explore Our Hub!\nExciting news! We've just launched our\u00a0#Hub\u00a0at\u00a0PolyModelsHub.com, and we're eager to showcase exceptional packages like this one! If you've developed or discovered remarkable work, sign up, upload, or connect with us. With just a click, you can seamlessly link to your GitHub repository \ud83d\ude0a.\n\n\ud83d\udd17 Link to Publication: https:\/\/lnkd.in\/dGdhj3A3\n\n#DrugDelivery #PharmaceuticalResearch #DataDrivenDesign #LipidNanoparticles #BioavailabilityEnhancement \ud83c\udf10\ud83e\uddf4","linkedinURL":"https:\/\/www.linkedin.com\/feed\/update\/urn:li:activity:7149026797920182272","githubURL":null,"paperURL":null,"author":"Antonio Benedetti","createdDate":"01\/05\/2024"},{"title":"The title is: Navigating Nitrosamine Risks: Insights from Automated Experimental and Kinetic Modeling Studies","description":"\ud83d\udc8a  Navigating Nitrosamine Risks: Insights from Automated Experimental and Kinetic Modeling Studies \ud83e\uddea\n\nIn response to the discovery of dialkyl N-nitrosamines in certain drug substances and products, healthcare marketing authorization holders are intensifying risk assessment efforts. A pivotal contribution to this ongoing endeavor is the kinetic modeling of the reaction between secondary amines and nitrite ions in aqueous solutions, shedding light on conditions that elevate the risk of N-nitrosamine formation.\n\n\ud83d\udd0d Samir Diab, Andrew Dominey, Paola Ferrini, John Hayler, Stephen H., Mike Urquhart, Mat Whiting, and James Wickens present an extensive study centered around di-n-butylamine, showcasing automated experimental nitrosation studies. The study emphasizes the conservative nature of the modeling approach, underlining that N-nitrosamine formation becomes a significant risk only at pH < 6 and higher concentrations of nitrite.\n\n\ud83d\udca1 The authors delve into kinetic modeling, incorporating an updated treatment of temperature dependence, and further experimentation on di-n-butylamine, solidifying the validity of their approach. \n\n\ud83d\udcbb The scope extends to the exploration of N-nitrosamine formation from tertiary amines, traditionally considered less susceptible to nitrosation due to the involved dealkylative step. Notably, a 2 orders of magnitude reduction in the rate of N-nitrosodibutylamine formation from tributylamine compared to di-n-butylamine is revealed for the considered pH, nitrite, and amine concentrations.\n\n\ud83d\udd17 Link to Publication: https:\/\/lnkd.in\/dEjr5HHS\n\n#NitrosamineFormation #KineticModeling #AutomatedExperimentalStudies #AqueousSolutionChemistry #HealthcareSafety \ud83c\udf10\ud83e\uddea","linkedinURL":"https:\/\/www.linkedin.com\/feed\/update\/urn:li:activity:7148659974490042369","githubURL":null,"paperURL":null,"author":"Antonio Benedetti","createdDate":"01\/04\/2024"},{"title":"The title is: Streamlining Kinetic Model Identification with #HoliMI : A Holistic Python Package leveraging MBDoE","description":"\ud83c\udf10 Streamlining Kinetic Model Identification with #HoliMI : A Holistic Python Package leveraging MBDoE  \ud83d\udc0d\n\nNavigating the complexity of kinetic model discrimination demands not just efficiency but a strategic approach. In this great work, Maerthe Theresa Tillmann and Federico Galvanin introduce a holistic Python package that optimize the selection of experimental design criteria, a crucial step in the kinetic model identification process.\n\n\ud83e\udde0 Starting with a candidate set of kinetic models, the package unleashes the power of Model-Based Design of Experiment (MBDoE) techniques. These techniques go beyond conventional approaches, determining experimental conditions with minimal runs to specify both model structure and corresponding parameters. Yet, the challenge lies in practicality\u2014defining optimal settings, criteria, and selection methods for model discrimination while considering parametric uncertainty throughout the identification procedure.\n\n\ud83d\udcbb The authors present a robust Python package, named HoliMI, designed to tackle this task. HoliMI comprises MBDoE for model discrimination and subsequently extends to MBDoE for enhancing parameter precision. The package undergoes rigorous testing on in-silico experiments, focusing on the identification of a Baker\u2019s Yeast model.\n\n\ud83d\udcca The evaluation and comparison span two critical aspects: i) determining the total number of experiments required for kinetic model identification with different experimental design criteria, and ii) assessing the rate of correct model selections using diverse model selection methods.\n\n\ud83d\ude80 Explore Our Hub!\nExciting news! We've just launched our\u00a0#Hub\u00a0at\u00a0PolyModelsHub.com, and we're eager to showcase exceptional packages like this one! If you've developed or discovered remarkable work, sign up, upload, or connect with us. With just a click, you can seamlessly link to your GitHub repository \ud83d\ude0a.\n\n\ud83d\udd17 Link to GitHub: https:\/\/lnkd.in\/dbmPmYDz\n\ud83d\udcda Link to Publication: https:\/\/lnkd.in\/d47ShVGv\n\n#KineticModelIdentification #PythonPackage #ModelBasedDesign #ExperimentalDesignCriteria #ParameterPrecision \ud83c\udf10\ud83d\udc0d","linkedinURL":"https:\/\/www.linkedin.com\/feed\/update\/urn:li:activity:7148281888003055616","githubURL":null,"paperURL":null,"author":"Antonio Benedetti","createdDate":"01\/03\/2024"},{"title":"The title is: Exploring AI Capabilities: Agent-based Learning of Materials Datasets from Scientific Literature","description":"\ud83c\udf10 Exploring AI Capabilities: Agent-based Learning of Materials Datasets from Scientific Literature \ud83e\udde0\n\nThe landscape of materials discovery is evolving, driven by advancements in machine learning and artificial intelligence. Yet, the challenge persists\u2014structured experimental data remains elusive. The solution lies within the extensive scientific literature, a valuable resource waiting to be tapped. \n\n\ud83e\udd16 Meet Eunomia, the chemist AI agent developed by Mehrad Ansari and\u00a0Mohamad Moosavi, armed with the prowess of large language models (LLMs), designed to autonomously extract structured datasets from the rich tapestry of natural language text, spanning sentences, paragraphs, and comprehensive research articles.\n\n\ud83d\udca1 Eunomia goes beyond automation; it's a cognitive agent capable of planning and executing actions, drawing on decades of scientific research, insights from scientists, online repositories, and various tools. In a quest to overcome challenges in quality maintenance, consistency, scalability, and human error, Eunomia benchmarks its performance across three information extraction tasks\u2014solid-state impurity doping, metal-organic framework (MOF) chemical formula, and property relations.\n\n\ud83d\ude80 Explore Our Hub!\nExciting news! We've just launched our\u00a0#Hub\u00a0at PolyModelsHub.com, and we're eager to showcase exceptional packages like this one! If you've developed or discovered remarkable work, sign up, upload, or connect with us. With just a click, you can seamlessly link to your GitHub repository \ud83d\ude0a.\n\n\ud83d\udd17 Link to GitHub: https:\/\/lnkd.in\/dFnU4Cj3\n\ud83d\udcbb Link to Live App: https:\/\/lnkd.in\/gN-2Vnzw\n\ud83d\udcc4 Link to Preprint: https:\/\/lnkd.in\/dyK5EvPw\n\n#MaterialsDiscovery #AIInnovation #NaturalLanguageProcessing #ChemistAIAgent #MachineLearningDatasets \ud83c\udf10\ud83e\uddea","linkedinURL":"https:\/\/www.linkedin.com\/feed\/update\/urn:li:activity:7148031412258992128","githubURL":null,"paperURL":null,"author":"Antonio Benedetti","createdDate":"01\/02\/2024"},{"title":"The title is: Happy New Year, Polymodelers!","description":"\ud83c\udf86 Happy New Year, Polymodelers! \ud83e\udd42 \n\n\ud83d\ude80Reflecting on the past year, our journey from the inception of this page just over a year ago has been nothing short of exciting. The growth of our community, now reaching 4.5K members, surpassed our wildest expectations.\n\n\ud83d\udcda\ud83d\udca1 Throughout 2023, we shared over 300 scientific publications focusing on modeling for life sciences, discovered and disseminated more than 150 open-source modeling packages, and proudly unveiled our open-source sharing Hub to advance this space even more.\n\n\ud83e\udd1d\ud83d\udcac But the real highlight was engaging with many of you at conferences, events, video calls and even casual pub gatherings. Your enthusiasm fueled our commitment to PolyModels Hub, pushing us beyond our initial vision.\n\n\ud83c\udf10\ud83d\udd0d PolyModels Hub was conceived to ignite the open-source modeling community in the life sciences, and 2024 promises even more excitement. We're set to expand our hub, introduce thrilling new features, and unveil our long-awaited open-source libraries.\n\n\u2699\ufe0f\ud83d\udd27 In our discussions with you and our experiences in the Pharma space, we recognized common challenges faced when integrating modeling and digital design into pharmaceutical process development. This realization prompted extensive behind-the-scenes efforts in the latter half of 2023.\n\n\ud83d\udc8a\ud83d\udcbb Now, as we step into 2024, we are thrilled to announce a pivotal development \u2013 PolyModels Hub is officially evolving into a startup! With a dedicated business arm, our goal is to provide modeling services and products to the pharmaceutical industry. Our mission is clear: to help companies accelerate innovation in pharmaceutical development by leveraging the best digital design tools available, both open-source and proprietary. We aim to empower companies to launch medicines faster, reducing costs and enhancing the quality of their products. \n\nExciting announcements lie ahead, but for now, we extend a heartfelt thank you and wish you an incredible 2024! Stay tuned for more updates! \ud83d\ude09 ","linkedinURL":"https:\/\/www.linkedin.com\/feed\/update\/urn:li:activity:7147628907146473472","githubURL":null,"paperURL":null,"author":"Antonio Benedetti","createdDate":"01\/01\/2024"},{"title":"The title is: Navigating Operational Challenges: The Essence of Feasibility\/Flexibility-based optimization in Process Design and Operations","description":"\ud83c\udf10 Navigating Operational Challenges: The Essence of Feasibility\/Flexibility-based optimization in Process Design and Operations \ud83d\udcd0 \n\nIn the ever-evolving landscape of the process industry, operational flexibility emerges as a cornerstone, responding to dynamic markets, heightened demand for customization, and increasingly stringent safety and environmental regulations. \n\n\ud83c\udfaf Now, more than ever, this flexibility is crucial, particularly in industries like pharmaceutical manufacturing, where the Quality by Design (QbD) initiative by the FDA has spotlighted the significance of the design space\u2014a multidimensional realm ensuring quality through a strategic interplay of input variables and process parameters.\n\n\ud83d\udcc4 Huayu Tian, Jnana Sai Jagana, Qi Zhang, and Marianthi Ierapetritou shed light on the critical interplay of feasibility and flexibility in their insightful paper. As operational landscapes grapple with uncertainty and intricate constraints, the authors explore computational approaches and concepts designed to evaluate feasibility and flexibility, presenting a nuanced perspective on process design and operations optimization.\n\n\ud83d\udcbb The interconnection between flexibility analysis and robust optimization is emphasized, with outlined opportunities to explore synergies between these components. Real-world applications in pharmaceutical design and process scheduling serve as illustrative contexts to showcase the practical implementation of the presented methodologies.\n\n------\n\ud83d\ude80 Explore Our Hub!\nExciting news! Our #Hub is now live at PolyModelsHub.com, and we're thrilled to showcase exceptional packages like this one! If you're a developer or enthusiast with remarkable work, sign up, upload, or connect with us. With just a click, seamlessly link to your GitHub repository \ud83d\ude0a.\n------\n\n\ud83d\udd17 Link to Publication: https:\/\/lnkd.in\/ekBssstg \n\n#OperationalFlexibility #ProcessDesign #FeasibilityOptimization #FlexibilityAnalysis #PharmaceuticalManufacturing \ud83c\udf10\ud83c\udfed","linkedinURL":"https:\/\/www.linkedin.com\/feed\/update\/urn:li:activity:7146908358816526336","githubURL":null,"paperURL":null,"author":"Antonio Benedetti","createdDate":"12\/30\/2023"},{"title":"The title is: Thermo: An Open-Source Software for Thermodynamics and Phase Equilibrium","description":"\ud83c\udf21  Quick Access to Thermodynamics with Thermo: The Thermodynamics and Phase Equilibrium component of Chemical Engineering Design Library (ChEDL) \ud83d\udce6 \n\nThermodynamics remains a challenging field for many engineers. After introducing several open-source thermo packages, today, we want to shed light on Thermo, an open-source software crafted by Caleb Bell and contributors.\n\n\ud83d\ude80 Thermo caters to engineers, scientists, technicians, and those with curiosity about the thermodynamics models governing our universe. It serves as a helpful tool for retrieving chemical constants, calculating temperature and pressure-dependent properties, and navigating the complexities of chemical mixtures, all made possible through various models.\n\n\ud83d\udd0d Thermo is designed to run seamlessly on all operating systems that support Python. Its quick and free installation ensures accessibility. The aim is simplicity without compromising functionality\u2014a tool for everyone seeking a deeper understanding of the world.\n\n\ud83d\udca1 Thermo was developed to be easy to use while delivering robust functionality. Whether you're exploring chemical constants or delving into the properties of mixtures, Thermo offers a straightforward approach to acquiring valuable insights.\n\n------\n\ud83d\ude80 Explore Our Hub!\nExciting news! We've just launched our\u00a0#Hub\u00a0at\u00a0PolyModelsHub.com, and we're eager to showcase exceptional packages like this one! If you've developed or discovered remarkable work, sign up, upload, or connect with us. With just a click, you can seamlessly link to your GitHub repository \ud83d\ude0a.\n-----\n\n\ud83d\udd17 Link to GitHub: https:\/\/lnkd.in\/e3iJj8E8\n\n#ThermoSoftware #OpenSource #ChemicalEngineering #ScientificTool #ChemicalInsights \ud83c\udf10\ud83d\udd2c","linkedinURL":"https:\/\/www.linkedin.com\/feed\/update\/urn:li:activity:7146508961448357888","githubURL":null,"paperURL":null,"author":"Antonio Benedetti","createdDate":"12\/29\/2023"},{"title":"The title is: Autonomous Kinetic Model Identification: Smart Laboratory Platform for Methane Complete Oxidation","description":"\ud83d\udd0d Autonomous Kinetic Model Identification: Smart Laboratory Platform for Methane Complete Oxidation \ud83e\uddea\n\n\ud83c\udf84 After a short Xmas break, we are back with a very interesting piece of research to read during this holiday season. This research by Arun Pankajakshan, Solomon Bawa, Asterios Gavriilidis and Federico Galvanin integrates automation and feedback optimization within a smart laboratory platform, introducing an interesting novel approach for online kinetic model identification.\n\n\ud83e\udd16 In this innovative platform, automation and feedback optimization converge to enable the real-time identification of kinetic models. Model-based design of experiments methods takes center stage in the feedback optimization loop, orchestrating optimal experiments that swiftly generate the required data for rapid model validation.\n\n\ud83d\udd04 Witness the platform's online sequential decision-making prowess as it autonomously navigates through the selection of the most appropriate kinetic model structure. This is followed by precise parameter estimation, achieved by dynamically switching objective functions. The platform discriminates between competing models and minimizes parametric uncertainty, ensuring a robust identification process.\n\n\ud83d\udd2c Beyond identification, the platform is equipped with advanced data analysis methods that delve into the behavior of models within their uncertainty limits. This not only expedites model validation but also yields uncertainty-aware predictive models\u2014a valuable asset for model-based decision systems.\n\n\ud83c\udf10 The platform undergoes rigorous testing in a case study focused on the kinetic model identification of complete oxidation of methane on a Pd\/Al2O3 catalyst, employing a micro-packed bed reactor. Astoundingly, a suitable kinetic model with precise parameter estimation emerges after a mere 20 automated experiments, completed within a span of two days.\n\n------\n\ud83d\ude80 Explore Our Hub!\nExciting news! We've just launched our\u00a0#Hub\u00a0at\u00a0PolyModelsHub.com, and we're eager to showcase exceptional packages like this one! If you've developed or discovered remarkable work, sign up, upload, or connect with us. With just a click, you can seamlessly link to your GitHub repository \ud83d\ude0a.\n-----\n\n\ud83d\udcda Link to Publication: https:\/\/lnkd.in\/e-uEvfQr\n\n#KineticModelIdentification #SmartLaboratoryPlatform #AutomationInResearch #DataAnalysis #DecisionSystems \ud83c\udf10\ud83e\uddea","linkedinURL":"https:\/\/www.linkedin.com\/feed\/update\/urn:li:activity:7146151529215913984","githubURL":null,"paperURL":null,"author":"Antonio Benedetti","createdDate":"12\/28\/2023"},{"title":"The title is: \"Exciting Last-Minute Xmas Presents for our PolyModelers: Github Direct Integration!\"","description":"\u00a0\ud83c\udf81 Exciting Last-Minute Xmas Presents for our PolyModelers: Github Direct Integration!\ud83c\udf1f\n\nAs we wrap up an incredible year with your unwavering support, we wanted to make your holiday season even more special. In 2023, we launched PolyModels Hub with the vision of innovating and enhancing the management of the open-source modeling community in the life sciences.\n\n\ud83d\ude80 We are thrilled to announce a major enhancement: Direct API Integration with Github! \ud83c\udf89 Now, with just one click, you can seamlessly link your Github repository to a PolyModels Hub repository. No more hassles managing two different versions of your project! This integration empowers you to effortlessly showcase your work on both platforms.\n\n\ud83d\udc49 Take a break from the holiday feasts and spend a minute creating a new repo, linking it to your Github work\u2014it's that simple! \ud83d\uddb1\ufe0f We're eager to see the amazing projects you've been working on. We'll be reposting all the repos uploaded, encouraging our vibrant community to discover and celebrate your contributions.\n\n\ud83d\udd17 Discover this now at PolyModelsHub.com : https:\/\/lnkd.in\/gM-TRds7\n\nYour support has been the driving force behind PolyModels' success in 2023, and this integration is our way of saying thank you! Wishing you a joyous holiday season filled with creativity and collaboration. \ud83c\udf84\u2728 \n\n#PolyModelsHub #OpenSource #GithubIntegration #HappyHolidays","linkedinURL":"https:\/\/www.linkedin.com\/feed\/update\/urn:li:activity:7143978547357839361","githubURL":null,"paperURL":null,"author":"Antonio Benedetti","createdDate":"12\/22\/2023"},{"title":"The title is: BayBE: Enhancing Experimental Design with Bayesian Back End for Design of Experiments","description":"\ud83d\udd2c BayBE: Enhancing Experimental Design with Bayesian Back End for Design of Experiments \ud83e\uddea\n\nExplore the work of Martin Fitzner, Adrian \u0160o\u0161i\u0107, Alexander Hopp, and G. Alex Lee as they introduce BayBE\u2014a practical Bayesian Back End toolbox for Design of Experiments (DoE). BayBE serves as a versatile solution, with a specific focus on chemistry and materials science.\n\n\ud83d\udee0\ufe0f BayBE provides a comprehensive solution for smart, iterative experimentation, particularly catering to the fields of chemistry and materials science. It goes beyond the basics to enable a more systematic approach by offering intelligent recommendations for the next experiment, aiming for efficient and meaningful results.\n\n\ud83d\udd04 Traditional approaches to experiment design often rely on the experience and intuition of the experimenter, leading to variations across different labs. In addressing these challenges, BayBE also functions as an assistant for automated equipment, contributing to closed-loop self-driving laboratories.\n\n\ud83d\udd0d BayBE leverages artificial intelligence (AI) to address complex problems in experimental optimization campaigns. By utilizing AI, BayBE aims to reduce the time and resources required for experiments in research, product development, and operations. This collaborative initiative involves Merck Group, a science and technology company, and the Acceleration Consortium based at the University of Toronto, Canada.\n\n------\n\ud83d\ude80 Explore Our Hub!\nExciting news! We've just launched our\u00a0#Hub\u00a0at\u00a0PolyModelsHub.com, and we're eager to showcase exceptional packages like this one! If you've developed or discovered remarkable work, sign up, upload, or connect with us \ud83d\ude0a.\n-----\n\n\ud83c\udf10 Link to GitHub: https:\/\/lnkd.in\/eHHQEhsq\n\n#BayesianStatistics #ExperimentDesign #AIinResearch #SmartExperimentation #OpenSourceInitiative \ud83c\udf10\ud83d\udd2c","linkedinURL":"https:\/\/www.linkedin.com\/feed\/update\/urn:li:activity:7143616552699920385","githubURL":null,"paperURL":null,"author":"Antonio Benedetti","createdDate":"12\/21\/2023"},{"title":"The title is: Pervaporation Modelling and Simulation","description":"\ud83c\udf1f\ud83d\udcbb Pervaporation Modelling and Simulation \ud83d\udcbb\ud83c\udf1f\n\n\ud83d\udcda We recently came across an insightful paper titled \"Modeling and simulation of pervaporation (PV) separation for alcohol dehydration\" by Nada Mahdi Farhan, Salah Ibrahim, and Qusay Alsalhy. This study investigates the separation performance of commercial membranes.\n\n\ud83d\udd0d The research focuses on the dehydration of two alcohol-water systems, namely ethanol-water and isopropanol-water mixtures, both featuring an azeotropic point. The team conducted pervaporation process (PV) experiments and employed #mathematical modelling to gain insights into the membranes' applicability for alcohol dehydration.\n\n\ud83d\udcca A semi-empirical solution-diffusion transport model was developed, demonstrating excellent agreement with experimental values. The team utilized #UNIQUAC to predict the activity coefficient of nonideal alcohol-water systems in PVA membranes. Furthermore, the conventional driving force model was employed to model the transport of alcohol-water across the commercial polymeric membrane.\n\n\ud83d\udcc8 The study resulted in the development of diffusivity correlations for water and alcohol through PVA membranes. Notably, the correlations were found to be strongly influenced by feed water activity and feed temperature for swollen membranes (PVA). The permeation flux of water and alcohol through the PVA membranes was predicted using the mass transport model and diffusivity correlations, showing an agreement between experimental data and the predictive model. \ud83c\udfaf\ud83c\udfaf\n\n\ud83d\udc4f Kudos to the authors! \ud83d\udc4f\n\n\ud83d\udd17 Link to the article: https:\/\/lnkd.in\/eV9wcGe7\n\n#Pervaporation #MembraneTechnology #ChemicalEngineering","linkedinURL":"https:\/\/www.linkedin.com\/feed\/update\/urn:li:activity:7143343607570186241","githubURL":null,"paperURL":null,"author":"Harry Christodoulou","createdDate":"12\/20\/2023"},{"title":"The title is: pHbot: Automated pH Adjustment for Viscous Formulations through Physics-Informed Machine Learning","description":"\ud83e\udd16 pHbot: Automated pH Adjustment for Viscous Formulations through Physics-Informed Machine Learning \ud83e\uddea\n\nIn many industrial processes, pH adjustment is a critical but often challenging step, typically reliant on manual trial-and-error methods. This challenge becomes more complex when dealing with viscous liquid formulations, especially when using weak, polyprotic titrants like citric acid, known for their chelation and buffering effects.\n\n\ud83d\ude80Discover the great work of Aniket Chitre, Jayce Cheng, Sarfaraz Ahamed, Robert Querimit, Benchuan Zhu, Ke Wang, Long Wang, Kedar Hippalgaonkar, and Alexei Lapkin, as they introduce pHbot\u2014a self-driving robot designed to revolutionize the pH adjustment process for viscous formulations.\n\n\ud83e\udd16 pHbot stands out as a hybrid solution, seamlessly combining robotics with physics-informed machine learning. This innovative model facilitates automated titration, even with the complexities presented by weak-strong acid\/base pairs. The researchers developed specific automated mixing and cleaning protocols to address the high viscosities of these formulations, ensuring accurate and efficient pH adjustment.\n\n\ud83c\udfaf The pHbot consistently achieves the target pH within two to five iterations across 250 distinct formulations in lab-scale small-batch titrations (approximately 10 mL and 12 samples). Moreover, the research demonstrates the scalability of the hybrid algorithm, proving its effectiveness at ~25\u00d7 scale-up, offering promising implications for industrial processes.\n\n------\n\ud83d\ude80 Explore Our Hub!\nExciting news! We've just launched our #Hub at PolyModelsHub.com, and we're eager to showcase exceptional packages like this one! If you've developed or discovered remarkable work, sign up, upload, or connect with us \ud83d\ude0a.\n-----\n\n\ud83d\udd17 Link to Github: https:\/\/lnkd.in\/emdzftah\n\ud83c\udf10 Interactive Webapp: https:\/\/lnkd.in\/eKuKWD7C\n\ud83d\udcda Link to Publication: https:\/\/lnkd.in\/eiQggUcB\n\n#pHAdjustment #Robotics #MachineLearning #ViscousFormulations #AutomationInIndustry #OpenSourceResearch \ud83c\udf10\ud83e\udd16","linkedinURL":"https:\/\/www.linkedin.com\/feed\/update\/urn:li:activity:7142855742297931776","githubURL":null,"paperURL":null,"author":"Antonio Benedetti","createdDate":"12\/19\/2023"},{"title":"The title is: Understanding Flooding Detection in Extraction Columns: Convolutional Neural Networks vs. a White-Box Approach for Image-Based Soft Sensor Development.","description":"\ud83c\udf0a Understanding Flooding Detection in Extraction Columns: Convolutional neural networks vs. a white\u2010box approach for image\u2010based soft sensor development \ud83d\udcf8\n\nSolvent extraction with countercurrent flow stands out as a highly energy-efficient process among various thermal separation methods. Researchers Omar Bayomie, Rafael F.\u2009L. de Cerqueira, Laura Neuendorf, Iwan Kornijez, Samuel Kieling, Tim Henrik Sandermann, Keno Lammers, and Kockmann Norbert are taking a close look at a crucial point in the process: the flooding state.\n\n\ud83d\ude80  Solvent extraction near the flooding point is all about efficiency, especially in achieving the highest separation efficiency. However, it comes with a catch\u2014the flooding point represents the limit of the extraction process, where at least one phase stops flowing. Keeping an eye on this point with optical supervision helps maintain efficiency.\n\n\ud83d\udc41\ufe0f This study assesses two methods for spotting the unwanted flooding state, using images from a see-through extraction column. One method explores a feature-based space for straightforward feature extraction, while the other uses a feature-extraction pipeline with a practical Convolutional Neural Network (CNN) model for a more detailed image analysis.\n\n\ud83d\udd04  The study explores the analysis of inference times, showcasing the potential of both models as real-time tools. Whether going for a straightforward feature-based approach or opting for the practicality of a CNN, the research offers feasible options for identifying the flooding state during everyday operations.\n\n--------\n\ud83d\ude80 We just launched our\u00a0#Hub\u00a0at\u00a0PolyModelsHub.com (www.polymodelshub.com)\u00a0and we're eager to host great packages like this! If you've developed or come across remarkable work, sign up, upload, or get in touch with us \ud83d\ude0a\u00a0\n--------\n\n\ud83d\udd17 Link to GitHub: https:\/\/lnkd.in\/eyBK9qqS\n\ud83d\udcda Link to Publication: https:\/\/lnkd.in\/eGyBTHD6\n\n#SoftSensorDevelopment #MachineLearning #ImageRecognition #ExtractionColumns #RealTimeApplications #EnergyEfficiency \ud83c\udf10\ud83d\udcf8","linkedinURL":"https:\/\/www.linkedin.com\/feed\/update\/urn:li:activity:7142470156982644736","githubURL":null,"paperURL":null,"author":"Antonio Benedetti","createdDate":"12\/18\/2023"},{"title":"The title is: A Hybrid Modelling Framework: Machine Learning for Computationally Expensive Transient Models (DEM)","description":"\ud83e\udd16 A Hybrid Modelling Framework: Machine Learning for Computationally Expensive Transient Models (DEM) \ud83d\udcca\n\nTransient simulations of dynamic systems, driven by physics-based scientific computing tools, face practical limitations due to computational resource constraints and power availability. \n\n\ud83e\udde0In this study by Prashant Kumar, PhD, Kushal Sinha, PhD, Nandkishor Nere, Yujin Shin, Raimundo Ho, Laurie Mlinar, and Ahmad Sheikh , the authors delve into uncharted territory, exploring the untapped potential of machine learning in developing a framework for computationally expensive transient models.\n\n\ud83d\udd04 The authors explore the integration of the discrete element method with time-series forecasting through auto regressive integrated moving average (ARIMA) and cutting-edge machine learning techniques. This ensemble approach takes center stage in simulating a complex pharmaceutical step: the development of an agitation protocol in an agitated filter dryer to ensure uniform solid bed mixing.\n\n\u2699\ufe0f The magic unfolds as this ensemble approach orchestrates a significant reduction in computational burden, paving the way for practical simulations. The framework not only lightens the load but also preserves model accuracy and performance, making simulations not just a possibility but a reality.\n\n\ud83d\udcc8 The machine-learning model developed in this study goes beyond expectations, showcasing remarkable predictability and alignment with existing literature. The results underscore the tremendous potential of machine learning in scientific computing, offering a glimpse into the future of efficient and accurate simulations.\n\n--------\n\ud83d\ude80 We just launched our\u00a0#Hub\u00a0at Polymodelshub.com\u00a0www.polymodelshub.com\u00a0and we're eager to host great packages like this! If you've developed or come across remarkable work, sign up, upload, or get in touch with us \ud83d\ude0a\u00a0\n--------\n\n\ud83d\udd17 Link to GitHub: https:\/\/lnkd.in\/eYichFgs\n\ud83d\udcda Read the Full Publication: https:\/\/lnkd.in\/ez2ei88s \n\n#MachineLearning #ScientificComputing #TransientModels #EnsembleApproach #ComputationalEfficiency #SimulationInnovation \ud83c\udf10\ud83e\udd16","linkedinURL":"https:\/\/www.linkedin.com\/feed\/update\/urn:li:activity:7142145180064784385","githubURL":null,"paperURL":null,"author":"Antonio Benedetti","createdDate":"12\/17\/2023"},{"title":"The title is: Dataset Design: The Crucial Role in Developing Models for Chemical Reactivity.","description":"\ud83d\udd2c From Data to Model Predictions: The Crucial Role of Dataset Design! \u2697\ufe0f\n\nDataset design is the construction of experimental datasets with modeling applications in mind. Priyanka Raghavan, Brittany Haas, Madeline Ruos, Jules Schleinitz, Abigail Doyle, Sarah Reisman, Matt Sigman, and Connor W. Coley delve into the concept of dataset design, recognizing its pivotal role in developing models that encapsulate our understanding of chemical reactivity.\n\n\ud83d\udcca The discussion centers on the fundamental importance of training set composition. A well-crafted dataset serves as the foundation for models capable of making precise predictions across the entire domain of interest. The team emphasizes the critical interplay between training set diversity and model generalizability, shedding light on the nuanced choices in molecular or reaction representation that underpin effective data-driven modeling.\n\n\u2699\ufe0f The discourse extends to the experimental constraints inherent in generating chemistry datasets. The team navigates through considerations surrounding dataset design and model construction, aligning the methodology with the intricacies of common types of chemistry datasets.\n\n\ud83d\udd17 Link to Publication: https:\/\/lnkd.in\/ePfbjNEQ\n\n#ChemicalReactivity #DataDrivenModeling #DatasetDesign #ChemistryModels #ScientificResearch \ud83d\udcc8\ud83d\udd0d","linkedinURL":"https:\/\/www.linkedin.com\/feed\/update\/urn:li:activity:7141758867293569025","githubURL":null,"paperURL":null,"author":"Antonio Benedetti","createdDate":"12\/16\/2023"},{"title":"The title is: PiML Toolbox for Interpretable ML Model Development and Validation","description":"\ud83d\udd0d Exploring Interpretable ML: Introducing the PiML Toolbox! \ud83d\udee0\ufe0f\n\nInterpretable machine learning (IML) becomes increasingly important in highly regulated industry sectors related to the health and safety or fundamental rights of human beings. In general, the inherently IML models should be adopted because of their transparency and explainability, while black-box models with model-agnostic explainability can be more difficult to defend under regulatory scrutiny.\n\n\ud83d\udcbb In this context, the team of Agus Sudjianto, Aijun Zhang, Zebin Yang, Yu Su and Ningzhou Zeng presents PiML, a Python toolbox for interpretable ML model development and validation, catering to diverse needs through a blend of low-code simplicity and high-code flexibility.\n\n\ud83e\uddf0 PiML offers a versatile toolkit for interpretable machine learning, catering to various models such as GLM, GAM, Decision Trees, XGBoost, EBM, GAMI-Net, ReLU-DNN, and more. \n\n\u2699 It covers a spectrum of outcome testing metrics, including accuracy metrics for regression and binary classification, post-hoc global and local explainability tools, fairness assessments, weak spot identification, overfit analysis, reliability assessments, and robustness evaluations. \n\n\ud83d\udce6 This toolbox is a one-stop solution for developing, validating, and interpreting interpretable machine learning models. \n\n--------\n\ud83d\ude80 We just launched our\u00a0#Hub\u00a0at\u00a0\u00a0 and we're eager to host great packages like this! If you've developed or come across remarkable work, sign up, upload, or get in touch with us \ud83d\ude0a\u00a0\n--------\n\n\ud83d\udd17 Explore PiML on GitHub: https:\/\/lnkd.in\/gAAvkP_a\n\n#PiMLToolbox #InterpretableML #MachineLearning #ModelDevelopment #Python \ud83c\udf10\ud83e\udd16","linkedinURL":"https:\/\/www.linkedin.com\/feed\/update\/urn:li:activity:7141466433107992576","githubURL":null,"paperURL":null,"author":"Antonio Benedetti","createdDate":"12\/15\/2023"},{"title":"The title is: Digital design of an integrated purification system for continuous pharmaceutical manufacturing.","description":"\ud83d\udd2c Digital design of an integrated purification system for continuous pharmaceutical manufacturing \ud83e\uddea\n\nIn this great study, Inyoung Hur, Daniel Casas-Orozco, Ph.D., Daniel Laky, Francesco Destro, and Zoltan Nagy present a novel digital design framework for an integrated purification system tailored for continuous pharmaceutical manufacturing. \n\n\ud83d\udd0d The researchers developed dynamic models of the continuous crystallization, filtration, deliquoring, washing, and drying steps using the open-source package #PharmaPy. These comprehensive models capture the intricate dynamics of each unit operation, enabling accurate simulations and optimization of the integrated process.\n\n\ud83c\udf31 The proposed integrated purification system utilizes a two-stage crystallization and filtration-drying carousel, providing a highly efficient and scalable approach for product separation. The carousel design facilitates continuous operation, minimizing batch-to-batch variability and enhancing process robustness.\n\n\u2699\ufe0f The digital design framework optimizes operating conditions using advanced techniques, ensuring process consistency while meeting quality constraints. Robustness against modeling errors was demonstrated through sensitivity analyses.\n\n--------\n\ud83d\ude80 We just launched our\u00a0#Hub\u00a0at\u00a0PolyModelsHub.com\u00a0(https:\/\/lnkd.in\/gM-TRds7) and we're eager to host great packages like this! If you've developed or come across remarkable work, sign up, upload, or get in touch with us \ud83d\ude0a\u00a0\n--------\n\n \ud83d\udd17 Link to Github: https:\/\/lnkd.in\/e_3gFQmi\n\ud83d\udcda Link to Publication: https:\/\/lnkd.in\/eH3e4m7S\n\n#DigitalDesign #PharmaceuticalManufacturing #ContinuousProcessing #PurificationSystem #ProcessOptimization #ModelUncertainty \ud83c\udf10\ud83d\udd2c","linkedinURL":"https:\/\/www.linkedin.com\/feed\/update\/urn:li:activity:7141093311846453248","githubURL":null,"paperURL":null,"author":"Antonio Benedetti","createdDate":"12\/14\/2023"},{"title":"The title is: Symbolic Regression: A method for fitting adsorption isotherms","description":"\ud83c\udf1f Symbolic Regression: A method for fitting adsorption isotherms \ud83c\udf1f\n\n\ud83d\ude80 Unlocking the mysteries of adsorption processes is crucial for advancing chemical separations. The heart of this exploration lies in the isotherm, a pivotal element in understanding how species move from a bulk to a surface. While theoretical models traditionally fit isotherms, they occasionally fall short in capturing the complexity of certain cases.\n\n\ud83d\udd0d We recently stumbled upon an interesting study by Reza Haghpanah and Danny Shade titled \"Fitting Adsorption Isotherms with Symbolic Regression.\" This research introduces Symbolic Regression (SR) as a tool for fitting complex isotherm forms.\n\n\ud83c\udf0a In this work, it is demonstrated that SR (with no prior physical knowledge) can accurately fit models to experimental isotherms with one or more steps, including: adsorption of water vapor, cooperative adsorption of CO2, & adsorption on flexible adsorbents. \n\n\ud83d\udca1 The authors showcase the potential of Symbolic Regression in advancing our comprehension of adsorption phenomena. By successfully fitting challenging isotherm forms, SR is a tool for researchers grappling with poorly understood physics or demanding accuracy \ud83c\udfaf in model fits.\n\n\ud83c\udf89 Congratulations to the authors for their contribution! \ud83c\udf89\n\n\ud83d\udd17 Link to the publication: https:\/\/lnkd.in\/ea-KfT9A","linkedinURL":"https:\/\/www.linkedin.com\/feed\/update\/urn:li:activity:7140778286954999808","githubURL":null,"paperURL":null,"author":"Harry Christodoulou","createdDate":"12\/13\/2023"},{"title":"The title is: Diastereomer Salt Crystallization: Comprehensive Process Modeling and DoE-driven Comparison of Custom-Coded and User-Friendly Simulators","description":"\ud83d\udc8eCrystallization\ud83d\udc8e: Modeling & DoE-driven comparison of custom-coded vs user-friendly simulators \n\n\ud83d\ude80 Process modeling is revolutionizing the pharmaceutical industry by offering a pathway to explore the design space with reduced experimentation. However, the complexity of numerical tools often hinders wider adoption.\n\n\ud83d\udd0d We recently came across an article on the subject titled \"Diastereomer Salt Crystallization: Comprehensive Process Modeling and DoE-driven Comparison of Custom-Coded and User-Friendly Simulators\" authored by \u00c1lmos Orosz, Miklos Bosits, Eva Pusztai, Hajnalka Pataki, Zsofia Szalay, Adam Demeter, and Botond Szilagyi. \n\n\ud83d\udcca The paper navigates through steps of model development, from experimentation to kinetic model identification and in-silico crystallization DoE execution. The focus is on comparing a user-friendly (yet restrictive\/less customizable) simulator against a highly technical custom-coded environment.\n\n\ud83d\udcc8 The research underscores the capability of user-friendly simulators in time-sensitive scenarios, offering a practical solution for those \"deterred\" by the complexity of traditional coding and custom modelling tools. \n\nBy demonstrating equivalent outcomes in a real-world scenario, this study suggests the wider adoption of user-friendly interfaces in #pharma process #modelling.\n\n\ud83c\udf89 Kudos to the authors for their interesting contribution \ud83c\udf89\n\n\ud83d\udd17 Link to the Paper: https:\/\/lnkd.in\/eXuUagTi","linkedinURL":"https:\/\/www.linkedin.com\/feed\/update\/urn:li:activity:7140371806967750658","githubURL":null,"paperURL":null,"author":"Harry Christodoulou","createdDate":"12\/12\/2023"},{"title":"The title is: Reaction Monitoring: RIPPLY Real-TIme Parallel Progress AnaLYsis of Organic Reactions Using NIR","description":"\ud83d\udcc8  Reaction Monitoring: RIPPLY Real-TIme Parallel Progress AnaLYsis of Organic Reactions Using NIR \ud83e\uddea\n\nIn drug substance development, High-Throughput Experimentation (HTE) is gaining a predominant role. However, conventional HTE workflows often lack real-time monitoring of reaction progress, leaving a void in understanding kinetic regimes such as induction and deactivation. Enter RIPPLY\u2014a great tool by Robbert van Putten, Koen De Smet, and Laurent Lefort, introducing a parallel reaction monitoring technique for micromole-scale organic reactions.\n\n\ud83d\udd2c RIPPLY leverages near-infrared (NIR) spectroscopy and multivariate semi-NMF analysis (Non-negative Matrix Factorization) to provide qualitative reaction progress profiles or semiquantitative concentration profiles. Notably, this approach eliminates the need for time-consuming calibration, offering efficiency and accuracy in monitoring reactions.\n\n\ud83d\udd04 One of RIPPLY's strengths lies in the simultaneous analysis of parallel reactions, enhancing confidence in the black box multivariate analysis. This feature allows a direct comparison of predicted and measured final compositions, offering a holistic understanding of reaction dynamics.\n\n\ud83e\uddea The efficacy of RIPPLY is demonstrated through the successful monitoring of two test reactions. Intriguingly, this study not only showcased the power of RIPPLY but also led to the serendipitous identification of a new ketone transfer hydrogenation catalyst.\n\n\ud83d\udcc8RIPPLY goes beyond mere monitoring by enabling initial rate kinetics and Variable Time Normalization Analysis (VTNA) experiments. This capability provides a tangible workflow that can be at the basis of reaction kinetics modelling.\n\n--------\n\ud83d\ude80 We just launched our\u00a0#Hub\u00a0at\u00a0PolyModelsHub.com\u00a0(https:\/\/lnkd.in\/gM-TRds7) and we're eager to host great packages like this! If you've developed or come across remarkable work, sign up, upload, or get in touch with us \ud83d\ude0a\u00a0\n--------\n\n\ud83d\udd17 Link to Github: https:\/\/lnkd.in\/ewcfREHN \n\ud83d\udcda Link to Publication: https:\/\/lnkd.in\/e7GB2ARB \n\n#ReactionMonitoring #HighThroughputExperimentation #RIPPLY #OrganicReactions #Innovation  \ud83d\ude80\ud83d\udd0d","linkedinURL":"https:\/\/www.linkedin.com\/feed\/update\/urn:li:activity:7140065029462089728","githubURL":null,"paperURL":null,"author":"Antonio Benedetti","createdDate":"12\/11\/2023"},{"title":"The title is: Predicting Stability in Oral Antibody Therapeutics: Insights from Accelerated Stability Modeling!","description":"\ud83d\udcca Predicting Stability in Oral Antibody Therapeutics: Insights from Accelerated Stability Modeling! \u23f0 \n\nThe exploration of oral delivery for protein therapeutics comes with its share of advantages and challenges. However, a critical gap in knowledge surrounds the stability and shelf life of orally delivered proteins. A recent study by Lulu Dai, Jeff Davis, Karthik Nagapudi, Priscilla Mantik, Kelly Zhang, Jackson Pellett, and Bingchuan Wei addresses this gap by conducting a detailed assessment of the stability of an orally delivered solid dosage variable domain of heavy-chain antibody (VHH antibody) drug product.\n\n\ud83d\udd0d The study identifies four stability-related quality attributes undergoing transformation under thermal and humidity stress, offering a focused analysis on unraveling the intricacies of oral protein therapeutic stability.\n\n\ud83d\ude80 The team utilizes an accelerated stability modelling approach. Stability data undergo modeling using the modified Arrhenius equation, obtaining best-fit values for key parameters like A, Ea, and B. The study evaluates various fit methods, ensuring the selection of the most accurate method based on R2 and Q2 metrics.\n\n\ud83d\udcca The modeling process yields satisfactory model quality and accurate predictions regarding protein stability during storage. An important finding emerges\u2014protein aggregation, resulting from a specific degradation pathway, requires additional adjustments to the modeling method, enhancing the model's predictive capabilities.\n\n\ud83d\udd17 Link to Publication: https:\/\/lnkd.in\/eP6xQ-hp\n\n#ProteinTherapeutics #OralDelivery #StabilityAssessment #AcceleratedStability #DrugProduct \ud83d\ude80\ud83e\uddec","linkedinURL":"https:\/\/www.linkedin.com\/feed\/update\/urn:li:activity:7139609720830455808","githubURL":null,"paperURL":null,"author":"Antonio Benedetti","createdDate":"12\/10\/2023"},{"title":"The title is: Design of Dynamic Experiments (DoDE) for Modernising Cell Culture Process Development","description":"\u2699\ufe0f Design of Dynamic Experiments (DoDE) for Modernising Cell Culture Process Development \ud83e\udda0\n\nIn cell culture process development, traditional methods often rely on iterative, one-factor-at-a-time experiments, limiting our understanding of the vast process space. Traditional Design of Experiments (DoE) is often see as the most valuable approach to Quality-By-Design. However, the direct application of DoE to study time-varying process inputs poses challenges due to the impracticality of using an extensive number of large scale bioreactor runs.\n\n\ud83d\ude80 In this study by Yu Luo, Duane Stanton, Rachel Sharp, Alexis Parrillo, Kelsey Morgan, Diana Ritz and Sameer Talwar the methodology of Design of Dynamic Experiments (DoDE) takes center stage, seamlessly incorporating dynamic feeding profiles into late-stage process development for therapeutic monoclonal antibodies.\n\n\ud83d\udd04 Unlocking great insights, the study reveals that:\n1\ufe0f\u20e3 Dynamic Optimization: The team not only estimates the effect of nutrient feed amount on various product attributes but also delves into optimizing the slope of time-trended feed rates. The findings showcase tangible improvements in productivity, with a 27% increase in titer and\u2009>\u200992% viability in a 200-L batch compared to the baseline process without dynamic feeding.\n2\ufe0f\u20e3 Higher-Order Dynamics: Exploring higher-order dynamic characteristics of time-trended feed rates, the study discerns that while they can be incorporated in the design, they do not significantly impact the measured responses.\n\n\ud83d\udcca Armed with DoDE data, a statistical model is developed, serving as a powerful tool to optimize several process conditions. The successful application of DoDE marks a transformative step toward more efficient workflows in optimizing dynamic process conditions during process development.\n\n\ud83d\udd17 Link to Publication: https:\/\/lnkd.in\/gRB7M4SB\n\n#CellCulture #ProcessOptimization #DesignOfExperiments #DynamicExperiments \ud83d\ude80\ud83e\uddeb","linkedinURL":"https:\/\/www.linkedin.com\/feed\/update\/urn:li:activity:7139305984035885057","githubURL":null,"paperURL":null,"author":"Antonio Benedetti","createdDate":"12\/09\/2023"},{"title":"The title is: Navigating Complex Synthesis: Hybrid Modeling Unravels the Dynamics of Pharmaceutical Ingredient Flow Synthesis!","description":"\ud83c\udf00 Navigating Complex Synthesis: Hybrid Modeling Unravels the Dynamics of Pharmaceutical Ingredient Flow Synthesis! \ud83c\udf10\n\nCrafting an efficient synthesis for an active pharmaceutical ingredient (API) through a ring-opening reaction of an epoxide with a Grignard reagent poses unique challenges. The inherent complexities, including the reaction's rapid and highly exothermic nature, make traditional batch reactor experiments challenging for collecting kinetic data. In response, Junu Kim, Yusuke Hayashi, Sara Badr, Kazuya Okamoto, Toshikazu Hakogi, Haruo Furukawa, Satoshi Yoshikawa, Hayao Nakanishi, and Hirokazu Sugiyama pioneer a hybrid modeling approach to understand the intricacies of this pharmaceutical synthesis.\n\n\ud83d\ude80 Overcoming the limitations of batch reactors, the team conducts a flow experiment, manipulating parameters like inner diameter and temperature to gather crucial kinetic information. A one-dimensional flow mechanistic model is meticulously developed, evaluating two reaction mechanisms\u2014with the Swain and Boyles mechanism emerging as the superior choice over the Meisenheimer and Casper mechanism.\n\n\ud83d\udd0d Notably, the model addresses the impact of varying reactor inner diameters by adjusting the pre-exponential factor as a function of the Reynolds number. This pragmatic adjustment simplifies the modeling effort, offering a practical solution relative to developing two-dimensional models.\n\n\ud83c\udf0a The synthesis presents an additional challenge with the generation of impurities and an unclear underlying mechanism. To tackle this, a data-driven approach employing a random forest regression model is introduced, enabling accurate quantification of impurities even when the full understanding of reaction mechanisms is elusive.\n\n\ud83d\udcbb \ud83d\udcc8 The hybrid model, incorporating both mechanistic and data-driven components, not only deepens the understanding of the reaction but also enhances predictive capabilities. The partial differential equations were solved using the Crank\u2013Nicolson method in Python 3.7.11 for the mechanistic part, and the parameter values were computed using the Nelder\u2013Mead method from the Python scipy.optimize.minimize module. Confidence intervals were calculated using the Python lmfit minimization with the Levenberg\u2013Marquardt method. For the data-driven part, the Random Forest Regression Results were implemented in Python using scikit-learn.\n\n\ud83d\udd17  Link to Publication: https:\/\/lnkd.in\/e6ss6jUt\n\n#HybridModeling #PharmaceuticalSynthesis #FlowChemistry #ComputationalApproach \ud83c\udf00\ud83d\udd2c","linkedinURL":"https:\/\/www.linkedin.com\/feed\/update\/urn:li:activity:7138942755866578944","githubURL":null,"paperURL":null,"author":"Antonio Benedetti","createdDate":"12\/08\/2023"},{"title":"The title is: Reaction Optimization: Machine Learning Meets Ultra-Fast Flow Chemistry!","description":"\ud83d\udd0d Reaction Optimization: Machine Learning Meets Ultra-Fast Flow Chemistry! \ud83e\uddea\n\nUnlocking the ideal process parameters for ultra-fast reactions, such as lithium\u2013halogen exchange reactions, often involves time and resource-intensive methods like one-factor-at-a-time optimization (OFAT) or classical factorial design of experiments (DoE). In this study, Dogancan Karan, Guoying Chen, Nicholas Jose, Jiaru Bai, Paul McDaidd, and Alexei Lapkin introduce a novel approach by combining a machine learning workflow with a precision-controlled flow chemistry platform for the optimization of lithium\u2013halogen exchange reactions.\n\n\ud83d\ude80 The flow chemistry platform proves instrumental, offering precise control over critical process parameters\u2014temperature, residence time, and stoichiometry. This control facilitates robust data collection to train a machine learning algorithm, paving the way for a more efficient optimization process.\n\n\ud83d\udd2c The team employs the Bayesian multi-objective optimization algorithm TSEMO (Thompson Sampling Efficient Multi-Objective Optimization) to navigate the optimization landscape. TSEMO successfully identifies optimal conditions, considering the trade-off between yield and impurity across different optimization campaigns with varying mixing intensifications, such as capillary reactor vs. microchip reactor.\n\n\ud83d\udcca Beyond optimizing yields, the results and Gaussian process (GP) surrogate models within TSEMO are scrutinized to glean insights into the operating regime of the system under different mixing intensifications\u2014shedding light on the interplay between mixing and reaction control.\n\n\ud83c\udf1f The machine learning workflow proves its mettle, demonstrating robustness and data efficiency while uncovering nuanced information about the studied reactions compared to conventional approaches.\n\n\ud83d\udd17 Link to Publication: https:\/\/lnkd.in\/g6RXhRUc \n\n#ReactionOptimization #MachineLearning #FlowChemistry #ProcessInnovation \ud83d\ude80\ud83d\udd2c","linkedinURL":"https:\/\/www.linkedin.com\/feed\/update\/urn:li:activity:7138532727774998529","githubURL":null,"paperURL":null,"author":"Antonio Benedetti","createdDate":"12\/07\/2023"},{"title":"The title is: FitMultiCell\u2014A Scalable Pipeline for Multi-Scale Model Simulation and Parameterization","description":"\ud83e\uddec Empowering Systems Biology: FitMultiCell\u2014A Scalable Pipeline for Multi-Scale Model Simulation and Parameterization! \ud83e\udda0\n\nBiological tissues, intricate and dynamic, present a unique challenge for analysis and understanding. Multi-scale models stand as invaluable tools to unravel the complex processes governing tissue dynamics. These models rely on parameters derived from experimental data to achieve quantitative insights, predict responses to perturbations, and assess competing hypotheses. Yet, the computational complexity of simulating multi-scale models poses a formidable obstacle even for advanced inference methods like approximate Bayesian computation (ABC).\n\n\ud83d\udd27 In response to this challenge, Emad Alamoudi, Yannik Sch\u00e4lte, Robert M\u00fcller , J\u00f6rn Starru\u00df, Nils Bundgaard, Frederik Graw, Lutz Brusch, and Jan Hasenauer present FitMultiCell\u2014a computational powerhouse and user-friendly open-source pipeline designed to seamlessly handle the entire workflow of modeling, simulating, and parameterizing multi-scale models of multi-cellular processes.\n\n\ud83d\ude80 FitMultiCell's modular architecture integrates Morpheus for modeling and simulation and pyABC for statistical inference. Its user-friendly design facilitates efficient handling of computationally intensive tasks, ensuring scalability to address complex problems. Notably, the pipeline introduces a novel standard for formulating parameter inference problems in multi-scale models, enhancing reproducibility and reusability.\n\n\ud83c\udf10 By applying FitMultiCell to diverse biological problems, the authors showcase its broad applicability, particularly benefiting image-based systems biology.\n\n--------\n\ud83d\ude80 We just launched our\u00a0#Hub\u00a0at\u00a0PolyModelsHub.com\u00a0(https:\/\/lnkd.in\/gM-TRds7) and we're eager to host great packages like this! If you've developed or come across remarkable work, sign up, upload, or get in touch with us \ud83d\ude0a\u00a0\n--------\n\n\ud83d\udd17 Link to Open-source Code Repository:  https:\/\/lnkd.in\/eap_b7Sn\n\ud83d\udcda Link to Publication: https:\/\/lnkd.in\/ek8rt9mP\n\n#SystemsBiology #FitMultiCell #MultiScaleModels #ComputationalBiology \ud83d\ude80\ud83e\udda0","linkedinURL":"https:\/\/www.linkedin.com\/feed\/update\/urn:li:activity:7138172092142739456","githubURL":null,"paperURL":null,"author":"Antonio Benedetti","createdDate":"12\/06\/2023"},{"title":"The title is: Batch Crystallization Digital Twin: A Hybrid Approach with Time-Series Transformers","description":"\ud83d\udd04  Batch Crystallization Digital Twin: A Hybrid Approach with Time-Series Transformers! \u2744\ufe0f \n\nAs the industry treads cautiously regarding the direct implementation of black-box tools in critical processes due to safety and operational concerns, the adoption of fully data-driven deep-neural-network (DNN)-based digital twins encounters a significant implementation hurdle. In response, hybrid models, seamlessly integrating physics-based first-principles with machine learning, have emerged as the \"best of both worlds\" solution.\n\n\ud83d\ude80 However, current simplistic DNN models fall short when it comes to predicting the long-term evolution of process data. Enter time-series transformers (TSTs), a recent innovation leveraging a multiheaded attention mechanism to capture both long and short-term process dynamics. These transformers have showcased superior performance, paving the way for a groundbreaking hybrid modeling framework in batch crystallization.\n\n\ud83c\udf1f In a pioneering study by Niranjan Sitapure, PhD and Joseph Kwon, a first-of-a-kind TST-based hybrid model has been developed. This model not only addresses the limitations of conventional black-box models but also offers enhanced accuracy and interpretability. The study introduces two distinctive configurations, series and parallel, of TST-based hybrid models, presenting a comparative analysis.\n\n--------\n\ud83d\ude80 We just launched our\u00a0#Hub\u00a0at\u00a0PolyModelsHub.com\u00a0(https:\/\/lnkd.in\/gM-TRds7) and we're eager to host great packages like this! If you've developed or come across remarkable work, sign up, upload, or get in touch with us \ud83d\ude0a\u00a0\n--------\n\n\ud83d\udd17Link to Publication: https:\/\/lnkd.in\/gDPfZZix\n\n#HybridModeling #TimeSeriesTransformers #BatchCrystallization #InnovationInProcessModeling \ud83d\udd04\ud83d\ude80","linkedinURL":"https:\/\/www.linkedin.com\/feed\/update\/urn:li:activity:7137772619449176064","githubURL":null,"paperURL":null,"author":"Antonio Benedetti","createdDate":"12\/05\/2023"},{"title":"The title is: A Data-driven Integrated Design of Solvents and Extractive Distillation Processes","description":"\ud83d\ude80 ANN for the Design of Solvents & Extractive Distillation Processes \ud83d\udcbb\n\n\ud83d\udcda We recently stumbled upon a very interesting paper titled \"Data-driven Integrated Design of Solvents and Extractive Distillation Processes,\" authored by Zihao Wang, Teng Zhou, and Kai Sundmacher. \n\n\ud83d\udd0d The paper addresses the challenge of computationally expensive computer-aided molecular and process design (CAMPD) problems due to the consideration of numerous variables in property & process models. The authors propose an efficient CAMPD approach for the simultaneous design of solvents and extractive distillation processes by leveraging a #data-driven modelling strategy. \ud83e\udde0\n\n\ud83c\udf1f The authors trained #artificial neural network (#ANN)-based process models to replace the physical models. The study identifies real solvents from a vast database that approximate the optimal property values obtained through the optimization process. The identified optimal solvents and process parameters are subjected to rigorous simulations of the extractive distillation process to evaluate their performance.\n\n\ud83d\udcb9 An economic evaluation reveals a lower annual cost compared to the benchmark process, showcasing the practical benefits of the proposed approach. Furthermore, a comprehensive chemical hazard assessment further confirms that acetylacetone emerges as a promising solvent for the separation of 1-butene from 1,3-butadiene.\n\n\ud83c\udf89 Congratulations to the authors for their contribution \ud83c\udf89\n\n\ud83d\udd17 Link to the article: https:\/\/lnkd.in\/eErhQEY7","linkedinURL":"https:\/\/www.linkedin.com\/feed\/update\/urn:li:activity:7137547394388234240","githubURL":null,"paperURL":null,"author":"Harry Christodoulou","createdDate":"12\/04\/2023"},{"title":"The title is: Optimization of Parameter Estimation for Model Fidelity in Pharmaceutical System Models","description":"\ud83c\udfaf  Optimization of Parameter Estimation for Model Fidelity in Pharmaceutical System Models \ud83c\udf10\n\nQuantitative models have become instrumental in advancing pharmaceutical process development. As these models play a pivotal role in understanding process phenomena and facilitating decision-making, ensuring their prediction fidelity becomes a paramount concern. This challenge is particularly pronounced in systems models (aka flowsheet models), where parameters from previous units can significantly impact the predictions of the final output.\n\n\ud83d\udcc8 In a comprehensive study led by Margherita Geremia, Giulio Cisco, Samir Diab, Gabriele Bano and Fabrizio Bezzo a novel framework is proposed to assess the reliability of model predictions. The focus is on optimizing the precision of parameter estimates to meet pre-set tolerance requirements for both process key performance indicators and product critical quality attributes.\n\n\ud83d\udc8a The study employs a direct compression systems model for manufacturing oral solid dosage products as a case study. The results demonstrate the effectiveness of the proposed methodology in ensuring target model fidelity and quantifying the maximum acceptable uncertainty in the estimates of model parameters.\n\n\ud83d\udd17 Link to Publication: https:\/\/lnkd.in\/eeJeZRkQ\n\n#PharmaceuticalSystemsModeling #PrecisionOptimization #ModelFidelity #ProcessDevelopment \ud83d\ude80\ud83d\udc8a","linkedinURL":"https:\/\/www.linkedin.com\/feed\/update\/urn:li:activity:7137092102772944896","githubURL":null,"paperURL":null,"author":"Antonio Benedetti","createdDate":"12\/03\/2023"},{"title":"The title is: Enhancing Freeze-Drying Quality Assessment: A Data-Driven Approach with Machine Learning and NIR Spectroscopy!","description":"\ud83d\udcca Enhancing Freeze-Drying Quality Assessment: A Data-Driven Approach with Machine Learning and NIR Spectroscopy! \u2744\ufe0f \n\nResidual Moisture (RM) in freeze-dried products is a critical quality attribute (CQA) crucial for the stability of active pharmaceutical ingredients (API). Traditionally, Karl-Fischer (KF) titration has been the standard, but its drawbacks have led to exploration of alternative methods.\n\n\ud83d\udca1 Ambra Massei, Nunzia Falco, and Davide Fissore present a nuanced study, utilizing Near-Infrared (NIR) spectroscopy and machine learning for RM prediction. Two models are compared: a linear regression model and a neural network-based approach with a carefully crafted architecture to optimize predictions.\n\n\ud83d\udcca Parity plots and absolute error plots provide a visual evaluation. Factors like wavelength range, spectra shape, and model type are considered. The study explores the potential of smaller datasets and different formulations.\n\n\ud83d\udcc9 Various formulations are analyzed, including sucrose percentages, sucrose-arginine mixtures, and trehalose. A product-specific model for a 6% sucrose mixture shows consistency across other sucrose mixtures and even with trehalose. Challenges arise with datasets featuring higher arginine percentages, leading to the development of a comprehensive global model.\n\n\ud83d\udd17 Link to Publication: https:\/\/lnkd.in\/e4fFCkmE\n\n#MachineLearning #NIRSpectroscopy #FreezeDryingQuality #PharmaceuticalInnovation \ud83d\ude80\ud83d\udd2c","linkedinURL":"https:\/\/www.linkedin.com\/feed\/update\/urn:li:activity:7136723287874662400","githubURL":null,"paperURL":null,"author":"Antonio Benedetti","createdDate":"12\/02\/2023"},{"title":"The title is: BoFlex: Robust Bayesian Optimization for Expensive Simulation-Based Flexibility Analysis with Uncertainty Bounds","description":"\ud83d\udca1  BoFlex: Robust Bayesian Optimization for Expensive Simulation-Based Flexibility Analysis with Uncertainty Bounds \ud83c\udf10\n\nThe performance of emerging biochemical systems hinges on their ability to adapt to uncertainties swiftly and accurately. Discover flexibility analysis, a quantitative framework designed to determine whether a system can maintain safe and feasible operation despite uncertainties. This challenge becomes particularly pronounced when dealing with expensive simulation-based models, where equation-oriented models are often challenging to obtain.\n\n\ud83d\udcc8 In this great paper by Akshay Kudva, Wei-Ting Tang, and Joel Paulson, a novel approach called BoFlex is introduced. BoFlex stands out as a sequential black-box flexibility analysis method, overcoming the limitations of assuming access to equation-oriented models. Instead, it constructs probabilistic surrogate models over the joint space of uncertain and recourse variables.\n\n\ud83d\udd04 BoFlex operates on a special alternating confidence bound procedure, demonstrating finite convergence to a correct solution under mild assumptions on the unknown functions. What sets it apart is the establishment of a rigorous upper bound on the convergence rate, quantified in terms of the maximum information gain of the surrogate model.\n\n\ud83c\udf10 The versatility of BoFlex is showcased through several case studies, including applications in a heat exchanger network and a bubble column reactor. The results underline its advantages in handling uncertainty and optimizing flexibility in diverse scenarios.\n\n--------\n\ud83d\ude80 We just launched our\u00a0#Hub\u00a0at\u00a0PolyModelsHub.com\u00a0(https:\/\/lnkd.in\/gM-TRds7) and we're eager to host great packages like this! If you've developed or come across remarkable work, sign up, upload, or get in touch with us \ud83d\ude0a\u00a0\n--------\n\n\ud83d\udd17 Link to GitHub: https:\/\/lnkd.in\/etmyU5TP\n\ud83d\udcda Link to Publication: https:\/\/lnkd.in\/eWErBxiN\n\n#BayesianOptimization #FlexibilityAnalysis #BiochemicalSystems #ResearchInnovation \ud83d\ude80\ud83d\udd2c","linkedinURL":"https:\/\/www.linkedin.com\/feed\/update\/urn:li:activity:7136439271325880320","githubURL":null,"paperURL":null,"author":"Antonio Benedetti","createdDate":"12\/01\/2023"},{"title":"The title is: Optimization of Hybrid Distillation-Pervaporation and Dividing Wall Column Structures","description":"\u2728 Optimisation of hybrid distillation-pervaporation & dividing wall column structures \u2728\n\n\ud83d\udca1 The quest for energy-efficient separation of azeotropic mixtures has led to the exploration of innovative approaches. Enter process intensification (PI), a key player in enhancing energy efficiency. \ud83d\ude80\n\n\ud83d\udd0d Just stumbled upon a very interesting scientific article titled \"Single- and multi-objective optimisation of hybrid distillation-pervaporation and dividing wall column structures,\" authored by Dian Ning Chia, Fanyi Duanmu, and Eva Sorensen MBE from UCL Chemical Engineering.\n\n\ud83d\udcda The study evaluates three hybrid distillation structures\u2014distillation followed by pervaporation (D-P), pervaporation followed by distillation (P-D), and distillation followed by pervaporation then by distillation (D-P-D). These are pitted against a hybrid dividing wall column (H-DWC) structure.\n\n\ud83d\udcc8 Through both single-objective and multi-objective (NSGA-II) optimization, the research demonstrates that the D-P-D and H-DWC structures stand out. Notably, they exhibit significantly lower total annualized costs compared to the other designs. \n\nThe secret lies in their judicious use of membranes to facilitate mixture composition crossing the azeotropic point, resulting in a reduced membrane area requirement.\n\n\ud83c\udf1f These findings pave the way for more energy-efficient and cost-effective separation processes. \ud83c\udf1f\n\n\ud83c\udf89 Kudos to the authors! \ud83c\udf89\n\n\ud83d\udd17 Link to the article: https:\/\/lnkd.in\/gKy-5Hvy","linkedinURL":"https:\/\/www.linkedin.com\/feed\/update\/urn:li:activity:7136012449761153024","githubURL":null,"paperURL":null,"author":"Harry Christodoulou","createdDate":"11\/30\/2023"},{"title":"The title is: \"The Future of Equation-based and Data-Driven Modeling Tools is #OpenSource!\"","description":"\ud83d\ude80 The Future of Equation-based and Data-Driven Modeling Tools is #OpenSource! \ud83d\udcca\n\nToday we want to share this super interesting article by LaGrande Gunnell, Bethany Nicholson, and John Hedengren that delves into the current state and future directions of open-source software in the context of equation-based and data-driven modeling. A review of current trends in scientific computing spotlights a transformative shift towards open-source platforms and the widespread adoption of higher-level programming languages, notably Python. \n\n\ud83d\udca1 Open-source modeling tools are identified as key catalysts for innovation in both equation-based and data-driven applications. Notably, there's a surge in the development of data-driven tools, with tech giants investing significantly in platforms like PyTorch, TensorFlow, and Scikit-learn. This strategic focus on machine learning services meets business needs while upholding the foundational ethos of keeping tools open.\n\n\ud83d\udcc8 Equally gaining traction are open-source equation-based tools, including Pyomo, CasADi, Gekko, and JuMP. Their momentum is not only substantiated by user community endorsement but also reflected in the impressive pace of development metrics.\n\n\ud83c\udf10 The frontier of progress lies in the integration of data-driven and principles-based tools. This synergistic approach holds promise for advancing modeling capabilities and solving complex problems that demand both approaches.\n\n\ud83d\udd27 As the landscape evolves, new computing hardware, productivity software, and training resources emerge as potential game-changers, poised to radically accelerate progress in scientific computing. However, a crucial aspect for sustaining this momentum is the establishment of long-term support mechanisms. These mechanisms are vital for the continued maintenance and evolution of critical foundational packages that underpin the open-source ecosystem.\n\n\u2b50 As our followers know, open-source Modeling is at the core of our Mission and we couldn't agree more with this work! Well done to the authors!\n\n------\n\ud83d\ude80 We just launched our\u00a0#Hub\u00a0at\u00a0PolyModelsHub.com\u00a0(https:\/\/lnkd.in\/gM-TRds7) and we're excited to host great packages like the ones mentioned in this article! If you've developed or come across remarkable work, sign up, upload, or get in touch with us \ud83d\ude0a\n-----\n\n\ud83d\udd17 Link to Publication: https:\/\/lnkd.in\/gJDk9K-2\n\n#OpenSourceSoftware #ScientificComputing #DataDrivenModeling #EquationBasedModeling \ud83d\ude80\ud83d\udcc8","linkedinURL":"https:\/\/www.linkedin.com\/feed\/update\/urn:li:activity:7135617564184903680","githubURL":null,"paperURL":null,"author":"Antonio Benedetti","createdDate":"11\/29\/2023"},{"title":"The title is: Precise Particle Size Control during Spherical Agglomeration of Benzoic Acid","description":"\u2728 Precise particle size control during spherical agglomeration \ud83c\udf10\n\nThe pharmaceutical industry is increasingly drawn to spherical agglomeration processes due to the possibility of\u00a0Direct Tabletting of Active Pharmaceutical Ingredients (APIs). The Life Sciences industry, in general, is continually striving to enhance bulk powder properties, leading to improved powder \"processability\".\n\n\ud83d\udd0d We recently came across a very interesting article that explores the fascinating realm of particle #agglomeration: \"Precise Particle Size Control during Spherical Agglomeration of Benzoic Acid by Modification of the Bridging Liquid Phase Using TWEEN 20\" by Nele Merkelbach, Christos Xiouras, Arne Vancleef, Leen Thomassen, and Leen Braeken.\n\n\ud83d\ude80 The article addresses the following challenge: While converting needle-shaped particles into spheres brings advantages like enhanced flowability and particle density; achieving precise control over agglomerate size remains a challenge. \ud83e\udd14\n\n\ud83d\udcda The paper explores the incorporation of surfactants, specifically TWEEN 20, at varying concentrations to control the particle size and shape of agglomerates. The experiments involved antisolvent crystallization in ethanol\/water using benzoic acid as a model compound, followed by the addition of a bridging liquid (toluene).\n\n\ud83d\udcc8 The researchers utilized in-process microscopy tools to monitor both crystallization and agglomeration processes in real-time. By adjusting TWEEN 20 concentration and, consequently, the interfacial tension of the bridging liquid, the study achieved highly tunable agglomerate sizes ranging from 160\u202f\u03bcm to 4412\u202f\u03bcm\ud83d\udc4f\n\n\ud83d\udca1 Question towards our Polymodels Hub community: Could mechanistic or hybrid modelling approach complement this excellent study?\n\n\ud83c\udf1f This research opens avenues for optimizing pharmaceutical processes and advancing the field towards more efficient and tailored drug manufacturing.\n\n\ud83c\udf89Kudos to the authors!\u2728\n\nRead the full article here: https:\/\/lnkd.in\/ggCGmb_y","linkedinURL":"https:\/\/www.linkedin.com\/feed\/update\/urn:li:activity:7135325036411817985","githubURL":null,"paperURL":null,"author":"Harry Christodoulou","createdDate":"11\/28\/2023"},{"title":"The title is: PyPINNChem - An Open-Source Framework for Physics-Informed Neural Networks in Chemical Reaction Modeling.","description":"\ud83d\udcbb Hybrid Approach to Chemical Reaction Modeling: Introducing PyPINNChem! \ud83e\uddea\n\nDynamic modeling of chemical reactions stands at the core of process modelling for any industry where a transformation of species takes place, influencing processes from optimization to technology transfer. In this great effort by M\u00e1ty\u00e1s Susits, \u00c1lmos Orosz, and Botond Szilagyi, PyPINNChem emerges as an open-source solution for Chemical Reaction Modeling using Physics-informed Neural Networks (PINNs).\n\n\ud83d\udd2c PyPINNChem leverages the potency of Physics-informed Neural Networks (PINNs), a cutting-edge method for simulating complex systems by amalgamating neural networks' flexibility with the foundational principles of dynamic first principle models.\n\n\ud83d\udcbb This Python framework serves as a rapid and open-source evaluation platform tailored for arbitrary chemical reaction networks. It streamlines the development, training, and analysis of PINNs, offering a comprehensive suite of features. The framework boasts a flexible and modular architecture, allowing users to effortlessly define and customize network structures, loss functions, and training strategies.\n\n\ud83d\udee0\ufe0f Seamlessly integrating with PyTorch, PyPINNChem harnesses the library's rich ecosystem of deep learning tools and techniques. This integration enhances its adaptability and effectiveness in handling chemical reaction systems.\n\n\ud83d\udcc8 The paper presents various case studies exemplifying PyPINNChem's capabilities and limitations. Despite the absence of hyperparameter optimization, these examples showcase the PINN's ability to effectively capture concentration dynamics using relatively simple neural networks. The experiments reveal a susceptibility to overfitting when too many free parameters are combined with limited training data. Nevertheless, with suitable network topology, PyPINNChem provides a substantially superior fit with considerably less physical data compared to traditional multilayer perceptrons.\n\n--------\n\ud83d\ude80 We just launched our #Hub at polymodelshub.com (https:\/\/lnkd.in\/gM-TRds7) and we're eager to host great packages like this! If you've developed or come across remarkable work, sign up, upload, or get in touch with us \ud83d\ude0a \n--------\n\n\ud83d\udd17 Link to #GitHub: https:\/\/lnkd.in\/eqDGfZYr\n\ud83d\udcda Link to #Publication: https:\/\/lnkd.in\/erFTTxve \n\n#ChemicalReactionModeling #PyPINNChem #PhysicsInformedNeuralNetworks #OpenSourceScience \ud83c\udf10\ud83e\uddec","linkedinURL":"https:\/\/www.linkedin.com\/feed\/update\/urn:li:activity:7134929119103852546","githubURL":null,"paperURL":null,"author":"Antonio Benedetti","createdDate":"11\/27\/2023"},{"title":"The title is: Model-Based Control System Design for Managing Process Parameters in Mammalian Cell Culture for Biopharmaceutical Manufacturing.","description":"\ud83d\udd2c Model-based control system design to manage process parameters in mammalian cell culture for biopharmaceutical manufacturing \ud83e\udda0\n\nIn biopharmaceutical manufacturing, continuous processing methods, such as perfusion, are gaining traction due to their potential to enhance robustness and flexibility. However, establishing an effective control strategy for these continuous upstream processes remains a challenge. This paper, authored by Ayumu Sakaki , Tetsushi Namatame, Makoto Nakaya, and Takeshi Omasa, presents a novel model-based control approach that addresses this critical need.\n\n\ud83d\udd0d The proposed approach systematically combines a culture model with control theory to determine controller specifications that achieve the desired control characteristics. This mechanistic approach eliminates the need for qualitative decision-making or preliminary experiments, streamlining the control system design process.\n\n \ud83e\uddebThe researchers developed a detailed culture model that captures the intricacies of mammalian cell culture dynamics. This model provides a comprehensive representation of the process, enabling accurate predictions of cell behavior under various conditions.\n\n\u2699\ufe0f Integrating the culture model with control theory allows for the systematic derivation of controller parameters. This approach ensures that the control system is tailored to the specific requirements of the bioprocess, leading to enhanced performance and stability.\n\n\ud83d\udd11 To validate the effectiveness of the model-based control algorithm, control simulations were conducted using a perfusion Chinese hamster ovary (CHO) culture system. The simulations demonstrated that the proposed approach successfully maintains critical process parameters within desired ranges, even in the face of complex fluctuations.\n\n\ud83d\udcda Link to Publication: https:\/\/lnkd.in\/ebdCEBVC\n\n#ModelBasedControl #BiopharmaceuticalManufacturing #CellCulture #ContinuousProcessing #Digitalization \ud83c\udf10\ud83d\udd2c","linkedinURL":"https:\/\/www.linkedin.com\/feed\/update\/urn:li:activity:7134563027382595584","githubURL":null,"paperURL":null,"author":"Antonio Benedetti","createdDate":"11\/26\/2023"},{"title":"The title is: Machine Learning and Process Systems Engineering: Navigating Challenges, Exploiting Opportunities","description":"\ud83e\udd16 Machine Learning and Process Systems Engineering: Navigating Challenges, Exploiting Opportunities \ud83c\udf10\n\n\ud83d\udcc8 Machine Learning (ML), Artificial Intelligence (AI), and the broader realm of Data Science have emerged as mainstream topics across various scientific and technological domains. In this white paper from recent FIPSE 5 conference, Prodromos Daoutidis, Jay H Lee, Srinivas Rengarajan, Leo Chiang, Bhushan Gopaluni, Artur Schweidtmann, Iiro Harjunkoski, Mehmet Mercang\u00f6z, Ali Mesbah, Fani Boukouvala, Fernando V. Lima, Ehecatl Antonio del Rio Chanona, and Christos Georgakis - delve into the profound impact of ML on Process Systems Engineering (PSE).\n\n\ud83c\udf10 The intersection of ML and PSE presents a landscape rich in challenges and opportunities. In the naturally evolving field of chemical engineering, ML techniques unfold potential applications across diverse domains such as cheminformatics, bioinformatics, materials design, and PSE itself.\n\n\ud83e\uddeaSome key areas of ML application in PSE are:\n\ud83d\udd39 Flowsheet Analysis\n\ud83d\udd39 Surrogate Modeling for Simulation and Optimization\n\ud83d\udd39 Integrated Planning and Scheduling\n\ud83d\udd39 Supply Chain Design and Operation\n\ud83d\udd39 Process Monitoring and Fault Diagnosis\n\ud83d\udd39 Real-Time Optimization and Control\n\n\ud83d\udd0d Yet, the union of ML and PSE does not come without hurdles. Many challenges arise such as data heterogeneity, high dimensionality, noise, bias, and adherence to physical laws. The distinction between \"observational\" and \"informational\" data poses a conundrum, especially considering the prolonged operational conditions of process plants.\n\n\ud83c\udf1f The discussions presented in this paper serve as an excellent starting point for establishing the foundations of how industry and academia can address these challenges. The journey is complex, yet the potential for transformative breakthroughs is boundless and can really shape the way we approach this field in the years to come.\n\n\ud83d\udcda  Link to Publication: https:\/\/lnkd.in\/eiEr7P5v\n\n#MachineLearning #ProcessSystemsEngineering #DataScienceInEngineering #InnovationJourney #ChallengesAndOpportunities \ud83e\udd16\ud83c\udf10","linkedinURL":"https:\/\/www.linkedin.com\/feed\/update\/urn:li:activity:7134220222139371520","githubURL":null,"paperURL":null,"author":"Antonio Benedetti","createdDate":"11\/25\/2023"},{"title":"The title is: AMUSE: Automated Multiscale Simulation Environment for Heterogeneous Catalysis","description":"\ud83c\udf10 Automated Multiscale Simulation Environment: AMUSE!  \u2699\ufe0f\n\nModelling heterogeneous catalysis faces significant challenges, particularly in integrating detailed atomistic information into predictive full-scale reactor models. Albert Sabadell-Rend\u00f3n, Kamila Kazmierczak, Santiago Morandi, Florian Euzenat, Daniel Curulla Ferr\u00e9, and N\u00faria L\u00f3pez address these challenges proposing an Automated MUltiscale Simulation Environment (AMUSE).\n\n\ud83d\ude80 The intricacies of multiscale modeling, especially concerning catalytic complexity and the disparity in time and length scales, have long hindered seamless implementation. AMUSE tackles this head-on, starting from Density Functional Theory (DFT), prepares it for microkinetic modeling, and subsequently integrates the results into a standard open-source Computational Fluid Dynamics (CFD) code.\n\n\ud83d\udcbb AMUSE capabilities have been demonstrated by first addressing the unimolecular iso-propanol dehydrogenation reaction and then tackling the more intricate process involving the pre-commercial Pd\/In2O3 catalyst for converting CO2 into methanol. The outcomes reveal that AMUSE enables a thorough computational exploration of heterogeneous catalytic reactions, offering crucial insights for designing catalysts across various scales, from atomistic details to reactor-scale levels.\n\n\ud83d\udd17 AMUSE Components:\n#AutoProfLib: Identifies reaction mechanisms automatically from DFT data.\n#PyMKM: Builds microkinetic models from atomistic DFT data, facilitating simulation of lab-scale catalytic reactors.\n#OpenFOAM: AutoProfLib and PyMKM outputs feed into open-source CFD code, extending standard solvers with CatalyticFOAM for detailed kinetic mechanisms.\n\n\ud83d\udd17 Link to GitHub : https:\/\/lnkd.in\/efutk_f3\n\ud83d\udcda Link to Publication: https:\/\/lnkd.in\/eginzbwH\n\n#MultiscaleSimulation #CatalysisAutomation #AMUSEFramework #ScientificAdvancements #CatalystDesign \ud83c\udf10\u2699\ufe0f","linkedinURL":"https:\/\/www.linkedin.com\/feed\/update\/urn:li:activity:7133816772406730753","githubURL":null,"paperURL":null,"author":"Antonio Benedetti","createdDate":"11\/24\/2023"},{"title":"The title is: \"Kinetic Barriers to Disproportionation of Salts of Weakly Basic Drugs\"","description":"\ud83d\ude80 Disproportionation of Salts of Weakly Basic Drugs: Looking into the kinetic barriers. \ud83d\udea7\n\nDisproportionation poses a significant challenge in formulations with salts of weakly basic drugs. While risk assessment methods for disproportionation have been of considerable interest, predicting salt-to-base conversion remain an interesting challenge for the #pharma Industry. \n\n\ud83d\udc49 We came across an excellent paper titled \"Kinetic Barriers to Disproportionation of Salts of Weakly Basic Drugs\" by Tu Van Duong, Samir Diab, Neil Hodnett, and Lynne Taylor. \n\n\ud83d\udcda This study investigates the complexities beyond pHmax, pinpointing kinetic barriers as crucial alongside thermodynamics. In-depth investigations of pioglitazone hydrochloride, sorafenib tosylate, and atazanavir sulphate using in situ Raman spectroscopy & pH monitoring, #revealed distinct disproportionation kinetics (even under favourable thermodynamic conditions).\n\n\ud83d\udd2c The team combined in situ Raman spectroscopy and pH monitoring, shedding light on the kinetics of salt disproportionation in aqueous slurries. By emphasizing the importance of free base nucleation kinetics, the study demonstrated how different drugs can have varying conversion times, even under similar pH conditions.\n\n\ud83d\udd0d The researchers adapted a thermodynamically based modelling framework, integrating kinetic effects to estimate the solid-state stability of salt formulations. This model (which considers the nucleation kinetic barrier) enhances understanding and prediction capabilities in assessing salt disproportionation in solid-state formulations.\n\n\ud83c\udf89 Kudos to the authors! \ud83c\udf89\n\n\ud83d\udd17 Please read the full paper here: https:\/\/lnkd.in\/eGbBY7iR\n\ud83c\udf1f Highly recommended! \ud83c\udf1f\n\n#Pharmaceuticals #DrugFormulation #ResearchInnovation #ReactionKinetics","linkedinURL":"https:\/\/www.linkedin.com\/feed\/update\/urn:li:activity:7133426730635014144","githubURL":null,"paperURL":null,"author":"Harry Christodoulou","createdDate":"11\/23\/2023"},{"title":"The title is: PAROC\u2014An integrated framework and software platform for the optimisation and advanced model-based control of process systems.","description":"\n\ud83c\udf10 PAROC\u2014An integrated framework and software platform for the optimisation and advanced model-based control of process systems\u2699\ufe0f\n\nIn Process Systems Engineering, the integration of model-based tools in design, operational optimisation and advanced control studies plays a pivotal role, and the #PAROC framework, developed some years ago by Stratos Pistikopoulos, Nikolaos Diangelakis, Richard Oberdieck, Maria Papathanasiou, Ioana Nascu, and Muxin Sun, is an interesting concept solution.\n\n\ud83d\udcca The paper outlines a systematic approach, introducing the main foundations and features of PAROC. This integrated framework and software platform facilitate the application of model-based tools across design, operational optimization, and advanced control studies.\n\n\ud83d\udee0 Dynamic Model Development: Crafting a high-fidelity dynamic model, followed by validation and thorough model analysis.\n\n\ud83c\udfaf Model Approximation: Incorporating system identification, model reduction, and global sensitivity analysis.\n\n\ud83d\ude80 Receding Horizon Modeling: Implementing model-predictive control (MPC) and reactive scheduling through a receding horizon approach.\n\n\ud83c\udf10 Multi-Parametric Programming: Employing techniques for optimization under uncertainty, explicit\/multi-parametric MPC, and state estimation.\n\n\ud83d\udd0d In-Silico Validation: Analyzing derived optimization, control, and scheduling strategies within the original high-fidelity model.\n\n\ud83d\ude80 The PAROC software platform is a practical solution, showcased through applications in diverse process systems engineering scenarios, including a combined heat and power energy system, a distillation column, and a periodic purification process for biopharmaceuticals.\n\n-------------------\n\ud83d\udd35 We just launched our PolyModels Hub (https:\/\/lnkd.in\/gM-TRds7) and we're eager to host exceptional packages like this! If you've developed or come across remarkable work, sign up, upload, or get in touch.\n-------------------\n\n\ud83d\udd17 Explore Website: https:\/\/paroc.tamu.edu\/\n\ud83d\udcda Read the Full Publication: https:\/\/lnkd.in\/eKFuG9KV \n\n#ProcessSystemEngineering #PAROCSoftware #ModelBasedControl #ScientificAdvancements #OptimizationPlatform \ud83c\udf10\u2699\ufe0f","linkedinURL":"https:\/\/www.linkedin.com\/feed\/update\/urn:li:activity:7133094083706671106","githubURL":null,"paperURL":null,"author":"Antonio Benedetti","createdDate":"11\/22\/2023"},{"title":"The title is: Confidence Interval and Uncertainty Propagation Analysis of SAFT-type Equations of State.","description":"\u00a0\ud83c\udf1f SAFT-type Equations of State: Confidence Interval and Uncertainty Propagation Analysis \ud83c\udf1f\n\n\ud83c\udf10 Thermodynamic models play a pivotal role in the #pharmaceutical sector by providing critical insights into the behaviour of complex systems, facilitating the Digital Design and Optimization of processes such as crystallization, multi-phase reaction and distillation.\n\n\ud83d\udd0d Just stumbled upon an excellent paper titled \"Confidence Interval and Uncertainty Propagation Analysis of SAFT-type Equations of State.\" \n\nThermodynamic model enthusiasts, this one is for you! \ud83c\udf21\ufe0f The paper concerns SAFT-type equations, which are pivotal in unravelling the mysteries of complex systems.\u00a0The authors, Pierre Walker, Simon Mueller, and Irina Smirnova, leverage the power of Clapeyron.jl, a Julia package, for their in-depth analysis.\n\n\ud83d\udcca The authors present a comprehensive framework for sampling parameter distributions in #PC-SAFT and #SAFT-VR Mie equations of state. They investigate the intricacies of parameter #Confidence-Intervals and correlations, shedding light on conserved quantities that impact system behaviour. \n\nComparing equations of state, the paper gives actionable insights. Additional parameters in the SAFT-VR Mie equation introduce more correlations, slightly decreasing relative uncertainties. Incorporating association through extra parameters leads to increased uncertainties but a reduction in correlations.\n\n\ud83d\udcc8 The study takes us on a journey of uncertainty propagation to derived properties, highlighting small uncertainties for data used in parameter regression. However, the plot thickens when extrapolating to saturated-vapour volumes near the critical point, resulting in larger uncertainties due to heightened sensitivity of the isothermal compressibility.\n\n\ud83c\udf2a\ufe0f Brace yourselves for a twist near the critical point! Uncertainties in saturated volumes diverge, causing a ripple effect on bulk properties. Isobaric heat capacity takes the spotlight, with uncertainties skyrocketing, emphasizing the impact of even minor uncertainties near the critical point on predicted properties.\n\n\ud83d\ude80 For the tech enthusiasts and fellow researchers, Clapeyron.jl, the Julia package wielded and developed by these brilliant minds, can be explored in-depth at our Polymodels Hub. \n\n\ud83c\udf89 Many congratulations to the authors and developers of the amazing Julia packages! \ud83c\udf89\n\n\ud83d\udd17 Dive into the future of thermodynamics with this enlightening read! Link to the paper:\u00a0 https:\/\/lnkd.in\/d5AYH7sW\n\ud83d\udd17 Link to the code: https:\/\/lnkd.in\/dFT5w395\n\u00a0\n\u00a0#Research #Thermodynamics #SAFT #JuliaLang\u00a0","linkedinURL":"https:\/\/www.linkedin.com\/feed\/update\/urn:li:activity:7132762447387504640","githubURL":null,"paperURL":null,"author":"Harry Christodoulou","createdDate":"11\/21\/2023"},{"title":"The title is: Advancing Liquid Crystal Design: Predicting Melting Points with Neural Networks!","description":"\ud83d\udc8e  Advancing Liquid Crystal Design: Predicting Melting Points with Neural Networks! \ud83d\udcbb \n\nWhen dealing with liquid crystal (LC) phases, the melting point (MP) plays a pivotal role, determining the practical suitability of these compounds for diverse applications. This work by Ademola Soyemi, Shubham Pandey, Shane Vaara, and Tibor Szilv\u00e1si stands out for its insightful use of directed message passing neural networks.\n\n\ud83d\udd2c The study undertakes a comprehensive evaluation, employing neural networks trained on an extensive database covering over 27,000 organic molecules. The primary focus is on predicting the MP of a diverse set of 780 LC and LC-like molecules, spanning various chemical compositions.\n\n\ud83d\udcca The results are noteworthy. The model demonstrates precision in MP predictions for LC and LC-like molecules, with an overall Mean Absolute Error (MAE) and Root Mean Square Error (RMSE) of 23\u00b0C and 30\u00b0C, respectively. The granularity of their approach is evident in distinct performance levels for different compound types.\n\n\ud83d\udcbb Taking a step beyond scientific exploration, the team introduces an online tool, LCMelt (v1.0) (lcmelt.streamlit.app), providing researchers with a cost-free means to anticipate the MP of potential LC candidates before synthesis.\n\n-------------------\nWe just launched our Hub (https:\/\/lnkd.in\/gM-TRds7) and we're eager to host great packages like this! If you've developed or come across remarkable work, sign up, upload, or get in touch.\n-------------------\n\n\ud83d\udd17 Link to #Github: https:\/\/lnkd.in\/eusJ-JbD\n\ud83d\udcda Read the Full Publication: https:\/\/lnkd.in\/etRcBFvM \n\ud83d\udcf1  Explore LCMelt (v1.0): https:\/\/lnkd.in\/eVmpQ-_n\n\n#LiquidCrystalDesign #NeuralNetworkPredictions #LCMeltTool #ScientificAdvancements #PredictiveModeling \ud83c\udf10\ud83d\udd2c","linkedinURL":"https:\/\/www.linkedin.com\/feed\/update\/urn:li:activity:7132441357150740481","githubURL":null,"paperURL":null,"author":"Antonio Benedetti","createdDate":"11\/20\/2023"},{"title":"The title is: Pioneering Innovation in Pharmaceutical Manufacturing: Developing a New Modular Continuous Mini-Tablet Production Line with Real-Time Quality Assurance!","description":"\ud83c\udf10 Pioneering Innovation in Pharmaceutical Manufacturing: Developing a New Modular Continuous Mini-Tablet Production Line with Real-Time Quality Assurance! \ud83d\udc8a\n\nThe pharmaceutical landscape is evolving, with a growing focus on small-scale modular manufacturing systems to produce medicinal products. These systems offer agility and flexibility, proving invaluable in scenarios demanding swift drug production, such as pandemics and humanitarian crises. Despite the industry's interest, the development of modular facilities for solid oral drug products has faced limited progress\u2014until now.\n\n\ud83d\udd27 Varun Sundarkumar, Wanning Wang, Madeline Mills, Sue Wei Oh, Zoltan Nagy, and Gintaras Reklaitis unveil an interesting prototype modular system utilizing drop-on-demand (DoD) printing to manufacture personalized solid oral drug products. The system showcases its capabilities in producing mini-tablets, specifically designed for pediatric drug products, in both continuous and semi-batch modes. The DoD printer generates molten formulation drops, solidifying them into mini-tablets, which are then seamlessly processed through continuous filtration and drying units integrated with the printer.\n\n\ud83c\udf21\ufe0f Real-time quality assurance takes center stage in this innovative system, with incorporated process monitoring tools tracking critical quality attributes and process parameters throughout the manufacturing operation. This ensures a meticulous and controlled production process.\n\n\ud83d\ude80 While presenting a significant leap in modular pharmaceutical manufacturing, the study also outlines future areas of innovation to enhance this prototype unit and pave the way for advanced drug manufacturing systems on this versatile platform.\n\n\ud83d\udcda Read the Full Publication: https:\/\/lnkd.in\/e5psdyGi \n\n#PharmaceuticalInnovation #ModularManufacturing #MiniTabletProduction #RealTimeQualityAssurance #ScientificAdvancements \ud83c\udf10\ud83d\udc8a","linkedinURL":"https:\/\/www.linkedin.com\/feed\/update\/urn:li:activity:7132020841243930625","githubURL":null,"paperURL":null,"author":"Antonio Benedetti","createdDate":"11\/19\/2023"},{"title":"The title is: Job Opportunities in the Digital Space","description":"\ud83e\udd1d Connecting Opportunities in Our Community \ud83c\udf10\n\nIn light of Pfizer's recent announcement of 500 redundancies at their UK site, we extend our support to affected community members, especially those in modeling functions.\u00a0It is sad to see so many talented friends and professional being impacted.\n\nToday, we invite you to leverage this post (usually reaching 3-5k people in the field) and the comments section to share job opportunities within your companies, specifically in the digital space.\n\n\ud83c\udf10 How can we all contribute?\n\u27a1 If your company has job vacancies suitable for individuals with modeling expertise or related skills, please drop the details in the comments.\u00a0\n\u27a1 If you're a member affected by the recent developments at Pfizer and are seeking new professional opportunities, share your expertise and job preferences in the comments. \n\nOur community is here to support you.\nThank you for being a part of the PolyModels Hub family. \ud83d\ude80\n\n#PolyModelsHub #CommunitySupport #JobOpportunities #DigitalSpace","linkedinURL":"https:\/\/www.linkedin.com\/feed\/update\/urn:li:activity:7131612852116680704","githubURL":null,"paperURL":null,"author":"Antonio Benedetti","createdDate":"11\/18\/2023"},{"title":"The title is: Biopharmaceutical Freezing Realities: SNOW Package Insights from Janssen COVID-19 Vaccine Production.","description":"\ud83c\udf10 Exploring Biopharmaceutical Freezing Realities: SNOW Package Insights from Janssen COVID-19 Vaccine Production! \u2744\ufe0f\n\nIn the realm of biopharmaceuticals, the freezing process is crucial for ensuring the stability of Active Pharmaceutical Ingredients (APIs). Building on our prior discussions about the SNOW package's simulation capabilities, Leif-Thore Deck, David Ochsenbein, and Marco Mazzotti also presented a practical application\u2014providing insights into how to use that in the manufacturing process of the Janssen COVID-19 vaccine.\n\n\ud83d\udd0d Large-scale freezing often involves complex pallets of vials over extended periods. Until now, this process's design has been mainly experimental due to the absence of a comprehensive understanding. However, the SNOW modeling framework, validated with real-world Janssen COVID-19 vaccine data, reveals stochastic ice nucleation as a key factor governing both process duration and batch heterogeneity.\n\n\ud83d\udca1 Armed with insights into the ice nucleation kinetics, crucial for rational freezing process design, the authors generously share their findings through the open-sourced SNOW package. This Python tool goes beyond theoretical simulations, offering a practical lens into the freezing process for vial batches.\n\n\u2744\ufe0f SNOW, grounded in first principles, considers the thermal evolution of vials during freezing. It allows tracking of pivotal quantities such as nucleation time, nucleation temperature, and solidification time, all correlated with frozen product attributes. \n\n-------------------\nWe just launched our Hub (https:\/\/lnkd.in\/gM-TRds7) and we're eager to host exceptional packages like this! If you've developed or come across remarkable work, sign up, upload, or get in touch.\n-------------------\n\n\ud83d\ude80 Link to Snow: https:\/\/lnkd.in\/eiDCq7Mz\n\ud83d\udcda Read the Full Publication: https:\/\/lnkd.in\/erjYAkxy\n\n#BiopharmaceuticalFreezing #SNOWPackage #JanssenVaccine #RealWorldApplications #ScientificInnovation \ud83c\udf10\ud83d\udd2c\u2744\ufe0f","linkedinURL":"https:\/\/www.linkedin.com\/feed\/update\/urn:li:activity:7131329685728169985","githubURL":null,"paperURL":null,"author":"Antonio Benedetti","createdDate":"11\/17\/2023"},{"title":"The title is: Exploring Robust Parameter Estimation: Online-Reparametrisation Package!","description":"\ud83c\udf10 Exploring Robust Parameter Estimation: Online-Reparametrisation Package! \ud83e\uddea\n\nIn a situation with numerous available models for the task at hand, the decision of which one to choose becomes pivotal. Automated model identification emerges as a potentially transformative approach. Within this framework, Marco Quaglio, Conor Waldron, Arun Pankajakshan, Enhong Cao, Asterios Gavriilidis, Eric Fraga, and Federico Galvanin introduce a practical solution \u2013 the \"Online-Reparametrisation\" package.\n\n\ud83d\udee0Automated model identification platforms play a crucial role in unmanned experimental campaigns, employing tools for parameter estimation and model-based experimental design. The effectiveness of these tools relies on well-conditioned objective functions, which becomes challenging with ill-conditioned objective functions, often seen in weakly parametrized models.\n\n\ud83d\udca1 The authors introduce a robust reparametrisation technique, showcasing its prowess through in-silico testing and real-world application within an automated model identification platform. The transformative impact of reparametrisation is exemplified in a case study involving the identification of a kinetic model for catalytic esterification in a flow microreactor.\n\n\ud83d\ude80 The result of this great work is the \"Online-Reparametrisation\" package, now accessible on our Hub . Kudos and a big thank you to Marco for being one of the first contributors to our mission to advancing and democratizing access to modeling in the Life Sciences!\n\n\ud83d\udd17 Link to #PolyModelsHub: https:\/\/lnkd.in\/eNjadw3E\n\ud83d\udcda Read the Publication: https:\/\/lnkd.in\/eBHxA4Ez\n\n#ParameterEstimation #ModelIdentification #OpenSourcePackage #ScientificInnovation  \ud83c\udf10\ud83d\udd2c","linkedinURL":"https:\/\/www.linkedin.com\/feed\/update\/urn:li:activity:7130982615548862465","githubURL":null,"paperURL":null,"author":"Antonio Benedetti","createdDate":"11\/16\/2023"},{"title":"The title is: PolyModels Hub is LIVE! \ud83d\ude80\ud83c\udf10\ud83e\uddec\ud83d\udcbb","description":"\ud83d\ude80 Breaking News: PolyModels Hub is LIVE! \ud83c\udf10\ud83e\uddec\ud83d\udcbb\n\nHey PolyModelers! The moment we've all been waiting for is finally here. \ud83c\udf89 We're ecstatic to announce that PolyModels Hub website ( www.polymodelshub.com ) is officially LAUNCHED and ready to revolutionize the Life Sciences industry! \ud83d\ude80\n \n\ud83c\udf1f What is PolyModels Hub?\nPolyModels Hub is not anymore just a community; it's a dynamic platform designed to drive innovation in Life Sciences through open-source collaboration. From digital design to smart manufacturing, we're on a mission to democratize access to modeling and build the most advanced open-source library. \ud83d\udca1\n\n\ud83d\udc65 Why Join the Hub?\nPolyModels Hub is now more than just a community; it's your platform to shine. Publish your own package, receive valuable feedback from the community, and draw inspiration from the incredible work of some of the brightest minds in this space. Who knows, your groundbreaking contributions might just catch the eye of influential business organizations. \ud83c\udf10 \ud83c\udf10\n\n\ud83d\ude80 Our Vision for Innovation\nBy bridging the gap in open-source models, we're empowering our community to lead the way of digitalisation in the life science domain. Let's transform challenges into opportunities together! \ud83e\udd1d\n\n\ud83d\udd17 Ready to Dive In?\u00a0Sign up NOW and upload some of your work!\nBe part of the movement. Join PolyModels Hub today by signing up at www.polymodelshub.com . Stay in the loop with the latest updates, discussions, and collaborative projects. \ud83d\udcbb\ud83d\udd2c\n\n\ud83c\udf89 Thank You for Your Support!\nA big thanks to our awesome community! Your support has been amazing and is the reason we've reached this exciting point with PolyModels Hub. Whether it's seeing our followers grow, chatting with you online, or meeting some of you in person, it's been a huge boost for us. And guess what? We're just getting started! Let's keep going and see how far we can take this together! \ud83d\ude80\ud83d\udcaa\n\n#PolyModelsHub #LifeSciences #InnovationUnleashed #CommunityLaunch #OpenSourceRevolution #DigitalDesign #SmartManufacturing #RegisterNow\n\n\ud83d\udce3  P.S. The Hub Needs You!\nThe Hub is all set up and ready, but it's not complete without your input! Your contribution is key to making this space vibrant and dynamic. Help us fill it with your ideas, projects, and energy. Spread the word, get others excited, and let's kick off this amazing journey together! \ud83d\ude80\ud83d\udca1 Your involvement makes all the difference. Let's make PolyModels Hub the go-to place for innovation! \ud83c\udf10\u2728","linkedinURL":"https:\/\/www.linkedin.com\/feed\/update\/urn:li:activity:7130524854771961857","githubURL":null,"paperURL":null,"author":"Antonio Benedetti","createdDate":"11\/12\/2023"},{"title":"The title is: Dynamic Optimization of Crystallization using Population Balance Modelling","description":"\ud83c\udf1f Dynamic Optimization of Crystallization using Population Balance Modelling \ud83d\udcca\n\n\ud83d\udd2cOften industrial crystallization processes rely on recipe-based temperature and antisolvent dosing trajectories derived from extensive exploratory experimentation. \ud83d\udcb0\u231b\n\n\ud83d\udcbb As companies embrace Digital Design, modelling approaches help Design & Optimize these processes.\ud83c\udf10\n\n\ud83d\udcda Recently we stumbled upon a very interesting article titled \"Dynamic Optimization of Active Pharmaceutical Ingredient (Semi-)Batch Crystallization using Population Balance Modelling.\" by Gustavo Lunardon Quill\u00f3, Jan F.M. Van Impe, Alain Collas, Christos Xiouras, and Satyajeet Bhonsale.\n\nThe authors developed a crystallization model which includes a 1-D Population Balance Equation combined with mass balance, (secondary) nucleation, and crystal growth kinetics. The dynamic optimization is tackled via \"single shooting\", discretizing the control trajectory as piecewise linear and determining the global solution via multi-start single-objective optimization. The overall simulation & optimization methodology is demonstrated in a combined cooling-antisolvent crystallization. The objective was to maximize the number-average crystal size while satisfying process constraints. \n\nThis paper is highly recommended for scientists interested in pharma modelling, simulation and optimization.\n\n\ud83d\udc4f Congratulations to the authors for their contribution \ud83d\ude4c\n\n\ud83d\udd17 Link to the article: https:\/\/lnkd.in\/eP56Ftie","linkedinURL":"https:\/\/www.linkedin.com\/feed\/update\/urn:li:activity:7130273417773092864","githubURL":null,"paperURL":null,"author":"Harry Christodoulou","createdDate":"11\/14\/2023"},{"title":"The title is: Exploring Ethanol Conversion to 1,3-Butadiene: A Detailed Kinetic Analysis using PyCatKin","description":"\ud83d\udcca Exploring Ethanol Conversion to 1,3-Butadiene: A Detailed Kinetic Analysis using PyCatKin \ud83c\udf10\n\nIn the world of catalytic reactions, Astrid Boje, William E. Taifan, Ph.D., Henrik Str\u00f6m, Tomas Bucko, Jonas Baltrusaitis, and Anders Hellman dive into the intricacies of transforming ethanol into 1,3-butadiene on a MgO (100) step-edge.\n\n\ud83d\udd0d Using first-principles-informed energy span and microkinetic analysis, the researchers investigate the free energy landscapes and competing reaction pathways. Dehydrogenation and dehydration of ethanol take the spotlight, revealing sensitivity to conditions and catalyst composition.\n\n\u26a1  The energy span concept uncovers the theoretical maximum turnover and degree of turnover frequency control for each pathway, emphasizing the dehydrogenation route's prominence. Rate-determining states in dehydrogenation, dehydration, and condensation steps are highlighted.\n\n\ud83c\udf21\ufe0f Exploring temperature's impact on relative rates provides insights into the varying temperature sensitivity of the free energy landscape. A microkinetic model examines pathway competition, interaction with gas-phase species, and surface coverage limitations.\n\n\u2699\ufe0f States determining turnover frequency with high surface coverage, like adsorbed ethanol and longer, oxygenated hydrocarbons, shape the narrative. The combined energy span and microkinetic analysis offer a dual perspective, untangling conflicting observations by considering both energetic and kinetic limitations.\n\n\ud83d\udcc8 Powered by the #PyCatKin Tool, this analysis uses a toolset for studying kinetics in heterogeneous catalysis, enabling the exploration of energy landscapes, energy span modeling, mean-field microkinetic modeling, and more.\n\n\ud83d\udd17 Link to Github : https:\/\/lnkd.in\/eUKPJjjS\n\ud83d\udcda Link to Publication : https:\/\/lnkd.in\/eySK_jMx\n\n#CatalyticAnalysis #EnergySpan #MicrokineticModeling #ScientificExploration #PyCatKinTool \ud83e\uddea\ud83d\udca1\ud83c\udf10","linkedinURL":"https:\/\/www.linkedin.com\/feed\/update\/urn:li:activity:7129890395542446080","githubURL":null,"paperURL":null,"author":"Antonio Benedetti","createdDate":"11\/13\/2023"},{"title":"The title is: Addressing Uncertainty in Pharmaceutical Models: A New Approach to Parameter Estimation.","description":"\ud83d\udcca Addressing Uncertainty in Pharmaceutical Models: A New Approach to Parameter Estimation \ud83c\udf10\n\nIn the Pharma R&D world, where data limitations often pose challenges, Iman Moshiritabrizi,\u00a0Kaveh Abdi,\u00a0Jon McMullen,\u00a0Brian Wyvratt and\u00a0Kim McAuley propose a methodology aimed at enhancing parameter estimation in fundamental models of pharmaceutical processes.\n\n\ud83e\udde9 The methodology specifically targets scenarios with insufficient data, complicating the reliable estimation of parameters, especially in the presence of uncertain independent variables. Here, the proposed method introduces an innovative approach employing an augmented sensitivity matrix to rank parameters and uncertain inputs. This ranking, from most estimable to least estimable, forms the basis for subsequent decisions.\n\n\ud83d\udcc8 To determine the appropriate parameters and inputs for estimation, the method leverages an updated mean-squared-error criterion. This criterion is applied to the ranked list, strategically identifying the components that should undergo estimation. The end result is a refined understanding of which parameters and inputs are most crucial for accurate estimation, mitigating the challenges posed by limited data.\n\n\ud83d\udd0d Illustrating the application of this method, the team delves into a model representing a step in a batch pharmaceutical production process. Notably, in a scenario involving uncertain initial reactant concentration, the methodology recommends estimating the initial reactant concentration along with a subset of the model parameters. To prevent overfitting, non-estimable parameters are judiciously fixed at their initial values.\n\n\ud83d\udcda Explore the Full Study: https:\/\/lnkd.in\/egvg5xMz \ud83c\udf10\ud83d\udcca\n\n#PharmaceuticalModeling #ParameterEstimation #UncertaintyAnalysis #ScientificAdvancements #ModelingMethodology \ud83e\uddea\ud83d\udd2c\ud83c\udf10","linkedinURL":"https:\/\/www.linkedin.com\/feed\/update\/urn:li:activity:7129481694457270273","githubURL":null,"paperURL":null,"author":"Antonio Benedetti","createdDate":"11\/12\/2023"},{"title":"The title is: Navigating Challenges in Freeze-Drying Scale-Up and Tech Transfer: Insights from Case Studies.","description":"\ud83e\uddca Navigating Challenges in Freeze-Drying Scale-Up and Tech Transfer: Insights from Case Studies \u2744\ufe0f\n\nThe scale-up and tech transfer of freeze-drying processes stand as intricate endeavors, often fraught with complexities and variations. Drawing from insightful case studies, Serguei Tchessalov and a team of experts across the industry shed light on both inefficient and effective practices, offering practical advice for industry professionals.\n\n\ud83d\udcca The conventional approach of employing identical process set points and times across laboratory and commercial-scale dryers has its pitfalls. This study underscores the potential risks, emphasizing that such uniformity may lead to the compromise of product quality\u2014manifesting as issues like collapse or vial breakage.\n\n\ud83c\udf10 An emerging modeling approach emerges as a valuable tool in this arena. Demonstrating practical advantages, it provides a structured methodology for understanding and optimizing the freeze-drying process. However, the study highlights a crucial prerequisite: the upfront generation of key input parameters, including vial heat transfer coefficient, minimum controllable pressure, and maximum sublimation rate, to effectively leverage the modeling approach.\n\n\ud83d\udd04 While the transfer of the primary drying step boasts a high degree of confidence, thanks to modeling, the secondary drying step follows suit in relative straightforwardness. Yet, a significant challenge looms during the prediction of potential changes in product behavior during freezing\u2014a crucial phase in the freeze-drying process.\n\n\u2744\ufe0f Factors influencing product quality during scale-up and tech transfer are multifaceted. Variances in equipment specifications, environmental conditions, and process attributes significantly impact heat and mass transfer dynamics. Equipment-specific parameters such as minimum controllable pressure, vial heat transfer coefficients, and limitations of refrigeration systems play pivotal roles.\n\n\ud83d\udcda Explore the Full Study: https:\/\/lnkd.in\/gniU3U-J\n \ud83c\udf10\ud83e\uddca\n\n#FreezeDrying #TechTransfer #ScaleUp #PharmaceuticalManufacturing #ScientificInsights \u2744\ufe0f\ud83d\udd2c\ud83d\udcca","linkedinURL":"https:\/\/www.linkedin.com\/feed\/update\/urn:li:activity:7128799281636864000","githubURL":null,"paperURL":null,"author":"Antonio Benedetti","createdDate":"11\/10\/2023"},{"title":"The title is: Advancing Bioprocess Optimization: Integrating Cybergenetics with Model-based Control Strategies","description":"\ud83d\udd2c Advancing Bioprocess Optimization: Integrating Cybergenetics with Model-based Control Strategies \ud83e\udda0\n\n\ud83e\uddec Metabolic and genetic engineering techniques delve into the intricacies of cellular processes. However, these methods often face challenges in dynamic environments and when disturbances occur. Empirical optimizations, lacking robust feedback mechanisms, further complicate the scenario.\n\n\ud83d\udca1 Enter cybergenetics, offering real-time modulation of gene expression for precise metabolic control, often utilizing external stimuli like light intensity in optogenetics. In this study by Sebasti\u00e1n Espinel R\u00edos, Bruno Morabito, Johannes Pohlodek, Katja Bettenbrock, Steffen Klamt, and Rolf Findeisen, cybergenetics converges with model-based optimization and predictive control.\n\n\ud83d\udd0d The approach involves dynamic constraint-based models, seamlessly integrating metabolic dynamics, resource allocation, and inducible gene expression. The team formulates a model-based optimal control problem, enabling the identification of optimal process inputs. Model predictive control steps in to address uncertainties in real-time through agile feedback mechanisms. The focus? Fed-batch processes, where the substrate feeding rate emerges as a critical optimization variable.\n\n\ud83c\udf1f In a simulation demonstration, the researchers showcase the power of optogenetic control. By dynamically modulating the ATPase enzyme complex, researchers can finely adjust enforced ATP wasting, thereby shaping product yield and productivity.\n\n\ud83d\udcda Read the Publication: https:\/\/lnkd.in\/egK_tmSp\n\n#BioprocessOptimization #Cybergenetics #ModelBasedControl #InnovativeBiotechnology #ScientificAdvancements \ud83e\udda0\ud83e\uddec\ud83d\udd0d","linkedinURL":"https:\/\/www.linkedin.com\/feed\/update\/urn:li:activity:7128410527831093248","githubURL":null,"paperURL":null,"author":"Antonio Benedetti","createdDate":"11\/09\/2023"},{"title":"The title is: Optimizing Impurity Rejection in Pharmaceutical Manufacturing through Batch Crystallization.","description":"\ud83d\udd2c Delving into the Realm of Crystallization: Optimizing Impurity Rejection in Pharmaceutical Manufacturing \ud83e\uddea\n\nIn the pharmaceutical industry, the presence of impurities above acceptable levels can pose significant safety concerns. Crystallization, a widely used purification technique, can be particularly challenging when dealing with impurities that exhibit poor solubility and co-precipitate alongside the desired active pharmaceutical ingredient (API). \n\nThis study, conducted by Mitchell Paolello, Ilyes BICHARI, Davinia Brouckaert, Mirvatte Francis, Dawn Yang, and Gerard Capellades, explores the application of a population balance model to optimize impurity rejection in batch crystallization.\n\n\ud83d\udd0d The researchers employed Raman spectroscopy, coupled with partial least squares (PLS) modeling, to monitor the crystallization process in situ. This innovative approach enabled the team to gather real-time insights into the crystallization dynamics, providing valuable data for model calibration.\n\n\ud83c\udf31 The developed population balance model, integrated into the gPROMS FormulatedProducts software, captured the intricate interplay between the API and the impurity during crystallization. This model proved instrumental in predicting the evolution of product purity throughout the process.\n\n\u2699\ufe0f Process optimization simulations revealed that high product purity near equilibrium can be achieved within the first two hours of crystallization. The purity of the API seed crystals emerged as the primary factor governing this phenomenon.\n\n\ud83d\udd11 The optimal strategy for effective impurity rejection involves a combination of factors: minimizing impurity nucleation rates, utilizing high-purity API seed crystals, and carefully controlling crystallization time to halt the process before impurity nucleation occurs.\n\n\ud83d\udcda This study not only sheds light on the fundamental mechanisms underlying impurity rejection in batch crystallization but also provides practical guidance for optimizing crystallization processes in the pharmaceutical industry.\n\n\ud83d\udc4f Kudos to the authors for their insightful contribution to this critical area of research!\n\n\ud83d\udcda Link to Publication: https:\/\/lnkd.in\/gdAqb4cx\n\n#CrystallizationOptimization #ImpurityRejection #PharmaceuticalManufacturing #ScientificAdvancement #InnovativeModeling \ud83c\udf10\ud83d\udd2c","linkedinURL":"https:\/\/www.linkedin.com\/feed\/update\/urn:li:activity:7128083189461372928","githubURL":null,"paperURL":null,"author":"Antonio Benedetti","createdDate":"11\/08\/2023"},{"title":"The title is: ORDerly - A Practical Python Package for Organizing Chemical Reaction Data","description":"\n\ud83e\uddea The Importance of High-quality Open-Source Chemical Reaction Datasets for AI: Introducing ORDerly\ud83c\udf1f\n\nIn the realm of life sciences, machine learning holds immense promise for discovering new molecules and accelerating product development. However, the availability of high-quality open-source datasets for chemical reactions has been limited. \n\n\ud83c\udf96 The team composed by Daniel Wigh,\u00a0Joe Arrowsmith,\u00a0Alexander P.,\u00a0Kobi Felton and Alexei Lapkin proposed #ORDerly, a practical Python package designed to simplify the organization of chemical reaction data according to the Open Reaction Database (ORD) schema.\n\n\ud83d\udd0d ORDerly focuses on meticulous data cleaning, a crucial step for training accurate machine learning models. Efforts are dedicated to crafting datasets for forward prediction, retrosynthesis, and pioneering the first benchmark for reaction condition prediction.\n\n\ud83e\udde0  Delving into the intricacies of chemical reactions, ORDerly is used to train neural networks for condition prediction. Our findings emphasize the significance of thorough cleaning steps, underscoring their impact on performance metrics. Additionally, we explore the versatility of this approach by training transformers for forward and retrosynthesis prediction.\n\n\ud83d\ude80 ORDerly isn't just a tool; it's a practical solution. By providing this open-source resource, the scientific community is empowered to explore machine learning applications in chemistry with precision and reliability.\n\n\ud83d\udd17 Explore ORDerly on #GitHub: https:\/\/lnkd.in\/eu-uWbRf\n\ud83d\udcda Read the Publication: 10.26434\/chemrxiv-2023-qkjtb-v2 \n\n#ChemicalResearch #MachineLearning #ScientificInnovation #OpenSourceTools #AdvancementsInScience \ud83c\udf10\ud83d\udd2c","linkedinURL":"https:\/\/www.linkedin.com\/feed\/update\/urn:li:activity:7127625763473772544","githubURL":null,"paperURL":null,"author":"Antonio Benedetti","createdDate":"11\/06\/2023"},{"title":"The title is: Advancing Decision-Making in Chemical Industry: Hierarchical Planning-Scheduling-Control","description":"\ud83d\udcca Advancing Decision-Making in Chemical Industry: Hierarchical Planning-Scheduling-Control \ud83e\uddea\n\nIn chemical companies, decisions are often made separately for planning, scheduling, and control. Traditionally, these areas were approached one after the other, but recent trends emphasize integrating them, focusing on feasibility and optimality at lower levels. This shift has led to the development of complex, but also challenging, potentially multi-level hierarchical formulations. \n\n\ud83c\udfaf Damien van de Berg, Nilay Shah, and Ehecatl Antonio del Rio Chanona recently delve into this complexity. Their research advocates for a holistic approach, combining lower-level feasibility with optimality in large-scale, multi-level hierarchical formulations. To tackle the ensuing challenges, they turn to cutting-edge techniques: optimality surrogates and derivative-free optimization.\n\n\ud83e\udde0 Their study offers a comprehensive roadmap, demonstrating a step-by-step workflow to solve a tri-level formulation of a multi-site, multi-product planning-scheduling-control scenario. By evaluating the tractability and accuracy of both optimality surrogates and derivative-free optimization, the team uncovers their individual strengths and limitations.\n\n\u2696\ufe0f Despite advancements over conventional heuristics, both techniques have drawbacks. In response, the researchers synthesize their findings into a methodology that combines the strengths of these approaches. Importantly, this method remains adaptable, accommodating various level-specific formulations by identifying linking variables. It also retains the traditional heuristic sequential solution as a fallback option, ensuring a robust and flexible decision-making framework.\n\n\ud83c\udf1f Pushing the boundaries of the field, the team employs innovative strategies such as parallelization, hyperparameter tuning, and a blend of off- and on-line computation. \n\n\ud83d\udd17 Explore the Implementations: https:\/\/lnkd.in\/e8mJJxj9\n\ud83d\udcda Read the Preprint: arXiv:2310.07870\n\n#ChemicalIndustry #DecisionMaking #HierarchicalApproach #OptimalitySurrogates #ScientificInnovation \ud83c\udf10\ud83d\udd2c\ud83d\udcca","linkedinURL":"https:\/\/www.linkedin.com\/feed\/update\/urn:li:activity:7127263367798366210","githubURL":null,"paperURL":null,"author":"Antonio Benedetti","createdDate":"11\/06\/2023"},{"title":"The title is: Scaling strategy for cell and gene therapy bioreactors based on turbulent parameters","description":"\ud83d\udd0d Scaling strategy for cell and gene therapy bioreactors \ud83d\ude80\n\nMost (bio)pharma companies are looking into insights in the field of bioreactor scale-up\/-down. \n\n\ud83d\udcda We recently came across an exciting article titled \"Scaling strategy for cell and gene therapy bioreactors based on turbulent parameters\" by Dima Iurashev, Peter Anthony Jones, Nadejda (Nadi) Andreev, Yana Wang, Tomoko Iwata-Kajihara, Barbara Kraus, and Juan A. Hernandez Bort, PhD.\n\n\ud83d\udcc8 The very interesting article introduces the critical concept of Kolmogorov length, shedding light on the impact of turbulent flow on cell integrity in reactor vessels. The study, which focused on the scalability of iPSC-derived lymphocyte production, spans volumes from 0.1 to 10 L, aligning with the scales commonly used in this domain. \n\nBy combining Computational Fluid Dynamics (#CFD) simulations with empirical models, the authors offer a comprehensive understanding of agitation speed and shear stress adjustments, enabling smoother process transfer between scales and bioreactor types.\u00a0 \n\nThese findings are very useful for the optimization of pharma processes, facilitating better product quality and yield.\u00a0\n\ud83d\udc4f Kudos to the authors for their innovative work! \ud83d\udc4f\n\n\ud83d\udd17 Link to the article: https:\/\/lnkd.in\/ekfgSE_k","linkedinURL":"https:\/\/www.linkedin.com\/feed\/update\/urn:li:activity:7126929444253888512","githubURL":null,"paperURL":null,"author":"Harry Christodoulou","createdDate":"11\/05\/2023"},{"title":"The title is: Exploring Chromatography Modeling and the Equilibrium Dispersion Model (EDM)","description":"\ud83d\udd2c Exploring Chromatography Modeling and the Equilibrium Dispersion Model (EDM) \ud83e\uddea\n\nIn the field of chromatography modeling, simplicity often conceals profound insights. In this work, researchers Konstantinos Katsoulas, Monica Tirapelle, Eva Sorensen MBE, and Luca Mazzei study the Equilibrium Dispersion Model (EDM).\n\n\ud83d\udd0d  EDM is a model that elegantly balances complexity and accuracy. At its core, EDM incorporates an apparent dispersion coefficient, a critical factor for accounting for mass transfer between phases. Yet, debates have persisted on which expression of this coefficient is the most accurate and applicable.\n\n\ud83c\udf31 To settle this debate, the team derived the EDM from the more intricate pore diffusion model (POR), an approach rooted in fundamental physical assumptions. Through rigorous analysis, they unearthed the correct formulation of the apparent dispersion coefficient, aligning with the less commonly used expression.\n\n\u2699\ufe0f To validate their findings, simulations were conducted, comparing EDM versions and the POR model. These simulations, run within a range where EDM and POR should be equivalent, affirmed the accuracy of their derived coefficient, providing concrete evidence for its application.\n\n\ud83d\udcda This study not only fortifies the theoretical foundations of EDM but also offers a practical guide, ensuring its correct application in chromatography modeling.\n\n\ud83d\udc4f Kudos to the author for this great publication!\n\n\ud83d\udcda Link to Publication: https:\/\/lnkd.in\/eWQ9CnZR\n\n#ChromatographyModeling #EquilibriumDispersionModel #ScientificInsights #AdvancedMathematics #InnovativeResearch \ud83c\udf10\ud83d\udd2c","linkedinURL":"https:\/\/www.linkedin.com\/feed\/update\/urn:li:activity:7126594386192130048","githubURL":null,"paperURL":null,"author":"Antonio Benedetti","createdDate":"11\/04\/2023"},{"title":"The title is: Rational Scale-Up of Catalytic Hydrogenation Involving Slowly Dissolving Reactants","description":"\ud83d\ude80 Scale-up of catalytic hydrogenation \ud83d\ude80\n\n\ud83d\udcda We came across a very interesting article titled \"Rational Scale-Up of Catalytic Hydrogenation Involving Slowly Dissolving Reactants\" by Filippo Nanto, Dario Ciato, and Paolo Canu.\n\n\ud83d\udcc3 The paper presents a model (\ud83e\uddeabased on an experimental campaign\ud83e\uddea), which addresses the challenges of scaling up a fed-batch catalytic hydrogenation process when dealing with slowly dissolving reagents. \n\n\ud83d\udcc8 The model considers mass transfer rates across the four phases, with a focus on solid reagent dissolution as the limiting factor. It incorporates chemical kinetics data for seven reactions, obtained from laboratory scale experiments. \n\n\ud83d\udcca \ud83c\udf10 Sensitivity analysis explored product purity, batch time, and dissolution time at a pilot scale. It was found that stirring played a crucial role in promoting solid dissolution and reducing batch time, with a more significant impact at lower temperatures.\n\nThe authors provide a rational approach to the scale-up of hydrogenation processes involving slowly dissolving reagents.\u00a0It is a testament to the power of research and modelling in improving efficiency and sustainability in chemical manufacturing. \ud83c\udf31\n\n\ud83d\udc4f Congratulations to the authors! \ud83d\udc4f\n\n\ud83d\udd17 Link to the article: https:\/\/lnkd.in\/grfVKkDm","linkedinURL":"https:\/\/www.linkedin.com\/feed\/update\/urn:li:activity:7126255536102133760","githubURL":null,"paperURL":null,"author":"Harry Christodoulou","createdDate":"11\/03\/2023"},{"title":"The title is: Advancing mAb Production: Optimizing Feed Nutrient Manipulation in Fed-Batch Bioreactors","description":"\ud83d\udd2c Advancing mAb Production: Optimizing Feed Nutrient Manipulation in Fed-Batch Bioreactors \ud83e\uddea\n\nMammalian cell cultivation is a meticulously orchestrated process, where the formulation of culture media is an intricate dance of substrates and amino acids. In the pursuit of enhancing the production of monoclonal antibodies (mAbs), researchers Wil Jones and Dimitrios I. Gerogiorgis introduce a dynamic in-silico optimization approach that looks an interesting concept to achieve substantial improvements.\n\n\ud83c\udf31 The foundation of this study lies in dynamic flux balance modeling, a powerful in-silico technique that allows researchers to bypass the time-consuming and costly in-vivo experiments. Through dynamic simulation and optimization of reliable models, researchers can visualize the untapped potential in boosting the production of target protein products, like mAbs.\n\n\ud83c\udfaf The study conducts a sensitivity analysis, comparing dynamic optimization outcomes for industrial-scale fed-batch bioreactors, spanning a spectrum of initial conditions. It's within these bioreactors that optimized feeding trajectories come to life, thanks to the utilization of the Nonlinear Programming (NLP) model, with the well known IPOPT solver.\n\n\u2699\ufe0f The APOPT NLP optimization code, hosted on the APMonitor web server, serves as the engine driving all dynamic optimization trajectories. The research pinpoints a specific sequence \u2013 glucose, followed by glutamine, and then asparagine \u2013 that leads to notable improvements in mAb yields and viable cell counts.\n\n\ud83d\udcda Read the Publication: https:\/\/lnkd.in\/evyEvbj7 \n\ud83d\udcda Discover IPOPT Solver: https:\/\/lnkd.in\/e6JdT4A5\n\n#BioreactorOptimization #MonoclonalAntibodies #DynamicModeling #ScientificAdvancements #IndustrialBioprocessing \ud83c\udf10\ud83d\udd0d\ud83e\uddec","linkedinURL":"https:\/\/www.linkedin.com\/feed\/update\/urn:li:activity:7125851681518448641","githubURL":null,"paperURL":null,"author":"Antonio Benedetti","createdDate":"11\/02\/2023"},{"title":"The title is: Digitalization of Food Properties with Python","description":"\ud83d\udda5\ufe0f Digitalization of Food Properties with Python \ud83d\udc0d\n\n\ud83d\ude80 In today's fast-paced world, digitalization has become the cornerstone of innovation and growth. When harnessed correctly, it can lead to a revolution in the Life Sciences Industry, setting the stage for a future of enhanced productivity, cost reduction, and unprecedented manufacturing capabilities. \ud83d\ude80\n\n\ud83c\udf1f We recently came across scisuit 1.1.2 by Gokhan Bingol, PhD. A very interesting and useful Python package for food process engineers and modelers in the Food industry. \n\n\ud83d\udcc8 Scisuit simplifies the calculation\/automation of various food properties, making it not only easier to work with data but also enabling the modelling of a broader range of processes. It is a tool that empowers professionals to do more in less time. \n\n\ud83d\udcda Want to dive deep into the world of \"Digitalization of Food Properties using Python with Applications\"? A detailed documentation resource is provided on the website: https:\/\/www.pebytes.com\/. \n\n\ud83d\udd17 You can find scisuit 1.1.2 in Github: https:\/\/lnkd.in\/eanERtkS\n\n\ud83c\udf89 Congratulations to Gokhan Bingol, PhD for developing the tool and making it available for others to use! We are looking forward to future releases and initiatives! \ud83d\udc4f \ud83d\udc4f","linkedinURL":"https:\/\/www.linkedin.com\/feed\/update\/urn:li:activity:7125426705753628672","githubURL":null,"paperURL":null,"author":"Harry Christodoulou","createdDate":"11\/01\/2023"},{"title":"The title is: Digitalizing the TIM-1 Model using Computational Approaches","description":"\u2b50 Digitalizing the TIM-1 gastrointestinal model \u2b50\n\n\ud83d\udd2c For nearly three decades, the TIM-1 gastrointestinal model has been at the forefront of biorelevant dissolution testing, closely simulating the human gastrointestinal tract. Within the pharmaceutical sector, TIM-1 system plays an important role in aiding drug product design and offering a biopredictive evaluation of drug product performance. \ud83d\udc8a\n\n\ud83d\ude80 We recently found this exciting paper, titled \"Digitalizing the TIM\u20111 Model using Computational Approaches\u2212Part One: TIM\u20111 Data Explorer\" by  Inese Sarcevica, Bart Hens, Irena Tomaszewska, and Mark McAllister. \n\nIn this\u00a0article, the authors introduce: TIM-1 Data Explorer. This  tool delves into the intricacies of fluid and mass balance, enabling a comprehensive understanding of experimental data.\u00a0Additionally, the tool empowers quantitative predictions of drug behaviour during TIM-1 experiments, including dissolution and precipitation.\n\nTwo case studies are used for validation: one with paracetamol and another with a weakly basic compound, PF-07059013. In both cases, the TIM-1 Data Explorer showcased good accuracy.\n\n\ud83d\ude4c Congratulations to the authors for the publication! \ud83d\ude4c\n\n\ud83d\udd17 Read the full article here:\u00a0https:\/\/lnkd.in\/eYzDP-WH\n\n#TIM-1 #Digitalization #Pharma-Modelling #ComputationalApproaches","linkedinURL":"https:\/\/www.linkedin.com\/feed\/update\/urn:li:activity:7125063727678124032","githubURL":null,"paperURL":null,"author":"Harry Christodoulou","createdDate":"10\/31\/2023"},{"title":"The title is: Optimal Indicator-Variable Approach for Trajectory Synchronization in Uneven-Length Multiphase Batch Processes","description":"\ud83d\ude80 Trajectory synchronization in uneven-length multiphase batch processes \ud83d\ude80\n\n\ud83d\udd0d Partial least-squares (PLS) regression models used for evaluating the end-point product quality in #Batch processes necessitate equal lengths for all measured variable trajectories across historical batches. \n\n\ud83d\udcda In our exploration of this topic, we stumbled upon a captivating article titled \"Optimal Indicator-Variable Approach for Trajectory Synchronization in Uneven-Length Multiphase Batch Processes\" by Francesco Sartori, Pierantonio Facco, Federico Zuecco, Fabrizio Bezzo, and Massimiliano Barolo.\n\n\ud83d\udca1 This paper introduces an optimal indicator-variable approach for phase partitioning and trajectory synchronization in uneven-length multiphase batch processes. The method automates phase partitioning and indicator variable selection, making it truly process-agnostic, suitable for complex batch processes, and efficient in terms of computational time. Tests with an industrial fed-batch process and a simulated penicillin (#pharma) manufacturing process demonstrate its performance. \ud83d\udca1\n\u00a0\n\ud83c\udf89\ud83c\udf89 Congratulations to the authors for their remarkable work! \ud83d\udc4f\ud83d\udc4f\n\n\ud83d\udd17 Link to the article: https:\/\/lnkd.in\/ec6AWpqp\n\n#PLS #Trajectory #Synchronization #BatchProcesses","linkedinURL":"https:\/\/www.linkedin.com\/feed\/update\/urn:li:activity:7124732739433455616","githubURL":null,"paperURL":null,"author":"Harry Christodoulou","createdDate":"10\/30\/2023"},{"title":"The title is: Machine Learning for Energy-Efficient Fluid Bed Dryers in Pharma","description":"\ud83c\udf1f Machine Learning for Energy-Efficient Fluid Bed Dryers in Pharma \ud83c\udf1f\n\n\ud83d\udd2c The pharmaceutical industry is undergoing a transformative phase, with a keen focus on cost containment and evolving healthcare regulations. One area where innovation is making a significant impact is the optimization of drug production equipment, particularly fluid bed dryers. \ud83d\udd2c \n\n\ud83d\udcda We recently came across an intriguing paper titled \"Machine Learning for Energy-Efficient Fluid Bed Dryer Pharmaceutical Machines\" by Roberto Barriga, Miquel Romero Obon and Houcine Hassan. This research showcases one way of how AI\/ML algorithms can be used by the Life Sciences manufacturing industry.\n\n\ud83d\udcd6 The authors used Exploration Data Analysis (EDA) and a Catboost machine-learning model. According to the article, the Catboost (Categorical Boosting) model was used effectively to reduce preheating phase time, resulting in significant energy savings. \n\n\ud83d\udca1 By continuously monitoring critical parameters, a paradigm shift from the conventional fixed-time models was achieved.\ud83d\udca1 \n\n\ud83c\udf89 Congratulations to the authors for their contribution! \ud83d\udc4f\n\n\ud83d\udd17 Link to the article: https:\/\/lnkd.in\/e7vJ3p3V\n\n#FluidBedDryers #MachineLearning #Catboost #EDA","linkedinURL":"https:\/\/www.linkedin.com\/feed\/update\/urn:li:activity:7124357456792580096","githubURL":null,"paperURL":null,"author":"Harry Christodoulou","createdDate":"10\/29\/2023"},{"title":"The title is: Mixed Solvent Electrolyte Solutions: A Review and Calculations with the eSAFT-VR Mie Equation of State","description":"\ud83c\udf1f eSAFT-VR Mie for Mixed Solvent Electrolyte Solutions \ud83c\udf1f\n\n\ud83d\udd2c Interest in the electrolyte thermodynamics is continually growing, driven by the notable impact of electrolyte presence in pharmaceutical processes.\n\n\ud83d\udcda On this subject we found the very interesting paper titled \"Mixed Solvent Electrolyte Solutions: A Review and Calculations with the eSAFT-VR Mie Equation of State\" by Nefeli Novak, Georgios Kontogeorgis, Marcelo Castier, and Ioannis Economou.\n\n\ud83d\udcd6 The authors conducted a literature review of existing electrolyte activity coefficient models and electrolyte equations of state (eEoS) for modelling mixed solvent electrolyte systems. Their analysis highlights the order of difficulty in property predictions: VLE, MIAC (mixed-solvent mean ionic activity coefficients), and LLE (the hardest \ud83d\udca5).\n\n\ud83d\udcbb eSAFT-VR Mie was used to predict MIAC, VLE, and LLE in mixed solvents. The model, initially parameterized for aqueous electrolyte solutions, was successfully extended to non-aqueous, single solvent electrolyte solutions. It yielded good results for MIAC and VLE, and while LLE remains challenging, it shows potential in quantitative calculations.\n\n\ud83c\udf89 Congratulations to the authors for their contribution! \ud83d\udc4f\n\n\ud83d\udd17 Link to the article: https:\/\/lnkd.in\/ekbrwUTU\n\n#Thermodynamics #Electrolytes #Pharma #Modelling","linkedinURL":"https:\/\/www.linkedin.com\/feed\/update\/urn:li:activity:7123985631105413120","githubURL":null,"paperURL":null,"author":"Harry Christodoulou","createdDate":"10\/28\/2023"},{"title":"The title is: i-SHIPMENT: A Digital Platform for the Design of Patient-Centric Supply Chains.","description":"\ud83d\udcbb Digital Platform for the design of patient-centric supply chains \ud83d\ude80\n\n\ud83d\udcda We have stumbled upon an exciting article titled \"A digital platform for the design of patient-centric supply chains\". This work introduces \"i-SHIPMENT,\" a digital platform which aims to assist the design and assessment of supply chain structures that can reliably and cost-efficiently deliver autologous Chimeric Antigen Receptor (CAR) T cell therapies.\n\n\ud83e\ude7a Chimeric Antigen Receptor (CAR) T cell therapies is an approach to treating acute lymphoblastic leukaemia and aggressive B cell lymphoma. Unlike traditional cancer treatments, CAR T cell therapies are tailored to each patient, making them unique in manufacturing and distribution. \n\n\ud83c\udf10 i-SHIPMENT stands for \"Individualised Supply cHain oPtimisation in Personalised MEdicine Treatments\". The tool can help build supply chains which can make personalized medicine accessible and cost-effective (#TotalCostMinimization). All the models have been implemented in #Python and #Pyomo.\n\n\ud83d\udcc8 This article is must-read for scientists interested in the intersection of cutting-edge medicine, supply chain optimization, and patient-centered care. Congratulations to the authors: Niki Triantafyllou, Andrea Bernardi, Matthew Lakelin, Nilay Shah & Maria Papathanasiou.\n\n\ud83d\udd17 Link to the article: https:\/\/lnkd.in\/gMqrTUik\n\n#Innovation #Pharmaceuticals #Optimization #SupplyChain #Pyomo","linkedinURL":"https:\/\/www.linkedin.com\/feed\/update\/urn:li:activity:7123631932940156928","githubURL":null,"paperURL":null,"author":"Harry Christodoulou","createdDate":"10\/27\/2023"},{"title":"The title is: Enhancing Process Design and Operations: Feasibility-Focused Optimization Perspectives","description":"\ud83c\udf10 Enhancing Process Design and Operations: Feasibility-Focused Optimization Perspectives \ud83d\udcca\n\nWhen dealing with process design and operations, understanding feasibility and flexibility is paramount. Huayu Tian, Jnana Sai Jagana, Qi Zhang, and Marianthi Ierapetritou present a comprehensive overview of key concepts and computational approaches that delve deep into these crucial aspects.\n\n\ud83e\udde0 This paper delves into cutting-edge topics, emphasizing feasible region evaluation, feasibility-based optimization, and the integration of flexibility requirements. These aspects are pivotal, especially in navigating the complexities of multiple constraints within black-box optimization contexts.\n\n\ud83c\udfaf The study sheds light on the efficient incorporation of constraints through process feasibility evaluation and feasibility-based optimization. By avoiding unnecessary exploration of infeasible spaces, these methods streamline the optimization process, enhancing efficiency and resource utilization.\n\n\u2699\ufe0f Furthermore, the paper explores the intricate relationship between flexibility analysis and robust optimization, highlighting the potential synergies between the two. These synergies open doors to novel opportunities in the realm of process design and optimization strategies.\n\n\ud83d\udd2c Real-world applications in pharmaceutical design and process scheduling provide concrete contexts, showcasing the practicality and applicability of the presented approaches in industrial settings.\n\n\ud83d\udcda Read the Publication: https:\/\/lnkd.in\/ekBssstg\n\n#ProcessOptimization #FeasibilityAnalysis #FlexibilityOptimization #IndustrialProcesses #ScientificAdvancements \ud83c\udf10\ud83d\udd2c\ud83e\uddea","linkedinURL":"https:\/\/www.linkedin.com\/feed\/update\/urn:li:activity:7123263002627186689","githubURL":null,"paperURL":null,"author":"Antonio Benedetti","createdDate":"10\/26\/2023"},{"title":"The title is: Advancing Catalytic Reactions: Adaptive Optimization for Enhanced Efficiency","description":"\ud83e\uddea Advancing Catalytic Reactions: Adaptive Optimization for Enhanced Efficiency \ud83c\udf1f\n\nWe have seen multiple times that in industrial processes, catalytic reactions significantly enhance efficiency and sustainability. However, the complexity arising from categorical and continuous variables often poses challenges for optimization methods.\n\nIn this recent study, Naser Aldulaijan, Joe Marsden, Jamie Manson, and Adam Clayton introduce the Adaptive Latent Bayesian Optimizer (#ALaBO). This algorithm addresses the complexities of mixed variable chemical reactions, offering a promising approach to optimization.\n\n\ud83d\udd0d ALaBO showcases its effectiveness through various test problems based on simulated kinetic data of catalytic reactions, demonstrating its ability to navigate intricate chemical landscapes.\n\n\ud83d\udca1 Integrated with a continuous flow reactor, ALaBO achieves a notable feat: the rapid self-optimization of a Suzuki\u2013Miyaura cross-coupling reaction involving six distinct ligands. Within a limited budget of 25 experiments, ALaBO identifies a substantial 93% yield, highlighting its practical efficiency and potential impact.\n\n\ud83d\udd17 Explore ALaBO on #GitHub: https:\/\/lnkd.in\/eg3V9b3h\n\ud83d\udcda Read the Publication: https:\/\/lnkd.in\/eUwHiPZ3\n\n#CatalyticReactions #BayesianOptimization #ChemicalEngineering #ScientificInnovation #EfficiencyEnhancement \ud83c\udf10\ud83d\udd2c\ud83d\udd0d","linkedinURL":"https:\/\/www.linkedin.com\/feed\/update\/urn:li:activity:7123014768520491009","githubURL":null,"paperURL":null,"author":"Antonio Benedetti","createdDate":"10\/25\/2023"},{"title":"The title is: Kinetic Studies of Reactions in Antibody-Drug Conjugate Synthesis","description":"\ud83c\udf1f Kinetic Studies of Reactions in Antibody-Drug Conjugate Synthesis \ud83e\uddea\n\n\ud83d\udcda We just stumbled upon an exciting publication by Subramanya Nayak, PhD, MBA and Steve Richter, investigating Antibody-Drug Conjugate synthesis. Their work, titled \"Kinetic Studies of the Partial Reduction and Conjugation Reactions in an Antibody-Drug Conjugate (ADC) Synthesis,\" is an easy recommendation for scientists and modellers in the field. \n\n\ud83d\udcaa Unlike conventional treatments, which can also damage healthy cells, Antibody Drug Conjugates are targeted medicines which deliver the \"chemotherapy agents\" \ud83d\udd75\ufe0f\u200d\u2642\ufe0f to cancer cells. \n\n\ud83d\udd2c ADCs are very powerful and useful drugs in our fight against cancer. However, their synthesis has long posed a challenge due to the heterogeneity of the resulting mixture, which affects pharmacological properties, stability & therapeutic efficacy.\n\n\ud83d\ude80This research delves deep into the kinetics of partial reduction and conjugation reactions involved in ADC synthesis. Some key findings include:\n1\ufe0f\u20e3 The partial reduction reactions are slower than the conjugation reactions and act as the rate-limiting steps.\n2\ufe0f\u20e3 Once one disulfide bond on the heavy\u2013heavy chains is broken, subsequent bonds on an antibody are preferentially reduced.\n3\ufe0f\u20e3 This results in variations in the reduction rates of positional isomers, contributing to a diverse product distribution.\n\ud83c\udfafThe authors developed kinetic models to predict the impact of process parameters on product distribution, aiding in optimizing ADC synthesis.\n\nCongratulations to the authors for their contribution!\n\n\ud83d\udd17 Link to the article: https:\/\/lnkd.in\/eCiEN3Gz\n\n#CancerTherapy #Innovation #Pharmaceuticals #ReactionKinetics","linkedinURL":"https:\/\/www.linkedin.com\/feed\/update\/urn:li:activity:7122636503272275968","githubURL":null,"paperURL":null,"author":"Harry Christodoulou","createdDate":"10\/24\/2023"},{"title":"The title is: Advancing Multivariate Batch Process Monitoring: Introducing BGen, an Open-Source Tool for Small-Data Scenarios.","description":"\ud83c\udf1f Advancing Multivariate Batch Process Monitoring: Introducing BGen, an Open-Source Tool for Small-Data Scenarios \ud83d\udcbb\n\nIn the field of multivariate batch process monitoring, challenges arise when historical data is limited, especially with new product introductions. The typical question that you often get is \"how many batches do you need build a robust process monitoring model ?\"\n\n\ud83d\udca1Luca Gasparini, (our) Antonio Benedetti, Giulia Marchese, Connor Gallagher, Pierantonio Facco, and Massimiliano Barolo decided to delve deep into this problem, presenting a pragmatic solution.\n\n\ud83e\udde0 This study refines a data-driven methodology utilizing machine learning algorithms, specifically Gaussian process state-space models. What sets this research apart is the development of automatic procedures to fine-tune various parameters within the machine-learning framework, streamlining the generation of consistent in-silico batch trajectory data. This optimization facilitates the seamless deployment of the framework at an industrial level.\n\n\ud83d\ude80 Moreover, the team introduces specialized indicators and metrics, ensuring the generated in-silico data aligns seamlessly with process monitoring requirements. This meticulous approach enhances the relevance of the data, making it invaluable for real-world applications.\n\n\ud83d\udd2c Emphasizing collaboration and community-driven progress, BGen is openly shared with the scientific community. This initiative invites Polymodelers like you to contribute and keep innovating in this field similarly to how the work of Aditya Tulsyan, Ph.D.\u00a0,\u00a0Chris Garvin\u00a0,\u00a0Cenk \u00dcndey inspired the creation of this tool!\n\n\ud83d\udd17 Explore BGen on #GitHub: https:\/\/lnkd.in\/e6VVqkPU\n\ud83d\udcda Read the #Publication: https:\/\/lnkd.in\/e5a-fu25\n\n#ProcessMonitoring #OpenSourceInnovation #CollaborativeScience #ScientificAdvancements #CommunityDrivenResearch \ud83c\udf10\ud83d\udd2c\ud83e\udd1d","linkedinURL":"https:\/\/www.linkedin.com\/feed\/update\/urn:li:activity:7122174833261465600","githubURL":null,"paperURL":null,"author":"Antonio Benedetti","createdDate":"10\/22\/2023"},{"title":"The title is: Innovating Food Industry: Mechanistic Modeling for Efficient Lactoferrin Purification","description":"\ud83e\udd5b Innovating Food Industry: Mechanistic Modeling for Efficient Lactoferrin Purification \ud83d\udcbb\n\nIn the realm of food industry processes, predictive mechanistic models are revolutionizing the landscape, offering a potent tool for in-silico downstream process development. This pioneering approach, which has found common ground in pharmaceuticals, is now making waves in the food sector. \n\n\ud83d\udd0dA noteworthy case study in this domain is this recent paper by Lukas Gerstweiler, Paulina Schad, Tatjana Trunzer, Lena Enghauser, Max Mayr and Dr Jagan Billakanti on an industrial purification of lactoferrin from bovine milk using a chromatographic process.\n\n\u2699\ufe0f This exploration delves deep into the complexities of purifying lactoferrin, considering the nuanced variables such as process water pH and the raw milk composition, which can fluctuate based on location and season. The challenge lies in achieving highly efficient processes amidst these variations.\n\n\ud83e\udde0 A predictive model, rooted in the general rate model with steric mass action binding and extended for pH dependence, was meticulously calibrated. This model, a product of rigorous lab-scale experiments combined with mechanistic modeling, accurately described the elution behavior of lactoferrin and its impurities. By evaluating parameters like flow rate, step elution conditions, and loading, the model showcased remarkable alignment with experimental data.\n\n\ud83c\udf31 The calibrated model, suitable for industrial applications, serves as a valuable tool for large-scale experiments in commercial milk processing plants. Its ability to extrapolate seamlessly without requiring recalibration underscores its reliability in practical scenarios.\n\n\ud83d\udcda Read the Publication: https:\/\/lnkd.in\/eVb6U-xJ\n\n#FoodIndustryInnovation #MechanisticModeling #LactoferrinPurification #ProcessOptimization #ScientificAdvancements \ud83c\udf10\ud83d\udd2c\ud83e\uddec","linkedinURL":"https:\/\/www.linkedin.com\/feed\/update\/urn:li:activity:7121856782699765762","githubURL":null,"paperURL":null,"author":"Antonio Benedetti","createdDate":"10\/22\/2023"},{"title":"The title is: Streamlining Pharma Innovation: Automated Workflow for Mass-Transfer Coefficient Characterization","description":"\ud83d\udd2c Streamlining Pharma Innovation: Automated Workflow for Mass-Transfer Coefficient Characterization \ud83e\uddea\n\nDive into the world of small-molecule pharmaceuticals, where biocatalytic aerobic oxidations emerged as green alternatives to traditional methods. Engineering intricacies like mass transfer and reactor design are pivotal in shaping these processes. Understanding mass transfer across various scales is vital, particularly the volumetric mass-transfer coefficient, kLa.\n\n\ud83d\udd0d Traditional methods of mass-transfer characterization can be laborious, especially with numerous processing conditions and diverse reactors. The challenge lies in meticulous planning and data capture to accurately derive kLa values. Addressing these hurdles head-on, a custom-automated reactor characterization workflow has been proposed by Keith Mattern\u00a0and\u00a0Shane Grosser.\n\n\u2699\ufe0f This automated system integrates data compression and processing scripts, coupled with automated parameter regression, ensuring swift and precise data analysis. A comprehensive analysis of system lag and error fine-tunes modeling during kLa experiments, enhancing accuracy.\n\n\ud83d\udcca Leveraging this workflow, a robust database with over 2000 distinct processing conditions in small-molecule batch chemistry reactors has been curated. Scientists can swiftly identify suitable conditions, complete with known kLa values, lowering adoption barriers and speeding up biocatalytic aerobic oxidation reaction development.\n\n\ud83d\udcda Read the Research: https:\/\/lnkd.in\/ewJgQYdy\n\n#PharmaDevelopment #BiocatalyticOxidations #AutomatedWorkflow #ScientificAdvancements #ChemEngineering \ud83c\udf10\ud83d\udd0d\ud83e\uddec","linkedinURL":"https:\/\/www.linkedin.com\/feed\/update\/urn:li:activity:7121563192094253056","githubURL":null,"paperURL":null,"author":"Antonio Benedetti","createdDate":"10\/21\/2023"},{"title":"The title is: Advancing Multiphase System Simulations: Exploring an Open-Source Computational Framework","description":" \ud83c\udf0a Advancing Multiphase System Simulations: Exploring an Open-Source Computational Framework \ud83d\udda5\ufe0f\n\nDive into the intricate world of polydisperse multiphase systems with a meticulously crafted computational framework developed by experts Deepak Kumar Singh, Pablo Brito-Parada, and Gaurav Bhutani. Their innovative work centers around the bivariate population balance equation (PBE), a fundamental mathematical framework essential for understanding the complexities of evolving systems.\n\n\ud83d\udd0d In this endeavor, the direct quadrature method of moments (DQMOM) finds its application within Fluidity, an open-source computational fluid dynamics (CFD) code. This integration allows for the numerical solution of bivariate PBE, providing deep insights into the dynamics of polydisperse multiphase systems.\n\n\u2699\ufe0f Fluidity stands out as an efficiently designed finite element (FE) CFD code, highly parallelized, and capable of mesh adaptivity on fully-unstructured meshes. Rigorous testing against spatially homogeneous bivariate PBEs, incorporating aggregation, breakage, growth, and dispersion, demonstrated remarkable accuracy, validated against analytical solutions. Additionally, benchmarking against Monte Carlo method solutions in real-world scenarios, such as gas\u2013liquid systems undergoing simultaneous bivariate aggregation and breakage, emphasized the framework's applicability in complex, practical situations.\n\n\ud83d\udcca This open-source framework, devoid of exaggeration, stands as a practical and reliable tool, offering scientists and engineers a powerful solution for simulating multifaceted polydisperse multiphase systems with unparalleled accuracy.\n\n\ud83d\udd17 Explore the Code: https:\/\/lnkd.in\/eu_FQz4y\n\ud83d\udcda Read the Research: https:\/\/lnkd.in\/eb8dKk27\n\n#MultiphaseSystems #ComputationalModeling #OpenSourceInnovation #ScientificAdvancements #FluidDynamics \ud83c\udf10\ud83d\udd0d\ud83d\udd2c","linkedinURL":"https:\/\/www.linkedin.com\/feed\/update\/urn:li:activity:7121120555038031872","githubURL":null,"paperURL":null,"author":"Antonio Benedetti","createdDate":"10\/20\/2023"},{"title":"The title is: Advancing Chemical Kinetics: Catalyst.jl for Comprehensive Chemical Reaction Network Modeling","description":"\ud83d\udd2cAdvancing Chemical Kinetics: Catalyst.jl for Comprehensive Chemical Reaction Network Modeling\ud83e\uddea\n\nMeet Catalyst.jl, a sophisticated Julia library crafted to elevate the standards of modeling and high-performance simulation in the realm of chemical reaction networks (CRNs). Developed collaboratively by experts including Torkel Loman, Yingbo Ma, Vasily Ilin, Shashi Gowda, Niklas Korsbo, Nikhil Yewale, Chris Rackauckas, and Samuel Isaacson, Catalyst.jl is a nuanced solution designed for the discerning researchers in chemical kinetics.\n\n\ud83d\ude80 Catalyst.jl offers a versatile toolkit supporting a spectrum of simulation methods for CRNs, encompassing stochastic chemical kinetics (jump process), chemical Langevin equation (stochastic differential equation), and reaction rate equation (ordinary differential equation) representations. Extensive benchmarking has revealed Catalyst's exceptional performance, often outpacing comparable tools by one to two orders of magnitude.\n\n\ud83d\udca1 Beyond its technical prowess, Catalyst.jl acts as a domain-specific language and an intermediate representation, facilitating the symbolic encoding of CRN models as native Julia objects. This distinctive feature streamlines critical tasks, including symbolic specification, analysis, and modification of CRNs. Catalyst models seamlessly transition into symbolic representations of concrete mathematical models, further compiled into optimized code for numerical solvers.\n\n\ud83e\udde0 Empowered by ModelingToolkit.jl and Symbolics.jl, Catalyst.jl enables comprehensive analysis, simplification, and compilation of models. Its flexibility shines as it integrates seamlessly with various Julia libraries, enriching its functionality and adaptability. Noteworthy open-source biological modeling projects have embraced Catalyst.jl's intermediate representation, emphasizing its wide-reaching impact in the scientific community.\n\n\ud83d\udd0d Link to #Github: https:\/\/lnkd.in\/eiynKwvg\n\ud83d\udcda Link to #Publication: https:\/\/lnkd.in\/eQbuagvP\n\n#ChemicalKinetics #ComputationalModeling #JuliaProgramming #ScientificInnovation #ChemicalResearch \ud83c\udf10\ud83d\udd0d\ud83e\uddec","linkedinURL":"https:\/\/www.linkedin.com\/feed\/update\/urn:li:activity:7120764340508471296","githubURL":null,"paperURL":null,"author":"Antonio Benedetti","createdDate":"10\/19\/2023"},{"title":"The title is: Formulating Data-Driven Surrogate Models for Process Optimization","description":"\ud83d\udcca Data-driven surrogate models for process optimization \ud83d\ude80\n\n\ud83d\udd0d We recently came across an intriguing article titled \"Formulating Data-Driven Surrogate Models for Process Optimization\" by professors Ruth Misener and Lorenz Biegler. The paper delves into the intersection of data-driven techniques, mathematical optimization, and process systems engineering (PSE). \ud83d\udd0d\n\n\ud83d\udca1 Since its inception, PSE has relied on data-driven methods and mathematical optimization, but the advent of data science and machine learning has opened up a world of new possibilities. The article addresses crucial aspects of integrating surrogates into process optimization, emphasizing robustness to uncertainties and accurate extrapolation. \ud83d\udca1\n\n\u2705 Two distinct perspectives for developing process engineering surrogates are explored: a surrogate-led approach and a mathematical programming-led approach. As these data-driven surrogate models play a pivotal role in larger process optimization problems, the article also delves into the critical verification problem. This involves ensuring that the optimum derived from the surrogate corresponds accurately to the optimum of the truth model. \u2705\n\n\ud83d\udcda The paper discusses two illuminating case studies on surrogate-based optimization. One case study focuses on heat exchanger network synthesis, while the other explores drill scheduling. \ud83d\udcda\n\n\ud83c\udf1f\ud83d\udc4f Congratulations to the authors!\ud83d\udc4f\ud83c\udf1f\n\n\ud83d\udd17 We highly recommend giving this article a read: https:\/\/lnkd.in\/eref-MGM","linkedinURL":"https:\/\/www.linkedin.com\/feed\/update\/urn:li:activity:7120369342906556416","githubURL":null,"paperURL":null,"author":"Harry Christodoulou","createdDate":"10\/18\/2023"},{"title":"The title is: Enhancing Bioprocess Insights: Multivariate Tools in Antibody Development","description":"\ud83e\udda0Enhancing Bioprocess Insights: Multivariate Tools in Antibody Development\ud83d\udcbb\n\nDeveloping cell culture processes for monoclonal antibodies is a complicated CMC journey, demanding a multitude of experiments across scales to define the process's design space and meet regulatory demands. \n\n\ud83d\udcdcThis not so recent but still valuable study by Michael Sokolov, Massimo Morbidelli, Alessandro Butte\u00e9, Jonathan Souquet, and herv\u00e9 Broly meticulously traces a comprehensive process development cycle for a biosimilar monoclonal antibody, from high throughput screening and optimization to scale-up and validation.\n\n\ud83e\uddee The essence of this analysis lies in the application of tailored multivariate tools, a toolbox primarily comprising Principal Component Analysis, Decision Trees, and Partial Least Square Regression, complemented by Genetic Algorithms. \n\n\ud83d\udccaThese tools serve as guiding lights, facilitating decision-making at every stage of the process development journey. They allow for visualizing the sequential enhancement of the high-dimensional quality profile toward the predefined target, aiding in the strategic selection of vital process variables. Moreover, they empower dynamic predictions of the complete set of product quality attributes.\n\n\ud83d\udcda Explore the #Study: https:\/\/lnkd.in\/ezQJWRfX\n\n#BioprocessDevelopment #MultivariateModeling #MonoclonalAntibodies #ScientificResearch #Biotechnology \ud83e\uddec\ud83d\udd0d","linkedinURL":"https:\/\/www.linkedin.com\/feed\/update\/urn:li:activity:7120000499927392257","githubURL":null,"paperURL":null,"author":"Antonio Benedetti","createdDate":"10\/16\/2023"},{"title":"The title is: Multi-objective optimization of adiabatic styrene reactors using Generalized Differential Evolution 3 (GDE3)","description":"\ud83d\ude80 Multi-objective optimization with Generalized Differential Evolution 3 \ud83d\ude80\n\n\ud83c\udf1f We recently stumbled upon a very interesting research paper titled \"Multi-objective optimization of adiabatic styrene reactors using Generalized Differential Evolution 3 (GDE3)\" by Bruno Leite, Andr\u00e9a Oliveira Souza da Costa, and Esly Ferreira da Costa Junior.\n\n\ud83d\udd2c What is it about?\nIn this study, industrial styrene reactors are optimized using a multi-objective algorithm, GDE3, aiming to maximize both conversion and selectivity. \n\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\n\ud83d\udcc8 The paper goes through multiple optimal scenarios, employing two- and three-objective approaches. The authors investigate the impact of various factors, including the steam-to-ethylbenzene molar feed ratio, catalyst bed count, catalyst loading, operating pressure, and inlet temperatures on reactor performance.\n\n\ud83d\udca1This paper suggests ways to enhance reactor performance and efficiency. Moreover, the authors have generously shared their GDE3 implementation, making it available in a public code repository and a Python package. This open-source approach fosters collaboration and knowledge sharing within our community.\n\n\ud83d\udd17 Source code: https:\/\/lnkd.in\/ewJufvJj\n\ud83d\udd17 Link to the article: https:\/\/lnkd.in\/eNzREyru\n\n\ud83d\udc4f Kudos to the authors! We hope to see more exciting work on #Optimization\ud83d\udc4f\n\n#ChemicalEngineering #Optimization #OpenSource","linkedinURL":"https:\/\/www.linkedin.com\/feed\/update\/urn:li:activity:7119730507503788032","githubURL":null,"paperURL":null,"author":"Harry Christodoulou","createdDate":"10\/16\/2023"},{"title":"The title is: Decoding Chemical Complexities: Thermodynamic Modeling of Formaldehyde Solutions","description":"\ud83e\uddea Decoding Chemical Complexities: Thermodynamic Modeling of Formaldehyde Solutions \u2697\ufe0f\n\nFormaldehyde, highly reactive and often stabilized in aqueous solutions with methanol, undergoes intricate reactions forming diverse products, including oligomers. These reactions, occurring in both liquid and vapor phases, significantly impact the properties of formaldehyde-containing solutions. Understanding vapor-liquid equilibria (VLE) in these solutions, given these complexities, is crucial for many industries including pharmaceutical ones.\n\n\ud83c\udf21\ufe0f In this study by Malak Wehbe, Ph.D., MRSC, Andrew Haslam, Salvador Garc\u00eda Mu\u00f1oz, George Jackson & Amparo Galindo, researchers employ the SAFT-\u03b3 Mie group-contribution equation of state. It unveils the fluid-phase behavior of binary and ternary mixtures involving formaldehyde, water, and methanol. A unique physical approach implicitly models oligomerization reactions, providing insights into chemical speciation in formaldehyde + water, formaldehyde + methanol, and formaldehyde + water + methanol mixtures.\n\n\ud83e\uddca A new group, CH2O, characterizing formaldehyde, emerges within the SAFT-\u03b3 Mie GC approach. Guided by experimental data for binary mixtures, interaction parameters are optimized. They enable accurate forecasts for the VLE of ternary formaldehyde + water + methanol mixtures across diverse temperatures and pressures, aligning closely with experimental data.\n\n\ud83d\udd2c Moreover, the SAFT-\u03b3 Mie approach, as demonstrated, adeptly predicts \nthe distribution of reaction species, particularly oligomers, within binary and ternary mixtures containing formaldehyde. This nuanced exploration stands as a testament to the intricate interplay of chemicals, shaping the landscape of industrial applications.\n\n\ud83d\udcda Explore the #Study: https:\/\/lnkd.in\/eT7B-UzM \n\n#ChemicalModeling #Thermodynamics #ChemicalSolutions #Research #ChemicalEngineering \ud83e\uddea\ud83c\udf21\ufe0f\ud83d\udd0d","linkedinURL":"https:\/\/www.linkedin.com\/feed\/update\/urn:li:activity:7119369557412048896","githubURL":null,"paperURL":null,"author":"Antonio Benedetti","createdDate":"10\/15\/2023"},{"title":"The title is: Advancing Pharmaceutical Manufacturing: A New Model for Predicting Powder Blend Flowability","description":"\ud83d\udc8a Advancing Pharmaceutical Manufacturing: A New Model for Predicting Powder Blend Flowability \ud83d\udcc8 \n\nIn OSD drug product development, predicting the flowability of powder blends is paramount for efficient manufacturing. Traditionally, decisions about manufacturing routes and formulations rely on the properties of the Active Pharmaceutical Ingredient (API). However, current methods involve extensive experimental work, leading to high labor and API consumption, thereby increasing costs.\n\n\ud83d\udd0d In this study, Magdalini Aroniada, Gabriele Bano, Yuliya Vueva, (our) Harry Christodoulou, Feng Li, and Jim Litster present a practical solution. They introduce a novel mixing rule designed to predict powder blend flowability, specifically for formulations created through Direct Compression (DC). Departing from conventional approaches, this model offers a cost-effective alternative, streamlining the prediction process.\n\n\ud83d\udee0\ufe0f This model operates on the assumption that cohesive forces dominate interactions between granular solids. It's calibrated based on typical industrial data, ensuring its applicability in real-world scenarios. Its versatility shines through, adaptable to a range of DC-relevant formulation compositions. This adaptability makes it a valuable tool for pharmaceutical engineers, promising accurate predictions without the need for extensive experiments.\n\n\ud83d\udcca Validation involved diverse APIs, confirming its effectiveness in predicting flowability properties across various formulations. Additionally, the researchers explored the correlation between the model and API properties like shape and size, enhancing its practical applicability.\n\n\ud83d\udcda Read the #Paper: https:\/\/lnkd.in\/eh78gZxS\n\n#PharmaceuticalManufacturing #PowderBlendFlowability #Modeling #DirectCompression #Research \ud83e\uddea\ud83c\udf2c\ufe0f\ud83d\udd2c","linkedinURL":"https:\/\/www.linkedin.com\/feed\/update\/urn:li:activity:7118908503276015616","githubURL":null,"paperURL":null,"author":"Antonio Benedetti","createdDate":"10\/14\/2023"},{"title":"The title is: Validating Model-Based Design of Experiments (MBDoE) for Continuous Wet Granulation and Drying Optimization","description":"\ud83e\uddea Validating Model-Based Design of Experiments (MBDoE) for Continuous Wet Granulation and Drying Optimization \ud83d\udd0d\n\nMBDoE is a fantastic technique that places process models at the center of process development. It helps design more targeted and informative experiments to explore the design space in silico, enhancing the knowledge that can be obtained from it.\n\n\ud83d\udd2cHowever, it's also possible to achieve this while minimizing the number of experiments, and this is precisely what Kensaku Matsunami, Tuur Vandeputte, Ana Alejandra Barrera Jim\u00e9nez, Michiel Peeters, Michael Ghijs, Daan Van Hauwermeiren, Fanny Stauffer, Eduardo dos Santos Schultz, Ingmar Nopens, and Thomas De Beer have demonstrated here.\n\n\ud83d\udd0d This framework integrates three meticulously developed models. First, a T-shaped partial least squares regression model predicts granule d-values after wet granulation, considering various process settings. Next, a hybrid population balance and partial least squares regression model computes a detailed granule size distribution. Finally, a mechanistic model of fluid-bed drying simulates drying time and energy efficiency, incorporating the outputs of the first two models.\n\n\ud83d\udee0\ufe0f In this application case, these models were applied to determine optimal operating conditions based on material properties and formulation characteristics. The framework's validation, achieved by comparing simulation results with experimental data, demonstrated its prowess. By significantly reducing material consumption by 73.2% and saving 72.3% of time, especially in the early process development phase, this framework showcases its potential to streamline pharmaceutical production.\n\n\ud83d\udcda Read the #Paper: https:\/\/lnkd.in\/eG47Xd6r\n\n#PharmaceuticalManufacturing #ExperimentDesign #ProcessOptimization #Innovation \ud83e\uddea\ud83d\udd0d\ud83c\udf1f","linkedinURL":"https:\/\/www.linkedin.com\/feed\/update\/urn:li:activity:7118624261736382464","githubURL":null,"paperURL":null,"author":"Antonio Benedetti","createdDate":"10\/13\/2023"},{"title":"The title is: ReactionDataExtractor 2.0: A Sophisticated Tool for Bridging Chemical Structure Graphs & Data with AI","description":"\ud83d\udd2cBridging Chemical Structure Graphs & Data with AI: Introducing ReactionDataExtractor 2.0 \ud83d\udcca\n\nAutomatising the extraction of info from chemical data, particularly when it involves intricate graphical representations like chemical reaction schemes, has been a significant challenge. Damian M. Wilary and Jacqueline M. Cole have made significant strides with ReactionDataExtractor 2.0, a sophisticated tool that combines neural networks and symbolic artificial intelligence seamlessly.\n\n\ud83c\udf10 Traditional dissemination of chemical knowledge relies heavily on visually intuitive reaction schemes, a language universally understood by chemists but often a puzzle for machines ( and even for ChemEng \ud83d\ude05 ). Existing tools grapple with limitations, necessitating manual preprocessing and impeding the extraction process. Enter ReactionDataExtractor 2.0, a solution that overcomes these hurdles, fusing advanced neural networks with symbolic AI to bridge the gap between human-intuitive graphics and machine-extractable data.\n\n\ud83d\udd0dThis tool's performance is exceptional, boasting F1 scores ranging from 75% to 96% on a diverse test set sourced from open-source journal articles. What sets this approach apart is the ability to further enhance these metrics. A data-driven methodology using synthetically generated data has been approached, allowing them to fine-tune their object-detection models for specific chemical subdomains.\n\n\ud83d\udee0\ufe0f Crucially, ReactionDataExtractor 2.0 features a modular architecture that strikes a perfect balance between speed and accuracy, ensuring a seamless, high-throughput chemical data extraction experience. \n\n\ud83d\udcda Explore the #Paper: https:\/\/lnkd.in\/eVh9F6gj\n\ud83d\udd17 Dive into the #GitHub Repository: https:\/\/lnkd.in\/efF9RdTu\n\n#ChemicalDataExtraction #AIInnovation #DataOptimization #ChemicalInnovation #AI #artificialintelligence \ud83e\uddea\ud83d\udd2c\ud83c\udf1f","linkedinURL":"https:\/\/www.linkedin.com\/feed\/update\/urn:li:activity:7118329847088562176","githubURL":null,"paperURL":null,"author":"Antonio Benedetti","createdDate":"10\/12\/2023"},{"title":"The title is: Advancing Chemical Processes: Exploring SI-M\/O for Complex Synthesis Reactions","description":"\ud83e\uddea Advancing Chemical Processes: Exploring SI-M\/O for Complex Synthesis Reactions \ud83d\udcca\n\nIf you've delved into reaction modeling, encountering reactions with unknown mechanisms is almost inevitable. In response to this challenge, Min Wu, Ulderico Di Caprio, Furkan Elmaz, Florence Vermeire, Bert Metten, Olivier Van Der Ha, Dries De Clercq, Siegfried Mercelis, Peter Hellinckx, Leen Braeken, and M. Enis Leblebici have pioneered SI-M\/O. This algorithm integrates swarm intelligence with chemical process fundamentals, providing a much-needed solution in this field.\n\n\ud83c\udf10 This unique approach integrates the exploratory abilities of swarm intelligence with essential knowledge of chemical reactions and thermodynamics. SI-M\/O not only discovers optimal solutions but also ensures chemical feasibility and complies with physical constraints. In a practical application, SI-M\/O led to a significant 5.3% productivity increase in a production plant, highlighting its practical effectiveness.\n\n\ud83d\udd0d Moreover, the researchers have developed a user-friendly graphical interface, enhancing accessibility for both researchers and practitioners. Powered by the PySwarms library, this development paves the way for enhanced chemical optimization methodologies.\n\n\ud83d\udcda Read the #Paper: https:\/\/lnkd.in\/esQsrayV \n\ud83d\udd17 #GitHub Repository: https:\/\/lnkd.in\/ehPPEMzi\n\n#ChemicalProcesses #SwarmIntelligence #DataOptimization #Innovation \ud83e\uddec\ud83d\udd2c\ud83c\udf1f","linkedinURL":"https:\/\/www.linkedin.com\/feed\/update\/urn:li:activity:7117826211631779840","githubURL":null,"paperURL":null,"author":"Antonio Benedetti","createdDate":"10\/10\/2023"},{"title":"The title is: Scale-up of heat transfer in a rotary drum Equipped with baffles","description":"\ud83c\udf1f Scale-up of Rotary Drums featuring Baffles \ud83c\udf1f\n\n\ud83d\udd04 Rotary drums are commonly used by the Life Sciences Industry. \n\n\ud83d\udcd6 We would like to highlight a very interesting recent paper titled \"Scale-up of heat transfer in a rotary drum Equipped with baffles\" authored by Elaheh Ardalani, Bill Borghard, Ben Glasser, and Alberto Cuitino.\n\nThe researchers employed Discrete Element Method (DEM) simulations to explore how baffles regulate heat transfer in a rotary drum. Their findings show the complex interplay of factors influencing this process. \n\n\ud83d\udcca An empirical relationship was developed, introducing a new characteristic time for baffles. This allowed the prediction of the average particle bed temperature, paving the way for scaling up the system.\n\n\ud83d\udd0d This study explores various parameters, including particle fill level, drum size, baffle size, baffle number, and rotation speed, to manipulate the operating conditions of the rotary drum. \n\n\ud83c\udf21\ufe0f Baffle effectiveness was found to be linked with the fill level and rotational speed, offering insights into temperature uniformity and heat transfer rates. \ud83c\udf21\ufe0f\n\n\ud83d\udd17 Link to the publication: https:\/\/lnkd.in\/ezGNujZJ\n\n\ud83d\ude4c Kudos to the authors for their valuable contribution! \ud83d\ude4c","linkedinURL":"https:\/\/www.linkedin.com\/feed\/update\/urn:li:activity:7117579015070040064","githubURL":null,"paperURL":null,"author":"Harry Christodoulou","createdDate":"10\/10\/2023"},{"title":"The title is: Model Predictive Control of Chemical Systems","description":"\u2b50 Model predictive control of Chemical Systems \u2b50\n\n\ud83d\ude80 Model predictive control (#MPC) finds valuable application in (bio)-pharma manufacturing by enabling real-time optimization of critical process variables, ensuring product quality.\n\n\ud83d\udd0d We came across an excellent paper on Model Predictive Control. The paper, titled \"Polynomial NARX-based nonlinear model predictive control of modular chemical systems,\" authored by Anastasia Nikolakopoulou and Richard D. Braatz, presents a very interesting approach to designing and implementing control systems in the chemical industry.\n\n\ud83d\udcc4 The authors leverage a specific class of nonlinear input\u2013output models called polynomial nonlinear-autoregressive-with-exogenous-inputs (NARX) models within NMPC frameworks. They apply machine learning techniques, specifically the elastic net algorithm, to intelligently select the terms to be included in the NARX polynomial series representation. This approach results in the construction of sparse predictive models, paving the way for real-time implementable NMPC.\n\n\ud83d\udcda To showcase the practicality of this approach, the authors have provided a compelling case study involving a chemical reactor.\n\n\ud83d\udcbb The Julia programming language is used to solve the optimization problem, resulting in low #computational #cost. \ud83d\udcbb\n\n\ud83c\udf89 Many congratulations to the authors! \ud83d\udc4f\n\n\ud83d\udd17 Link to the article: https:\/\/lnkd.in\/exS4zWFW\u00a0","linkedinURL":"https:\/\/www.linkedin.com\/feed\/update\/urn:li:activity:7117207233263742978","githubURL":null,"paperURL":null,"author":"Harry Christodoulou","createdDate":"10\/09\/2023"},{"title":"The title is: \"Continuous Mixing Technology: Validation of a DEM Model.\"","description":"\ud83d\udc8a Discrete Element Method for Solid Oral Dosage form manufacturing \ud83d\udc8a\n\n\ud83d\udca1 In the realm of pharmaceutical development, precision is paramount. Therefore, validating our models against experimental data is of utmost importance, though undeniably a challenging endeavour. \ud83d\ude80\n\n\ud83d\udd0d We recently stumbled upon a very interesting paper titled \"Continuous Mixing Technology: Validation of a DEM Model.\" by Peter Toson, Pankaj Doshi, Marko Matic, Eva Siegmann, Daniel Blackwood, Ashwinkumar Jain, Jenna Brandon, Kai Lee, David Wilsdon, James Kimber, Hugh Verrier, Johannes Khinast, and Dalibor Jajcevic.\n\n\ud83d\udcbb The paper explores the use of Discrete Element Method (DEM) modelling to optimize vertical continuous mixing technology (CMT) \ud83c\udfed\n\n\ud83d\udcca This paper underscores the vital significance of validating models. Whether we are working with pharmaceuticals or any other field, trusting a model to make informed decisions necessitates rigorous validation. This process ensures that the model accurately mirrors real-world processes, boosting the reliability of results. \n\n\ud83d\udcc8 The authors calibrate the cohesive contact model through small-scale experiments. This not only reduces the need for costly experimental runs but also differentiates between blend properties caused by varying API particle sizes within the same formulation. Moreover, the DEM simulations of CMT, compared to tracer spike experiments under different conditions, exhibit good agreement.\n\n\ud83d\udc4f Kudos to the authors for this excellent paper! \ud83c\udf1f\n\n\ud83d\udcda Link to the article: https:\/\/lnkd.in\/eXGHdPHg","linkedinURL":"https:\/\/www.linkedin.com\/feed\/update\/urn:li:activity:7116751225169014784","githubURL":null,"paperURL":null,"author":"Harry Christodoulou","createdDate":"10\/08\/2023"},{"title":"The title is: Enhancing Biomanufacturing: A Deep Dive into Smart Process Analytics","description":"\ud83e\uddec Enhancing Biomanufacturing: A Deep Dive into Smart Process Analytics \ud83c\udf10\n\nIn the intricate landscape of biopharmaceutical manufacturing, the extensive data generated throughout an End-to-End (E2E) process can be overwhelming. Companies rely on data-driven models crafted through sophisticated data analytics and machine learning methods. However, the challenge lies not just in the utilization of these tools but in selecting the most fitting ones for a specific dataset, ensuring accuracy and reliability in the final model.\n\n\ud83d\udd0d Addressing this challenge, Moo Sun Hong, Fabian Mohr, Chris Castro, Ben Smith, Jacqueline Wolfrum, Stacy Springs, Anthony Sinskey, Roger Hart, Tom Mistretta, and Richard D. Braatz present an approach that delves into Smart Process Analytics software, a tool designed at Massachusetts Institute of Technology to handle the intricacies of industrial manufacturing data.\n\n\ud83d\udd2c At its core, this innovative application automates the task of selecting appropriate data analytics and machine learning tools. By delving into the specifics of the product and the process, the software determines the ideal methods for constructing precise models. The study\u2019s results, showcasing the capture of unique product- and process-specific traits for different monoclonal antibody productions, represent a significant advancement.\n\n\ud83d\udee0\ufe0f Beyond its immediate application, this study equips the biomanufacturing industry with tools that extend far beyond. These tools are keys to unlocking the doors of root cause analysis, prediction, and control within the biopharmaceutical landscape.\n\n\ud83d\udd17 Link to Publication: https:\/\/lnkd.in\/eGNhXDqp\n\n#Biopharmaceuticals #DataAnalytics #MachineLearning #ProcessOptimization #Innovation \ud83e\uddea\ud83d\udcca\ud83d\udd2c","linkedinURL":"https:\/\/www.linkedin.com\/feed\/update\/urn:li:activity:7116409623389057026","githubURL":null,"paperURL":null,"author":"Antonio Benedetti","createdDate":"10\/07\/2023"},{"title":"The title is: Exploring Optimal Experimental Campaigns: A Probabilistic Approach","description":"\ud83e\uddea Exploring Optimal Experimental Campaigns: A Probabilistic Approach \ud83d\udcca\n\n\ud83d\udd0d Early in the model development phase, uncertainties loom large, making it essential to consider these uncertainties to avoid uninformative or infeasible experiments. \n\n\ud83d\udcdaThis article from Kennedy Putra Kusumo, Kamal Kuriyan, Shankarraman Vaidyaraman, Salvador Garc\u00eda Mu\u00f1oz, Nilay Shah, and Benoit Chachuat introduces a novel approach to designing optimal experimental campaigns under the shadow of uncertainties and hard constraints. What sets this method apart is its ability to balance risk and reward effectively.\n\n\ud83c\udf31 This innovative computational framework unfolds in two stages. First, a probabilistic approach samples the feasible experimental space, acknowledging uncertainties. Then, a meticulous search within this space leads to the design of continuous-effort optimal experiments. This approach ensures that every experiment conducted is not only informative but also safe, especially in situations with potential hazards.\n\n\ud83d\udd2c To demonstrate the practicality of this methodology, a challenging case study is presented: the exothermic esterification of propionic anhydride, a process laden with the risk of thermal runaway. The implementation of this approach, based on Python packages DEUS and Pydex, is freely available for researchers.\n\n\ud83d\udd17GitHub Repo for DEUS: https:\/\/lnkd.in\/e3c6_zjR\n\ud83d\udd17GitHub Repo for Pydex: https:\/\/lnkd.in\/eF9_xtK8\n\ud83d\udd17Research Publication: https:\/\/lnkd.in\/efijXann\n\n#ExperimentalDesign #ModelCalibration #UncertaintyManagement #ScientificInnovation #Research \ud83e\uddec\ud83d\udd2c\ud83c\udf1f","linkedinURL":"https:\/\/www.linkedin.com\/feed\/update\/urn:li:activity:7116105061012762624","githubURL":null,"paperURL":null,"author":"Antonio Benedetti","createdDate":"10\/06\/2023"},{"title":"The title is: Enhancing Robust Optimization: #ROmodel for Pyomo","description":"\ud83e\uddee Enhancing Robust Optimization: #ROmodel for Pyomo \ud83d\udc0d\n\nIn the intricate landscape of optimization, the shift from deterministic to robust models has long been a hurdle. Uncertainties in real-world scenarios often challenge the efficacy of traditional optimization approaches. Johannes Wiebe and Ruth Misener recognized this challenge and delved into the heart of it.\n\n\ud83d\udee0\ufe0f ROmodel introduces modeling objects that enable the formulation of robust models with remarkable similarity to their mathematical counterparts. The package provides a library of widely used uncertainty sets, represented through matrices, and allows the flexibility of defining custom uncertainty sets using Pyomo constraints.\n\n\ud83d\udd0d Supporting adjustable variables via linear decision rules, ROmodel enhances the robustness of models. It goes a step further, offering solvers implementing both robust reformulation and cutting-plane approaches, providing a comprehensive platform for implementing and comparing custom uncertainty sets and reformulations.\n\n\ud83c\udf10 ROmodel's versatility shines as it integrates data-driven models into optimization processes. The package has been put through its paces in six diverse case studies, showcasing its adaptability and efficiency.\n\n\ud83d\udd17 #GitHub Repository: https:\/\/lnkd.in\/ez27re7i\n\ud83d\udcda Read the Paper: https:\/\/lnkd.in\/e8g6qWH4\n\n#RobustOptimization #Pyomo #OpenSource #DataIntegration #OptimizationTools \ud83e\udde0\ud83d\udd2c\ud83c\udf1f","linkedinURL":"https:\/\/www.linkedin.com\/feed\/update\/urn:li:activity:7115746934404833281","githubURL":null,"paperURL":null,"author":"Antonio Benedetti","createdDate":"10\/05\/2023"},{"title":"The title is: Predicting sample injection profiles in liquid chromatography: A modelling approach based on residence time distributions","description":"\ud83c\udf1f Liquid Chromatography: Using a Modelling Approach \ud83c\udf1f\n\n\ud83e\uddea\u00a0A significant proportion of Drug Manufacturing #costs \ud83d\udcb0 are incurred during Downstream Purification, where reversed-phase liquid chromatography plays a pivotal role. \n\n\ud83d\udcbb These days, pharmaceutical and bio-pharmaceutical industries are using simulations of liquid chromatographic processes for method development and #cost-reduction. \n\n\ud83d\udcc4 We came across a very interesting paper on the subject. It is titled \"Predicting sample injection profiles in liquid chromatography: A modelling approach based on residence time distributions\" by Monica Tirapelle, Maximilian Besenhard, Luca Mazzei, Jinsheng Zhou, Scott Hartzell, and Eva Sorensen MBE.\n\n\ud83d\udcbb The author's model, based on residence time distribution theory, considers the sample's residence time through various components like injection loops, connecting tubes, and heat exchangers upstream of the chromatographic column. To validate the model, the authors compared simulation results with experimental injection profiles. \n\nThe model can predict injection profiles accurately across a range of sample volumes and loop-filling levels without the need for #calibration. This modelling approach promises to enhance the quality of in-silico simulations and optimizations in analytical chromatography, ultimately contributing to more efficient and cost-effective drug manufacturing processes.\n\n\ud83d\udc4f Kudos to all the authors of the paper!\ud83d\udc4f \n\n\ud83d\udd17 Link to the paper here : https:\/\/lnkd.in\/eD6-BF2Q","linkedinURL":"https:\/\/www.linkedin.com\/feed\/update\/urn:li:activity:7115425417380917250","githubURL":null,"paperURL":null,"author":"Harry Christodoulou","createdDate":"10\/04\/2023"},{"title":"The title is: Semi-continuous fluidized bed drying: A mechanistic modelling approach.","description":"\u2b50 Semi-continuous fluidized bed drying: A mechanistic modelling approach \ud83d\udcbb\n\n\ud83d\udc8a Simulating the fluidized bed drying process is essential for optimizing tabletability and drug product quality!\n\n\ud83d\udcda We stumbled upon a very interesting paper titled \"Mechanistic modeling of semicontinuous fluidized bed drying of pharmaceutical granules\" by Tuur Vandeputte, Michael Ghijs, Daan Van Hauwermeiren, Eduardo Dos Santos Schultz, Elisabeth Sch\u00e4fer, Fanny Stauffer, Thomas De Beer, and Ingmar Nopens. \n\n\ud83d\udcca The authors have developed a mechanistic model for semi-continuous fluidized bed drying. Their work combines a mechanistic bulk model and a single-particle drying kinetics model in a semi-continuous mode.\n\n\ud83d\udc0d The authors developed this complex model using #Python, leveraging tools like #SciPy, #NumPy, #Pandas, #Seaborn, & #Matplotlib for their analysis.\n\nThe model's performance was quantified through industrially relevant case studies. Finally, the authors discuss how their approach can be enhanced by including more phenomena into the model! \ud83d\ude80\n\n\ud83d\udc4f Congratulations to all the authors for this contribution. We are looking forward to future developments! \ud83d\udc4f\n\n\ud83d\udd17 Link to the article: https:\/\/lnkd.in\/e9MN_u8Z\n\n#MechanisticModelling #Drying #PharmaModelling\u00a0#Python","linkedinURL":"https:\/\/www.linkedin.com\/feed\/update\/urn:li:activity:7114954777637052416","githubURL":null,"paperURL":null,"author":"Harry Christodoulou","createdDate":"10\/03\/2023"},{"title":"The title is: Unleashing Industrial Data Potentials: Tagreader for Seamless Connectivity with Process Historians","description":"\ud83d\udd0c Unleashing Industrial Data Potentials: Tagreader for Seamless Connectivity with Process Historians \ud83c\udfed\n\n\ud83d\udd0d When dealing with data science projects on industrial data, process historians such as IP21 and OsiPI become a key data source for process data. These systems, meticulously designed for sectors spanning manufacturing, life science, energy, and utilities, form the bedrock of data science initiatives in industrial domains.\n\n\ud83d\udee0\ufe0fMeet Tagreader, a Python package purpose-built to effortlessly extract timeseries data from OSIsoft PI and Aspen Infoplus.21 Information Manufacturing Systems (IMS) systems. \n\n\ud83d\udd2cThis open-source gem simplifies a complex task, offering user interfaces mirroring those of the backend historians.\nDeveloped by Equinor, Tagreader thrives on collaborative efforts. \ud83e\udd1d\ud83d\ude80\n\n\ud83d\udd17 Explore on #GitHub: https:\/\/lnkd.in\/eV5JC7-K\n\n#DataScience #IndustrialData #OpenSource #DataConnectors #Innovation \ud83d\udcca","linkedinURL":"https:\/\/www.linkedin.com\/feed\/update\/urn:li:activity:7114608036391829504","githubURL":null,"paperURL":null,"author":"Antonio Benedetti","createdDate":"10\/02\/2023"},{"title":"The title is: Identification of Stoichiometric Models for Complex Reaction Systems","description":"\u2b50 Identification of Stoichiometric Models for Complex Reaction Systems \u2b50\n\n\ud83d\udd2c The advent of high-throughput technologies has made it easier to collect extensive reaction data, enabling scientists to monitor compound compositions, such as intermediates and by-products. \n\n\ud83d\udca1 While most of the times the \"overall\" #stoichiometry of primary reactants and products is typically clear, understanding the stoichiometric reactions responsible for generating these intermediates and by-products is often a challenge.\u00a0 \n\n\ud83d\udcda We came across a very interesting research article titled \"Toward the Identification of Stoichiometric Models for Complex Reaction Mixtures\" by Jenna Fromer, Christos Georgakis, and Jason Mustakis. \n\nIn their study, the authors present a method to identify stoichiometric and kinetic models accurately. Even without prior knowledge of potential reaction candidates!\n\n\ud83d\udcca The authors applied their algorithm to two case studies involving complex mixtures of species and multiple reactions, successfully identifying the actual stoichiometric and kinetic models for both systems. \ud83d\udcc8\n\nWe are looking forward to applying these techniques to more #pharma Case Studies!\n\nFor more details regarding the methodology and the algorithm check out the article here: https:\/\/lnkd.in\/euVSSeBP\n\n\ud83d\udc4f\ud83d\udc4f Kudos to the authors for their contribution! \ud83d\udc4f\ud83d\udc4f\n\n#BayesianInformation #ReactionNetworks #ChemicalEngineering #PharmaModelling\u00a0","linkedinURL":"https:\/\/www.linkedin.com\/feed\/update\/urn:li:activity:7114217388144762880","githubURL":null,"paperURL":null,"author":"Harry Christodoulou","createdDate":"09\/30\/2023"},{"title":"The title is: Condensing Online Data for Enhanced Bioprocess Control","description":"\ud83e\udda0 Condensing Online Data for Enhanced Bioprocess Control \ud83d\udcbb\n\nIn biopharmaceuticals, precise control of critical process parameters is essential. Nishanthi Gangadharan, Ayca Cankorur Cetinkaya, Matthew Cheeks PhD, MBA, Alexander Routh, and Duygu Dikicioglu, have developed a pragmatic solution in their paper on online data condensation.\n\n\ud83d\udcca Multivariate monitoring generates extensive real-time data. Integrating online and offline datasets is challenging due to varying volumes. This study introduces a method for condensing online data into a manageable offline matrix. \n\n\ud83d\udc68\u200d\ud83d\udd2cThis approach, more effective than traditional averaging, expands the variables for mapping the process design space. Additionally, it explores error propagation, identifying crucial tolerance intervals in bioprocess monitoring.\n\n\ud83d\udca1 Beyond condensation, this research provides insights for refining control strategies. By distilling online data, this methodology promises improved control actions, potentially enhancing biopharmaceutical processes.\n\n\ud83d\udd17 Link to #Publication: https:\/\/lnkd.in\/evKajpdP\n\n#Biopharmaceuticals #DataAnalysis #ControlStrategies #Innovation #Research \ud83e\uddec\ud83d\udd2c","linkedinURL":"https:\/\/www.linkedin.com\/feed\/update\/urn:li:activity:7113873254909399040","githubURL":null,"paperURL":null,"author":"Antonio Benedetti","createdDate":"09\/30\/2023"},{"title":"The title is: Opportunities for Machine Learning and Artificial Intelligence to Advance Synthetic Drug Substance Process Development","description":"\ud83d\ude80Opportunities in Machine Learning & AI for Drug Substance Development!\ud83e\uddea\n\n\ud83d\udcda Just stumbled upon a fascinating article titled \"Opportunities for Machine Learning and Artificial Intelligence to Advance Synthetic Drug Substance Process Development\" by Daniel Griffin, Connor W. Coley, Scott Frank, Joel Hawkins, and Klavs Jensen.\n\nIn their paper, the authors achieve three major goals:\n\n1\ufe0f\u20e3 Informing a broad audience: They provide valuable insights into synthetic drug substance process development, catering to both machine learning (ML) and artificial intelligence (AI) enthusiasts and professionals.\n\n2\ufe0f\u20e3 Breaking down complex DS process development tasks: They break down the intricate task of synthetic drug substance process development into manageable subtasks.\n\n3\ufe0f\u20e3 Highlighting AI Potential: The authors emphasize the untapped potential of ML and AI in this field, particularly focusing on how these technologies can significantly benefit process chemists and engineers.\n\n\ud83d\udca1 At Polymodels Hub, found very insightful and inspirational is the vision of the authors who proposed the development of a \"digital partner\" platform which integrates predictive tools to guide the entire process development lifecycle.\n\nThis \u2b50\ufe0f tool would combine physics-based modelling and empirical data-driven models to create a digital twin, helping optimize routes, assess risks, capture machine learning predictions, design experiments, predict physical properties, anticipate impurities, and guide overall process development decisions. \n\n\ud83d\udc4f Many congratulations to the authors for their insightful article! \ud83d\udc4f\n\n\ud83d\udd17 Link to article: https:\/\/lnkd.in\/e5Afep5r \n\n#DrugSubstanceDevelopment #ArtificialInteligence #MachineLearning #Modelling\n\n\ud83d\udd00 PS: For those interested in pharmaceutical modelling platforms, please consider registering on our website to be among the first to receive updates about our Polymodels Hub Platform: https:\/\/lnkd.in\/gM-TRds7","linkedinURL":"https:\/\/www.linkedin.com\/feed\/update\/urn:li:activity:7113514382604525568","githubURL":null,"paperURL":null,"author":"Harry Christodoulou","createdDate":"09\/29\/2023"},{"title":"The title is: Exploring Bayesian Hybrid Models for Learning and Optimization under Epistemic Uncertainty","description":"Exploring Bayesian Hybrid Models for Learning and Optimization under Epistemic Uncertainty \ud83d\udcda\n\n\ud83c\udf1f Elvis Eugene, Kyla Jones, Xian Gao, Jialu Wang, and Alexander Dowling  present a nice perspective on the the pioneering work of  Kennedy-O\u2019Hagan to quantify epistemic uncertainty in hybrid (grey-box) models.\n\n\ud83e\udde9 Grey-box models seamlessly blend data-driven components with mechanistic models to account for unknown or computationally challenging phenomena. This innovative concept builds upon the pioneering work of statisticians Kennedy and O\u2019Hagan, introducing a paradigm to quantify epistemic (model-form) uncertainty.\n\n\ud83d\udcc8 While Kennedy\u2013O\u2019Hagan hybrid models have gained popularity in various engineering disciplines for accurate uncertainty estimation, this research takes a step further. It explores computational strategies to harness Bayesian hybrid models for optimization under uncertainty.\n\n\ud83c\udfaf The posterior distributions of Bayesian hybrid models offer a structured uncertainty framework for tackling stochastic programming, chance-constrained optimization, or robust optimization. Through two illustrative case studies, the effectiveness of these hybrid models is demonstrated, even when working with limited training data.\n\n\ud83d\udca1 This paper not only provides valuable insights but also offers recommended best practices and delves into the trade-offs associated with different hybrid model architectures.\n\n\ud83d\udc0d If you're eager to delve into the core package that drives this work, look no further than PyMC. \n\n\ud83d\udd17 Link to Publication: https:\/\/lnkd.in\/eJJpM5DK\n\ud83d\udc0dLink to PyMC: https:\/\/lnkd.in\/dvmqPk5w\n\n#BayesianModels #Optimization #Uncertainty #HybridModels #MachineLearning #Engineering #Research","linkedinURL":"https:\/\/www.linkedin.com\/feed\/update\/urn:li:activity:7113232870424338432","githubURL":null,"paperURL":null,"author":"Antonio Benedetti","createdDate":"09\/28\/2023"},{"title":"The title is: Simulation-Optimization Framework for the Digital Design of Pharmaceutical Processes","description":"\ud83c\udf1f   PharmaPy and Pyomo: A Simulation-Optimization Framework for the Digital Design of Pharmaceutical Processes  \ud83d\udc8a\n\nThe pharmaceutical industry faces complex problems in process design and optimization. We need robust frameworks that allow users to utilize process simulators and optimization methodologies.\n\n\ud83d\ude80   We have stumbled upon another excellent article from the #PharmaPy folks. The article is titled \"Simulation-Optimization Framework for the Digital Design of Pharmaceutical Processes Using Pyomo and PharmaPy,\" and it introduces a framework which can tackle some of the industry's most challenging computational hurdles.\n\nThe framework's effectiveness has been demonstrated in two case studies, including the synthesis of an anti-cancer active pharmaceutical ingredient and a complex synthesis-purification-isolation train of a pharmaceutical manufacturing process. The results speak for themselves, both in terms of accuracy and computational efficiency.\n\n\ud83d\udcd1  Moreover, this paper underscores the significance of bridging the gap between theoretical knowledge and practical implementation in pharmaceutical process optimization. It's a testament to the power of innovative thinking and interdisciplinary collaboration.\n\n\ud83d\udca1  Combining the open-source Pyomo and PharmaPy is highly recommended to modelers in the pharmaceutical field who are looking to develop innovative solutions and accelerate pharmaceutical drug development. \ud83d\udc8a\n\n\ud83c\udf89   Many congratulations to the authors: Daniel Laky , Daniel Casas-Orozco, Ph.D. , Carl Laird , Gintaras Reklaitis, and Zoltan Nagy  \ud83c\udf89\n\n\ud83d\udd17Link to the article: https:\/\/lnkd.in\/etu7NgZB \n\ud83d\udd17Link to PharmaPy: https:\/\/lnkd.in\/edEZccEC \n\n#Pyomo #Optimization #PharmaPy #Simulation #Pharmaceuticals \ud83c\udf1f","linkedinURL":"https:\/\/www.linkedin.com\/feed\/update\/urn:li:activity:7112722565202075651","githubURL":null,"paperURL":null,"author":"Antonio Benedetti","createdDate":"09\/26\/2023"},{"title":"The title is: Industrial Data Science Workshop","description":"\ud83d\udc4f Congratulations to Francisco J. Navarro Brull, Mattia Vallerio and Carlos P\u00e9rez-Galv\u00e1n for delivering an amazing Industrial Data Science Workshop! \ud83c\udf89\n\nWe definitely would like to see more of these Workshops from the Team! \nVery useful for both academics and industry practitioners. Highly recommended! \ud83d\ude4c","linkedinURL":"https:\/\/www.linkedin.com\/feed\/update\/urn:li:activity:7112378060129083392","githubURL":null,"paperURL":null,"author":"Harry Christodoulou","createdDate":"09\/26\/2023"},{"title":"The title is: Reduced Model-Based Global Optimization of Large-Scale Steady State Nonlinear Systems.","description":"\u2b50\ud83d\udcc8 Reduced Model-Based Global Optimisation \ud83c\udf10 \ud83d\udd0d\n\n\ud83d\udd0d Today we bring you this interesting article that we cam across titled \"Reduced Model-Based Global Optimization of Large-Scale Steady State Nonlinear Systems.\" The authors, Min Tao, Jie Li, and Constantinos Theodoropoulos from The University of Manchester, have delved into a complex but critical area of #Process #Optimization.\n\n\ud83c\udf10 Many engineering systems are simulated using partial differential equations (#PDEs), resulting in large-scale distributed parameter systems. While deterministic global optimization algorithms (GOP) can compute global optimal solutions, they could face challenges when applied to distributed parameter systems.\n\n\ud83d\udca1 The authors employ a novel approach combining Principal Component Analysis (#PCA) and Artificial Neural Networks (#ANNs) for model reduction. This methodology aims to help optimization experts and practitioners working on large-scale distributed steady state systems.\n\n\ud83d\udd2c The practical application of this PCA-ANN-GOP framework is demonstrated through an illustrative example\u2014an exothermic reaction within a tubular reactor. This showcases the potential real-world impact of their research.\n\n\ud83d\udc4f Kudos to the authors for their paper!\ud83d\udc4f\n\n\ud83d\udd17 Link to the article: https:\/\/lnkd.in\/ebYkMsEA\n\n#ProcessOptimization #ModelReduction #Engineering #Research #Innovation #OptimizationMethods","linkedinURL":"https:\/\/www.linkedin.com\/feed\/update\/urn:li:activity:7112129120683057152","githubURL":null,"paperURL":null,"author":"Antonio Benedetti","createdDate":"09\/25\/2023"},{"title":"The title is: Enhancing Pharmaceutical Manufacturing: The Role of Digital Twins","description":"\ud83e\uddea Enhancing Pharmaceutical Manufacturing: The Role of Digital Twins \ud83c\udf10\n\nIn the complex world of pharmaceuticals, optimizing the production of Active Pharmaceutical Ingredients (APIs) is a critical task. Organic synthesis, catalytic reactions, and separations are just some of the steps involved. Understanding and improving this process on an industrial scale requires a deep dive into process units, reactors, and separators.\n\n\ud83d\udcc8 Dimitrios I. Gerogiorgis and Daniel Castro-Rodriguez provide a comprehensive overview of the role that Digital Twins (DT) can play in this space. In this paper, they introduce a DT aiming to evaluate the multicomponent adsorption of Volatile Organic Compounds (VOC) emissions during salbutamol synthesis.\n\n\ud83c\udf2a\ufe0f What's unique about this approach? It combines first-principles, like PDE-based adsorption, with data-driven methodologies, including Principal Component Analysis (PCA). This integration ensures both efficiency and cost-effectiveness.\n\n\ud83d\udca1 This research highlights the potential of Digital Twins in pharmaceutical manufacturing, offering a promising path towards more efficient and sustainable processes.\n\n\ud83d\udd17 Learn more about this development: https:\/\/lnkd.in\/ek-irgnT\n\n#PharmaManufacturing #DigitalTwin #ProcessOptimization #Pharmaceuticals #Research #Innovation","linkedinURL":"https:\/\/www.linkedin.com\/feed\/update\/urn:li:activity:7111694309216669696","githubURL":null,"paperURL":null,"author":"Antonio Benedetti","createdDate":"09\/24\/2023"},{"title":"The title is: Yield Prediction in Chemical Research: Challenges and Opportunities","description":"\ud83d\udcbb When yield prediction does not yield prediction: an overview of the current challenges \ud83e\uddea\n\n\ud83e\udd16Machine Learning is transforming the landscape of chemical research, but not without its share of challenges. Varvara Voinarovska, Mikhail Kabeshov, Dmytro Dudenko, Samuel Genheden, and Igor V. Tetko delve into the complexities of predicting advanced chemical properties, such as yield and optimal reaction conditions.\n\n\ud83c\udf10 These challenges arise from the high-dimensional nature of the task, with a multitude of variables at play\u2014reactants, reagents, catalysts, temperature, and purification processes. Developing a reliable predictive model in this intricate domain has the potential to revolutionize High-Throughput experiments and enhance retrosynthetic predictive approaches.\n\n\ud83d\udd2c In their review, the authors systematically assess the effectiveness of current Machine Learning methodologies in chemoinformatics. They shed light on the milestones achieved and also address the inherent limitations.\n\n\ud83e\uddea Furthermore, a detailed case study examination offers valuable insights into the challenges related to data availability and transferability within the discipline.\n\n\ud83d\udcda Dive deeper into this insightful review: https:\/\/lnkd.in\/eR37Peaz\n\n#MachineLearning #ChemicalResearch #YieldPrediction #Chemoinformatics #Challenges #Chemistry #Research","linkedinURL":"https:\/\/www.linkedin.com\/feed\/update\/urn:li:activity:7111329424574173184","githubURL":null,"paperURL":null,"author":"Antonio Benedetti","createdDate":"09\/23\/2023"},{"title":"The title is: Process Design Space Identification: A New Approach for Complex Problems with Surrogate Models.","description":"\ud83c\udf0c Process Design Space Identification : A New Approach for Complex Problems with Surrogate Models  \ud83d\ude80\n\nWhen dealing with process design space identification, identifying the elusive combinations of input parameters that satisfy constraints is a critical task. Margherita Geremia, Fabrizio Bezzo, and Marianthi Ierapetritou have introduced a novel framework that sheds light on this complex puzzle.\n\n\ud83d\udcca When dealing with disjoint feasible regions and computationally expensive\/nonconvex problems, surrogate-based approaches have become invaluable. However, choosing the right surrogate and ensuring its prediction accuracy is a challenge.\n\n\ud83e\udde9 In this study, a novel workflow emerges, combining mathematical tools to:\n(i) Discover the process's feasible space based on available training data.\n(ii) Determine the minimum number of sampling points required to grasp the complexity of the feasibility function.\n(iii) Select the most suitable surrogate model while enhancing accuracy.\n\n\ud83d\udcc8 This methodology has been put to the test on analytical problems and a pharmaceutical process, demonstrating its effectiveness in uncovering intricate feasible regions.\n\n\ud83d\udd17 Learn more about this innovative approach in the full Publication: https:\/\/lnkd.in\/ep2xuXch\n\n#FeasibilityAnalysis #ComplexFeasibleSpaces #SurrogateModels #Research #Mathematics #Innovation","linkedinURL":"https:\/\/www.linkedin.com\/feed\/update\/urn:li:activity:7110940825726906368","githubURL":null,"paperURL":null,"author":"Antonio Benedetti","createdDate":"09\/21\/2023"},{"title":"The title is: Scaling Up Bioprocesses: a CFD Modelling Strategy","description":"\ud83d\udd0d Scaling Up Bioprocesses: a CFD Modelling Strategy \ud83c\udf31\n\nScaling bioprocesses is no easy feat, but Stefan Seidel, Fruhar Mozaffari, R\u00fcdiger Maschke, Matthias Kraume, Regine Eibl, Dieter Eibl recently published a very interesting approach. They've tackled the challenge of geometrically non-similar bioreactors with innovation and automation.\n\n\u2699\ufe0f Traditionally, selecting a scale-up strategy involved juggling multiple process parameters. This study introduces an alternative approach by focusing on the Kolmogorov length scale distribution, determined through computational fluid dynamics (CFD).\n\n\ud83c\udf10 Using open-source tools like OpenFOAM and DAKOTA, an automated optimization process was employed. The result? A remarkable achievement in scaling up from benchtop to pilot scale for HEK293-F cell expansion.\n\n\ud83d\udcc8 By optimizing stirrer geometry, position, and speed, the team achieved comparable results to small-scale cultivation. Moreover, they maintained a strict cell aggregate size distribution, a crucial factor in bioprocessing.\n\n\ud83e\uddec This results bring us closer to efficient and scalable bioprocesses, offering exciting possibilities for bioreactor optimization.\n\n\ud83d\udd17 Link to #GitHub: https:\/\/lnkd.in\/ej5hvrMn\n\ud83d\udcdaLink to #Publication: https:\/\/lnkd.in\/eQskgPJF \n\n#Bioprocessing #ScalingUp #Optimization #CFD #Research #opensource #openfoam ","linkedinURL":"https:\/\/www.linkedin.com\/feed\/update\/urn:li:activity:7110578417317597185","githubURL":null,"paperURL":null,"author":"Antonio Benedetti","createdDate":"09\/20\/2023"},{"title":"The title is: Predicting Growth Rate from Gene Expression: A Machine Learning Approach.","description":"\ud83d\udcc8 Understanding #Microbial #Growth: Predicting Growth Rate from Gene Expression \ud83e\uddec\n\n\ud83d\ude80In the world of microorganisms, growth rate is a critical factor. It influences genetic mutations and population survival. But modelling the link between genes and growth has always been a complex challenge.\n\n\ud83d\udd2c Thomas Wytock and Adilson Motter presented here a very interesting approach. They've directly connected gene expression to growth rates, using data from Escherichia coli and Saccharomyces cerevisiae.\n\n\ud83e\udd16 Using machine learning, specifically k-nearest-neighbors regression, they've created a model that predicts growth rates from gene expression data. The results are noteworthy:\n\n\u2728 For E. coli, they've explained 81% of the variance in growth rate with just nine features.\n\u2728 In S. cerevisiae, they've accounted for 89% of the variance in growth rate with only 18 dimensions.\n\n\ud83d\udd17 Link to #Github: https:\/\/lnkd.in\/gT9X2rNR\n\ud83d\udcdaLink to #Publication: https:\/\/lnkd.in\/gXdHVXZx\n\n#Microbiology #GrowthRate #GeneExpression #MachineLearning #Research","linkedinURL":"https:\/\/www.linkedin.com\/feed\/update\/urn:li:activity:7110216022871216128","githubURL":null,"paperURL":null,"author":"Antonio Benedetti","createdDate":"09\/18\/2023"},{"title":"The title is: RSOME in Python: A Robust Stochastic Optimization Package for Easy Problem Solving","description":"\ud83d\udc0d  Robust Stochastic Optimization Made it Easy: Introducing #RSOME in Python \ud83d\udcca\n\nIf you're working on problems that requires stochastic optimization, take a look at this new tool by Zhi Chen and Peng Xiong. They've created RSOME, a Python package that makes solving tough stochastic optimization problems easier.\n\n\ud83d\udce6 RSOME is an open-source framework that excels in modeling a wide range of optimization challenges with distributional ambiguity. What makes it stand out? Let's explore:\n\n1\ufe0f\u20e3 Readability and Intuitiveness: RSOME is engineered for user-friendliness, allowing you to model complex problems with clarity and ease.\n\n2\ufe0f\u20e3 Versatility: Whether you work in machine learning, data analysis, or visualization, RSOME seamlessly integrates with popular Python libraries, making it ideal for data-driven models.\n\n3\ufe0f\u20e3 Parameter Flexibility: RSOME empowers users with convenient interfaces for fine-tuning parameters across different solvers.\n\n\ud83d\udd17 Link to GitHub : https:\/\/lnkd.in\/e5TtT5Qy \n\ud83d\udcdaLink to Publication: https:\/\/lnkd.in\/eXDKNR_W\n\n#Optimization #PythonPackage #OpenSource #RobustOptimization #DataScience","linkedinURL":"https:\/\/www.linkedin.com\/feed\/update\/urn:li:activity:7109853647080968192","githubURL":null,"paperURL":null,"author":"Antonio Benedetti","createdDate":"09\/18\/2023"},{"title":"The title is: Population Balance Modelling of Precipitation","description":"\u2697\ufe0f Population Balance Modelling of Precipitation \ud83d\udc8a\n\n\ud83d\udd2c We stumbled upon this intriguing article titled \"Application of Population Balance Model to Simulate Precipitation of Weak Base and Zwitterionic Drugs in Gastrointestinal pH Environment\" by Hibiki Yamamoto, Ravi Shanker, and Kiyohiko Sugano.\n\n\ud83d\udcc8 The authors aimed to assess the suitability of the Population Balance Model (PBM) for predicting the precipitation of poorly soluble weak base and zwitterionic drugs in the gastrointestinal pH environment. \ud83d\udcc8\n\n\ud83d\udcca Five specific drugs were utilized as models for this investigation: dipyridamole, haloperidol, papaverine, phenazopyridine, and tosufloxacin. PBM involves equations for primary nucleation, secondary nucleation, and particle growth, each containing two empirical parameters. The research employed a pH shift (pH-dumping) precipitation test covering pH levels from 3.0 to 6.5 to determine the model parameters for each drug. \ud83e\uddea\n\n\ud83c\udfaf Due to difficulties in determining all six parameters simultaneously, the authors reduced the parameter count from six to three by excluding the secondary nucleation process and applying a common exponent for the particle growth equation. Despite this assumption, the PBM accurately described precipitation profiles in pH shift tests. Subsequently, the constructed PBM successfully predicted precipitation profiles in an artificial stomach-intestine transfer (ASIT) test. \n\n\ud83d\ude80 These results suggest that Population Balance Modelling can effectively simulate the precipitation of weak base and zwitterionic drugs in the gastrointestinal pH environment, offering valuable insights for biopharmaceutics #modeling and #simulation. \ud83d\ude80\n\n\ud83d\udc4f Congratulations to the authors for their very interesting article! \ud83d\ude4c\n\n\ud83d\udd17 Link to the article: https:\/\/lnkd.in\/gvbGHZGk","linkedinURL":"https:\/\/www.linkedin.com\/feed\/update\/urn:li:activity:7109551254674046976","githubURL":null,"paperURL":null,"author":"Harry Christodoulou","createdDate":"09\/18\/2023"},{"title":"The title is: Techno-Economic and Life Cycle Assessment of Standalone Single-Stream Material Recovery Facilities in the United States.","description":"\ud83c\udf31 Exploring Sustainable Waste Management \ud83d\udd04\n\n\u2b50 Today, we would like to talk about a very interesting scientific journal article which investigates the world \ud83c\udf0d of Material Recovery Facilities (MRFs) and their role in achieving a circular economy. \u267b\ufe0f\n\n\ud83d\udcd6 Titled \"Techno-Economic and Life Cycle Assessment of Standalone Single-Stream Material Recovery Facilities in the United States,\" this research, authored by Olumide ('Mide) Olafasakin, Jiaze Ma, Sabrina Bradshaw, Horacio Aguirre-Villegas, Craig Benson, George Huber, Victor M Zavala, and Mark Mba Wright, is an intriguing paper in the field of waste management.\n\n\ud83c\udfed Material Recovery Facilities (MRFs) are instrumental in handling complex waste streams and efficiently extracting valuable recyclables. This study conducts a comprehensive analysis, including Techno-Economic Assessment (#TEA) and Life Cycle Assessment (#LCA), to evaluate the economic feasibility and environmental impacts of a commercial-scale standalone single-stream MRF.\n\n\ud83d\udcca The results are very interesting both from an economical and an environmental perspective. Notably, the research highlights the profound influence of waste composition on costs and environmental footprints, emphasizing the \"interconnectedness\" of regional effects.\n\n\ud83d\udcc8 #Sensitivity and #Uncertainty analyses reveal critical factors affecting profitability, including: waste composition, market prices, facility capacity, fixed capital cost, and others.\n\n\ud83d\udc4f Kudos to the authors for this great publication\ud83d\udc4f\n\n\ud83d\udd17 To dive deeper into this research, check out the full article here: https:\/\/lnkd.in\/e6XmsFdU","linkedinURL":"https:\/\/www.linkedin.com\/feed\/update\/urn:li:activity:7109159906854752256","githubURL":null,"paperURL":null,"author":"Harry Christodoulou","createdDate":"09\/17\/2023"},{"title":"The title is: Multi-Objective Model-Based Design of Experiments for Pharma Tableting","description":"\u2b50 A novel Multi-Objective Model-Based Design of Experiments for Pharma Tableting \ud83d\udc8a\n\n\ud83d\udca1 Developing advanced digital technologies in #pharma demands systematic methods for creating useful and actionable mathematical models, soft sensors, and #DigitalTwins. These tools are crucial for optimizing process and plant design, ensuring smooth operations, and upholding quality standards. An efficient way to tackle these challenges is by employing Model-Based Design of Experiments (MBDoE) to generate the minimum (yet informative!) set of experiments. \ud83d\udca1\n\n\ud83d\udcda We just stumbled upon an insightful article titled \"Multi-Objective Model-based Design of Experiments of Pharmaceutical Tableting Process\" by Ilias Bouchkira and Brahim Benyahia from Loughborough University. \n\n\ud83d\udcc3 The authors' Multi-Objective Model-Based Design of Experiments (#MOMBDoE) approach aims to generate a minimal set of information-rich experiments, reducing experimentation costs and enhancing predictive model capabilities. The key focus is on simultaneously maximizing the D-optimal design of experiments criterion and the #Estimability potential of model parameters. \ud83d\udcca\n\nThe intricate process incorporates Global Sensitivity Analysis to construct the Fisher Information Matrix, allowing either the maximization or minimization the #MOMBDoE criteria. \ud83c\udf10\n\nFurthermore, the article outlines the use of Pareto optimal solutions as a means to determine the most favourable experimental compromises. These solutions represent the ideal trade-offs among multiple objectives, thereby aiding in the selection of the most suitable alternatives for experimental validation. The authors validate this approach using a #tablet lubrication process as a case study! \ud83d\udc8a\n\n\ud83d\udc4f Congratulations to the authors for this insightful article \ud83d\udc4f\n\n\ud83d\udd17 Link to the article: https:\/\/lnkd.in\/eJ_Fxh8S","linkedinURL":"https:\/\/www.linkedin.com\/feed\/update\/urn:li:activity:7108785478438408192","githubURL":null,"paperURL":null,"author":"Harry Christodoulou","createdDate":"09\/16\/2023"},{"title":"The title is: CHOmpact: A reduced metabolic model of Chinese hamster ovary cells with enhanced interpretability","description":"\ud83e\uddecCHOmpact: Reduced Metabolic Model with Enhanced Interpretability \ud83d\ude80\n\nIn the world of biopharmaceutical cell culture processes, metabolic modelling plays a pivotal role. These models help optimize the growth and productivity of Chinese hamster ovary (CHO) cells. However, they come with significant challenges, especially regarding their size and the ability to ensure physiologically consistent results.\n\n\ud83d\udcd6 We recently came across an intriguing paper titled \"CHOmpact: A reduced metabolic model of Chinese hamster ovary cells with enhanced interpretability,\" authored by Ioscani Jim\u00e9nez del Val, Sarantos Kyriakopoulos, Simone Albrecht, Henning Stockmann, Pauline Rudd, Karen Polizzi, and Cleo Kontoravdi\n\nThe authors introduce CHOmpact. \ud83d\ude80 A reduced metabolic network which consists of 101 metabolites interconnected by 144 reactions, providing a more manageable framework for robust, nonlinear optimization.\n\n\ud83d\udca1 The result? Computed flux distributions which are physiologically consistent. Moreover, CHOmpact enhances the interpretability of simulation results, shedding light on key mechanisms governing anaplerotic consumption and ammonia detoxification within mitochondria.\n\n\ud83d\ude4c Kudos to the team for developing CHOmpact! \ud83d\ude4c\n\nLink to the paper: https:\/\/lnkd.in\/eFbCgzHg","linkedinURL":"https:\/\/www.linkedin.com\/feed\/update\/urn:li:activity:7108530516189958144","githubURL":null,"paperURL":null,"author":"Harry Christodoulou","createdDate":"09\/15\/2023"},{"title":"The title is: Towards a unified multi-scale strategy for biomanufacturing process development.","description":"\u2b50 Systematic framework for biomanufacturing process development \u2b50\n\n\ud83e\uddec Biomanufacturing has been increasingly receiving attention in the past few decades. However, the scalability issues and lack of fundamental understanding have been significant roadblocks in this sector.\n\n\ud83d\udcc4 We came across a paper from the ESCAPE33 conference held in Athens this June. The paper, titled \"Towards a unified multi-scale strategy for biomanufacturing process development,\" authored by Thomas Bisgaard, Nima Nazemzadah, Eduardo Krebs Kleingesinds, Negin Yousefi, Christian Beenfeldt, and Seyed Soheil Mansouri, addresses challenges in the field of biomanufacturing.\n\n\ud83d\udca1 This paper introduces a conceptual systematic framework which unites knowledge from multiple disciplines to tackle these challenges. By delving into the fundamental phenomena at various scales, it paves the way for a more efficient process scale-up. This multi-scale strategy can help make biomanufacturing more sustainable and adaptable to our changing world.\n\n\ud83e\udd1d Let us commend the authors for their very interesting article \ud83c\udf89\n\n\ud83d\udd17 Link to the article: https:\/\/lnkd.in\/e8TjYtET\n\n#Biomanufacturing #Sustainability #ESCAPE33 #Bioprocess\u00a0","linkedinURL":"https:\/\/www.linkedin.com\/feed\/update\/urn:li:activity:7108108712954732544","githubURL":null,"paperURL":null,"author":"Harry Christodoulou","createdDate":"09\/14\/2023"},{"title":"The title is: Improving Transferable Force-Fields for Describing Crystal Structures Containing Hydrogen-Bonds","description":"\u2728 Force-Fields for Describing Crystal Structures \u2728\n\nCrystal structure prediction is vital for the pharmaceutical sector as it enables the development of drugs with optimized properties.\n\n\ud83d\udcc4 This morning, we stumbled upon a very interesting article titled: \u201cImproving Transferable Force-Fields for Describing Crystal Structures Containing Hydrogen-Bonds\u201d. \ud83d\udcc4\n\n\ud83d\udd0d In this study, the authors harnessed the power of periodic DFT-D generated reference data to parameterize a force-field specifically tailored for crystals with hydrogen-bond interactions. They employed Tang-Toennies damping on the Buckingham potential, exploring various fitting schemes.\n\n\ud83d\udca1 The result?\n\nA Force Field (FF) which achieved agreement with both energy and geometry training data, whether dealing with structures featuring hydrogen-bonds or not. Even when put to the test with a validation set, their FF's predictive ability held, demonstrating its transferability.\n\n\ud83d\udc4f Congratulations to the authors: Benjamin Tan , David Bowskill , Adam Keates , Costas Pantelides  and Claire Adjiman .\ud83c\udf89\n\n\ud83d\udd17 Link to the paper: https:\/\/lnkd.in\/e3Gpk7KY\n\n#Crystals #HydrogenBonds #ForceField","linkedinURL":"https:\/\/www.linkedin.com\/feed\/update\/urn:li:activity:7107786037325635585","githubURL":null,"paperURL":null,"author":"Antonio Benedetti","createdDate":"09\/13\/2023"},{"title":"The title is: Data-Driven & Physics-Informed Modelling of Bioreactors","description":"\ud83e\uddec Data-Driven & Physics-Informed Modelling of Bioreactors \ud83d\ude80\n\n\ud83e\udda0 CHO cells are widely employed in biological and pharma research, serving as the predominant mammalian cell line for manufacturing therapeutic proteins. Yet, the fact that we do not have complete quantitative mathematical models for their behaviour and metabolism makes it difficult to accurately and precisely simulate and control these systems. \ud83e\udda0\n\n\ud83d\udcda We stumbled upon an exciting recent article titled \"Data-driven and Physics-Informed Modelling of Chinese Hamster Ovary Cell Bioreactors\". This study was conducted by a great team of researchers hailing from Johns Hopkins University and The Pennsylvania State University.\n\n\ud83c\udf1f In a world where biologics production is of paramount importance for the #pharma industry, the article delves into the realm of fed-batch culture and its role in utilizing mammalian cell cultures for biologics production. The authors have taken a very interesting approach by proposing a \"gray box\" hybrid model, which combines physics-based knowledge with data-driven techniques. This model not only incorporates physical laws, like mass balances, but also kinetic expressions for metabolic fluxes.\n\n\ud83e\udd16 The researchers employ ML not only to directly learn the evolution equations (black-box modelling) but also to recover unknown physical parameters (white-box parameter fitting) and even unveil partially unknown kinetic expressions (gray-box modelling).\n\n\ud83d\udc4f Kudos to the authors: Tianqi Cui, Tom Bertalan, Nelson Ndahiro, Pratik Khare, Michael Betenbaugh, Costas Maranas, Ioannis Kevrekidis. \ud83d\udc4f\n\n\ud83d\udd17 Link to the interesting paper here: https:\/\/lnkd.in\/dnwk3RnD\n\n#DataDriven #PhysicsInformed #ML #BioReactors","linkedinURL":"https:\/\/www.linkedin.com\/feed\/update\/urn:li:activity:7107389567053250561","githubURL":null,"paperURL":null,"author":"Harry Christodoulou","createdDate":"09\/12\/2023"},{"title":"The title is: Navigating the Dynamics of Bioreactors : Insights into Oscillatory Behavior","description":"\ud83e\udda0 Navigating the Dynamics of Bioreactors : Insights into Oscillatory Behavior\ud83c\udf00\n\nIn the world of bioreactors, control is everything. Pavan Inguva, Krystian Ganko, Alexis Dubs, and Richard D. Braatz are highlighting some of the critical aspect that impacts the dynamic and the control of oscillatory behaviours in different bioreactors.\n\n\ud83e\udda0 Bioreactors play a pivotal role in product generation, employing a range of host cells. However, some bioreactors exhibit unexpected periodic behavior in key variables like metabolite concentrations and biomass. What causes these oscillations, and how can we tame them?\n\n\ud83d\udcca This article offers a comprehensive overview of oscillatory dynamics, exploring the mechanisms behind these fluctuations. It dives into process control strategies that not only suppress but also provide fresh insights.\n\n\ud83d\ude80 Looking to the future, alternative process configurations are proposed to bypass the mechanisms that trigger oscillations, offering a path to more stable operations.\n\n\ud83c\udf1f Impressive work, and it's wonderful to see this valuable methodology shared as open source.\n\n\ud83d\udd17 Link to GitHub: https:\/\/lnkd.in\/eX_Q2fXz\n\ud83d\udcda Link to Preprint:  https:\/\/lnkd.in\/e7Fvhp2S\n\n#Bioreactors #ProcessControl #Dynamics #Research #Biotechnology","linkedinURL":"https:\/\/www.linkedin.com\/feed\/update\/urn:li:activity:7106973769046323201","githubURL":null,"paperURL":null,"author":"Antonio Benedetti","createdDate":"09\/11\/2023"},{"title":"The title is: Hybrid Deep Modeling in CHO-K1 Fed-Batch Processes","description":"\ud83e\uddec Moving Towards Biopharma 4.0: Hybrid Deep Modeling in CHO-K1 Fed-Batch Processes \ud83e\udda0\n\nToday, let's delve into some recent work in the biopharm process modelling field. Jos\u00e9 Pinto, Jo\u00e3o Ramos, Rafael Costa, Sergio Rossell, Patrick Dumas, and Rui Oliveira recently published an insightful paper on Hybrid Deep Modeling for CHO-K1 Fed-Batch Processes.\n\n\ud83d\udc39 Chinese Hamster Ovary (CHO) cells are vital in glycoprotein production, and hybrid modeling is key to Biopharma 4.0. While previous studies focused on shallow hybrid models, this study ventures into the depths of incorporating deep learning.\n\n\ud83d\udcca This study compares deep and shallow hybrid modeling in a CHO process development context, using data from 24 fed-batch cultivations. The findings are significant.\n\n\ud83e\udde0 Deep hybrid models, with their adaptive training methods, provide valuable insights and predictive capabilities for key metabolites like lactate, ammonium, glutamine, and glutamate.\n\n\ud83d\ude80 With deep hybrid modeling leading the way, the biopharma sector is advancing towards high-fidelity digital twins. The future holds promise!\n\n\ud83d\udd17 Link to Study: https:\/\/lnkd.in\/esPsWK9u\n\n#Biopharmaceuticals #HybridModeling #DeepLearning #Research #Biopharma4.0","linkedinURL":"https:\/\/www.linkedin.com\/feed\/update\/urn:li:activity:7106575767882321920","githubURL":null,"paperURL":null,"author":"Antonio Benedetti","createdDate":"09\/10\/2023"},{"title":"The title is: Unlocking a World of Possibilities: A Modular Approach to Pharmaceutical Process Design","description":"\ud83d\udc8aPharmaceutical #Process #Design: A Closer Look at #ModelBased #Modular #Concepts \ud83e\uddf1 \n\nTraditional biopharmaceutical process design often relies solely on experimental methods. But if you followed us for some time you should know there's a better way! \ud83c\udf10\n\nToday we want to bring to you this interesting publication by Mariona Bertran and Deenesh K. Babi. They show you clearly how, by integrating experiments, unit models, and flowsheet models, we're unlocking a world of possibilities.\ud83d\udd0d \n\nThese innovative methods and flowsheet models provide a systematic framework to explore, analyze, and evaluate the vast landscape of design options within the molecule-to-manufacturing value chain.\ud83d\udd2c\n\nModular process designs are in the spotlight, especially as the industry shifts toward multiproduct, multiprocess approaches. But how do we evaluate their true potential?\ud83d\udcc8 \n\nThis paper presents an in silico approach for the evaluation of modular designs. It's not just a concept; it's a systematic method exemplified through the manufacture of an active pharmaceutical ingredient (API).\n\nThis approach shows us how to transition from the traditional design-for-purpose to a modular design. It leverages data, modeling, simulation, and uncertainty\/sensitivity analyses to quantify selection metrics like process robustness and flexibility. \ud83d\udca1\n\n\ud83d\udd17 Link to #Publication: https:\/\/lnkd.in\/eBzptrer\n\n#PharmaceuticalManufacturing #ModularDesign #Innovation #Research #PharmaceuticalIndustry","linkedinURL":"https:\/\/www.linkedin.com\/feed\/update\/urn:li:activity:7106270247094996992","githubURL":null,"paperURL":null,"author":"Antonio Benedetti","createdDate":"09\/09\/2023"},{"title":"The title is: DualSPHysics: Empowering Engineers, Scientists, and Researchers to Simulate Fluid Flows with SPH","description":"\ud83c\udf0a Diving into Fluid Dynamics with SPH: The Power of DualSPHysics! \ud83d\ude80\n\nSmoothed Particle Hydrodynamics (SPH) is a Lagrangian, meshless technique that finds application in a growing spectrum of scenarios within the realm of #CFD. In SPH, particles represent the flow, interact with structures, and exhibit large deformation with moving boundaries. \ud83d\udcc8 Ongoing enhancements and adaptations are elevating the method's accuracy, stability, and reliability to a point where it is becoming increasingly suitable for practical engineering and (our #pharma) applications. \ud83c\udf10\n\n\ud83c\udf1f Today, we would like to talk about a software package that empowers engineers, scientists, and researchers to simulate fluid flows with SPH: DualSPHysics! \ud83d\udca1\n\n\ud83d\udca1 SPH simulations can be computationally demanding.\u00a0Leveraging the parallel computing power of GPUs is a \"game\"-changer \ud83d\ude09 for SPH methods, allowing for the parallelization of the same loops for each particle in simulations. DualSPHysics, implemented in C++ and CUDA, allows simulations with millions of particles\n\n\ud83d\udd17 Get Started:\nReady to dive into the world of DualSPHysics? You can access it here: https:\/\/dual.sphysics.org\/\nGitHub: https:\/\/lnkd.in\/eTKwkcZG\n\n\ud83d\udc4f Let's give a big shoutout to the DualSPHysics team: Jos\u00e9 Dom\u00ednguez, Georgios Fourtakas, Alejandro Crespo, Benedict Rogers, Renato Vacondio, Corrado Altomare, Angelo Tafuni, Peter Stansby, Moncho G\u00f3mez Gesteira. \ud83d\udc4f\n\n#FluidDynamics #Simulation #DualSPHysics","linkedinURL":"https:\/\/www.linkedin.com\/feed\/update\/urn:li:activity:7105905630619525121","githubURL":null,"paperURL":null,"author":"Harry Christodoulou","createdDate":"09\/08\/2023"},{"title":"The title is: Quantifying #Uncertainty in #Chromatography Modeling: Advanced Error Modeling and Bayesian Uncertainty Quantification.","description":"\ud83e\uddea Quantifying #Uncertainty in #Chromatography Modeling: Advanced Error Modeling and Bayesian Uncertainty Quantification\ud83d\udcca\n\nWhen we talk about liquid chromatography modeling, precision is the name of the game. But what if we could do more than just account for detector noise? William Heymann, Juliane Glaser, Fabrice Schlegel, Will Johnson, Pablo Rolandi, and Eric von Lieres just tried to answer that.\ud83d\udd2c \n\nCurrent methods often miss the mark when it comes to understanding the impact of experimental errors like pump delays and variable feed composition on model parameters and chromatograms. This paper introduces an advanced uncertainty quantification method that addresses this limitation.\ud83d\udcc8 \n\nGrounded in Bayes' theorem and powered by Markov chain Monte Carlo with an ensemble sampler, this method offers robustness and versatility. It has been rigorously tested with both synthetic and industrial data, demonstrating its effectiveness. \ud83c\udfaf\n\n\ud83d\udd17Explore the #GitHub: https:\/\/lnkd.in\/eZxd86qU\n\ud83d\udcdaRead the #Publication: https:\/\/lnkd.in\/erN6BAZs\n\n#ChromatographyModeling #BayesianAnalysis #DataScience #ResearchTools #OpenSource","linkedinURL":"https:\/\/www.linkedin.com\/feed\/update\/urn:li:activity:7105607356293488641","githubURL":null,"paperURL":null,"author":"Antonio Benedetti","createdDate":"09\/07\/2023"},{"title":"The title is: Mastering XRay Diffraction (XRD) Made Easier with xrd Python Package!","description":"\ud83d\udd0d Mastering #XRay #Diffraction (XRD) Made Easier with #xrd Python Package! \ud83e\uddec\n\nIf you had to deal with X-ray diffraction (XRD) analysis, you know that deciphering those intricate profiles can be a challenge. But there's a game-changer in town, and it's called \"xrd.\"\ud83e\uddea\n\nDeveloped by the brilliant Amvrosios G. Georgiadis, this Python package simplifies XRD profile analysis. No more wrestling with complex software or spending hours on fitting!\ud83d\udcca \n\n\"xrd\" does it differently. It leverages the power of Python's automation capabilities to calculate XRD Crystallite (grain) size using the renowned Scherrer equation.\ud83d\udcc8\n\n Not only does it provide accurate size calculations, but it also delivers fitting plots and residuals for a crystal-clear comparison.\ud83d\ude80\n\n\ud83d\udd17 Ready to simplify your XRD analysis? Check out the \"xrd\" package here: https:\/\/lnkd.in\/efZu2GqG\n\n\ud83d\udca1 Kudos to Amvrosios G. Georgiadis for making XRD analysis accessible and efficient! \ud83d\ude4c\n\n#XRDAnalysis #PythonPackage #MaterialsScience #DataAnalysis #ResearchTools","linkedinURL":"https:\/\/www.linkedin.com\/feed\/update\/urn:li:activity:7105241998181183488","githubURL":null,"paperURL":null,"author":"Antonio Benedetti","createdDate":"09\/06\/2023"},{"title":"The title is: CFD Modeling of Powder Flow in a Continuous Horizontal Mixer","description":"\ud83c\udf1f Exploring CFD Modeling for Powder Flow in Pharma \ud83d\udc8a\n\nPowder flow and mixing are very important in industries like #pharmaceuticals, food, and cosmetics. In some industries, there has been a shift in the mixing process, moving away from conventional batch units and transitioning towards continuous mixers #continuous. \n\n\ud83d\udcda We just stumbled upon an intriguing journal article titled \"CFD Modeling of Powder Flow in a Continuous Horizontal Mixer\". \ud83d\udca1\n\nIn this work, the authors introduce a model to simulate powder flow in continuous horizontal mixers. Their main challenge? Finding a reliable rheological model to accurately simulate granular flows. They opted for the \u03bc(I)-rheology model, kicking off an exciting journey.\n\n\ud83e\uddea First, they conducted a series of granular collapse experiments, proving that this model can successfully replicate complex flows. They also used experimental data to assess the material properties of the powders they studied.\n\n\ud83d\udcbb The authors had to tackle another obstacle: Computational Cost \ud83d\udcb0. They explored two techniques: sliding mesh and multiple reference frame (MRF). While sliding mesh proved to be accurate, it came at a high cost due to boundary rotations, making it impractical for industrial use. On the flip side, the multiple reference frame technique delivered precise results with significantly lower computational expenses.\n\n\ud83c\udf10 The results section concludes with a sensitivity analysis, shedding light on how the mixer solid mass loading is affected by the material properties of the powder \ud83d\udcc8\n\n\ud83d\udd17 For the complete article and in-depth insights, check out the publication:\u00a0https:\/\/lnkd.in\/eHZXm-XD\n\n\ud83d\udc4f Let's give a round of applause to the authors Mehdi Biroun, Eva Sorensen, Jon Hilden, and Luca Mazzei \ud83d\udc4f\n\n#PharmaResearch #PowderFlow #Modelling #Simulation #CFD","linkedinURL":"https:\/\/www.linkedin.com\/feed\/update\/urn:li:activity:7104803265963257856","githubURL":null,"paperURL":null,"author":"Harry Christodoulou","createdDate":"09\/05\/2023"},{"title":"The title is: SPyCE: A Structured and Tailored Series of Python Courses for (Bio)Chemical Engineers","description":"\ud83d\udca1 Are you a (Chemical) Engineer who wants to learn how to program in Python? \ud83d\udc0d\n\n\ud83c\udf10 In today's world, the demand for digitalization & Industry 4.0 skills has never been greater. Python, at the forefront of this transformation, stands out as one of the most sought-after tools in the engineering domain.\n\n\ud83c\udf1f For this reason, we are really excited to come across SPyCE: A Structured and Tailored series of Python Courses, designed specifically for (Bio)Chemical Engineers.\n\n\ud83c\udf93 As a testament to its effectiveness, part of the SPyCE series has already been integrated into the curriculum at the prestigious Technical University of Denmark (DTU). Students who have taken these courses have reported significant benefits, from solving systems of differential equations to conducting simulations and much more, all using Python.\n\n\ud83d\udcaa What is even better? The SPyCE series is available to everyone! It is accessible on GitHub, making it a valuable resource for engineers, industry professionals, students, and Python enthusiasts. \u2764\ufe0f\ud83d\udc0d \n\n\ud83c\udf89\ud83d\udc4f Kudos to the people behind SPyCE and authors of the article introducing the Python Courses: Fiammetta Caccavale, Carina L. Gargalo, Krist Gernaey and Ulrich Kr\u00fchne, from DTU - Technical University of Denmark \ud83c\udf89\ud83d\udc4f\n\n\ud83d\udd17 Dive into the world of SPyCE on GitHub: https:\/\/lnkd.in\/eC_bnuzt\n\ud83d\udd17 Link to the article: https:\/\/lnkd.in\/eDyUnWXH\n\n#Education #ChemicalEngineers #Python #Courses","linkedinURL":"https:\/\/www.linkedin.com\/feed\/update\/urn:li:activity:7104452437117149184","githubURL":null,"paperURL":null,"author":"Harry Christodoulou","createdDate":"09\/04\/2023"},{"title":"The title is: Physics-informed Neural Networks for Bioprocess Hybrid Model Construction","description":"\ud83e\udde0 Physics-informed Neural Networks for Bioprocesses \ud83e\udda0\n\n\ud83d\udcc8 Mathematical modelling is crucial for understanding and optimizing bio  processes, as validated dynamic models can predict outcomes, reducing the need for extensive experiments. \n\n\ud83d\udca1 However, challenges arise in finding appropriate kinetic model structures, often leading to overparameterization, while data-driven models may suffer from overfitting and poor generalization due to limited experimental data. \ud83e\udd14\n\n\ud83d\udcda In the paper titled \"Investigating physics-informed neural networks for bioprocess hybrid model construction,\" researchers from the The University of Manchester and Imperial College London introduce an interesting solution to streamline complex biochemical modelling. They use Physics-Informed Neural Networks (PINNs) to combine physical knowledge and data, improving the way we design and optimize biochemical processes.\n\n\ud83e\udd16 The framework combines possible kinetic structures from phenomenological knowledge and simultaneously identifies the most likely hybrid model structure and time-varying parameter trajectories. By doing so, it offers a promising solution to enhance the efficiency and accuracy of hybrid model construction in biochemical engineering research.\n\n\ud83d\udc4f Hats off to the researchers behind this ESCAPE33 contribution: Alexander William Rogers, Ilya Orson Sandoval, Ehecatl Antonio del Rio Chanona, and DONGDA ZHANG \ud83c\udf1f\n\n\ud83d\udd17 To know more about this work, you can read the full article here: https:\/\/lnkd.in\/e9FjdNke\n\n#PhysicsInformed #NeuralNetwork #ChemicalEngineering #ESCAPE33","linkedinURL":"https:\/\/www.linkedin.com\/feed\/update\/urn:li:activity:7104086270812774400","githubURL":null,"paperURL":null,"author":"Harry Christodoulou","createdDate":"09\/03\/2023"},{"title":"The title is: Beyond the Endpoint: The Power of #Dynamic #Design of #Experiments (#DoDE)","description":"\ud83e\uddeaBeyond the Endpoint: The Power of #Dynamic #Design of #Experiments (#DoDE)\ud83d\udd2c\n\nWe've delved into the power of Design of Experiment (DoE) methodologies, but what if we could capture not just the endpoint but the entire dynamic journey of experiments? Enter the groundbreaking work by Christos Georgakis in the realm of chemical processes. \ud83d\ude80\n\nIn 2013, Georgakis introduced a game-changing methodology for designing experiments, taking optimization to a whole new level. This approach is a game-changer for processes like specialty chemical, pharmaceutical, and food production, where knowledge-driven models may not be readily available.\ud83d\udd04\n\n The approach, known as the Design of Dynamic Experiments (DoDE), goes beyond the traditional DoE by systematically exploring dynamic signatures, called dynamic subfactors (DSFs), in the time-dependent behavior of decision variables.\ud83c\udf21\ufe0f \n\nCase studies involving a nonisothermal reactor and a penicillin fermentation process showcase the power of DoDE. With just a handful of experiments, precise process optimization becomes a reality, even without a comprehensive knowledge-driven model.\ud83d\udca1 \n\nThe results? Optimal operating conditions obtained through DoDE are remarkably close to those derived from knowledge-driven models. This means faster, more efficient optimization for time-varying processes.\ud83d\udcd6 \n\n\ud83d\udcdaDive deeper into this innovative methodology: https:\/\/lnkd.in\/ei9ggXVG\n\n#ChemicalProcesses #ExperimentDesign #ProcessOptimization #Innovation #ChemicalEngineering","linkedinURL":"https:\/\/www.linkedin.com\/feed\/update\/urn:li:activity:7103731389648248832","githubURL":null,"paperURL":null,"author":"Antonio Benedetti","createdDate":"09\/02\/2023"},{"title":"The title is: Exploring Explainable ML: Predicting Solvation Gibbs Energy","description":"\ud83d\udd0d Exploring Explainable ML: Predicting Solvation Gibbs Energy \ud83d\udd2c\n\nChallenges persist in predicting solvation free energy (\u0394Gsol) for diverse chemical systems. Enter a novel approach by Jos\u00e9 Caetano, Filipe Teixeira, and Natalia Cordeiro.\ud83c\udf1f\n\n In the realm of Machine Learning (ML), they've developed a supervised model that not only predicts \u0394Gsol accurately but also provides valuable insights into chemical predictions.\ud83e\uddea\n\n The model utilizes open-source chemical features, encompassing electronic, structural, and surface area descriptors for various solvents and solutes. It goes beyond prediction by offering a glimpse into the \"why\" behind the predictions\ud83d\udcc8\n \nBy analyzing individual descriptor importance and optimizing their model, the team achieved remarkable results. Their model outperforms benchmark Neural Network methods without the need for complex quantum mechanical or molecular dynamic simulations.\n\ud83d\ude80\n\n The key takeaway? This model is a game-changer for computational chemistry problems. It's not just about making predictions; it's about understanding why those predictions are made.\n\n\ud83d\udd17 Interested in delving deeper? Check out the GitHub repo for the code: https:\/\/lnkd.in\/egYUUf8R\nPublication: https:\/\/lnkd.in\/eGP2jhNR\n\n#MachineLearning #Chemistry #SolvationEnergy #ExplainableAI #ComputationalChemistry","linkedinURL":"https:\/\/www.linkedin.com\/feed\/update\/urn:li:activity:7103414020207951873","githubURL":null,"paperURL":null,"author":"Antonio Benedetti","createdDate":"09\/01\/2023"},{"title":"The title is: BioSTEAM","description":"\ud83c\udf3f Discover BioSTEAM: Empowering Biorefinery Design, Simulation, Techno-Economic Analysis, & Life-Cycle Assessment \ud83c\udfed\n\nExploring the realm of biorefineries, where innovation meets sustainability! \ud83c\udf31 Traditional techno-economic analysis (TEA) methods have often fallen short, offering only glimpses into complex uncertainties and sensitivities.\n\n\ud83c\udf1f Just stumbled upon a very interesting open source platform. BioSTEAM addresses the intricate needs of designing, simulating, performing techno-economic analysis (TEA), and evaluating life-cycle assessments (LCA) for biorefineries. \n\nWhat sets BioSTEAM apart is its fusion of community-driven development and research institution support. This collaborative approach ensures that the platform remains relevant and up-to-date, benefiting from the expertise and input of a diverse group of contributors.\n\n\ud83d\udd17 You can found out more about the tool here: https:\/\/lnkd.in\/e_dNYg9z\n\ud83d\udd17 All models can be found in GitHub: https:\/\/lnkd.in\/eQUNdRE7\n\n\ud83d\ude80 Congratulations to Yoel Cortes-Pena, Jeremy Guest and all other developers and contributors to the platform. \ud83d\ude80\n\n#BioSTEAM #QSDsan #LCA #TEA #Simulation #OpenSource","linkedinURL":"https:\/\/www.linkedin.com\/feed\/update\/urn:li:activity:7102967843654094848","githubURL":null,"paperURL":null,"author":"Harry Christodoulou","createdDate":"08\/31\/2023"},{"title":"The title is: A Python-based approach for thermodynamic consistency tests of binary VLE data","description":"\u2b50 Thermodynamic consistency tests of VLE data. A Python-based tool \ud83d\udc0d\n\n\ud83e\uddea In our world of modelling, reliable experimental data is the critical for process design and optimization. However, the assessment of experimental vapor-liquid equilibrium (VLE) data often involves painstaking data mining and rigorous statistical analyses.\n\n\ud83d\udcda Just stumbled upon an interesting article titled \"A Python-based approach for thermodynamic consistency tests of binary VLE data\" authored by Pedro Cezareth and Martina Costa Reis from the University of S\u00e3o Paulo.\n\n\ud83d\udd2c This research introduces a Python-based approach that allows the evaluation of experimental VLE data for binary mixtures. The authors are developing a computational tool, \ud83c\udf89 openly accessible \ud83c\udf89, that accelerates the process of thermodynamic consistency testing. The approach includes a suite of tests like the L-W and Redlich-Kister. \n\n\ud83d\udcca This work promises to be a useful tool for modellers, enabling them to harness experimental data more efficiently in process simulation. \ud83d\udc4f Kudos to the authors!\ud83d\udc4f\n\n\ud83d\udd17 Curious to dive into the details? Check out the full paper here: https:\/\/lnkd.in\/ekcSz7in\n\n#ThermoModels #PythonInScience #ThermodynamicConsistency #VLEdata","linkedinURL":"https:\/\/www.linkedin.com\/feed\/update\/urn:li:activity:7102623875066146817","githubURL":null,"paperURL":null,"author":"Harry Christodoulou","createdDate":"08\/30\/2023"},{"title":"The title is: Embracing the Era of Big Data: A Fusion of Genome-Scale Modelling and Machine Learning","description":"\ud83d\udd2c\ud83d\udcca Embracing the Era of Big Data: A Fusion of Genome-Scale Modelling and Machine Learning \ud83e\uddec\ud83e\udd16\n\nIn the landscape of modern science, the realm of genomics stands as a colossal generator of data. With the avalanche of omics data surging forth at an unprecedented pace, the integration of genome-scale modelling and machine learning has emerged as a transformative force in organizing and deciphering this wealth of information. Authored by Athanasios Antonakoudis, Rod Barbosa, Pavlos Kotidis, and Cleo Kontoravdi, this exploration delves into the convergence of genome-scale modelling and machine learning techniques, revolutionizing our understanding of complex biological systems. \ud83c\udf0d\ud83d\udd0d\n\nIn this age of abundant data, genome-scale modelling takes center stage, orchestrating the intricate dance of organizing and analyzing omics data. Yet, the horizon of scientific knowledge occasionally falls short, especially in deciphering the intricate mechanisms underlying these data troves. Machine learning can be a versatile ally that steps in when mechanistic insights are insufficient or when data curation precedes mechanistic modelling. This synergy not only unlocks the hidden gems within complex biological systems but also propels the boundaries of what's achievable. \ud83d\udca1\ud83d\udee0\ufe0f\n\nThe discourse extends to the latest advancements in genome-scale modelling, emphasizing the development of optimization algorithms tailored for network enhancement, error reduction, intracellular constraining, and applications in strain design. Beyond the laboratory, the spotlight shines on the application of both supervised and unsupervised machine learning techniques in the realm of omics datasets, spanning microbial and mammalian cell systems.\ud83e\udda0\ud83d\udd0d\n\nAmidst the wealth of knowledge, a key highlight is the pioneering effort to meld the strengths of both modelling realms through hybrid approaches. The outcome is an enhanced capacity to dissect intricate biological systems with a multifaceted perspective, offering a more holistic understanding of the complexities at play. \ud83c\udf10\ud83e\uddea\n\nThis exploration goes beyond academia, offering practical insights enriched with references to open-source algorithms and tools that can facilitate new researchers to get familiar with the state of the art.\n\n \ud83d\udcda\ud83d\udd17 Link to Publication: https:\/\/lnkd.in\/eT3E4gp\n\n#Genomics #MachineLearning #DataAnalysis #BiologicalInsights #ScientificAdvancements #OmicsData #HybridModelling #OpenSourceResources #ResearchBreakthroughs","linkedinURL":"https:\/\/www.linkedin.com\/feed\/update\/urn:li:activity:7102325389603041282","githubURL":null,"paperURL":null,"author":"Antonio Benedetti","createdDate":"08\/29\/2023"},{"title":"The title is: HiGHS - An Optimization Tool for Linear Programming","description":"\ud83d\udd2c\ud83c\udf10 Unveiling HiGHS: An Optimization Tool for Linear Programming \ud83d\udca1\ud83d\ude80\n\nIn the dynamic field of life sciences, where data-driven decisions steer medical advancements and research breakthroughs, having robust optimization tools at hand is crucial. This brings us to HiGHS, a high-performance software that has caught the attention of professionals seeking effective solutions for linear programming challenges. Developed by Julian Hall, Ivet Galabova, Michael Feldmeier, and Filippo Zanetti from HiGHS Team at The University of Edinburgh, HiGHS presents itself as a significant contribution to the world of optimization tools. \ud83d\udee0\ufe0f\ud83d\udd0d\n\nHiGHS emerges as a versatile instrument capable of addressing intricate problems like large-scale sparse linear programming (LP), mixed-integer programming (MIP), and quadratic programming (QP) models. With both serial and parallel processing options, this software adapts to a wide range of computational requirements often encountered in life science endeavors. \ud83d\udcbb\ud83d\udcca\n\nNotably, HiGHS boasts adaptability at its core. Developed using C++11, it establishes seamless connections with various programming languages such as C, C#, FORTRAN, Julia, and Python. This adaptability is particularly significant for fostering interdisciplinary collaborations and promoting effective problem-solving\u2014an essential characteristic in the realm of life sciences.\n\nWhat's more, HiGHS is available for free under the MIT license on GitHub, providing professionals and researchers with a convenient means to integrate it into their workflow. \ud83c\udf10\ud83d\udd27\n\n\ud83d\udd17Link to #Github: https:\/\/lnkd.in\/e8-peGkx\n\n#HiGHS #OptimizationTool #LinearProgramming #LifeSciences #ResearchTools #ScientificAdvancements #ComputationalSolutions #DataDrivenInsights","linkedinURL":"https:\/\/www.linkedin.com\/feed\/update\/urn:li:activity:7101978602216243200","githubURL":null,"paperURL":null,"author":"Antonio Benedetti","createdDate":"08\/28\/2023"},{"title":"The title is: \"Digital Twins: The Key to Smart Product Development\"","description":"\ud83c\udf10\ud83d\udd2c Exploring #Digital #Twins in Smart Product Development \ud83d\ude80\ud83d\udca1\n\nAmid relentless innovation, we've often shared practical examples of digital tools that integrate with digital twins. Today, we're highlighting the enlightening article \"Digital Twins: The Key to Smart Product Development\" by McKinsey & Company \ud83d\udee0\ufe0f\ud83d\udcc8\n\nIn this piece, the authors stress that corporate success hinges on innovative product introductions. Around $30 trillion in forthcoming revenues are linked to unreleased products \ud83c\udf0d\ud83d\udcca\n\nAmid these challenges, digital twins emerge as transformative solutions. They replicate real-world product attributes, aiding design speed, cost reduction, and process enhancement. Riveting data shows that 75 percent of product development executives prioritize digitization \ud83d\udcbb\ud83d\udcaa\n\nThe article uncovers applications and benefits of digital twins, from risk-free design exploration to real-world data-driven enhancements. Testimonials highlight digital twins' impact on development time, prototyping, and product quality.\ud83c\udf1f\ud83d\udcca\n\nIntegration of digital twins unlocks transformative potential, especially for customized products. This tech facilitates pre-design simulations, verifying customer needs. A phased approach spans competitive intelligence, design, software definition, and excellence. \u2728\ud83d\udd0d\n\nAre you prepared to embrace this new era of product development, driven by digital twins? \ud83d\ude80\ud83d\udd0d\n\nLink to Publication: https:\/\/mck.co\/44vCjns\n\n\ufeff#DigitalTwins #SmartProductDevelopment #Innovation #TransformativeTechnology #ProductCreation #FutureofDesign #Optimization #IndustryInsights #TechAdvancements #VirtualReplicas","linkedinURL":"https:\/\/www.linkedin.com\/feed\/update\/urn:li:activity:7101561567413968896","githubURL":null,"paperURL":null,"author":"Antonio Benedetti","createdDate":"08\/27\/2023"},{"title":"The title is: Enhancing Crystallization Process Design through Combined D-optimal and Estimability Model-Based Design of Experiments","description":"\ud83d\udd2c\ud83d\udcca Enhancing Crystallization Process Design through Combined D-optimal and Estimability Model-Based Design of Experiments\u2744\ufe0f\ud83c\udf10\n\nMathematical models play a crucial role in the optimization of batch crystallization processes, driving efficiency and reliability in pharmaceutical and chemical production. In this context, Xuming Yuan and Brahim Benyahia have introduced an innovative approach to enhance the reliability of mathematical models for batch crystallization processes. Their work focuses on optimizing the design of experiments (DoE) to create robust models, specifically studying the cooling crystallization of paracetamol in water and propanol. This insight can have broader applications in the field of crystallization research. \ud83e\uddea\ud83d\udcc8\n\nThe foundation of their approach is a detailed mathematical model that accounts for various aspects of the crystallization process. From nucleation to growth, agglomeration, and dissolution kinetics, the model captures the complexities involved. \ud83e\uddca\u2699\ufe0f\n\nThey begin by analyzing the structural identifiability of the model, checking if the model parameters can be uniquely determined based on the process behavior. This helps identify the key outputs needed for accurate model development. \ud83e\uddd0\ud83d\udd0d\n\nThe core of their method is a Model-Based Design of Experiments (MBDoE) that combines two techniques: D-optimal criterion and estimability analysis. This fusion aims to increase the accuracy of model parameters and reduce uncertainties. Their approach also involves a clever experimental strategy called temperature cycling, which maximizes data collection efficiency while minimizing waste. \ud83c\udf21\ufe0f\ud83e\uddfc\n\nThis work has implications beyond the specific crystallization process studied, offering valuable insights for optimizing various chemical processes. To delve deeper into their research, explore the full publication: https:\/\/lnkd.in\/euebqQZP\n\n#CrystallizationResearch #ProcessOptimization #MathematicalModeling #ExperimentalDesign #ChemicalProcesses #InnovativeApproach #ScientificInsights #DataDrivenMethods #EnhancingReliability","linkedinURL":"https:\/\/www.linkedin.com\/feed\/update\/urn:li:activity:7101239412914548736","githubURL":null,"paperURL":null,"author":"Antonio Benedetti","createdDate":"08\/26\/2023"},{"title":"The title is: Advancing Solubility Prediction with Unified Machine Learning Framework","description":"\ud83d\udd2c\ud83e\uddea Advancing #Solubility #Prediction with Unified #ML Framework \ud83d\udcca\ud83d\ude80\n\nIn the dynamic landscape of molecular thermodynamic, a significant step has been taken by Antony D. Vassileiou, along with Murray Robertson, Bruce Wareham, Mithushan Soundaranathan, Sara Ottoboni, PhD, MRSC, Alastair Florence, Thoralf Hartwig, and Blair Johnston. This innovative effort introduces a unified machine learning (ML) framework that sets a new standard for predicting solubility across diverse organic solvents, offering potential applications that extend beyond the boundaries of this field. \ud83c\udf10\ud83d\udd0d\n\nAt the core of this achievement is a single, cohesive ML-based model tailored for predicting solubility across various solvents. This integrated approach seeks to unravel insights while addressing inherent challenges. The framework's performance was rigorously compared with COSMO-RS, a widely used mechanistic model for solubility predictions. Importantly, the study explored the effectiveness of the model with and without COSMO-RS integration in the training data, resulting in a hybrid model that combines data-driven insights with mechanistic understanding. This hybrid approach is inspired by successful applications of ML across different domains. \ud83d\udcc8\ud83d\udd2c\n\nDriving this framework is the Random Forest (RF) algorithm, carefully chosen for its simplicity, robust performance, and rapid execution. In comparison to other ML algorithms, RF's streamlined hyperparameters offer efficiency and reliability. The algorithm's ability to adaptively select features ensures efficient use of relevant information, minimizing the need for complex hyperparameter tuning, especially in the early stages of exploration. \ud83d\udee0\ufe0f\ud83d\udca1\n\n\ud83d\udd17Link to #Github: https:\/\/lnkd.in\/dPiTQ_2E\n\ud83d\udcdaLink to Publication: https:\/\/lnkd.in\/dTxhQxmD\n\n#MolecularScience #SolubilityPrediction #MachineLearning #Innovation #HybridModels #ScientificInsights #ResearchDiscoveries #Cheminformatics #DataDrivenApproach #ScientificAdvancements","linkedinURL":"https:\/\/www.linkedin.com\/feed\/update\/urn:li:activity:7100847847222259713","githubURL":null,"paperURL":null,"author":"Antonio Benedetti","createdDate":"08\/25\/2023"},{"title":"The title is: Moisture Soft Sensor for Agitated Pan Dryers Using a Hybrid Modeling Approach","description":"\ud83d\udcc8 Soft Sensor for agitated pan dryers \ud83c\udf1f\n\nIn the ever-evolving world of pharmaceutical modelling, precision is paramount \ud83c\udfaf. Soft sensors enable real-time monitoring and control of critical process variables, improving product quality and process efficiency while reducing the need for expensive and time-consuming experiments and laboratory tests. \n\n\u2b50 In this regard, we would like to share a highly intriguing paper titled 'Moisture Soft Sensor for Agitated Pan Dryers Using a Hybrid Modeling Approach,' authored by Zilong Wang, Reza Kamyar, Hamidreza Mehdizadeh, and Pushkar Yashvant Pendse. \u2b50 \n\n\ud83d\udcda The article introduces a hybrid soft sensor model which monitors moisture content in Active Pharmaceutical Ingredient (#API) wet cake during agitated drying. By utilizing data from five batches for calibration and validating it through an additional 21 commercial-scale batches, this modelling approach shows accuracy in real-time moisture estimations.\n\n\ud83d\udd0d What's more, the study delves into dynamic Global Sensitivity Analysis , investigating the impact of input process parameters on the variability of soft sensor predictions throughout the drying process. These findings highlight the soft sensor's role in not just monitoring and controlling the API drying process, but also paving the way for a Quality by Design (#QbD) approach.\n\n\ud83c\udf89 Kudos to the Pfizer team for their great work at the intersection of technology, modelling and healthcare! \ud83d\udca1\n\nLink to the paper: https:\/\/lnkd.in\/eaa6nxnd\n\n#PharmaInnovation #SoftSensor #ManufacturingExcellence #PharmaModelling","linkedinURL":"https:\/\/www.linkedin.com\/feed\/update\/urn:li:activity:7100469100476256256","githubURL":null,"paperURL":null,"author":"Harry Christodoulou","createdDate":"08\/24\/2023"},{"title":"The title is: Simplifying Gas Phase Mixture Modeling and Beyond","description":"\ud83d\udd2c\ud83d\udcca #ASALI: Simplifying Gas Phase Mixture Modeling and Beyond \ud83d\ude80\ud83d\udca1\n\nToday we want to introduce ASALI, a transformative package for modeling gas phase mixtures. Developed by Stefano Rebughini , this open-source tool offers a gateway for engineers, chemists, and students to delve into the intricacies of gas phase mixture modeling and explore its possibilities. \ud83c\udf10\ud83d\udd0d\n\nASALI caters to two distinct user profiles, each designed to match varying levels of expertise:\n\n1\ufe0f. GUI Version: For those venturing into the realm of gas phase mixture modeling, the GUI version of ASALI proves to be an invaluable asset. With its user-friendly interface, this version is particularly beneficial for newcomers who wish to grasp the fundamentals of gas phase mixture modeling without delving into complex coding. It serves as an accessible entry point for intuitive modeling and simulation, making the learning curve smoother. \ud83c\udf9b\ufe0f\ud83d\udd2c\n\n2\ufe0f. API Version: Geared towards individuals aspiring to master the art of gas phase mixture modeling, the API version of ASALI stands as a robust tool. This version offers a seamless integration pathway into various programming languages, allowing advanced users to craft intricate simulations with precision. By harnessing ASALI's API capabilities, users can plunge into the depths of modeling intricacies while honing their expertise in this dynamic field. \ud83d\udcbb\ud83d\ude80\n\nASALI's strong integration with Cantera further amplifies its potential, enabling both novices and experts to harness the power of gas phase mixture modeling without being hindered by coding complexities. Whether you're embarking on your first journey into this realm or striving to become a seasoned authority, ASALI guides you through the intricate landscape of gas phase mixture dynamics. \ud83d\udcbb\ud83d\udd27\n\n\ud83d\udd17For a deeper dive into ASALI and its features, explore the #GitHub Repository: https:\/\/lnkd.in\/ey4e7vvu\n\n#ASALI #GasPhaseMixture #Modeling #OpenSource #ChemicalEngineering #EngineeringTools #CanteraIntegration #Simulation #ExpertiseDevelopment #Innovation","linkedinURL":"https:\/\/www.linkedin.com\/feed\/update\/urn:li:activity:7100071556248137728","githubURL":null,"paperURL":null,"author":"Antonio Benedetti","createdDate":"08\/23\/2023"},{"title":"The title is: Novana - A Swift Cheminformatics Tool for Molecular Analysis","description":"\ud83d\udd2c\ud83d\udcca Unveiling #Novana: A Swift #Cheminformatics Tool for #Molecular #Analysis \ud83d\ude80\ud83d\udca1\n\nToday, we're shifting gears to delve into a great cheminformatics tool known as Novana (Novelty Analysis), crafted by Gian Marco Ghiandoni. This tool introduces a rapid, millisecond-level molecular dissection into scaffolds and shapes, inspired by a method outlined in ACS Med. Chem. Lett. 2020.  \ud83d\ude80\ud83d\udd0d\n\nWith Novana, molecule datasets can be scrutinized across multiple levels of abstraction, offering an alternative approach to conventional structural and similarity methods. Moreover, the tool opens doors to innovative applications, from drug repurposing to curating data sets for machine learning. Novana is a cheminformatics tool that takes an input molecule and produces its scaffold and shape decompositions. The tool can potentially also be used for drug discovery\/repurposing and the creation of train\/validation data sets for machine learning. \ud83d\udca1\ud83d\udc8a\n\nExplore Novana's Fascinating Functionality:\n\ud83c\udf10 Beginning with a SMILES input:A scaffold emerges through recursive removal of terminal atoms, retaining only those bonded with at least two different atoms (e.g., cycles and chains). Notably, double-bonded terminal atoms are eliminated.\nTo maintain molecular stability, any retained atoms with unfavorable valences are adjusted through hydrogen addition or removal, guided by predefined heuristics.\n The charges of modified atoms are neutralized, while unchanged atoms retain their original charges.\n\ud83e\uddea Novana doesn't stop there - it deftly handles mixtures:If a mixture is detected, the largest fragment containing rings becomes the input for decomposition.\nIn cases where ring-containing structures are absent from the SMILES input, Novana provides error feedback.\n\nFor more details, check out Novana's repository: https:\/\/lnkd.in\/gy-aUE7j\n\n#Novana #Cheminformatics #MolecularDecomposition #Innovation #ChemicalAnalysis #MachineLearning #DataAnalysis #Chemistry #ScientificBreakthrough","linkedinURL":"https:\/\/www.linkedin.com\/feed\/update\/urn:li:activity:7099769594168438784","githubURL":null,"paperURL":null,"author":"Antonio Benedetti","createdDate":"08\/22\/2023"},{"title":"The title is: Pymoo: Multi-Objective Optimization in Python","description":"\ud83d\udca1 Introducing Pymoo: Multi-Objective Optimization in Python! \ud83d\udc0d\n\nPython's prowess in data science, machine learning, and deep learning is undeniable. But what about multi-objective optimization? Enter Pymoo, a comprehensive Multi-Objective Optimization package in Python.\n\n\ud83d\udd17 Learn more: https:\/\/pymoo.org\n\n\ud83d\ude80 Pymoo is a solution for multi-objective optimization challenges. With its flexible architecture, customization options, and parallelization capabilities, Pymoo empowers modellers and industry practitioners to tackle complex optimization tasks head-on. Pymoo's modifiability gives to the end-user the power to fine-tune optimization strategies. Adding to everything else, we must admit that we love the visualization methods coded into Pymoo!\n\n\ud83d\udc49 Ready to explore? Check out the article \"Pymoo: Multi-Objective Optimization in Python\" to get started with Pymoo's capabilities. \n\n\ud83d\udd17 Link to the article: https:\/\/lnkd.in\/eeNuDKq6\n\n\ud83c\udf89 Many congratulations to the developers Julian Blank and Kalyanmoy Deb! \ud83c\udf89\n\n#Pymoo #Optimization #Python #Optimization","linkedinURL":"https:\/\/www.linkedin.com\/feed\/update\/urn:li:activity:7099432998067916801","githubURL":null,"paperURL":null,"author":"Harry Christodoulou","createdDate":"08\/21\/2023"},{"title":"The title is: Exploring Dynamic Surrogate Modeling for Continuous Processes","description":"\ud83c\udf1f Exploring Dynamic Surrogate Modeling for Continuous Processes \ud83c\udf1f\n\nThere is significant interest within the pharmaceutical industry regarding surrogate models, especially when addressing scheduling and control problems. Surrogate models have demonstrated their crucial role in many instances, enhancing computational efficiency and refining the efficacy and speed of optimization algorithms. \ud83d\udca1\n\nWe recently came across an intriguing article titled \"Dynamic Surrogate Modeling for Control Applications in Continuous Processes\" by Alessandro Di Pretoroa, Andrea Tomaselli, Flavio Manenti, and Ludovic Montastruc from Universit\u00e9 de Toulouse and Politecnico di Milano. The study focuses on the dynamic non-isothermal CSTR reactor, elucidating the process of surrogate modelling for temperature and concentration. By utilizing a variety of sampling techniques and sizes through the ALAMO\u00ae software, the researchers constructed comprehensive models. \ud83d\udcda\n\nThe authors not only successfully developed a dynamic surrogate modelling approach for process control, proving its effectiveness, but also achieved a remarkable one-order-of-magnitude reduction in computational time. \u23f2\ufe0f\n\nKudos to the team! \ud83d\udc4f If you are interested in delving deeper into this research, you can find more information through this link: https:\/\/lnkd.in\/ecMfjdtS \ud83d\udd17\n\n#ALAMO #SurrogateModelling #Optimization #ProcessControl\u00a0","linkedinURL":"https:\/\/www.linkedin.com\/feed\/update\/urn:li:activity:7099027303480844288","githubURL":null,"paperURL":null,"author":"Harry Christodoulou","createdDate":"08\/20\/2023"},{"title":"The title is: \"Multi-fidelity Bayesian Optimisation of Reactor Simulations using Deep Gaussian Processes\"","description":"\ud83c\udf1f Unlocking the Potential of Deep Gaussian Processes: Let's accelerate Reactor Optimization \ud83d\udcc8\n\n\ud83d\ude80 Coiled tube reactors + pulsed-flow = Good Mixing! \ud83d\ude80\n\n\ud83d\udca1 But wait, there is more! \n\n\ud83d\udcc4 In a recent article, authored by Tom Savage, Nausheen Basha, Omar Matar, and Ehecatl Antonio del Rio Chanona, a very interesting strategy for Coiled Tube Reactor Optimization emerges. This strategy capitalizes on the prowess of Deep Gaussian Processes within a Bayesian optimization framework.\n\n\ud83d\udd0d Titled \"Multi-fidelity Bayesian Optimisation of Reactor Simulations using Deep Gaussian Processes,\" the paper delineates a very interesting approach which leverages deep Gaussian processes in a Bayesian optimization algorithm. Through the integration of multi-fidelity surrogate models, the team expedites optimization, fostering the design of state-of-the-art chemical reactors with versatile applications in industries such as #pharmaceuticals.\n\n\ud83c\udf89 Let's extend hearty congratulations to the authors from Imperial College London for propelling innovation in #chemical #engineering! \ud83c\udf89\n\n\ud83d\udd17 Dive into the full article here: https:\/\/lnkd.in\/efTbJwBt\n\n#ChemicalEngineering #GaussianProcesses #BayesianOptimization #ReactorModelling","linkedinURL":"https:\/\/www.linkedin.com\/feed\/update\/urn:li:activity:7098651955891200000","githubURL":null,"paperURL":null,"author":"Harry Christodoulou","createdDate":"08\/19\/2023"},{"title":"The title is: Extended Multiple-Curve Resolution Framework for the Calibration of First-Principles Models","description":"\u2b50 Framework for the Calibration of First-Principles Models \ud83d\udcbb\n\nThe 33rd European Symposium on Computer-Aided Process Engineering was successfully concluded in June. However, we continue to discover remarkable scientific works which were presented during the event. We just came across the article titled \"Extended Multiple-Curve Resolution Framework for the Calibration of First-Principles Models\".\n\n\ud83d\udca1This work introduces a parameter estimation framework which tackles the fusion of both spectral and non-spectral information for precise Crystallization Model parameter estimation. The authors showcase their approach through a detailed analysis of a crystallization system. Spectroscopic data captures the dynamics of the liquid phase, while particle sizing techniques characterize the solid phase.\n\n\ud83d\udcca The outcomes of this study underscore the framework's versatility in handling diverse experimental data type used for parameter estimation. Particularly for secondary nucleation, the authors have found a strong influence of data uncertainty on the estimation accuracy. Such findings highlight the importance of addressing uncertainties in data, and even reconsidering the structure of first principles models.\n\n\ud83e\udd47And we have saved the best for last: The Parameter Estimation framework of the paper is integrated into #PharmaPy. You can access PharmaPy through its official documentation at https:\/\/lnkd.in\/ej7vXtWP and in GitHub: https:\/\/lnkd.in\/e_3gFQmi\n\n\ud83d\udc4f Congratulations to Daniel Casas-Orozco, Ph.D., Jaron Mackey, Ilke Akturk, Rex Reklaitis, and Zoltan Nagy for this insightful paper! \n\n\ud83d\udd17 Links:\n- to the book https:\/\/lnkd.in\/epE7PpDc\n[Computer Aided Chemical Engineering 52, 1439-1444]\n- to the article https:\/\/lnkd.in\/eX2Uw7kg\n\n#ProcessEngineering #Innovation #PharmaPy #ParameterEstimation #UncertaintyAnalysis","linkedinURL":"https:\/\/www.linkedin.com\/feed\/update\/urn:li:activity:7098310451167408128","githubURL":null,"paperURL":null,"author":"Harry Christodoulou","createdDate":"08\/18\/2023"},{"title":"The title is: Enhancing Model Validation with Procrustes Cross-Validation.","description":"\ud83d\udd2c\ud83d\udcca Enhancing #Model #Validation with #Procrustes #CrossValidation (PCV) \ud83d\udcc8\ud83d\udd0d\n\nWhether you're still embracing the term \"chemometrics\" or have transitioned to the data science AI\/ML buzz, you undoubtedly recognize the significance of model validation. Introducing Procrustes cross-validation (PCV), a method developed by Sergey Kucheryavskiy, Oxana Rodionova, and Alexey Pomerantsev. This technique adds a new layer of depth to validation procedures and addresses the critical need for robust model evaluation. \ud83d\ude80\ud83e\uddea\n\nImagine you're crafting chemometric models like PCA, SIMCA, PCR, or PLS. Ensuring these models are robust is paramount. PCV steps in with a fresh perspective. It generates a PV-set, a new dataset incorporating sampling uncertainties estimated through k-fold cross-validation. This set functions as an independent test bed for validating your models. \ud83d\udcca\ud83d\udd2c\n\nThe mechanics behind PCV are rooted in the k-fold cross-validation algorithm. Unlike traditional methods, PCV doesn't just validate the model; it creates a pseudo-validation set that emulates real-world sampling variations. This facilitates calculations of residual distances, explained variance, scores, and more, providing insights into model performance that might otherwise remain hidden. \ud83d\udd0e\ud83d\udcc8\n\nThe repository accompanying PCV offers implementations in various programming languages: #R, #MATLAB, #Python, and #Javascript. Kudos to the authors for this great efforts towards accessibility and open-source!!!\n\n\ud83d\udd0dLink to #Github: https:\/\/lnkd.in\/ei9RPtGs. \n\ud83d\udcdaLink to Publication: https:\/\/lnkd.in\/eVj7Rzm9\n\n#Chemometrics #ModelValidation #ProcrustesCrossValidation #DataPrecision #EnhancedInsights #DataAnalysis #Research #ValidationApproach #opensource","linkedinURL":"https:\/\/www.linkedin.com\/feed\/update\/urn:li:activity:7098000308919746561","githubURL":null,"paperURL":null,"author":"Antonio Benedetti","createdDate":"08\/17\/2023"},{"title":"The title is: FreeFlux: A Helpful Python Tool for Metabolic Insights","description":"\ud83d\udd2c\ud83d\udd04 Introducing #FreeFlux: A Helpful Python Tool for #Metabolic #Insights \ud83c\udf1f\ud83e\uddea\n\nEver wondered how the intricate dance of molecules happens inside living cells? It's like a captivating puzzle waiting to be solved. Welcome to the world of metabolic flux analysis, a powerful tool that helps us decipher these molecular movements. But wait, there's a twist\u2014finding the right software to analyze this complex choreography can be a challenge. That's where Chao Wu, Michael Guarnieri, Ph.D., and Wei Xiong come in, introducing FreeFlux, a remarkable Python package that unravels the mysteries of metabolism! \ud83d\ude80\ud83d\udd2c\n\nMetabolic flux analysis is like being an investigator of cellular pathways. It allows us to understand how molecules move, react, and transform inside cells. Think of it as a spotlight illuminating the secrets of biochemical reactions. But until now, there haven't been many user-friendly and open-source tools to help scientists explore this fascinating realm efficiently.\n\nEnter FreeFlux! This ingenious Python package is designed to tackle the complexities of metabolic flux analysis. It's like having a trusty guide that helps us navigate the intricate pathways within cells. FreeFlux is built to simulate how molecules are labeled and how they move around, helping us comprehend the dynamic choreography of metabolism. \ud83c\udf10\ud83d\udd0d\n\nFreeFlux doesn't just stop at the basics. It's not only a friend to researchers but also a versatile companion that plays well with other programs. It can estimate the flux of molecules quickly and accurately, providing us with insights into cellular behavior. It's like having a map that lets us explore the mysteries hidden within every cell. \ud83c\udf31\ud83d\udcca\n\nTo make sure FreeFlux is doing its job right, scientists have tested it against other tools, and it's proven to be really reliable. Whether they used fake data or real experiments, FreeFlux's guesses were really close to the truth. \ud83c\udfc6\ud83d\udca1\n\n\ud83d\udd17Link to #Github : https:\/\/lnkd.in\/eGY6qDrb  \n\ud83d\udcdaLink to Documentation: https:\/\/lnkd.in\/e7xZQr2F\n\n#CellMysteries #EasyScienceTools #HelpfulSoftware #SmartComputers #MetabolismDiscoveries #ResearchAdvances  #InnovativeIdeas #UnderstandingCells","linkedinURL":"https:\/\/www.linkedin.com\/feed\/update\/urn:li:activity:7097613981724336128","githubURL":null,"paperURL":null,"author":"Antonio Benedetti","createdDate":"08\/16\/2023"},{"title":"The title is: Mastering the Complexity of Piecewise Regression Analysis","description":"\ud83d\udcca\ud83d\udd27 Mastering the #Complexity: Unveiling the Power of #Piecewise #Regression #Analysis \ud83c\udf1f\ud83d\udcc8\n\nIn the realm of predictive analysis, regression stands tall as a beacon of insight, unraveling the intricate relationships between independent and dependent variables. This journey into understanding is guided by Ioannis Gkioulekas, PhD and Lazaros Papageorgiou , who navigate the complexities with precision and innovation. \ud83d\ude80\ud83d\udcca\n\nAt its core, regression seeks to craft a mathematical narrative that captures the interplay between predictors and responses. The essence lies in uncovering how the response's value dances in tandem with the varying predictors. While linear regression paints the simplest picture, the landscape evolves when multiple predictors come into play. Enter the stage, piecewise regression analysis. \ud83c\udfad\ud83d\udca1\n\nPiecewise regression analysis elevates the game by segmenting the data into distinct regions, each painted with its unique regression function. A star of this approach is the OPLRA (Optimal Piecewise Linear Regression Analysis) model, a mathematical programming marvel that optimally partitions the data and curates linear regression functions, all while minimizing the Mean Absolute Error between prediction and reality. \ud83c\udf10\ud83d\udcc9\n\nHowever, where many regions converge, overfitting lurks in the shadows, potentially clouding outcomes. This endeavor doesn't merely end with the OPLRA; it's the launching pad for an ingenious extension. A novel model emerges, one that wields the power to tackle overfitting and to elegantly decide the optimal number of regions. \ud83c\udfaf\ud83d\udd0d\n\nHow does this magic unfold? Information criteria like the Akaike and the Bayesian step onto the stage. These criteria applaud predictive prowess while casting a critical eye on model complexity. With this dual-edged sword, the extended OPLRA navigates through the overfitting maze, transforming data into insight with unparalleled accuracy and clarity. \ud83c\udf1f\ud83c\udf93\n\n\ud83d\udd17Link to Publication: https:\/\/lnkd.in\/gSTqYdMP\n\n#RegressionAnalysis #PiecewiseRegression #OptimalModeling #InformationCriteria #StatisticalInsight #InnovativeResearch #DataAnalysis #ModelComplexity #PredictiveProwess #ResearchAdvancements #StatisticalWisdom","linkedinURL":"https:\/\/www.linkedin.com\/feed\/update\/urn:li:activity:7097269375031808000","githubURL":null,"paperURL":null,"author":"Antonio Benedetti","createdDate":"08\/15\/2023"},{"title":"The title is: Mastering Thermal Radiation Modelling in Freeze Drying of Biopharmaceutical Product","description":"\ud83d\udd2c\ud83c\udf21\ufe0f Mastering #Thermal #Radiation Modelling in #Freeze #Drying of Biopharmaceutical Product \ud83e\uddea\ud83e\uddca\n\nFreeze drying, a cornerstone of biopharmaceutical manufacturing, faces a unique challenge: the impact of thermal radiation. This factor significantly influences the drying process, particularly for vials positioned near the tray edges and corners, leading to uneven product outcomes. To ensure precision in determining drying endpoints amid varying heat transfer rates, understanding and predicting thermal radiation effects is paramount. Have a read at this great study by Prakitr Srisuma, George Barbastathis, and Richard D. Braatz. \ud83d\udca1\ud83d\udd0d\n\nIn this work, a novel mechanistic model takes the spotlight, offering insights into the intricate thermal radiation dynamics during primary drying in conventional, microwave-assisted, and hybrid freeze drying setups. The model hinges on the diffuse gray surface model and radiation network approach, ingeniously incorporating radiation exchange between every surface, from vials to chamber walls. This holistic framework adapts smoothly to dissect diverse freeze-dryer designs. \ud83c\udf10\ud83d\udcd0\n\nValidation against literature data underscores the model's prowess, accurately predicting drying times for all vial positions, be it inner, edge, or corner. The validated model then embarks on a journey of thermal radiation analysis and parametric explorations. These not only enrich our comprehension but also steer the course for designing and optimizing freeze dryers. \ud83d\ude80\ud83d\udd2c\n\nThe MATLAB implementation of this pioneering mechanistic model, coupled with the radiation network and the Monte Carlo method for view factor calculation, is readily accessible at: https:\/\/lnkd.in\/eBCE7_7T. Publication pre-print is available at: https:\/\/lnkd.in\/efAU3BMV.\n\n#FreezeDrying #ThermalRadiation #BiopharmaceuticalManufacturing #MechanisticModeling #InnovationInScience #Optimization #ResearchAdvancements #opensource #MATLABImplementation #GitHubRepository","linkedinURL":"https:\/\/www.linkedin.com\/feed\/update\/urn:li:activity:7096807689787166720","githubURL":null,"paperURL":null,"author":"Antonio Benedetti","createdDate":"08\/12\/2023"},{"title":"The title is: Navigating Prediction Uncertainty: Unveiling an Innovative Approach to Enhance Model-Based Design of Experiments","description":"\ud83d\udd2c\ud83e\uddea Navigating #Prediction #Uncertainty: Unveiling an Innovative Approach to Enhance Model-Based Design of Experiments \ud83c\udf1f\ud83d\udcd0\n\nThe world of experimental design is a game of intricate balances, where the quest for optimal information often dances with the shadows of uncertainty. Within this domain, a new horizon emerges thanks to the fantastic work of Francesca Cenci, Arun Pankajakshan, Pierantonio Facco, and Federico Galvanin. \ud83d\ude80\ud83d\udd0d\n\nIn this brilliant study, the challenge lies in the tightrope walk between the expansive exploration of experimental design space and the minimization of model prediction uncertainty. The traditional approach to optimal experimental design often leaves gaps, as it fails to fully account for the intricacies of model prediction across the entire design space. Parameters precision alone doesn't guarantee the taming of prediction variance throughout the model's application. \ud83c\udfaf\ud83d\udcca\n\nEnter a pioneering solution: the novel model-based design of experiments (MBDoE) method, elegantly named G-map eMBDoE. This inventive method introduces a G-optimality mapping, effectively charting a course that not only boosts space exploration but also deftly tames the uncertainty that can cloud model predictions. \ud83d\uddfa\ufe0f\ud83d\udca1\n\nThe power of G-map eMBDoE shines through rigorous testing on two increasingly complex models. A showdown against conventional factorial design of experiments, Latin Hypercube (LH) sampling, and traditional MBDoE methods unveils its might. The results paint a clear picture: G-map eMBDoE not only dances with efficiency in the experimental design space but emerges as a champion, reigning supreme in the realm of uncertainty reduction and parameters precision maximization. \ud83c\udfc6\ud83d\udd2c\n\nLink to Publication: https:\/\/lnkd.in\/eki8UHyX\n\n#ExperimentalDesign #ModelBasedApproach #UncertaintyReduction #InnovativeResearch #OptimalInformation #Exploration #ModelPrediction #ResearchAdvancements #PrecisionMaximization #GMapEMBDoE","linkedinURL":"https:\/\/www.linkedin.com\/feed\/update\/urn:li:activity:7096445283785433088","githubURL":null,"paperURL":null,"author":"Antonio Benedetti","createdDate":"08\/12\/2023"},{"title":"The title is: Harnessing Model-Based Systems Engineering for Enhanced Chemicals and Materials Manufacturing","description":"\ud83d\udd2c\ud83c\udfed Harnessing #ModelBased #Systems #Engineering for Enhanced Chemicals and Materials Manufacturing \ud83d\udcc8\ud83d\udd0d\n\nIn the ever-evolving landscape of engineering methodologies, Model-Based Systems Engineering (MBSE) emerges as a pivotal approach, embraced by diverse disciplines. This time, we're exploring how MBSE is used in the field of making chemicals and materials. \ud83e\uddea\ud83d\udd27\n\nIn this great open access perspective by Quang Le, Joshua Feingold, Bill Glandorf, Jeff Kent, Bob Sherman, and James K. Ferri, the significance of MBSE is emphasised by analyzing the complexities and vulnerabilities of the U.S. chemical supply chains. Amid this complexity, MBSE emerges as a potential solution, steering us away from the limitations of traditional approaches. \ud83d\udcbc\ud83d\udd17\n\nThis comprehensive exploration takes us through the foundations of systems engineering (SE), the intricacies of Process Systems Engineering (PSE), and ultimately, the assertion for MBSE as a more adaptable and universal approach. The authors introduce us to novel systems modeling strategies tailored to MBSE, including an innovative method designed for the analysis of chemical supply chains. \ud83d\udd04\ud83d\udee0\ufe0f\n\nA practical illustration takes the form of a systems model for the manufacturing of Atropine, an active pharmaceutical ingredient. This use case showcases the prowess of MBSE in action, accentuating its potential to streamline complex manufacturing processes. \ud83d\udc8a\ud83c\udfed\n\nConcluding on a forward-looking note, the authors highlight the avenues for further development, envisioning how MBSE can continue to shape the design and management of chemical supply chains. \ud83d\ude80\ud83d\udca1\n\n\ud83d\udd17 Dive into the full study: https:\/\/lnkd.in\/ezSeBrp2\n\n#MBSE #ChemicalsAndMaterials #Manufacturing #SystemsEngineering #Innovation #SupplyChain #EngineeringApproaches #ResearchInsights #ModelingStrategies #IndustrialDesign","linkedinURL":"https:\/\/www.linkedin.com\/feed\/update\/urn:li:activity:7096103384834793472","githubURL":null,"paperURL":null,"author":"Antonio Benedetti","createdDate":"08\/12\/2023"},{"title":"The title is: NLoed: A Python Package for Nonlinear Optimal Experimental Design in Systems Biology","description":"\ud83d\udd2c\ud83e\uddec Introducing #NLoed: A Python package for nonlinear optimal experimental design in systems biology \ud83c\udf1f\ud83d\udcca\n\n In systems and synthetic biology, accurate modeling depends on precise parameter estimates, which in turn rely on quality data. Optimal Experimental Design (OED) steps in to identify efficient experiments for better modeling. However, current OED software struggles with diverse nonlinear models and non-normal data common in biology, leading to inefficiency and untapped numerical tools. \ud83d\udcbb \ud83d\udcc9\n\nToday we introduce NLoed, an open-source Python library curated by Nathan Braniff, Taylor Pearce, Zixuan Lu, Michael Astwood, William Forrest, Cody Receno, and Brian Ingalls. This package takes a stride forward by offering a streamlined gateway to OED techniques, with a specific focus on enhancing experimental design for systems biology inquiries. NLoed effortlessly supports a wide spectrum of nonlinear, multi-input\/output, and dynamic models, making it adaptable to diverse data types encountered in the field. \ud83d\ude80\ud83d\udcbb\n\nTo turbocharge OED investigations, NLoed incorporates maximum likelihood fitting and diagnostic tools, crafting an all-encompassing modeling workflow. By embracing NLoed, you'll have access to an accessible, modular, and flexible OED toolkit tailored for the myriad of experimental scenarios that punctuate systems biology research. \ud83e\uddea\ud83d\udca1\n\n\ud83d\udd17Link to #GitHub: https:\/\/lnkd.in\/e4ZVEEak\n\ud83d\udcdaLink to Documentation: https:\/\/lnkd.in\/euvC74-k. \n\nKudos to the brilliant minds behind #NLoed for advancing systems biology with this interesting approach to optimal experimental design! \ud83d\udc4f\ud83d\udd0d\n\n#SystemsBiology #OptimalExperimentalDesign #NLoed #BiologicalResearch #PythonLibrary #DataScience #ResearchInnovation #OpenSource #ExperimentalDesign #Modeling #NumericalTools","linkedinURL":"https:\/\/www.linkedin.com\/feed\/update\/urn:li:activity:7095767776748789760","githubURL":null,"paperURL":null,"author":"Antonio Benedetti","createdDate":"08\/11\/2023"},{"title":"The title is: Unveiling Assimulo: Empowering ODE Solvers in PharmaPy","description":"\ud83e\uddee\ud83d\udcbbUnveiling Assimulo: Empowering ODE Solvers in PharmaPy \ud83e\uddea\ud83d\ude80\n\nAs we journey deeper into the world of PharmaPy, today we want to introduce you to one of its fundamental pillars\u2014Assimulo, a unified framework for solving ordinary differential equations (ODEs). Developed by Christian Winther, Claus F\u00fchrer, Johan \u00c5kesson, and contributors, Assimulo is great open-source numerical ODE solver. \ud83d\udca1\ud83d\udd0d\n\nA distinguishing feature of Assimulo is its ability to handle the complexity of modern dynamic system models. In industrial scenarios, dynamic models often involve more than just differential equations; they encompass discrete controllers, friction, impacts, and other intricate components. \ud83e\uddee\ud83d\udcbb\n\nAssimulo performs well in efficiently managing these discontinuities, ensuring accurate simulations even in the presence of challenging scenarios. Furthermore, as data-rich models become the norm, Assimulo manages to handle the massive influx of data while maintaining robust performance. \ud83d\udcbb\ud83d\udcca\n\nAt its core, Assimulo provides a high-level interface that unifies classical and modern solvers regardless of their programming language. Seamlessly integrated into Python\/Cython, this interface offers a structured environment to effortlessly control parameter settings and tackle discontinuities across a wide spectrum of problem classes. \ud83d\ude80\ud83d\udd2c\n\n\ud83d\udd17 Link to #Github: https:\/\/lnkd.in\/eJhECQnz\n\ud83d\udcda Learn more about Assimulo: https:\/\/lnkd.in\/eTdkvyYX\n\n#PharmaPy #Assimulo #ODESolvers #NumericalSimulation #PharmaceuticalResearch #DataHandling #IndustrialModeling #ResearchInnovation #PythonProgramming #JmodelicaOrg","linkedinURL":"https:\/\/www.linkedin.com\/feed\/update\/urn:li:activity:7095364009406656515","githubURL":null,"paperURL":null,"author":"Antonio Benedetti","createdDate":"08\/10\/2023"},{"title":"The title is: Improving Chemical Synthesis with Bayesian Reaction Optimization","description":"\ud83d\udd2c\ud83d\udcca Improving Chemical Synthesis with Bayesian Reaction Optimization \ud83d\ude80\ud83e\uddea\n\nFine-tuning chemical reactions is at the core of synthetic chemistry, whether it's about boosting industrial yields or optimizing conditions for medicinal compounds. There are several different modelling approaches to try to optimize reaction development . Today we want to propose new another great example of a Bayesian optimization framework, an approach that can be very useful when combined with Designed of Experiments(DOE) .\n\nIn this study by Benjamin J. Shields et al, the power of Bayesian optimization for reaction optimization is demonstrated. They've constructed a framework and an open-source tool that seamlessly integrates cutting-edge optimization methods into everyday lab practices. Their approach, tested on a benchmark dataset for a palladium-catalyzed reaction, goes beyond theory. It pits Bayesian optimization against human decision-making in a systematic study, utilizing both expert chemists' judgments and real lab experiments. \ud83d\udca1\ud83c\udf1f\n\nBayesian optimization surpasses human-driven choices in both optimization efficiency and consistency. In simple terms, it not only requires fewer experiments but also ensures more predictable outcomes. By adopting Bayesian optimization into routine lab procedures, this research hints at an era of more informed, data-driven decisions in chemical synthesis. \n\nKudos to Benjamin Shields, Jason Stevens, Jun Li, Marvin Parasram, Farhan Damani, Jesus I. Martinez Alvarado, Jake Janey, Ryan Adams, and Abigail Doyle  for publishing this great work and releasing the package as open source! \ud83d\udc4f\ud83d\udd0d\n\n\ud83d\udd17 Check out their work on GitHub: https:\/\/lnkd.in\/eT6zgqqZ\n\ud83d\udcda Dive into the full publication: https:\/\/lnkd.in\/eqxGHaiy\n\n#ChemicalSynthesis #BayesianOptimization #LabPractices #DataDrivenDecisions #ResearchInnovation #Chemistry #AI #OptimizationMethods #OpenSource","linkedinURL":"https:\/\/www.linkedin.com\/feed\/update\/urn:li:activity:7094991858015039488","githubURL":null,"paperURL":null,"author":"Antonio Benedetti","createdDate":"08\/09\/2023"},{"title":"The title is: Unleash the power of Flowsheet modelling for Tablet Direct Compression.","description":"\ud83c\udf1f Unleash the power of Flowsheet modelling for Tablet Direct Compression \ud83d\udc8a \n\n\ud83d\udca5 Direct Compression is a crucial manufacturing route for pharmaceutical tablets due to its efficiency in reducing unit operations and simplifying the process, leading to streamlined production and cost-effectiveness. The ability to comprehensively evaluate the impact of varying process parameters and the inherent variability of raw material properties on manufacturability and product quality attributes is pivotal for the development of a robust manufacturing process. \n\n\ud83d\udd2c In this study, presented at #ESCAPE33 in Athens, Magdalini Aroniada, Houda Khaled and our own Harry Christodoulou delve into the intricacies of creating a Direct Compression process #flowsheet (system) #model. This research is aimed at understanding how process parameters and material properties intertwine to influence in-vitro #dissolution behaviour. The authors outline the model equations, expound upon the calibration and validation steps using real-world industrial data, and subsequently employ a powerful Global Sensitivity Analysis (#GSA) technique to unravel the effects of process parameters and material attributes on \"in-vitro\" dissolution outcomes.\n\nThis article represents a significant stride in the journey toward optimizing tablet manufacturability, ensuring consistent product quality, and propelling the industry forward. \ud83c\udf1f\n\n\ud83d\ude4c\ud83c\udf89 Kudos to the authors for their contributions to advancing pharmaceutical modelling research & innovation!\ud83d\ude80\n\nLink to the paper: https:\/\/lnkd.in\/ekveuQ9M\n\n#DirectCompression #FlowsheetModelling #ProcessModelling #GSA","linkedinURL":"https:\/\/www.linkedin.com\/feed\/update\/urn:li:activity:7094650096201392131","githubURL":null,"paperURL":null,"author":"Harry Christodoulou","createdDate":"08\/08\/2023"},{"title":"The title is: Exploring Pharmaceutical Crystallization: Challenges and Opportunities.","description":"\u2744\ufe0f\ud83e\uddea Exploring #Pharmaceutical #Crystallization: Challenges and Opportunities \ud83e\uddea\u2744\ufe0f\n\nCrystallization is a cornerstone process in the pharmaceutical industry, serving both purification and property control purposes. In their comprehensive perspective, Aaron Cote, Deniz Erdemir, Kevin Girard, Daniel Green, Michael Lovette, Eric Sirota, and Nandkishor Nere delve into the current state and the potential ahead in pharmaceutical crystallization process development. \ud83c\udf1f\ud83d\udc8a\n\nThis insightful perspective addresses the intricate balance between crystallization design, purification, and particle engineering. It highlights the immense significance of crystallization science, exemplified by dedicated experts in major pharmaceutical companies. From isolating intermediates to achieving targeted crystal forms, the role of crystallization spans diverse stages of drug development. \ud83d\udc8e\ud83d\udca1\n\nAs the authors emphasize, the ability to tailor crystallization solvent systems and operating conditions for effective impurity removal remains a vital challenge. The aspiration of particle engineering through controlled crystallization is acknowledged, but its realization often requires a deep mechanistic understanding that aligns with real-world constraints. \ud83d\udcaa\ud83d\udd2c\nModeling emerges as a promising avenue to enhance efficiency and knowledge generation. While first-principles models hold potential for in silico design, their applicability to complex systems is a rare sight. The paper dives into the complexities, acknowledging the need to bridge the gap between aspiration and reality. \ud83d\udcca\ud83c\udf10\n\nThe authors pave the way for advancing pharmaceutical crystallization by dissecting key areas. They explore the nuances of polymorphs, solubility, and crystal shape. Impurity rejection takes center stage as a critical process deliverable. Analytical challenges and opportunities are laid bare, followed by discussions on crystallization kinetics, hydrodynamics modeling, scale-up, and continuous crystallization. \ud83d\ude80\ud83d\udd2c\n\nKudos to the authors for their insightful contribution to pharmaceutical crystallization. This work can serve as a basis for future innovation in the field  \ud83d\udc4f\ud83c\udf10\n\n\ud83d\udd17 Full Perspective: https:\/\/lnkd.in\/eWQtQvtb\n\n#PharmaceuticalCrystallization #ProcessDevelopment #DrugPurification #ParticleEngineering #Modeling #Innovation #ScientificInsights #PharmaIndustry #Research #ChallengesAndOpportunities","linkedinURL":"https:\/\/www.linkedin.com\/feed\/update\/urn:li:activity:7094364978501050368","githubURL":null,"paperURL":null,"author":"Antonio Benedetti","createdDate":"08\/07\/2023"},{"title":"The title is: Enhancing Continuous Twin-Screw Granulation Insights: PLS Regression for Material-Driven PBMs.","description":"\ud83d\udcbb\ud83d\udcca Enhancing #Continuous #TwinScrew #Granulation Insights: PLS Regression for Material-Driven PBMs \u2699\ufe0f\ud83d\udc8a\n\nIn the dynamic world of OSD pharmaceutical manufacturing, continuous twin-screw wet granulation is gaining traction as an efficient approach for crafting solid drug products. To enable digital design and simulation of such a process, population balance models (PBMs) have emerged as the key tool for modelling the computation of granule size distributions and unraveling how this affects downstream CQAs. However, a roadblock exists\u2014the missing link between material properties and model parameters\u2014a hindrance to swiftly applying PBMs to novel active pharmaceutical ingredients (APIs). \ud83d\udcc8\ud83d\udc8a\n\nThis compelling study by Ana Alejandra Barrera Jim\u00e9nez et al introduces a novel solution to estimate the model parameters: partial least squares (PLS) regression models. By using this data-driven approach, you can decipher the influence of material properties on PBM parameters. By meticulously exploring ten formulations with varying liquid-to-solid ratios using Design of Experiments, the researchers unveiled how material properties and liquid-to-solid ratios interrelate with compartmental one-dimensional PBMs parameters via PLS models. The outcome? A precise identification of pivotal material properties, a crucial step in accurate calculations. Properties related to size and moisture exerted a significant influence in the wetting zone, while density-related properties took the lead in the kneading zones. \ud83d\ude80\ud83d\udcca\n\n\ud83d\udc4f Well done to Ana Alejandra Barrera Jim\u00e9nez , Kensaku Matsunami, Daan Van Hauwermeiren, Michiel Peeters, Fanny Stauffer, Eduardo dos Santos Schultz, Ashish Kumar, Thomas De Beer and Ingmar Nopens for proposing this interesting solution to link material properties and PBM parameters. \ud83c\udf1f\n\n\ud83d\udd17 Read the full research article here: https:\/\/lnkd.in\/ehZxRTV6\n\n#PharmaceuticalIndustry #ContinuousManufacturing #PopulationBalanceModels #MaterialProperties #ResearchInnovation #DataAnalysis #PharmaceuticalResearch #ChemicalEngineering #ProcessOptimization #DigitalDesign","linkedinURL":"https:\/\/www.linkedin.com\/feed\/update\/urn:li:activity:7093908569284046849","githubURL":null,"paperURL":null,"author":"Antonio Benedetti","createdDate":"08\/05\/2023"},{"title":"The title is: Advancing #Bioprocess #Efficiency with #ModelBased #Predictions: Exploring Cellular Metabolism and Protein Glycosylation \ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd","description":"\ud83d\udd2c\ud83e\uddea Advancing #Bioprocess #Efficiency with #ModelBased #Predictions: Exploring Cellular Metabolism and Protein Glycosylation \ud83e\udda0\ud83d\udcc8\n\nIn the dynamic world of biologics, meeting market demands and enhancing competitiveness is a constant challenge. Process intensification in biomanufacturing is key, and traditional experimental approaches are increasingly giving way to more efficient methods. Mathematical modeling is the game-changing approach that promises to optimize processes while reducing the resource-intensive burden of experimentation. \ud83d\udca1\ud83c\udf10\n\nIn this insightful study by Jayanth Venkatarama Reddy, Katie Raudenbush, E. Terry Papoutsakis, and Marianthi Ierapetritou, the focus is on the modeling of cellular metabolism and N-linked glycosylation in upstream manufacturing of biologics. With a spotlight on mammalian cells, their research delves into kinetic and stoichiometric modeling frameworks to simulate, optimize, and enhance the mechanistic understanding of biopharmaceutical processes. \ud83d\udcca\ud83d\udd0d\n\nThe review not only covers the theoretical side but also evaluates real-world scenarios by considering the effect of critical bioreactor-specific parameters like pH, dissolved oxygen, temperature, and heterogeneity. Notably, this study broadens its scope beyond the traditional Chinese Hamster Ovary (CHO) cells, extending its applicability to diverse mammalian cell-based manufacturing platforms, from monoclonal antibodies to CAR-T cell therapies and viral vector manufacturing. \ud83c\udf1f\ud83e\uddec\n\nKudos to the authors for providing such a clear overview of the mathematical modeling landscape that's crucial for creating effective digital designs in bioprocessing \ud83d\ude4c\ud83d\udcbb\n\n\ud83d\udd17 Read the full research article here: https:\/\/lnkd.in\/eM9qt76Z\n\n#BioprocessOptimization #MathematicalModeling #CellularMetabolism #ProteinGlycosylation #Biomanufacturing #ResearchInnovation #Science #Biotechnology #EfficiencyBoost #ProcessIntensification","linkedinURL":"https:\/\/www.linkedin.com\/feed\/update\/urn:li:activity:7093565168504197120","githubURL":null,"paperURL":null,"author":"Antonio Benedetti","createdDate":"08\/05\/2023"},{"title":"The title is: \u03a6Flow: Where Optimization and Machine Learning Meet Fluid Dynamics","description":"\ud83d\udca1\ud83c\udf1fUnveiling #\u03a6Flow: Where Optimization and Machine Learning Meet Fluid Dynamics \ud83c\udf0a\ud83d\udcbb \n\nIntroducing PhiFlow (\u03a6Flow), the open-source simulation toolkit designed to elevate your optimization and machine learning applications. Crafted by Philipp Holl, Vladlen Koltun, Nils Thuerey and other contributors, this powerhouse toolkit reshapes the landscape of fluid simulation and learning. \ud83d\ude80\n\nWritten mainly in Python and compatible with NumPy, PyTorch, Jax, and TensorFlow, \u03a6Flow boasts seamless integration with these machine learning frameworks. This synergy empowers \u03a6Flow to harness the prowess of automatic differentiation, facilitating the creation of end-to-end differentiable functions that blend learning models and physics simulations. \ud83d\udcca\ud83d\udd0d\ud83e\udde0\n\nKey Features:\n\ud83c\udf00 Dive into a diverse array of built-in PDE operations, meticulously honed for fluid phenomena simulations, enabling concise and precise simulations.\n\ud83c\udfaf Forge a potent alliance with PyTorch, Jax, and TensorFlow for streamlined neural network training, featuring fully differentiable simulations capable of GPU acceleration.\n\ud83c\udf10 Navigate a flexible web interface that delivers live visualizations and interactive controls, empowering on-the-fly adjustments to simulations and network training.\n\ud83e\udde9 Embrace the elegance of object-oriented, vectorized design that harmonizes expressive code, user-friendliness, adaptability, and extendability.\n\ud83d\udd01 Experience the versatility of reusable simulation code, agnostic to backends and dimensions. The same code can fuel a 2D fluid simulation with NumPy or a 3D counterpart powered by TensorFlow or PyTorch.\n\ud83d\udd0d Unlock the potential of a high-level linear equation solver enriched with automated sparse matrix generation.\n\n\ud83d\udd17Link to #Github: https:\/\/lnkd.in\/ehZs_Y2m \n\ud83d\udd17Link to #Documentation: https:\/\/lnkd.in\/exbHv3ZZ \n\n\ud83d\udc4f Big applause to Holger Marschall as well for generously sharing fantastic content on his Linkedin! Calling all CFD enthusiasts - follow him for a treasure trove of CFD insights and discoveries. \ud83c\udf2c\ufe0f\ud83d\ude80\n \n#SimulationToolkit #MachineLearning #Optimization #DataScience #OpenSource #PythonProgramming #PhysicsSimulations #DataAnalysis #PhiFlow #Innovation","linkedinURL":"https:\/\/www.linkedin.com\/feed\/update\/urn:li:activity:7093206755387564032","githubURL":null,"paperURL":null,"author":"Antonio Benedetti","createdDate":"08\/04\/2023"},{"title":"The title is: ReNView - A Standalone Visualizer for Reaction Network Analysis","description":"\ud83c\udf0c Visualizing #Chemical #Transformation #Pathways: Meet #ReNView! \ud83d\ude80\ud83d\udd2c\n\nReaction Path Analysis (RPA) plays a vital role in unraveling the key reaction pathways that drive chemical transformations within complex reaction networks. In this work, an exciting open-source framework, Reaction Network Viewer (ReNView), has been developed for visualizing complex reaction systems. This standalone visualizer generates graphical representations of reaction networks based on reaction fluxes, facilitating the identification of dominant reaction pathways and mechanism reduction. \ud83d\udcca\ud83d\udca1\n\nWith ReNView, researchers and scientists can gain valuable insights into the intricate dynamics of chemical reactions. The visualizer generates network and species visualizations using the output of a microkinetic model. The beauty of this python-based code lies in its seamless integration with any chemical kinetics solver, offering flexibility and convenience in data analysis. \ud83d\udcbb\ud83d\udcc8\n\nTo showcase the efficacy of ReNView, three compelling case studies demonstrate its prowess in deciphering complex reaction networks. By leveraging this open-source tool, the exploration of reaction pathways becomes more accessible and insightful, ultimately advancing our understanding of chemical transformations. \ud83d\ude80\ud83d\udd0d\n\n\ud83d\udc4f Kudos to Udit Gupta and Dion Vlachos for their outstanding work on this remarkable package. The contribution of Dion's group of research to the open-source software community is impressive! \ud83c\udf1f We're excited to share more about their innovative work in the upcoming posts! Stay tuned for exciting insights and discoveries! \ud83d\ude80\ud83d\udcbb\ud83d\udd2c\n\n\ud83d\udd17 Link to #Github: https:\/\/lnkd.in\/eQ_tPCF7\n\ud83d\udcda Link to #Publication: https:\/\/lnkd.in\/ejkpPGPf\n\n#ReactionPathAnalysis #ChemicalReactions #DataVisualization #ChemicalKinetics #DataAnalysis #OpenSource #ResearchTool #Chemistry #DataScience #ScienceCommunity","linkedinURL":"https:\/\/www.linkedin.com\/feed\/update\/urn:li:activity:7092843342828318720","githubURL":null,"paperURL":null,"author":"Antonio Benedetti","createdDate":"08\/03\/2023"},{"title":"The title is: Unlocking the Power of #R #Tidyverse for Life Science Research","description":"\ud83d\udd2c\ud83d\udcca Unlocking the Power of #R #Tidyverse for Life Science Research \ud83c\udf1f\ud83d\udd2c\n\nWe haven't often talked about the R #opensource ecosystem for data analysis and modeling, so today, we want to take the chance to introduce you to the R tidyverse. The Tidyverse is a collection of R packages designed to enhance data manipulation, visualization, and analysis. It offers a powerful and efficient approach to working with complex datasets and generating insightful results. \ud83d\udcbb\ud83d\udcca\n\nSo, how can the tidyverse benefit our life science endeavors?\n\n\ud83d\udd0d dplyr simplifies data manipulation, making it easier to filter, mutate, and summarize data. These functions empower us to transform and reshape datasets effortlessly, saving valuable time during analysis.\n\ud83d\udcca ggplot2 introduces the \"grammar of graphics,\" allowing us to create visually informative plots. Whether it's gene expression patterns or medical imaging data, ggplot2 helps us effectively communicate our findings.\n\ud83d\udd00 tidyr helps us organize and tidy up messy datasets. By converting data between wide and long formats, tidyr ensures that our data is ready for exploration and modeling.\n\nIf you're new to the tidyverse, don't worry! There's an incredible wealth of resources and tutorials available online. Embracing this toolkit can be beneficial for researchers, scientists, and data enthusiasts in the life sciences. \ud83c\udf10\ud83d\udca1\n\nAre you already using the tidyverse? Share your experiences and tips in the comments below! \n\n\ud83d\udd17Link to Github: https:\/\/lnkd.in\/eTNZMKSg\n\ud83d\udd17Link to Tidyverse.org: https:\/\/www.tidyverse.org\/\n\n#DataAnalysis #DataModeling #RStats #Tidyverse #DataVisualization #LifeScienceResearch #DataScience #RProgramming ","linkedinURL":"https:\/\/www.linkedin.com\/feed\/update\/urn:li:activity:7092594849480077312","githubURL":null,"paperURL":null,"author":"Antonio Benedetti","createdDate":"08\/02\/2023"},{"title":"The title is: GatedPINN: Advancing Large-Scale Neural Networks for Partial Differential Equations.","description":"\ud83d\udcbb\ud83e\udde0 Advancing #PDE #Solvers with Large-Scale Neural Networks: Introducing #GatedPINN! \ud83c\udf1f\n\nPartial differential equations (PDEs) play a pivotal role in various scientific fields, enabling the modeling of complex processes. Recent numerical solvers have required manual discretization and specialized code for distributed computing, resulting in extended runtimes when exploring model parameters. However, promising computational solutions have emerged over the last years to address these challenges! \ud83d\ude80\n\nGatedPINN, a physics-informed neural network (PINN), tries to introduce a new alternative approach for PDE solvers. Unlike traditional machine learning-based surrogate models, GatedPINN remarkably requires only initial\/boundary values and validation points for training, without the need for full simulation data. This approach not only reduces costs but also mitigates the curse of dimensionality through an innovative domain decomposition, optimizing neuron distribution per unit volume and improving runtime. \u23f3\u26a1\n\nGatedPINN's potential extends to distributed training on large-scale cluster systems, utilizing the power of multiple GPUs with remarkable efficiency. An in-depth evaluation study validates its capability to handle significant computational resources. \ud83c\udf10\ud83d\udd0d\n\nThe accuracy of GatedPINN is examined against analytical and state-of-the-art numerical solvers, such as spectral solvers. The results are promising! \ud83d\udcca\u2728\n\nKudos to Patrick Stiller,\u00a0Friedrich Bethke,\u00a0Maximilian B\u00f6hme,\u00a0Richard Pausch,\u00a0Sunna Torge,\u00a0Alexander Debus,\u00a0Jan Vorberger,\u00a0Michael Bussmann\u00a0&\u00a0Nico Hoffmann for their work in developing GatedPINN and advancing large-scale neural solvers for partial differential equations. \ud83d\udcaa\ud83c\udfc6\n\n\ud83d\udd17Link to GitHub: https:\/\/lnkd.in\/eik3sGnK\n\ud83d\udcdaLink to Paper: https:\/\/lnkd.in\/eTDBXMzi\n\n#NeuralSolvers #GatedPINN #PDEs #MachineLearning #PhysicsInformedNN #DistributedComputing #ScientificResearch #ComputationalPhysics #Innovation #LargeScale #DataScience #OpenSource #ResearchTools #Engineering","linkedinURL":"https:\/\/www.linkedin.com\/feed\/update\/urn:li:activity:7092096667109208068","githubURL":null,"paperURL":null,"author":"Antonio Benedetti","createdDate":"07\/31\/2023"},{"title":"The title is: GasCompressibility-py: Simplifying Gas Compressibility Factor Calculation in Python!","description":"\ud83d\udd2c\ud83d\udcc8 GasCompressibility-py: Simplifying Gas Compressibility Factor Calculation in Python! \ud83d\udca8\u2728\n\nPrecise gas compressibility factor calculations are indispensable for modeling and simulating various processes, including chemical drug substance development. Understanding the behavior of gases is vital in optimizing chemical reactions, designing equipment, and ensuring overall system efficiency. \ud83e\uddea\ud83d\udcbb\n\nIntroducing GasCompressibility-py, a Python library for effortlessly calculating the gas compressibility factor (Z-factor) based on the real gas law, specially tailored for practical oil field applications. With user-friendly inputs (specific gravity, temperature, and pressure), obtain accurate results from surface facilities with ease. \ud83d\ude80\n\n\u2728 Highlighted Features:\n\u2714\ufe0f Easy to use, even for newcomers\n\u2714\ufe0f Z-factor calculation for accurate results\n\u2714\ufe0f Pseudo-critical property calculation (Ppc, Tpc, Pr, Tr)\n\u2714\ufe0f Speed optimization for faster computation\n\u2714\ufe0f Supports correction for non-hydrocarbon impurities (CO2, H2S, N2)\n\u2714\ufe0f Engage in a discussion forum for sharing questions and insights! \ud83d\udcdd\ud83e\udd1d\n\nGasCompressibility-py simplifies complex gas mixture calculations, making it a powerful tool for your Python projects. Kudos to Eric Kim for developing this great tool and for the great documentation that comes with it\ud83c\udf1f\ud83d\udca8\n\n\ud83d\udd17Check it out on #GitHub: https:\/\/lnkd.in\/eZ5s5q2k \n\n#GasCompressibility #PythonLibrary #ChemicalEngineering #ProcessModeling #Simulation #Petrochemical #DataScience #OpenSource #ResearchTools #DataAnalysis #Engineering #Chemistry","linkedinURL":"https:\/\/www.linkedin.com\/feed\/update\/urn:li:activity:7091734265217855488","githubURL":null,"paperURL":null,"author":"Antonio Benedetti","createdDate":"07\/31\/2023"},{"title":"The title is: Advancing Process Systems with Data-Driven Models: A State-of-the-Art Review","description":"\ud83d\udcda\ud83d\udca1 Advancing Process Systems with Data-Driven Models: A State-of-the-Art Review \ud83c\udf10\ud83d\udd0d\n\nModeling and optimizing various processes play a pivotal role in enhancing operational efficiency and facilitating new process developments. With the rapid progress in computing power, data-driven models, particularly Machine Learning (ML) techniques, have become the go-to solution in numerous chemical engineering applications. Compared to traditional mechanistic models, data-driven models might give the impression that they offer relative ease of implementation and the flexibility to be regularly updated, providing an accurate representation of the system dynamics. \ud83d\ude80\ud83e\uddea\n\nThe adoption of data-driven modeling tools is on the rise in process systems. These models have shown great potential to complement or even replace traditional optimization tools across various process industries. They have proven their worth in diverse areas, including reactor modeling, molecular design, safety analysis, and reliability assessment. However, despite their promise, data-driven modeling still faces some challenges. \ud83e\udd14\ud83d\udd2c\n\nOne of the key obstacles lies in the lack of specialized tools tailored for macro systems and scaling up from micro to industrial levels. Existing datasets predominantly stem from limited experimental studies, which constrain their applicability to microsystems. Addressing these limitations is essential to unlock the full potential of data-driven models in broader process systems. \ud83c\udf1f\n\nIn this insightful review paper by SUMIT KUMAR BISHNU, Sabla Alnouri, and Dhabia Al-Mohannadi, the recent applications of data-driven modeling in process systems are thoroughly examined. The authors delve into the prominent challenges faced by these models and explore future outlooks. \ud83d\udcca\ud83d\udcc8\n\nThe potential of data-driven models to revolutionize process optimization and system design is undeniable. As we overcome the challenges and unlock new opportunities, data-driven modeling will continue to drive innovation in process engineering, shaping the future of the chemical industry. \ud83d\udc4f\ud83d\udcbb\n\n\ud83d\udd17 Link to #Publication: https:\/\/lnkd.in\/eJ4F8n5E\n\n#DataDrivenModeling #ChemicalEngineering #MachineLearning #ProcessOptimization #Innovation #DataScience #FutureOutlooks #ComputationalModeling #DataAnalysis","linkedinURL":"https:\/\/www.linkedin.com\/feed\/update\/urn:li:activity:7091371854250029056","githubURL":null,"paperURL":null,"author":"Antonio Benedetti","createdDate":"07\/29\/2023"},{"title":"The title is: \"Online Monitoring and Adaptive Feed: A Breakthrough for High Throughput Bioreactors\"","description":"\ud83d\udd2c\ud83e\udda0 #Nonlinear #State #Estimation for Online Monitoring & Adaptive Feed: A Breakthrough for #HighThroughput #Bioreactors \ud83d\ude80\ud83d\udca1\n\nThe advent of robotic facilities capable of conducting advanced cultivations in high throughput has revolutionized the bioprocess development pipeline, significantly boosting speed and reliability. However, developing analytical technologies that can keep up with the throughput of these cultivation systems has posed significant challenges. The accuracy of traditional analytical methods is compromised due to low sampling volumes, while the sheer number of samples to process rapidly becomes overwhelming. \ud83e\udd16\n\n\ud83e\uddea\ud83e\uddec In this exciting work, Annina Kemmer, Nico Fischer, and their team tackle this issue head-on with their implementation of a Sigma-Point Kalman Filter in a high throughput platform with 24 parallel experiments at the mL-scale. The Sigma-Point Kalman Filter proves its mettle by enabling continuous estimation of critical states, such as biomass concentration. This vital information allows for real-time monitoring of specific rates of production and consumption in the process, bringing new insights and control possibilities. \ud83c\udf1f\n\nThe selected case study centers on the recombinant production of an antibody fragment using Escherichia coli cultivations. The ultimate objective is to ensure precise and tight control of the selected specific substrate consumption rate throughout the entire cultivation process. \ud83d\ude80\ud83d\udca1 \n\nThis remarkable research demonstrates the viability and added value of the Sigma-Point Kalman Filter in high throughput experiments, marking a significant step forward in online monitoring and adaptive feed approaches. The continuous estimation capability opens the door to implementing feedback control methods even in miniaturized bioreactor systems, where real-time observations of process states were previously limited. \ud83d\udcbb\ud83d\udcca\n\nKudos to Annina Kemmer, Nico Fischer, Terrance Wilms, Linda Cai, Sebastian Gro\u00df, Rudibert King, Peter Neubauer, and M. Nicolas Cruz B.  for publishing this exciting work ! \ud83d\udc4f\ud83c\udf31\n\n\ud83d\udd17 Link to #Publication: https:\/\/lnkd.in\/eFp-jwQt\n\n#Bioprocess #Biotechnology #HighThroughput #KalmanFilter #DataAnalysis #Bioreactor #ResearchInnovation #AdaptiveControl #OnlineMonitoring","linkedinURL":"https:\/\/www.linkedin.com\/feed\/update\/urn:li:activity:7091027465275334656","githubURL":null,"paperURL":null,"author":"Antonio Benedetti","createdDate":"07\/29\/2023"},{"title":"The title is: Optimizing Tablet Coating Variability: Let's use DEM simulations!","description":"\ud83c\udf1f Optimizing Tablet Coating Variability: Let's use DEM simulations! \ud83c\udf1f\n\nThe #pharmaceutical #industry grapples with two crucial challenges concerning tablet coating variability: achieving uniform coating thickness across individual tablets and maintaining consistent coating quality throughout the entire batch.\n\n\ud83d\udcda We just stumbled upon a very interesting time-scale extrapolation method which addresses the prediction of coating material distribution on tablets. By leveraging \"short\" discrete element method (#DEM) simulations, this workflow enables accurate determination of #coating amounts on pre-defined tablet surfaces during the Process Time.\n\nThe article describing the method, titled \"Simultaneous optimization of inter- and intra-tablet coating variability in a lab-scale coating process via DEM-MC simulations,\" is a must-read for specialists and modelers in the OSD field.\n\nThe team from the Research Center Pharmaceutical Engineering GmbH in Austria extensively explores #process #parameters, including filling mass, rotational speed, and spray rate, and their impact on coating quality for individual tablets in a lab-scale pan coater. The findings highlight the workflow's accuracy in predicting both inter- and intra-tablet coating variability. Furthermore, their work underscores the significance of tailoring coating optimization efforts based on the specific purpose, as a universal optimal process setting does not exist.\n\n\ud83c\udf89 Congratulations to Fatemeh (Bahar) Mostafaei, Johannes Khinast, Johan Remmelgas, and Thomas Forgber on their outstanding paper! \ud83d\udc4f Their #DEM  \/ #montecarlo simulation approach paves the way for optimizing the #Coating #Process with the potential for numerous benefits in drug formulation and manufacturing processes.\n\nLink to the article: https:\/\/lnkd.in\/eU55UdJ9\n\n#PharmaceuticalEngineering #SimulationInPharma #DrugFormulation #CoatingProcess #DEM","linkedinURL":"https:\/\/www.linkedin.com\/feed\/update\/urn:li:activity:7090684425264345088","githubURL":null,"paperURL":null,"author":"Harry Christodoulou","createdDate":"07\/28\/2023"},{"title":"The title is: \"Swiss Knife Partial Least Squares (SKPLS): A Unified Mathematical Implementation for Chemometrics Modeling\"","description":"\ud83d\udd2c\ud83d\udca1 Unlocking New Algorithms in #Chemometrics: Introducing Swiss Knife Partial Least Squares (#SKPLS) \ud83c\udf1f\ud83d\udd0d\n\nPLS is a widely embraced technique in multivariate data analysis, adept at handling high collinearity by substituting covarying variables with common subspaces represented by orthogonal latent variables. Its simplicity, employing straightforward linear algebra steps, sets it apart from resource-intensive deep learning methods with complex hyperparameter tuning. \ud83e\uddee\n\nPLS excels in diverse tasks, from single block modeling to multiblock, multiway data modeling, regression, and classification. Innovative PLS-based approaches now incorporate meta-information to enhance subspace extraction. However, the current landscape with separate tools and codes for different PLS tasks presents a challenge for users seeking specific mathematical implementations. \ud83d\udcda\ud83d\udd0d\n\nBut fret not! Puneet Mishra and Kristian Hovde Liland have introduced a new  solution - the Swiss knife Partial Least Squares (SKPLS) modeling approach. \ud83c\udde8\ud83c\udded\u2699\ufe0f \n\nThis methodology offers a unified mathematical implementation, empowering PLS practitioners to conduct analyses of single block, multiblock, multiway, multiblock multiway, multi-response, and even incorporate meta-information in PLS modeling. SKPLS has it all for both classification and regression tasks, simplifying the access to different chemometrics models. \ud83c\udf1f\ud83e\uddea\n\nAt the heart of SKPLS lies the stepwise PLS strategy known as Response Oriented Sequential Alternation (ROSA), which has been skillfully generalized to enable all the aforementioned analysis possibilities. The algorithm's fundamental structure takes the spotlight, and this groundbreaking approach is exemplified through diverse case studies, including single block, multiblock, multiway, multiblock multiway, multi-response PLS modeling, and the incorporation of meta-information. \ud83d\udcc8\ud83d\udcca\n\n \ud83d\ude80\ud83c\udf10 Kudos to Dr. Puneet Mishra and Kristian Hovde Liland for this exciting work in advancing the field of chemometrics and opening new doors to data analysis possibilities! \ud83d\udc4f\ud83d\udca1\n\n\ud83d\udd17 Link to #Github: https:\/\/lnkd.in\/ePHC74FQ \n\ud83d\udcda Learn more about #SKPLS: https:\/\/lnkd.in\/esVKF247\n\n#DataAnalysis #PLS #DataModeling #MachineLearning  #Chemistry  #Innovation #DataScience #opensource","linkedinURL":"https:\/\/www.linkedin.com\/feed\/update\/urn:li:activity:7090390401378856961","githubURL":null,"paperURL":null,"author":"Antonio Benedetti","createdDate":"07\/27\/2023"},{"title":"The title is: Development of a Digital Twin for the Prediction and Control of Supersaturation during Batch Cooling Crystallization","description":"\ud83d\udc8e Harnessing #digitaltwins for Supersaturation Control in Batch Cooling Crystallization \ud83d\udcbb\n\nWe stumbled upon an innovative article titled \"Development of a Digital Twin for the Prediction and Control of Supersaturation during Batch Cooling Crystallization\" by Ryan Leeming, Tariq Mahmud, Kevin J Roberts,\u00a0Neil George, Jennifer Webb, Elena Simone, and Cameron Brown \ud83d\udcda\n\n\ud83d\udd79\ufe0f The very interesting study introduces a Model Predictive Control\u00a0(MPC) strategy, leveraging a mechanistic model to optimize fine chemical production through batch crystallization. By using a #DigitalTwin of the crystallizer, the researchers achieved precise control of supersaturation, leading to the desired crystal size distribution. The approach significantly reduced the need for extensive experimental testing, saving valuable time and resources. \u23f1\ufe0f\ud83d\udcb0\n\n\ud83d\udd0d The team successfully implemented the #MPC approach on a physical crystallizer, using real-time in situ measurements from calibrated attenuated total reflection\u2212Fourier transform infrared (ATR-FTIR) spectroscopy. The results showcased precise supersaturation control. By optimizing #crystal  size distribution, this research paves the way for enhanced product properties and manufacturing efficiency. \ud83d\udcc8\n\n\ud83d\udc4f Congratulations to the authors for their exceptional work in advancing batch cooling #crystallization and #digital twin technology! This study has broad implications for the pharmaceutical and fine chemical industries, offering opportunities for future adaptations and advanced control objectives. \ud83c\udf89\n\n\ud83d\udd17 Link to the article: https:\/\/lnkd.in\/ethn-3jb \n\n#Crystallization #DigitalTwin #MPC #ChemicalEngineering\u00a0","linkedinURL":"https:\/\/www.linkedin.com\/feed\/update\/urn:li:activity:7089970220689149952","githubURL":null,"paperURL":null,"author":"Harry Christodoulou","createdDate":"07\/26\/2023"},{"title":"The title is: PharmaPy","description":"\ud83d\udd2c\ud83d\ude80 #PharmaPy is #Out! Join Us as We Unveil this Exciting Tool for the Development of Hybrid Pharmaceutical Flowsheet Models  \ud83c\udf1f\n\nAAfter sharing several publications on PharmaPy, we couldn't be more thrilled to announce the official release of PharmaPy's GitHub repository! \ud83c\udf1f\ud83d\ude80 \n\nDeveloped by the exceptional team led by Daniel Casas-Orozco, Ph.D. under the supervision of Rex Reklaitis, and Zoltan Nagy at Purdue University and  generously funded by FDA, PharmaPy is a Pythonic modeling platform with the potential to revolutionize open-source modeling of pharmaceutical manufacturing systems. \ud83d\udc8a\ud83d\udca1\n\n\ud83d\udd17 #GitHub Repository: https:\/\/lnkd.in\/e_3gFQmi\n\nPharmaPy introduces a novel, object-oriented approach to the development of hybrid pharmaceutical flowsheets. It's specifically designed to tackle the computational challenges faced by the chemical engineering and process optimization communities in handling complex and large-scale applications. \ud83d\udcbb\ud83d\udd0d\n\nIt allows to simulate the dynamics of standalone, drug substance unit operations in a variety of operating modes (batch, continuous, semibatch). Also, PharmaPy facilitates setting up and simulating pharmaceutical\u00a0flowsheets, i.e., interconnected unit operations running in one or more operation modes, offering flexibility to simulate end-to-end batch, end-to-end continuous, and hybrid operation schemes (combination of batch and\/or continuous and semicontinuous unit operations). \ud83d\udd04\ud83c\udf10\n\nIn the coming days, we'll be diving deep into the incredible capabilities of PharmaPy in a series of future posts. \ud83d\udcda Stay tuned as we analyze this groundbreaking tool, explore its functionalities, and uncover its potential to optimize pharmaceutical manufacturing processes. \ud83d\ude80\ud83d\udd2c\n\nWe extend our heartfelt appreciation to the brilliant minds behind PharmaPy for their dedication and innovation in advancing pharmaceutical process modelling. \ud83d\udc4f\ud83d\udca1\n\n#PharmaPy #PharmaceuticalManufacturing #PythonLibrary #PharmaceuticalScience #GitHubRelease #ScientificInnovation #PharmaceuticalFlowsheets #ProcessOptimization ","linkedinURL":"https:\/\/www.linkedin.com\/feed\/update\/urn:li:activity:7089668019483746304","githubURL":null,"paperURL":null,"author":"Antonio Benedetti","createdDate":"07\/25\/2023"},{"title":"The title is: Advancing Gas-Liquid-Solid #Multiphase #Flow #Modeling: A Resolved CFD-DEM Framework with Evaporation","description":"\ud83c\udf0a\ud83d\udca8 Advancing Gas-Liquid-Solid #Multiphase #Flow #Modelling: A Resolved CFD-DEM Framework with Evaporation \ud83e\uddea\ud83d\udd0d\n\nGas-liquid-solid multiphase systems find widespread applications in engineering, such as in inkjet printing, spray drying, and coating processes. The development of a robust numerical framework for modeling these complex multiphase systems holds immense significance. In this groundbreaking study, Huihuang Xia and Marc Kamlah present an improved, resolved CFD-DEM (Computational Fluid Dynamics-Discrete Element Method) framework to simulate multiphase free surface flow with and without evaporation. \ud83d\udcbb\ud83d\udd2c\n\nThe researchers have successfully developed an enhanced capillary force model, specifically tailored for computing the interactions between partially floating particles at a free surface. The framework is thoroughly validated through two well-known benchmark cases, namely drag coefficient calculation and single sphere settling, confirming its accuracy in capturing fluid-solid interactions and predicting the trajectory of solid particles interacting with the liquid phase. \ud83d\udcca\ud83d\udcd0\n\nExcitingly, the resolved CFD-DEM model introduced in this study demonstrates its efficacy in accurately simulating fluid-solid interactions in various scenarios, including cases with evaporation. Numerical demonstrations feature two particles moving along a free surface while the liquid phase evaporates, and the transport and accumulations of particles inside an evaporating sessile droplet, providing insightful performance insights for the resolved model. \ud83c\udf2a\ufe0f\ud83c\udf0a\n\nThis research makes a significant contribution to the field of gas-liquid-solid multiphase flow modeling and presents a promising framework for a wide range of engineering applications. The availability of this advanced numerical framework opens new avenues for innovation and exploration in multiphase flow research. \ud83d\ude80\ud83d\udca1\n\n\ud83d\udcda Link to the research article: https:\/\/lnkd.in\/e86FNhsK\n\n#CFD #DEM #MultiphaseFlow #FluidDynamics #Evaporation #Engineering #Modeling #Research #Innovation #GasLiquidSolid #NumericalFramework #Science #Simulation #EngineeringApplications","linkedinURL":"https:\/\/www.linkedin.com\/feed\/update\/urn:li:activity:7089197541845540865","githubURL":null,"paperURL":null,"author":"Antonio Benedetti","createdDate":"07\/23\/2023"},{"title":"The title is: Model-based End-to-End Process Development: The Integration of Drug Substance and Drug Product Manufacturing Models.","description":"\ud83d\udd2c\ud83d\udc8a Model-based End-to-End Process Development: The Integration of Drug Substance and Drug Product Manufacturing Models \ud83e\uddea\ud83d\udca1\n\nIn the pursuit of accelerated development in the pharmaceutical industry, #System #Modeling has emerged as a powerful tool. However, current practices often involve separate modelling activities for drug substance (DS) and drug product (DP) manufacturing, driven by time constraints and fixed decision criteria. To unlock the true potential of modelling and gain a comprehensive process understanding, the integration of DS and DP process models becomes the missing link. \ud83d\ude80\ud83d\udd17\n\nIn this research, led by our own Harry Christodoulou and colleagues and presented at #ESCAPE33 in Athens, the significance of connecting DS and DP process models is vividly demonstrated. The study explores how key attributes of an isolated DS can dynamically propagate through a DP tableting line, ultimately impacting the DP dissolution. An uncertainty analysis on a flowsheet model of a crystallization and direct compression line further emphasizes the importance of end-to-end flowsheet modelling to harness the full benefits of the modelling approach. \ud83c\udf10\ud83c\udf1f\n\nThe findings highlight the essential role of integrating DS and DP process models in achieving a holistic understanding of pharmaceutical processes. By addressing the interdependencies and interactions between the DS and DP stages, the researchers advocate for a more comprehensive approach to process development.\ud83d\udca1\ud83e\udde9\n\nIn addition to unveiling the potential of end-to-end flowsheet modelling, the study also delves into the technical and regulatory obstacles that must be navigated to implement such an integrated approach successfully. By addressing these challenges, the pharmaceutical industry can embrace a more robust, model-based end-to-end process development approach. \ud83c\udfed\ud83d\udee0\ufe0f\n\nThe authors highlight the growing importance of developing Drug Substance and Drug Product System (Flowsheet) Models while looking for the \"missing links\" in the pursuit of optimized drug development and manufacturing.\u00a0\ud83d\udc4f\ud83c\udf0c\n\n\ud83d\udcda Check out the ESCAPE paper for more details: https:\/\/lnkd.in\/esxmJC_k\n\n#ProcessModeling #DrugSubstance #DrugProduct #EndToEnd #PharmaceuticalModelling","linkedinURL":"https:\/\/www.linkedin.com\/feed\/update\/urn:li:activity:7088884558359605248","githubURL":null,"paperURL":null,"author":"Harry Christodoulou","createdDate":"07\/23\/2023"},{"title":"The title is: Investigating #Chemistry #Knowledge in Large Language Models #LLM: A Journey into #Code #Generation","description":"\ud83d\udd2c\ud83d\udcbb Investigating #Chemistry #Knowledge in Large Language Models #LLM: A Journey into #Code #Generation \ud83d\udcdd\ud83e\uddea\n\nThe scientific community has been closely examining the capabilities of code-generating large language models and their understanding of chemistry. The study delves into this intriguing inquiry, aiming to assess the extent to which these models possess genuine chemistry knowledge. The results shed light on their abilities and potential implications. \ud83d\ude80\ud83d\udd0d\n\nAn expandable framework is introduced for rigorous evaluation, prompting these language models with chemistry problems framed as coding tasks. A carefully curated benchmark set of problems covering various chemistry topics serves as the basis for evaluation, employing both automated testing and expert assessments. \ud83e\uddea\ud83d\udca1\n\nThe findings are noteworthy \u2013 recent large language models demonstrate a considerable ability to produce correct code across diverse domains in chemistry. Leveraging prompt engineering strategies, such as incorporating copyright notices at the beginning of files, has shown promising improvements in accuracy. \ud83d\udcbb\ud83d\ude80\n\nTo promote transparency and collaboration, the dataset and evaluation tools are made open source, offering a shared platform for future researchers to explore new models and their chemistry capabilities. This community resource empowers researchers to delve deeper into the fascinating world of large language models and their potential applications in chemistry. \ud83e\udd1d\ud83c\udf1f\n\nAdditionally, the research provides valuable insights into best practices for employing large language models in chemistry, ensuring responsible and effective utilization in teaching and research. The potential impact of these models on the field of chemistry is substantial, and further research will continue to explore their applications. \ud83c\udf1f\ud83e\uddec\n\nKudos to the dedicated researchers behind this investigation \u2013 Andrew D. White, Glen Max Hocky, Heta Gandhi, Mehrad Ansari, Sam Cox, Geemi Wellawatte, Ph.D, Subarna Sasmal, Ziyue Yang, Kangxin Liu, Yuvraj Singh, and Willmor J. Pe\u00f1a Ccoa.  \ud83c\udfc6\ud83c\udf10\n\n\ud83d\udd17 Link to Publication: https:\/\/lnkd.in\/eH8Dyamw\n\ud83d\udd17 Link to code for generating completions with contexts: https:\/\/lnkd.in\/eJp5gqH7 \n\ud83d\udd17 Link to Incoder model: https:\/\/lnkd.in\/eQnVVyCs\n\n#Chemistry #LanguageModels #AI #Research #Innovation #Education #OpenSource #ChemistryKnowledge #CodeGeneration #ScientificCommunity #Collaboration","linkedinURL":"https:\/\/www.linkedin.com\/feed\/update\/urn:li:activity:7088491409489448961","githubURL":null,"paperURL":null,"author":"Antonio Benedetti","createdDate":"07\/22\/2023"},{"title":"The title is: QUBO.jl - A Game-Changing Julia Package for Quantum-Inspired Operations Research.","description":"\ud83d\udd2c \ud83d\ude80 Exciting News for Operations Research and Quantum Computing Enthusiasts! \ud83d\ude80\ud83d\udd2c\n\nWe just found out about QUBO.jl, a ground-breaking Julia package set to redefine how we approach quantum-inspired techniques in Operations Research (OR). QUBO.jl specializes in the reformulation of complex optimization problems into Quadratic Unconstrained Binary Optimization (QUBO) formulations. This is a significant development for OR specialists, as many quantum-inspired techniques require QUBO formulations to function effectively.\n\nBut why is this so important? The power of QUBO.jl lies in its reformulation capabilities. It's not just about solving problems but about transforming them into a format that can be more efficiently processed by quantum-inspired algorithms. QUBO.jl empowers researchers, developers, and Operations Research (OR) specialists to effortlessly transform complex problems into Quadratic Unconstrained Binary Optimization (QUBO) form.\n\nFor OR specialists, QUBO.jl is a game-changer. It allows us to leverage the power of quantum-inspired techniques without getting bogged down in the intricacies of problem formulation. It's like having a translator who can fluently convert the language of complex optimization problems into the language of quantum computing.\n\nMoreover, QUBO.jl integrates seamlessly with the JuMP ecosystem, further enhancing its utility and ease of use #userfriendly.\n\nThis integration allows for a smooth transition between problem formulation and solution, making it an invaluable tool for anyone working in the OR field. So, whether you're a seasoned OR professional, a quantum computing enthusiast, or a curious newcomer to the field, QUBO.jl is a tool that promises to open up a world of possibilities. \n\nIt's not just about solving problems; it's about transforming them, making them more accessible and manageable for quantum-inspired techniques.\nCongratulations to all the developers!!!\n\nFor more information, feel free to contact David Esteban Bernal Neira and Pedro Maciel Xavier\n\n\ud83d\udd17 GitHub Repository: https:\/\/lnkd.in\/eGuRuDac\n\ud83d\udcd8 Documentation: https:\/\/lnkd.in\/eRYzdiCZ\n\n#QuantumComputing #QuantumInspired #QUBO #Julia #Optimization #OperationsResearch #JuMP #QUBOjl #PSREnergy #PSR","linkedinURL":"https:\/\/www.linkedin.com\/feed\/update\/urn:li:activity:7088169848253374464","githubURL":null,"paperURL":null,"author":"Harry Christodoulou","createdDate":"07\/21\/2023"},{"title":"The title is: Empowering Liquid-Handling Robots with an Open-Source Interface","description":"\ud83d\udd2c\ud83e\udd16 Introducing #PyLabRobot: Empowering #LiquidHandling #Robots with an #OpenSource Interface \ud83c\udf1f\ud83e\uddea\n\nLiquid handling robots play a crucial role in laboratory automation, but their potential has often been hindered by proprietary programming interfaces that restrict compatibility with specific robot types and operating systems. This limitation not only hampers method sharing but also slows down development and innovation. \ud83d\ude80\n\nBut fear not! Rick W. and team have come to the rescue with PyLabRobot, an exceptional open-source Python interface that transcends these constraints. PyLabRobot empowers scientists to program diverse liquid-handling robots, including Hamilton STARs, Tecan EVOs, and Opentron OT-2s, all under one unified platform. \ud83d\udcbb\ud83e\udd16\n\nThe true power of PyLabRobot lies in its universal set of commands and representations for deck layout and labware, providing seamless control over various accessory devices. This extensible interface works harmoniously with any robot that manipulates liquids within a Cartesian coordinate system. To ensure reliability, the system has been rigorously validated through unit tests and application demonstrations. \ud83e\uddea\ud83e\uddec\n\nNotable features of PyLabRobot include a browser-based simulator, a position calibration tool, and a path-teaching tool for complex movements. Such versatility and ease of use enable researchers to freely share protocols, foster a collaborative environment, and accelerate scientific progress. \ud83d\ude80\ud83d\udca1\n\nThe Python API integration allows users with basic Python skills to interact with a wide scientific computing ecosystem and harness the power of large language models for programming assistance. PyLabRobot transcends the limitations of proprietary robotic systems, unlocking a world of possibilities for scientists. \ud83d\udcab\ud83d\udd0d\n\nKudos to the brilliant minds behind PyLabRobot \u2013 Rick W., Stefan Golas, Wilson Ho , Connor W. Coley, and Kevin Esvelt \u2013 for their exceptional work in advancing laboratory automation and scientific collaboration \ud83d\udc4f\n\n\ud83d\udc49\ud83c\udffbAccess #Github: https:\/\/lnkd.in\/eqWzxuMc\n\ud83d\udc49\ud83c\udffbAccess the #Publication: https:\/\/lnkd.in\/eaRjYvCe\n\n#Python #Automation #Robotics #Laboratory #OpenSource #Collaboration #Innovation #LiquidHandling #ScientificResearch","linkedinURL":"https:\/\/www.linkedin.com\/feed\/update\/urn:li:activity:7087836815440654337","githubURL":null,"paperURL":null,"author":"Antonio Benedetti","createdDate":"07\/20\/2023"},{"title":"The title is: Chromatography Models in CADET: Spatial Discontinuous Galerkin Spectral Element Method for Efficient Computational Modeling","description":"\ud83d\udcc8 Chromatography models in CADET \ud83d\udcbb\n\nAre you interested in Chromatography Modeling or searching for a \"Simulations Platform\"? \ud83d\udd2c\n\n\ud83d\udcda We stumbled upon an intriguing research article titled: \"Spatial Discontinuous Galerkin Spectral Element Method for Chromatography Models in CADET\"  Authored by Jan Michael Breuer, Samuel Leweke, Johannes Schm\u00f6lder, Gregor Gassner, and Eric von Lieres from Forschungszentrum J\u00fclich and the University of Cologne.\n\nThe authors introduce spatial discontinuous Galerkin (DG) discretization for commonly used chromatography models, including the general rate model (GRM). What makes this research even more exciting is the integration of these methods into the #open-source CADET software!\n\nThrough rigorous #validation and #benchmarking, the authors have demonstrated significant performance advantages of the DG #CADET code, particularly for discrete problem sizes. They achieved an order of magnitude speed-up for a four-component steric mass action general rate model. These findings have profound implications for enhancing efficiency and accuracy in chromatographic processes in the #Pharma and Chemical Industries. \ud83d\udca1\n\nMake sure you give CADET a try: \ud83d\udc49 https:\/\/lnkd.in\/dU3scw6b \ud83d\udc48\n\nCheck out the paper here: \ud83d\udc49 https:\/\/lnkd.in\/eTF3vgYm \ud83d\udc48\n\nWe extend our heartfelt congratulations to the authors of the paper and the developers of CADET! \ud83c\udf89\ud83d\udc4f\n\n#ResearchHighlight  #ChemicalEngineering  #ChromatographyModels  #CADET \ud83d\udcbb #ComputationalModeling \ud83d\udcc8","linkedinURL":"https:\/\/www.linkedin.com\/feed\/update\/urn:li:activity:7087488514128273410","githubURL":null,"paperURL":null,"author":"Harry Christodoulou","createdDate":"07\/19\/2023"},{"title":"The title is: Explicit\/Multiparametric Model Predictive Control through Robust Optimization","description":"\ud83d\udce2 Explicit\/Multiparametric Model Predictive Control through Robust Optimization \ud83d\ude80\n\n\ud83d\udd2c Seeking innovative strategies to apply in the field of Model Predictive Control (#MPC)? Look no further! We've stumbled upon a great article which is sure to captivate your interest: \"Explicit model predictive control through robust optimization\" published in the AIChE Journal. \n\nThe research is conducted by Iosif Pappas, Nikos Diangelakis, and Stratos Pistikopoulos from Texas A&M University and the Technical University of Crete. In their work, they introduce a strategy which calculates an explicit state feedback policy for discrete-time uncertain linear systems with constraints. Notably, their method effectively addresses both multiplicative and additive uncertainty. The authors tackle the problem by calculating a \"terminal set constraint\" and reformulating state constraints in the \"prediction horizon\", ensuring operational feasibility even in the face of #uncertainty . Furthermore, they employ variable and constraint elimination approaches to enhance #computational performance. \n\nTo highlight how the approach can be used, the authors provide an example for a #bioreactor . These type of problems\/challenges appear very often in the Life Sciences and Pharma Industries and it is amazing to see novel methodologies being developed. \n\n\ud83d\udc4f Let's extend our warmest congratulations to the authors for their outstanding article!\n\n\ud83d\udd17 You can access the full article here: https:\/\/lnkd.in\/ekVVjK2m\n\n#ResearchHighlights #ControlSystems #RobustOptimization #BioreactorModeling #Innovation","linkedinURL":"https:\/\/www.linkedin.com\/feed\/update\/urn:li:activity:7087039457731698688","githubURL":null,"paperURL":null,"author":"Harry Christodoulou","createdDate":"07\/18\/2023"},{"title":"The title is: ChemBioMultimodalAutoencoders: Bridging the Gap between Single-Cell Imaging and Sequencing Data with AI","description":"\ud83d\udd2c\ud83d\udcf7 Introducing ChemBioMultimodalAutoencoders : Bridging the Gap between #SingleCell #Imaging and #Sequencing #Data with #AI \ud83c\udf1f\ud83d\udd0d\n\nThe emergence of single-cell methods has transformed our understanding of cellular heterogeneity by capturing diverse data modalities, including imaging and sequencing. Each modality offers unique insights into the complex realm of cell states, highlighting the significance of their integration in unraveling the functional implications of cellular diversity. While integrating different sequencing data modalities has been extensively explored, combining imaging and sequencing data remains a formidable challenge. \ud83e\uddec\ud83d\udd2c\n\nExcitingly, Thibault Bechtler et al have developed ChemBioMultimodalAutoencoders, leveraging the work of Karren Dai Yang et al. This innovative Python package introduces a groundbreaking approach that harnesses the power of autoencoders to establish a probabilistic coupling between vastly different data modalities. By mapping these modalities to a shared latent space, it enables the fusion of single-cell RNA-seq and chromatin images, unveiling distinct subpopulations of human naive CD4+ T-cells primed for activation. \ud83e\uddeb\ud83e\uddea\n\nChemBioMultimodalAutoencoders empowers researchers with streamlined multidomain data integration and translation, fueled by an advanced cross-modal autoencoder architecture. This transformative package enables seamless integration and translation of diverse data modalities, unlocking new avenues for deeper insights and groundbreaking discoveries. \ud83d\ude80\ud83d\udca1 \n\nWith ChemBioMultimodalAutoencoders, researchers can effortlessly incorporate new data modalities and train models for seamless translation, enabling exploration of uncharted territories in data analysis. This package heralds a paradigm shift in the field of multidomain data integration and translation, propelling research to unprecedented heights. \ud83e\uddec\ud83d\ude80\n\n\ud83d\udc4f Congratulations to Thibault Bechtler, Bartosz Baranowski, Michal Pikusa,\u00a0and Steffen Renner. It's inspiring to witness how you are pushing the frontiers of research and simultaneously promoting open access publication and open-source code sharing. \ud83d\udd2c\ud83c\udf1f\n\n\ud83d\udd17 Access to #Github : https:\/\/lnkd.in\/eFNFM7nU\n\ud83d\udcda Reference Karren Dai Yang et al : https:\/\/lnkd.in\/e3daidzr\n\n#Python #PyTorch #OpenSource #Cheminformatics #DeepLearning #MultimodalAutoencoders #AI #Innovation","linkedinURL":"https:\/\/www.linkedin.com\/feed\/update\/urn:li:activity:7086756632595968000","githubURL":null,"paperURL":null,"author":"Antonio Benedetti","createdDate":"07\/17\/2023"},{"title":"The title is: Advancing #Bioprocess #Optimization via #DigitalTwins: A Multiscale Modelling Approach","description":"\ud83e\uddea\ud83d\udd2c Advancing #Bioprocess #Optimization via #DigitalTwins: A Multiscale Modelling Approach\ud83e\udda0\ud83d\udcc8\n\nMammalian cells play a crucial role in the production of therapeutic proteins, accounting for up to 80% of the commercially available products. Among them, Chinese Hamster Ovary (CHO) cells have emerged as the primary host for protein manufacturing. This intricate process involves a series of reactors, with the final stage typically operated in fed-batch mode, enabling cell growth and protein production. However, the feeding strategy used is often predetermined based on past operations or experimental designs, failing to consider the real-time conditions of the process. \ud83d\udc89\ud83d\udd0d\n\nIn this great study by Mariana Monteiro et al, a paradigm-shifting approach is introduced. The team proposes a Model Predictive Control (MPC) formulation that leverages a hybrid kinetic-stoichiometric reactor model to generate optimal feeding policies in real-time. Remarkably, this MPC formulation is culture-agnostic, allowing it to be seamlessly transferred across various CHO cell culture systems. \ud83d\udcca\ud83d\udca1\n\nTo showcase the advantages of the proposed controller formulation, a comparative analysis is performed. An open-loop simulation is contrasted with closed-loop optimization, facilitated by a digital twin that emulates the bioprocess. This demonstration serves as a testament to the remarkable potential of real-time optimization in enhancing bioprocess efficiency and performance. \ud83d\ude80\ud83d\udcbb\n\n\ud83d\udc4fKudos to Mariana Monteiro, Sarah Fadda, and Cleo Kontoravdi for their pioneering work in pushing the boundaries of bioprocess optimization. \ud83e\udda0\n\n\ud83d\udd17 Read the full research article here: https:\/\/lnkd.in\/epK3EPX4\n\n#BioprocessOptimization #MultiscaleModelling #MPCFormulation #CHOCellCulture #TherapeuticProteins #ResearchInnovation #Science #Biotechnology #DigitalTwin #Efficiency","linkedinURL":"https:\/\/www.linkedin.com\/feed\/update\/urn:li:activity:7086298424127442944","githubURL":null,"paperURL":null,"author":"Antonio Benedetti","createdDate":"07\/15\/2023"},{"title":"The title is: Unlocking Efficient Crystallization Kinetics: Experimental Design for Polymorphic Systems","description":"\ud83d\udd2c\ud83e\uddea Unlocking Efficient #Crystallization #Kinetics #Determination: #Experimental #Design for Polymorphic Systems \ud83d\udc8e\ud83d\udca1\n\nCrystallization, a vital step in drug substance and product manufacturing, holds significant importance in the pharmaceutical industry. Over 90% of active pharmaceutical ingredient (API) manufacturing involves crystallization, where purity is the primary concern. However, other factors like crystal size distribution (CSD), polymorphic form, and morphology also greatly impact product manufacturability and bioavailability. Among these, controlling polymorphic forms is of utmost importance. \ud83c\udf21\ufe0f\ud83d\udc8e\n\nIn this study by Shivani Kshirsagar, Ph.D. et al , the focus is on ortho-aminobenzoic acid (OABA), a dimorphic model compound. Through a combination of experimental characterization and population balance modeling, the team dives into the intriguing world of crystallization kinetics. \ud83d\udd2c\ud83d\udc8e\n\nTo streamline the process and conserve valuable resources and time, a novel experimental design is introduced. This design aims to estimate the crystallization kinetic parameters of the polymorphic system within a combined cooling and antisolvent crystallization (CCAC) process using the minimum number of experiments required. Such efficiency holds great significance, especially in the drug substance development stage. \ud83e\uddea\n\nThe modeling studies shed light on the growth rates of the two polymorphs, revealing their dependency on solvent composition. Specifically, at a given temperature and supersaturation, the growth rate of form I increased with higher solvent content, while the growth rate of form II decreased with increased solvent proportion. \ud83d\udcc8\ud83d\udd0d\n\nBy identifying and validating the kinetic parameters governing nucleation and growth rates for both polymorphs across various solvent compositions and temperatures, the team established a reliable model. Leveraging this validated model, they conducted in silico design of experiments to create a design space. This design space empowers researchers to identify precise operating conditions that can be utilized to achieve desired crystal sizes and polymorphic forms. \ud83d\udca1\ud83d\udcbb\n\nHats off to Shivani Kshirsagar, Ph.D., Botond Szilagyi, and Zoltan Nagy for their insightful work in advancing experimental design and crystallization kinetics understanding. \ud83d\udc4f\ud83d\udd2c\ud83d\udc8e\n\n\ud83d\udd17Read the full research article here: https:\/\/lnkd.in\/eR_ETPs7\n\n#CrystallizationKinetics #ExperimentalDesign #PolymorphicSystems #DrugSubstanceDevelopment #Research #Innovation #Science #CrystalFormation #Efficiency ","linkedinURL":"https:\/\/www.linkedin.com\/feed\/update\/urn:li:activity:7085991672068616192","githubURL":null,"paperURL":null,"author":"Antonio Benedetti","createdDate":"07\/15\/2023"},{"title":"The title is: Autonomous Kinetic Model Identification: A Digitalization Game-Changer!","description":"\ud83d\ude80 Autonomous Kinetic Model Identification: A Digitalization Game-Changer! \ud83c\udf1f\n\nThe fast-paced digitalization in process industries is automating decision-making processes in plant operations, utilizing high-fidelity kinetic models continuously validated through feedback optimization loops. This is enabled by the integration of #flow chemistry & #computational methods.\n\n\ud83d\udcda We just came across this super article: \"Autonomous Kinetic Model Identification Using Optimal Experimental Design and Retrospective Data Analysis: Methane Complete Oxidation as a Case Study\" and the relevant #Github repository!\n\n\ud83d\udcbb The authors have developed a smart laboratory platform that can autonomously identify the most suitable kinetic models in real-time. This platform integrates model-based design of experiments methods and employs online sequential decision-making to select the most appropriate kinetic model structure and precisely estimate its parameters. The platform also uses switching objective functions to minimize parametric uncertainty.\n\nPankajakshan et al. put their platform to the test in a case study focused on the complete oxidation of methane on a Pd\/Al2O3 catalyst using a micro packed bed reactor. In 20 automated experiments, the platform successfully determined a suitable kinetic model with precise parameter estimation. This is a great achievement, as it would have taken weeks or even months to complete using traditional methods! #acceleration \n\nThis research shows potential to accelerate the pace of innovation in the chemical engineering and #Life Sciences industry. By automating the process of kinetic model identification, the platform will enable researchers to focus on more creative and strategic work.\n\n\ud83d\udc4f Congratulations to Arun Pankajakshan, Solomon Bawa,  Asterios Gavriilidis, and Federico Galvanin on their amazing research!\n\n\ud83d\udd17 Article link: https:\/\/lnkd.in\/ehR_xZps\n\n#ChemicalEngineering #Automation #DataAnalysis #KineticModels #Pharmaceuticals","linkedinURL":"https:\/\/www.linkedin.com\/feed\/update\/urn:li:activity:7085644681715281920","githubURL":null,"paperURL":null,"author":"Harry Christodoulou","createdDate":"07\/14\/2023"},{"title":"The title is: Generalized Disjunctive Programming (GDP) for JuMP.jl","description":"\ud83e\udde9\ud83d\udcbb Introducing DisjunctiveProgramming.jl: #Generalized #Disjunctive #Programming for JuMP.jl \ud83c\udf1f\ud83d\udd2c\n\nWhen it comes to modeling systems with discrete and continuous decisions, mixed-integer programming in algebraic form is commonly employed. However, this approach can quickly become complex, even for experienced modelers.\n\nEnter Generalized Disjunctive Programming (GDP), a systematic approach that brings clarity to such systems. GDP allows for modeling at a logic-based level of abstraction, capturing the fundamental rules through algebraic constraints and logic. The beauty of GDP lies in its ability to group related constraints into disjuncts, clearly defining subsets of the feasible space. \ud83e\udde9\ud83d\udd0d\n\nTo simplify the modeling and optimization process for GDP problems, DisjunctiveProgramming.jl comes to the rescue. Developed by Hector Perez, Shivank Joshi, and Ignacio Grossmann, this Julia package extends the functionality of JuMP.jl. It enables problem modeling using logical propositions and disjunctive constraints. \ud83d\udcc8\ud83d\udca1\n\nWith various reformulation options like the Big-M and Hull relaxations, DisjunctiveProgramming.jl seamlessly integrates with existing mathematical programming infrastructure, such as JuMP. \nThis package proves particularly valuable in industrial scenarios, including different stages of Drug Substance Manufacturing Processes. \u2728\ud83d\udca1\n\nHeartfelt congratulations to the brilliant developers for their exceptional work!\n\n\ud83d\ude80 Explore the #GitHub repository: https:\/\/lnkd.in\/eiTX5KsT\n\ud83d\udcda Check out the paper here: \u00a0https:\/\/lnkd.in\/ePH7vq2z\n\n\n#DisjunctiveProgramming #GDP #JuMP #Optimization #Modeling #IndustrialApplications #Research #Innovation #OpenSource","linkedinURL":"https:\/\/www.linkedin.com\/feed\/update\/urn:li:activity:7085316966499934209","githubURL":null,"paperURL":null,"author":"Antonio Benedetti","createdDate":"07\/13\/2023"},{"title":"The title is: Scipion PKPD - An Open-Source Platform for Biopharmaceutics, Pharmacokinetics, and Pharmacodynamics Data Analysis.","description":"\ud83d\udd2c\ud83d\udcbb Exploring #Scipion #PKPD: An #OpenSource Platform for Biopharmaceutics, Pharmacokinetics and Pharmacodynamics Data Analysis\n \ud83d\udcca\ud83d\udc8a\n\nBiopharmaceutics delves into the interrelationship between a drug's physical and chemical properties, the dosage form (drug product) in which it is administered, and the chosen route of administration. It plays a pivotal role in understanding the rate and extent of systemic drug absorption. On the other hand, pharmacokinetics focuses on studying how drugs move within the body. By employing mathematical models, it evaluates the processes of absorption, distribution, metabolism, and excretion (ADME) within an organism. Lastly, pharmacodynamics explores the effects of these drugs on the organism. \ud83d\udc8a\ud83c\udf1f\n\nPharmacokinetics data typically comprises samples collected over time, measuring drug concentration in plasma or specific tissues. Similarly, pharmacodynamics data consists of samples collected over time, capturing specific biophysical quantities like temperature or blood pressure. The data is subjected to non-parametric analyses to describe observed patterns (e.g., calculating the Area Under the Curve). Alternatively, parametric analyses involve fitting models, often based on differential equations, to make predictions about future events. \ud83d\udcc8\ud83d\udd2c\n\nIn this paper, Carlos Oscar Sanchez Sorzano et al present Scipion PKPD, an open-source platform designed for data analysis in the domains of Biopharmaceutics, Pharmacokinetics, and Pharmacodynamics. This powerful platform not only implements the most widely-used models but also welcomes new contributions. With almost 100 high-level operations, known as protocols, the platform provides researchers with a comprehensive toolkit for their data analysis needs. \ud83d\udca1\ud83d\udcbb\n\nScipion PKPD empowers scientists to explore and uncover valuable insights from complex biopharmaceutics, pharmacokinetics, and pharmacodynamics data. By combining the flexibility of an open-source platform with its diverse modeling capabilities, researchers can perform sophisticated analyses and gain a deeper understanding of drug behaviors and their impact on living organisms. \ud83c\udf10\ud83c\udf31\n\nKudos to Carlos Oscar Sanchez Sorzano, Yunior Fonseca Reyna, and Mariangeles Perez de la Cruz Moreno for their innovative work in developing this great open-source tool.  \ud83c\udf89\ud83d\udd2c\n\n\ud83d\udd17Link to #Github: https:\/\/lnkd.in\/e37ghe6i\n\ud83d\udd17Link to #Publication: https:\/\/lnkd.in\/evqFe4Ky\n\n#ScipionPKPD #Biopharmaceutics #Pharmacokinetics #Pharmacodynamics #DataAnalysis #OpenSource #Research #Innovation ","linkedinURL":"https:\/\/www.linkedin.com\/feed\/update\/urn:li:activity:7084954475613810688","githubURL":null,"paperURL":null,"author":"Antonio Benedetti","createdDate":"07\/12\/2023"},{"title":"The title is: Slow Feature Analysis (SFA) with sklearn-sfa","description":"\ud83e\udde0 Condition-based sensor-health monitoring: #Slow #Feature #Analysis (SFA) with sklearn-sfa! \ud83c\udf1f\ud83d\udd2c\n\nSlow Feature Analysis (SFA) is a remarkable computational method used in machine learning and signal processing to extract slowly varying features from time-varying data. It delves into the very essence of data by capturing the underlying structure or dynamics through the identification of features that change gradually over time. \u23f3\ud83c\udf1f\n\nThe concept behind SFA is rooted in the observation that real-world signals, such as speech, natural images, and sensory inputs, often possess temporal dependencies and convey valuable information through their slow variations. By focusing on these slow-changing features, SFA uncovers meaningful and invariant representations of the data, which find applications in diverse tasks including classification, prediction, and understanding complex systems. \ud83c\udf99\ufe0f\ud83d\udcc8\n\nIn the world of scikit-learn, an implementation of Slow Feature Analysis known as sklearn-sfa (or sksfa) offers a valuable tool. It stands as a standalone transformer for dimensionality reduction and serves as a fundamental building block for constructing intricate representation learning pipelines that harness scikit-learn's extensive collection of machine learning methods. \ud83e\uddf1\ud83d\udd27\n\nThis comprehensive package offers a solver for linear SFA along with various auxiliary functions. The accompanying documentation provides a thorough explanation of the algorithm, explores different use-cases, and offers valuable insights on fully harnessing the potential of SFA. You can dive into non-linear basis functions and more sophisticated architectures to maximize the power of SFA. \ud83d\udcda\ud83d\ude80\n\nKudos to Merlin Sch\u00fcler and Moritz L.  for their exceptional work in developing sklearn-sfa  \ud83d\udcbb\ud83c\udf0c\n\n\ud83d\udd17Link to #Github: https:\/\/lnkd.in\/e6HUUeCK\n\n#SlowFeatureAnalysis #MachineLearning #SignalProcessing #DimensionalityReduction #DataAnalysis #sklearnsfa #OpenSource #Innovation","linkedinURL":"https:\/\/www.linkedin.com\/feed\/update\/urn:li:activity:7084486483390160896","githubURL":null,"paperURL":null,"author":"Antonio Benedetti","createdDate":"07\/10\/2023"},{"title":"The title is: Unlocking Insights with #Automated #ImageBased #Color #Analysis: A Versatile PAT Tool","description":"\ud83e\uddeaUnlocking Insights with #Automated #ImageBased #Color #Analysis: A Versatile PAT Tool \ud83d\udcf7\ud83d\udca1\ud83d\udd2c\n\nIn the dynamic landscape of pharmaceutical research and development (R&D), the importance of process analytical technology (PAT) is becoming increasingly more visible. PAT tools enable the collection of crucial data needed to build efficient models and drive advancements in the field. As the industry increasingly adopts data-driven approaches, harnessing the right type of data becomes paramount. \ud83e\uddea\ud83d\udc65\n\nIn this groundbreaking article by Simon Smolders et al, the authors demonstrate the incredible ease and accessibility of using cameras to gather data in almost every unit operation. While previous publications have explored applications of basic to advanced image analysis algorithms, this study focuses on a simple yet powerful color analysis method that boasts broad applicability without the need for extensive model training. \ud83d\udcf7\ud83d\udcc8\n\nRemarkably, there is currently limited literature available on color-based analysis, with few published papers focusing on specific use cases. However, the color analysis showcased in this study surpasses expectations, providing valuable information on reaction progress, color removal, level monitoring, settling times, solubility determination, nucleation detection, filtration curves, and even the color of isolated materials. What's more, this analysis requires no additional tuning or calibration. \ud83c\udf08\ud83d\udca1\n\nIn several instances, the data derived from the color analysis not only matched but also outperformed state-of-the-art PAT tools. This results opens up new possibilities for pharmaceutical researchers, empowering them to gather critical insights in a non-invasive and efficient manner. \ud83d\udcca\ud83d\udd2c\n\nFurthermore, to promote knowledge sharing and collaboration, the authors have generously made the R and Python code for the image analysis algorithm openly available in the support information. \ud83c\udf10\ud83d\udcda\n\nKudos to Simon Smolders, Huibo S., Matthew Mower, Aditi Potdar, and Jan Dijkmans for this great publication ! \ud83d\udcaa\ud83d\udc8a\n\n\ud83d\udd17Link to #Publication: https:\/\/lnkd.in\/egaCJFEQ\n\n#PharmaceuticalRnD #ImageAnalysis #ProcessAnalyticalTechnology #ColorAnalysis #DataDrivenApproach #Innovation #OpenScience","linkedinURL":"https:\/\/www.linkedin.com\/feed\/update\/urn:li:activity:7084173193933938688","githubURL":null,"paperURL":null,"author":"Antonio Benedetti","createdDate":"07\/10\/2023"},{"title":"The title is: Advancing #RealTime #Monitoring: An Adaptive #SoftSensor for #AntibodyDrug #Conjugation Reactions","description":"\ud83d\udd2c Advancing #RealTime #Monitoring: An Adaptive #SoftSensor for #AntibodyDrug #Conjugation Reactions \ud83c\udf21\ufe0f\ud83d\udc89\n\nThe production of antibody-drug conjugates (ADCs) relies on a critical step known as the conjugation reaction, which directly influences the final product's composition, safety, and efficacy. Real-time monitoring of this reaction has become increasingly important, and spectroscopic sensors coupled with multivariate regression models have gained popularity in recent years. \ud83d\udcaa\ud83d\udd0d\n\nIn this exciting study by Robin Schiemer et al, an innovative approach using an extended Kalman filter (EKF) as an adaptive soft-sensor was developed for monitoring site-directed ADC conjugation reactions in real-time. The EKF acts as a fusion tool, combining sensor predictions with long-horizon forecasts from process models. This dynamic fusion enables the continuous update of the reaction's current state, enhancing robustness against experimental noise and model errors. \ud83e\uddea\ud83d\udcc8\n\nDeploying soft-sensors in biopharmaceutical applications poses challenges due to the uncertainty associated with sensor and process models. To overcome this, the study integrates an uncertainty-aware sensor model with a kinetic reaction model using the EKF. A Gaussian process regression model serves as the sensor model, facilitating time-variant determination of sensor uncertainty. The EKF effectively fuses the time-discrete predictions of conjugated drug amounts from the sensor model with time-continuous predictions from the kinetic model.\n\nRemarkably, even when the ADC species were indistinguishable by online-recorded UV\/Vis spectra, the developed soft-sensor dynamically updated all relevant reaction species. By incorporating time-variant process and sensor noise computation approaches, the performance of the EKF was significantly improved. The prediction error was reduced by up to 23% compared to using the kinetic model alone. This framework demonstrated enhanced robustness against noisy sensor measurements and incorrect model initialization, successfully transitioning from batch to fed-batch mode. \ud83d\udcca\ud83d\udd2c\n\nThe developed framework holds promising implications for model-based process control in ADC production and can be adapted for other types of ADC conjugation reactions.  \ud83d\udca1\ud83d\udc89\n\nKudos to Robin Schiemer, Jan Tobias Weggen, Katrin Marianne Schmitt, and J\u00fcrgen Hubbuch for their remarkable work!  \ud83d\udc4f\ud83c\udf0d\n\n\ud83d\udd17 Link to #Publication: https:\/\/lnkd.in\/eBi2J472\n\n#RealTimeMonitoring #SoftSensor #Biopharmaceuticals #ADCs #BiotechResearch #Innovation #ProcessOptimization","linkedinURL":"https:\/\/www.linkedin.com\/feed\/update\/urn:li:activity:7083782293814693888","githubURL":null,"paperURL":null,"author":"Antonio Benedetti","createdDate":"07\/09\/2023"},{"title":"The title is: Accelerating #Biotechnological Insights: #RoboticDriven Characterization of E. coli Strains Unveils the Power of #ModelBased Approaches! \ufffd\ufffd\ufffd\ufffd\ufffd","description":"\ud83d\udd2c Accelerating #Biotechnological Insights: #RoboticDriven Characterization of E. coli Strains Unveils the Power of #ModelBased Approaches!\ud83e\udda0\ud83d\udd0d\n\nEscherichia coli, a widely used bacterium in biotechnology, relies on glucose-limited fed-batch technology to achieve high space-time yields. However, this approach triggers an overflow metabolism of acetate at high glucose concentrations. \ud83e\udda0\ud83d\udd0d\n\nTo explore alternatives, Niels Krausch et al developed various E. coli knockout (KO) strains with limited glucose uptake. However, these strains have not been thoroughly characterized under process conditions. \ud83d\udcc8\ud83d\udca1\n\nTo showcase the efficiency of their high-throughput robotic platform, the researchers carried out comprehensive characterization of three different exemplary E. coli KO strains at three different scales: microtiter plates, 10 mL bioreactor system, and 100 mL bioreactor system. The characterization was conducted under excess glucose conditions with varying initial glucose concentrations. \ud83e\udd16\ud83d\udcbb\n\nBy extensively measuring growth behavior, substrate consumption, respiration, and overflow metabolism, they obtained crucial data for determining growth parameters using a mechanistic mathematical model. This allowed for a comprehensive comparative analysis of the strains. Remarkably, the results could be successfully transferred from one reactor configuration to another. \ud83d\udcaa\ud83d\udd2c\n\nThe study revealed that single and double KO mutants exhibited reduced specific rates for substrate uptake and acetate production. Additionally, higher glucose concentrations had adverse effects on the biomass yield coefficient. Notably, compared to previous studies, this research also provided insights into the specific oxygen uptake rate and carbon dioxide production rate, highlighting differences in the strains' metabolic behavior. \ud83d\udcca\ud83d\udd2c\n\nThis study exemplifies the power of combining automated robotic equipment and model-based approaches in characterizing strains and obtaining comprehensive information more rapidly, albeit with a trade-off between throughput and analytical capacity. \ud83c\udf31\ud83d\udca1\n\nKudos to Niels Krausch, Lucas Kaspersetz, Rogelio Diego Gayt\u00e1n-Castro, Marie-Therese Schermeyer, Alvaro R. Lara, Guillermo Gosset, Mariano Nicolas Cruz Bournazou, and Peter Neubauer for their groundbreaking work! \n\ud83d\udc4f\n\n\ud83d\udd17Link to #Publication: https:\/\/lnkd.in\/eD7kcQMx\n\n#Biotechnology #Microbiology #Research #Bioprocess #Characterization #Automation #ModelBasedApproach #Innovation","linkedinURL":"https:\/\/www.linkedin.com\/feed\/update\/urn:li:activity:7083479226665852928","githubURL":null,"paperURL":null,"author":"Antonio Benedetti","createdDate":"07\/08\/2023"},{"title":"The title is: Artificial Intelligence for Performance Prediction of Organic Solvent Nanofiltration Membranes","description":"\ud83c\udf1f Organic Solvent Nanofiltration #Membranes: Utilizing #AI for Performance Prediction \ud83d\ude80\n\n\ud83d\udce2 We would like to highlight a very interesting contribution in the field of Organic Solvent nanofiltration (OSN) with a focus on performance prediction. The article titled \"Artificial intelligence for performance prediction of organic solvent nanofiltration membranes\" presents an approach to address the challenges associated with predicting OSN membrane performance.\ud83d\udcda\n\nTraditionally, predicting OSN membrane performance has been challenging due to complex interactions and countless solvents involved. But now, the work by Jiahui Hu et al. has leveraged #artificialintelligence  \ud83e\udd16 and a good dataset. By training three #ai models (neural network, support vector machine, and random forest) on a dataset with 38k+ data points and 18+ parameters, they achieved accuracy of 98% (permeance) and 91% (rejection). \ud83c\udfaf\n\nTo gain deeper insights into the factors influencing membrane performance, a thorough principal component analysis (#pca) was conducted. The analysis revealed striking similarities in the factors impacting both permeance and rejection. These findings have implications not only for performance prediction but also for enhancing membrane #design and #development. \u2728\n\n\ud83d\udcca The results have the potential to accelerate the implementation of OSN in industrial settings by providing accurate predictive models for membrane performance. Finally, this work also shows the value of improved data standardization.\n\n\ud83c\udf89 We commend the research team for their exceptional work: Jiahui Hu, Changsu Kim, Peter Halasz, Jeong F. Kim, Jiyong Kim, and Gyorgy Szekely \ud83d\udc4f\n\nWe eagerly anticipate the practical applications that will arise from this research and the positive impact it will have on industrial processes.\n\nTo learn more about this research, we invite you to read the full paper: https:\/\/lnkd.in\/ezHFpnFz\n\n#OSNmembranes #artificialintelligence #MembraneDesign #performance ","linkedinURL":"https:\/\/www.linkedin.com\/feed\/update\/urn:li:activity:7083081079787515905","githubURL":null,"paperURL":null,"author":"Harry Christodoulou","createdDate":"07\/07\/2023"},{"title":"The title is: multiRegionFoam","description":"\ud83c\udf1f multiRegionFoam: A Modular Multiphysics Framework \ud83c\udf1f\n\nWe recently found out about the release \ud83c\udf89 of #multiRegionFoam, a #multiphysics framework for solving complex coupled continuum-physical problems within OpenFOAM (FOAM-extend). Developed by a talented team, multiRegionFoam offers a modular design that empowers users to tackle multi-physics problems region-by-region and interface-by-interface.\n\n\ud83d\udcd0 This framework provides the flexibility to choose different coupling methods for each Transport equation. It also features a generalized formulation of Boundary Conditions. With multiRegionFoam, detailed and advanced \"first-principle\", \"mechanistic\", \"physics-based\" predictive models are now -even more- within reach.\n\n\ud83d\udd17 The developers have generously shared the code of multiRegionFoam: https:\/\/lnkd.in\/eqc-xsYZ \ud83d\udcbb\n\nTo demonstrate its capabilities, the developers have showcased several examples in an article on #arXiv. These examples include forced convection heat transfer \ud83c\udf21\ufe0f, air bubble oscillation and rising in water, shell-and-tube heat exchangers, and high-temperature polymer electrolyte fuel cells. Check out the paper: https:\/\/lnkd.in\/ey84Sr69 \ud83d\udd17\n\nPlease join us in congratulating the people behind multiRegionFoam: Heba Alkafri, Constantin Habes, Mohammed Elwardi Fadeli, Steffen Hess, Steven Beale, Shidong Zhang, Hrvoje Jasak, Holger Marschall \ud83d\udc4f Kudos to all developers and contributors to the platform! \ud83d\udc4f\n\nTheir contributions enable collaboration and knowledge exchange across diverse disciplines including #lifesciences. \n\n#multiRegionFoam #multiphysics #simulation #OpenFOAM\u00a0","linkedinURL":"https:\/\/www.linkedin.com\/feed\/update\/urn:li:activity:7082742417350635520","githubURL":null,"paperURL":null,"author":"Harry Christodoulou","createdDate":"07\/06\/2023"},{"title":"The title is: Overcoming #Cell & #Gene #Therapies #Challenges with #Mechanistic #Modeling!","description":"\ud83d\ude80 Overcoming #Cell & #Gene #Therapies #Challenges with #Mechanistic #Modeling! \ud83d\udcaa\ud83d\udd2c\n\nExciting news! The FDA has recently approved AAV-based gene therapies for Duchenne muscular dystrophy (DMD) and hemophilia A, representing a significant breakthrough in treating these conditions. These approvals are the first-ever for DMD and hemophilia A, offering immense potential to improve the lives of countless patients. \ud83e\ude7a\u2728 They also build upon the impressive progress made in gene therapies for cancer and blindness in recent years. \ud83c\udf1f\ud83d\udd2c\n\nBut what about the economic challenges associated with manufacturing these therapies? Well, I've got great news! This great recent study by Francesco Destro et al. has tackled the bottlenecks in AAV manufacturing with the baculovirus\/Sf9 system. \ud83e\uddea\ud83d\udd0d Their work suggests process and genetic enhancements in the baculovirus vector to boost productivity and reduce manufacturing costs.  They achieved this by developing a mechanistic model that describes critical extracellular and intracellular events during baculovirus infection and rAAV maturation in the baculovirus expression vector system (BEVS). \ud83d\udcc8\ud83d\udca1\n\nTo validate their model, they successfully compared its predictions against experimental measurements of the vector genome, as well as structural and non-structural proteins obtained from rAAV manufacturing in the BEVS using TwoBac and ThreeBac constructs. Their model-based analysis pinpointed specific bottlenecks hindering full capsid formation.\n\nBest of all, the team has made their research freely available, and their #opensource models can be found in the link in the comments section. \ud83d\udcda\ud83c\udf10\n\n#Kudos to Francesco Destro, John Joseph, Prasanna Srinivasan, Joshua Kanter, Caleb Neufeld, Jacqueline Wolfrum, Paul Barone, Stacy Springs, Anthony Sinskey, Sylvain Cecchini, Robert Kotin, and Richard D. Braatz. \n\nThis collaboration between the Braatz lab at MIT, the MIT Center for Biomedical Innovation, and UMass Chan Medical School showcases the power of teamwork and innovation in overcoming challenges in gene therapy manufacturing. \ud83e\ude7a\u2728\n\n#CellAndGeneTherapies #MedicalBreakthroughs #GeneTherapyManufacturing #Innovation #Research #OpenSource #Collaboration","linkedinURL":"https:\/\/www.linkedin.com\/feed\/update\/urn:li:activity:7082335322688081920","githubURL":null,"paperURL":null,"author":"Antonio Benedetti","createdDate":"07\/05\/2023"},{"title":"The title is: ChemometricsTools.jl: Empowering Chemometrics Analysis in Julia!","description":"\ud83c\udf1f Introducing #ChemometricsTools.jl: Empowering Chemometrics Analysis in Julia! \ud83e\uddea\ud83d\udcbb\n\nChemometrics is the chemical discipline that uses mathematical and statistical methods to design or select optimal measurement procedures and experiments, and to provide maximum relevant chemical information by analyzing chemical data. \ud83e\uddea\n\n It leverages applied linear algebra and statistical techniques to uncover patterns and relationships. Unlike traditional machine learning, chemometrics prioritizes understanding the physics and contextual meaning of chemical measurements. Chemometricians carefully evaluate the trade-offs between black box modeling and pure machine learning methods. \ud83e\uddee\n\nToday, we are excited to unveil ChemometricsTools.jl, a powerful Julia package developed by Casey Kneale. It enhances chemometrics analysis and unlocks meaningful insights from chemical data! \ud83d\ude80\ud83c\udf89\n\nChemometricsTools.jl offers a comprehensive suite of tools for chemometric analysis, enabling you to:\n\n\ud83d\udd39 Simplify data handling with consistent transformations and reusable pipelines for seamless preprocessing. \ud83d\udd04\ud83d\udcca\n\n\ud83d\udd39 Effortlessly perform K-fold validation, moving window sampling\/training, and utilize advanced methods like Kennard Stone. Build ensemble models quickly, such as SIPLS, P-DS, and P-OSC. \ud83d\udcaa\ud83d\udcc8\n\n\ud83d\udd39 Choose from a diverse range of regression methods, including CLS, Ridge, Kernel Ridge, LS-SVM, PCR, PLS, ELMs, Regression Trees, Random Forest, and more. Assess performance using various metrics and built-in plots. \ud83d\udcc9\ud83d\udcca\n\n\ud83d\udd39 Discover powerful classification techniques, including LDA\/PCA, Hierarchical LDA, SIMCA, multinomial softmax\/logistic regression, PLS-DA, K-NN, Gaussian Naive Bayes, Classification Trees, Random Forest, and more. Generate LaTeX\/CSV reports for easy documentation. \ud83d\udcda\u2728\n\n\ud83d\udd39 Explore Tucker decomposition methods like HOSVD and HOOI for multiway\/multilinear modeling. Gain insights into multilinear PLS and effective data preprocessing. Contribute to the development of this exciting field! \ud83d\udd04\ud83d\udd20\n\nKudos to Casey Kneale and contributors (Mos\u00e8 Giordano, Wolfgang Pupp, Thibaut Lienart and Fredrik Ekre) for their outstanding work in advancing chemometrics analysis in Julia! \ud83d\udca1\ud83d\udd2c\n\n\ud83d\udd17Link to #Github: https:\/\/lnkd.in\/eiwvWa_M \n\n#Chemometrics #DataScience #Chemistry #JuliaLang #Analytics #DataAnalysis #ChemometricsToolsjl","linkedinURL":"https:\/\/www.linkedin.com\/feed\/update\/urn:li:activity:7082011988414877696","githubURL":null,"paperURL":null,"author":"Antonio Benedetti","createdDate":"07\/04\/2023"},{"title":"The title is: KiMoPack: A Python Package for Kinetic Modelling of the Chemical Mechanism","description":"\ud83c\udf1f KiMoPack: A Python Package for Kinetic Modelling of the Chemical Mechanism\ud83d\udcbb\n\n\ud83d\udce2 We wanted to highlight a great article that we believe will greatly benefit all those interested in kinetic modelling of chemical mechanisms. \ud83e\uddea\n\nThe authors of the article introduce #KiMoPack, a cutting-edge analysis tool for the kinetic modelling of transient spectroscopic data. Developed by Carolin M\u00fcller, Torbj\u00f6rn Pascher, Axl Eriksson, Pavel Chabera, and Jens Uhlig, this open-source #python package offers a comprehensive front-end for data pre-processing, fitting, and plotting of 2-dimensional data.\n\n\ud83d\udca1 KiMoPack enables users to perform standard fitting, global analysis, and complex kinetic model fitting \ud83d\udcc8. With its intuitive graphical user interface and user-friendly functions, it bridges the gap between beginners and advanced users, ensuring ease of use for everyone.\n\nThe authors have gone the extra mile by providing a detailed explanation of model construction, error analysis, data export, and a summary of the tutorials. They have even shared a #jupyternotebook demonstrating the general workflow, which you can find in the Supporting Information of the article.\n\nWe are thrilled to share this valuable resource with our community and encourage you to check out the article to explore the power and potential of KiMoPack. \ud83d\ude80\n\n\ud83c\udf89 Many congratulations to the authors! \ud83c\udf89\n\nLink to the paper: https:\/\/lnkd.in\/esniZg38\n\nLink to code: https:\/\/lnkd.in\/eYrF6HGc\n\n#Chemistry #KineticModeling #DataAnalysis #OpenSource #Python","linkedinURL":"https:\/\/www.linkedin.com\/feed\/update\/urn:li:activity:7081649100105887744","githubURL":null,"paperURL":null,"author":"Harry Christodoulou","createdDate":"07\/03\/2023"},{"title":"The title is: Geometry Optimization of a Continuous Millireactor via CFD and Bayesian Optimization","description":"\ud83c\udf1f Can CFD & Bayesian Optimization be combined to design a reactor? \ud83d\udd2c\n\n\ud83d\udca1Yes, they can!\ud83d\udca1\nWe stumbled upon a fascinating paper titled \"Geometry Optimization of a Continuous Millireactor via CFD and Bayesian Optimization\" by researchers from RWTH Aachen University and Delft University of Technology. \ud83d\udcda\n\nThis study introduces a framework that combines Computational Fluid Dynamics (#CFD) and #Bayesian Optimization to optimize continuous milli-scale reactors. By automating geometry optimization through CFD simulations and utilizing the multi-objective Bayesian Optimization algorithm TSEMO (Thompson sampling efficient multi-objective optimization), the authors have achieved good results and they were able to find #pareto-optimal reactor variations. \ud83d\udcbb\n\nWhat's even more exciting is that this framework can be applied to various devices and optimization objectives, making it highly adaptable. We envision its potential in fields such as Life Sciences and Pharma! \ud83d\udc8a\n\nCongratulations to the authors: Moritz Begall, Artur Schweidtmann, Adel Mhamdi, and Alexander Mitsos! \ud83c\udf89\ud83d\udc4f\n\nRead the paper here: https:\/\/lnkd.in\/eDDQedgG\n\n#ChemicalEngineering #CFD #BayesianOptimization\n","linkedinURL":"https:\/\/www.linkedin.com\/feed\/update\/urn:li:activity:7081279443146526720","githubURL":null,"paperURL":null,"author":"Harry Christodoulou","createdDate":"07\/02\/2023"},{"title":"The title is: Exploring the Power of AI\/ML in Biopharmaceutical Manufacturing","description":"\ud83d\udd2c\ud83d\udca1 Exploring the Power of #AIML in #Biopharmaceutical #Manufacturing \ud83d\udd2c\ud83d\udca1\n\n\ud83c\udf10\ud83e\udd16 The field of biopharmaceutical manufacturing is undergoing a remarkable transformation with the integration of Artificial Intelligence and Machine Learning (AI\/ML) techniques. These cutting-edge technologies have the potential to revolutionize the industry by reducing the need for human supervision and enabling automated and continuous processing. \ud83d\ude80\ud83d\udd2c\n\n\ud83d\udd0d\ud83d\udcca Multivariate data analysis algorithms have emerged as the cornerstone of AI\/ML approaches, finding widespread implementation in the biopharmaceutical industry. These powerful tools enable comprehensive analysis and interpretation of complex datasets, leading to improved process optimization and quality control. \ud83d\udcc8\ud83d\udd2c\n\n\ud83d\udca1\ud83e\udde0 Artificial neural networks and reinforcement learning approaches are gaining increasing interest for monitoring and control of biopharmaceutical manufacturing processes. These intelligent algorithms can learn from data and adapt in real-time, enhancing process efficiency and reliability. The potential of these techniques to optimize the design, monitoring, and control of biopharmaceutical manufacturing is truly exciting. \ud83c\udf1f\ud83d\udd2c\n\n\ud83d\udd11 However, several key challenges must be addressed to fully leverage the benefits of AI\/ML in biopharmaceutical manufacturing. These challenges include the lack of regulatory guidance, incomplete data, difficulty in risk assessment, absence of biopharma-specific tools, and a shortage of trained talent. Overcoming these hurdles will be crucial for the widespread adoption and success of AI\/ML in the industry. \ud83e\udde9\ud83c\udf10\n\n\ud83d\udcda\ud83d\udd2c This review provides a comprehensive overview of AI\/ML applications in biopharmaceutical manufacturing. It highlights the most commonly used AI\u2013ML algorithms, such as multivariate data analysis, artificial neural networks, and reinforcement learning. \n\nKudos to Anurag Rathore, NIKITA SAXENA, Garima Thakur, PhD, and Somesh Mishra for providing this great overview \ud83d\udc4f\ud83d\udd2c\n\n\ud83d\udd17 Dive into the full publication by following the link in the comments below! \n\n#Biopharmaceuticals  #ArtificialIntelligence #AI #MachineLearning  #ProcessOptimization #QualityControl #Industry4_0 #innovation  #Biotechnology ","linkedinURL":"https:\/\/www.linkedin.com\/feed\/update\/urn:li:activity:7080877899087499264","githubURL":null,"paperURL":null,"author":"Antonio Benedetti","createdDate":"07\/01\/2023"},{"title":"The title is: Adapting Modelling and Simulation Credibility Standards to Computational Systems Biology.","description":"\u2b50\ufe0f Adapting Modelling and Simulation Credibility Standards \u2b50\ufe0f\n\n\ud83d\ude80 #NASA pioneers the use of \ud83d\udcbbcomputational models to perform complex experiments that were once deemed too costly or reliant on microgravity conditions.  Meanwhile, both the #FDA and #EMA  have began embracing and accepting the power of models and simulations as valuable evidence for expediting the approval process of life-changing pharmaceuticals and cutting-edge medical devices. For all organizations, model #credibility is extremely important!\n\n\ud83d\udcc4We would like to highlight an exciting paper with the title: \"Adapting Modelling and Simulation Credibility Standards to Computational Systems Biology\".\n\n\ud83d\udcda The authors delve into the importance of credibility standards for computational models in #systemsbiology. They propose a quantitative credibility scoring system to compare and improve model trustworthiness, while advocating for the publication of credibility metrics alongside models for informed decision making.\n\nAs models become more complex and influential, the need for a credibility assessment system tailored to this domain becomes imperative. The authors highlight the absence of specific standards and scoring systems for model credibility in systems #biology and discuss the challenges of automating credibility assessment.\n\n\ud83d\udce3 Congratulations to Lillian Tatka, Lucian Smith, Joseph Hellerstein, and Herbert Sauro for their exceptional work, which holds significant relevance not only for the #pharma and #lifesciences industry but also for organizations like #NASA, where computational models are integral to ground-breaking experiments.\n\n\ud83d\udd17 Read the full paper here: \nhttps:\/\/lnkd.in\/eiwymGwj\n\n#ComputationalSystemsBiology #ModelCredibility #ResearchInnovation #Pharma #LifeSciences #Bioengineering #SystemsBiology #NASA","linkedinURL":"https:\/\/www.linkedin.com\/feed\/update\/urn:li:activity:7080537922248028160","githubURL":null,"paperURL":null,"author":"Harry Christodoulou","createdDate":"06\/30\/2023"},{"title":"The title is: PyMC: Python package for Bayesian statistical modelling & inference.","description":"\ud83d\udcc8 PyMC: Python package for Bayesian statistical modelling & inference. \ud83c\udf1f\n\nBy leveraging a probabilistic programming framework, the pharmaceutical industry can enhance drug development by incorporating Bayesian statistical modelling and inference to optimize #processdesign and make informed decisions about #drugsafety and quality.\n\nWe recently found out about #PyMC, a very interesting and useful #python  package for #Bayesian Statistical Modelling. The package focuses on advanced Markov chain Monte Carlo (MCMC) and variational inference (VI) algorithms. It has multiple features that need highlighting:\n\n\ud83d\udd2c Intuitive interface:\nExpress complex relationships and incorporate prior knowledge effortlessly with PyMC's intuitive interface.\n\n\ud83c\udfaf Bayesian Inference made simpler:\nSample from the posterior distribution using advanced MCMC methods, quantifying uncertainty and drawing meaningful conclusions from your data.\n\n\ud83d\udcca Model fitting and comparison:\nFit models to your data, from maximum likelihood estimation to Bayesian model averaging. Visualize parameter distributions and convergence diagnostics with ease.\n\n\ud83d\udd27 Integration:\nPyMC seamlessly integrates with popular scientific libraries like NumPy and Pandas, ensuring a smooth data analysis workflow.\n\nWe recommend applying PyMC in #Pharmaceutical and other #Modelling projects to make informed decisions during process development.\nCongratulation to the all contributors & developers: John Salvatier, Thomas V. Wiecki\u200b, Christopher Fonnesbeck, and many others!\n\n\ud83c\udf10 Learn more about PyMC: https:\/\/lnkd.in\/exJrEVTR\n\n\ud83d\udd17 GitHub link: https:\/\/lnkd.in\/dvmqPk5w\n\nFeel free to adjust the post as needed. Happy Bayesian modelling!\n\n#PyMC #BayesianAnalysis #Python","linkedinURL":"https:\/\/www.linkedin.com\/feed\/update\/urn:li:activity:7080226734029037569","githubURL":null,"paperURL":null,"author":"Harry Christodoulou","createdDate":"06\/29\/2023"},{"title":"The title is: Advancing #Metabolic #Analysis with #pyTFA and #matTFA: Unleashing the Power of #Thermodynamics-based #Flux #Analysis","description":"\ud83d\udd2c\ud83c\udf1f Advancing #Metabolic #Analysis with #pyTFA and #matTFA: Unleashing the Power of #Thermodynamics-based #Flux #Analysis \ud83d\udd2c\ud83c\udf1f\n\n\ud83d\udd0d\u2728 High-throughput analytic technologies have opened up a treasure trove of omics data, revolutionizing studies in Systems Biology and Biotechnology. However, many analyses still overlook a crucial physicochemical constraint: thermodynamics. \u2697\ufe0f\n\nThermodynamics-based Flux Analysis (TFA) is a game-changing approach that integrates quantitative metabolomics data and provides critical insights into net-flux directionality and metabolic engineering decisions. \ud83d\udca1\ud83e\uddea\n\nThis paper from Pierre Salvy et al showcases the advancements achieved with pyTFA and matTFA in the field of metabolic analysis. The Python package, pyTFA, and Matlab toolbox, matTFA, are powerful implementations of TFA, enabling researchers to unlock the true potential of thermodynamics-based flux analysis. \ud83d\ude80\ud83d\udcbb\n\nAn example application on both reduced and genome-scale models of E. coli demonstrates the superiority of TFA in reducing the feasible flux space compared to constraint-based Flux Balance Analyses (FBA). The integration of TFA and data enhances accuracy and provides a deeper understanding of metabolic dynamics, facilitating informed decisions in metabolic engineering. \ud83d\udcc8\ud83d\udcbb\n\n\ud83c\udf89\ud83d\udc4f A huge round of applause to the brilliant authors, Pierre Salvy, Georgios Fengos, Meric Ataman, Thomas Pathier, Keng Soh, and Vassily Hatzimanikatis, for their exceptional work and contributions to the open-source sharing\ud83d\udcbb\ud83c\udf1f\n\n\ud83d\udd17 Link to #GitHub: \n - pyTFA: https:\/\/lnkd.in\/ezk9QrZW\n - matTFA: https:\/\/lnkd.in\/ePtahGBe\n\ud83d\udd17 Link to #Publication: https:\/\/lnkd.in\/ewCW3m2c \n\n#Science #Research #MetabolicAnalysis #Thermodynamics #TFA #Python #Matlab #pyTFA #matTFA #Biotechnology #SystemsBiology #DataIntegration #OpenSource","linkedinURL":"https:\/\/www.linkedin.com\/feed\/update\/urn:li:activity:7079911273391378433","githubURL":null,"paperURL":null,"author":"Antonio Benedetti","createdDate":"06\/28\/2023"},{"title":"The title is: Awesome Chemical Engineering Education","description":"\ud83c\udf1f The awesome repo for chemical engineering education \ud83c\udf1f\n\nWe recently stumbled upon a great resource that can certainly improve way we approach chemical engineering education. It's the \"Awesome Chemical Engineering Education\" repository created by Kevin Greenman, a Ph.D. Candidate in Chemical Engineering and Computation at Massachusetts Institute of Technology.\n\n\ud83d\udcda This curated list is a treasure trove of online chemical engineering education resources, with a special emphasis on materials that are free, open source, and offer a significant computational component (e.g., #python , #julialang, etc.). From online courses and textbooks to free open source software, this repository covers it all.\n\n\ud83d\udca1 What makes this repository very interesting is the intersection of traditional chemical engineering concepts with computational tools. By incorporating programming languages like #Python, #Julia, or #matlab, learners can gain a deeper understanding of theoretical concepts while improving their computational skills.\n\n\ud83d\udc49 However, it's important to remember that these resources were created by dedicated individuals who generously shared their knowledge. If you intend to use these materials in your own courses, be sure to review the licenses in each repository, and provide proper credit where it's due. \n\n\ud83c\udf10 Whether you're a student, educator, or professional, this repository can be very useful.  Kudos to all contributors! \n\n\ud83d\udd17 Check out the repository here: https:\/\/lnkd.in\/gamqKgQi\n\n#ChemicalEngineering #Education #OpenSource #ComputationalModeling #LearningResources","linkedinURL":"https:\/\/www.linkedin.com\/feed\/update\/urn:li:activity:7079488957259927552","githubURL":null,"paperURL":null,"author":"Harry Christodoulou","createdDate":"06\/27\/2023"},{"title":"The title is: Fresa: An Algorithm for Black-Box Single and Multiple Objective Optimization","description":"\ud83d\udcc8 Fresa: An Algorithm for Black-Box Single and Multiple Objective Optimization \ud83d\udcc8\n\nWe recently came across #Fresa, a \"plant \ud83c\udf31 propagation\" algorithm for solving single and multiple objective optimization problems. Developed by Professor Eric Fraga from UCL Chemical Engineering , #Fresa implements a nature-inspired plant propagation approach within a stochastic direct search framework. \u2728\n\nOne notable aspect of Fresa is its ability to handle black-box objective functions, where little information about the underlying system is available. By treating the objective function as a #blackbox , Fresa is designed to tackle problems that prove challenging for traditional #mathematical #programming methods.\n\nMoreover, Fresa supports both single and multi-objective optimization. Whether seeking a single optimal solution or identifying a set of trade-off solutions representing a #pareto front, Fresa is equipped to handle the task efficiently. \ud83c\udfaf\n\nThe ease of installation and low dependencies make Fresa accessible to a wide range of users. With its availability in the #julialang General Registry and #opensource nature, researchers and practitioners alike can take advantage of this powerful #optimization tool. \ud83d\ude80\n\nWe commend Professor Eric Fraga \ud83d\ude4c for his valuable contribution to the optimization field with #Fresa. \n\nIf you're interested in exploring Fresa further, you can find the open-source code and additional information on the project's GitHub repository: https:\/\/lnkd.in\/eTdB4eRH \ud83d\udcda\n\nDetailed documentation found here: https:\/\/lnkd.in\/ebgVhZN9 \ud83d\udca1\n\n#Optimization  #NatureInspiredResearch","linkedinURL":"https:\/\/www.linkedin.com\/feed\/update\/urn:li:activity:7079093557424222208","githubURL":null,"paperURL":null,"author":"Harry Christodoulou","createdDate":"06\/26\/2023"},{"title":"The title is: Low-Alcohol Beer (LAB) Production: A Flavorful and Innovative Brewing Approach","description":"\ud83c\udf7b\ud83d\ude0e \"Beer-ifying the Heatwave: #Modelling Low-Alcohol #Beer #Production!\" \ud83c\udf1e\ud83c\udf7a\n\nHey PolyModellers, surviving the scorching summer? \ud83c\udf21\ufe0f\u2600\ufe0f Today, we've got something exciting for you: the latest trend sweeping the beverage world\u2014Low-Alcohol Beer (LAB) and Alcohol-Free Beer (AFB)! \ud83c\udf0d\ud83c\udf7b \n\nPerfect for those seeking a refreshing sip without the buzz, they offer incredible flavor, health benefits, and suit evolving lifestyle choices.\nNow, let's dive into a fascinating paper on the science of LAB production. \ud83d\udcda\ud83d\udd2c \n\nResearchers Dylan Pilarski, PMP & Dimitrios I. Gerogiorgis explore Cold Contact Fermentation (CCF), a simple and cost-effective brewing method gaining popularity. It's like a cool breeze in beer production! \u2744\ufe0f\ud83c\udf7b\n\nThe researchers reparameterize the de Andr\u00e9s-Toro et al. model, a dynamic model widely used in conventional brewing, specifically tailored for CCF. Validated with industrial data, this model proves highly reliable and predictive. \ud83d\udcc8\ud83d\udd0d\n\nSo, what does it mean for our beloved beer flavors? The paper delves into the impact of temperature variations on sugar consumption, ethanol production, and the evolution of flavor compounds like ethyl acetate and diacetyl during CCF. Ethyl acetate, responsible for fruity notes, is particularly sensitive to CCF conditions. By fine-tuning temperature profiles, brewers can enhance the fruity flavor in LAB and AFB. \ud83c\udf50\ud83c\udf21\ufe0f\n\nBut there's more! The authors construct a reparameterized model that accurately describes CCF, allowing for hypothetical changes and sensitivities. This opens doors for future advancements, demanding larger datasets and global optimization algorithms to unlock the brewing method's full potential. \ud83c\udf0c\ud83d\udd2c\nAs I explore the paper further, trade-offs and challenges emerge. Implementing new temperature profiles for superior flavor and AFB quality requires capital expenditure. It's a balancing act between flavor refinement, ethanol reduction, and profitability. A true brewing juggling act! \ud83e\udd39\ud83c\udf7b\n\nThe paper also emphasizes capturing a broader range of beer flavors. While dynamic models have limitations in representing bitterness and wortiness, the researchers highlight the need for comprehensive models to deliver an authentic and satisfying LAB experience.\n\nSo, let's raise our glasses to Dylan Pilarski, PMP & Dimitrios I. Gerogiorgis and their enlightening research! Cheers to the science behind the flavor! \ud83c\udf0d\ud83c\udf7a\n\nLink to #Publication: https:\/\/lnkd.in\/efwNBasM\n\n#BeerModelling #BeerScience #BrewingInnovation #FlavorExploration #RefreshingBrews","linkedinURL":"https:\/\/www.linkedin.com\/feed\/update\/urn:li:activity:7078727935779590145","githubURL":null,"paperURL":null,"author":"Antonio Benedetti","createdDate":"06\/25\/2023"},{"title":"The title is: Rethinking Pharmaceutical Process Development: The Role of Modelling and Virtual Experiments","description":"\ud83c\udf1f Rethinking #Pharmaceutical #Process #Development: Continuous Manufacturing (#CM) and the Role of #Modelling & #VirtualExperiments! \ud83e\uddea\ud83d\udca1\n\nPharmaceutical manufacturing is rapidly evolving, driven by pricing pressure and regulatory expectations. Continuous manufacturing (CM) has emerged as an innovative manufacturing platform, offering improved agility, flexibility, and product quality. However, understanding the complex input-output relationships in interconnected unit operations presents challenges.\n\nTraditional approaches like Design of Experiments (DoE) have limitations in CM due to interconnected relationships across the telescoped unit ops and non-linearity of the system. Therefore, mechanistic models coupled with computer experiments can be a game-changer solution \ud83d\udcaa\n\n\ud83d\ude80 Introducing a groundbreaking workflow for continuous manufacturing of Active Pharmaceutical Ingredients (APIs)! This paper by Boung Wook Lee et al. unveils an innovative approach that revolutionizes API manufacturing. The workflow includes:\n\n1\ufe0f\u20e3 Develop Mechanistic Process Models\n2\ufe0f\u20e3 Verify\/Validate the Model\n3\ufe0f\u20e3 Convert Model Parameters to Process Parameters\n4\ufe0f\u20e3 Design Computational Grid\n5\ufe0f\u20e3 Perform Simulations\n6\ufe0f\u20e3 Fit Meta-Model (Surrogate Model) to Output Parameter\n7\ufe0f\u20e3 Analyze Meta-Model with Global Sensitivity Analysis\n8\ufe0f\u20e3 Slice and Dice the Model for Further Analysis\n\nThis workflow addresses complexity, driving efficiency, enhanced process understanding, and innovation in pharmaceutical process development. \n\nKudos to the authors Tim Boung Wook Lee, John Peterson, Frank Yin, Greg Stockdale, Yangmu Chloe Liu, and Alexander O'Brien for this excellent work ! \ud83d\udc4f\n\n\ud83d\udd17Link to #Publication: https:\/\/lnkd.in\/ehcgm4de\n\n#ContinuousManufacturing #API #ProcessOptimization #ProcessDevelopment #PharmaceuticalIndustry #Innovation #Research \ud83c\udf0d","linkedinURL":"https:\/\/www.linkedin.com\/feed\/update\/urn:li:activity:7078343573422657536","githubURL":null,"paperURL":null,"author":"Antonio Benedetti","createdDate":"06\/24\/2023"},{"title":"The title is: Identifying the Design Space of Pharmaceutical Processes: Combining Partial Least Squares and Radial Basis Function Analysis.","description":"\ud83d\udca1\u00a0Identifying the #Design #Space of #Pharmaceutical Processes: Combining #PartialLeastSquare and #RadialBasisFunction Analysis  ! \ud83c\udf1f\n\nIdentifying the design space of pharmaceutical processes is crucial as it enables the optimization of manufacturing parameters, leading to improved efficiency, enhanced product quality, and cost reduction in the pharmaceutical industry.  \ud83c\udfaf\n\nFeasibility analysis is a mathematical technique used to identify the design space (DS) of a pharmaceutical process. However, its drawback lies in the curse of dimensionality, where simulations become computationally expensive and cumbersome with a large number of input factors. Moreover, visually representing the high-dimensional design space compactly poses a challenge.\n\nIf you seek an innovative solution to address this challenge, I highly recommend exploring this great paper authored by Gabriele Bano et al. \ud83d\udcdd The authors introduce a captivating methodology that effectively addresses the complexities associated with identifying the design space in intricate pharmaceutical processes.\n\nBy harnessing partial least-squares (PLS) regression modeling, they reduce the dimensionality of the feasibility problem, overcoming the computational burden associated with a large number of input factors.\u00a0Using a Radial Basis Function (RBF) adaptive sampling feasibility analysis in a lower dimensional space, they accurately pinpoint the feasible region of the process. \ud83e\uddee\n\nThe authors validate their approach through three simulated case studies, including continuous direct compaction of a pharmaceutical powder. The results consistently demonstrate the methodology's effectiveness in reducing computational complexity while ensuring precise and robust identification of the design space. \ud83d\udd2c\ud83d\udcca\n\nLink to #Publication: https:\/\/lnkd.in\/eGCkUE7d\n\nCongratulations to Gabriele Bano, Zilong Wang, Pierantonio Facco, Fabrizio Bezzo, Massimiliano Barolo, and Marianthi Ierapetritou for their innovative contributions to pharmaceutical process design! \ud83d\ude4c \n\n#PharmaceuticalResearch #DesignSpace #Innovation #FeasibilityAnalysis #PLS #RBF #datadriven #modelling ","linkedinURL":"https:\/\/www.linkedin.com\/feed\/update\/urn:li:activity:7078035328309059584","githubURL":null,"paperURL":null,"author":"Antonio Benedetti","createdDate":"06\/23\/2023"},{"title":"The title is: Machine Learning-Based Methods for Chemical Processes Optimization Under Uncertainty","description":"\ud83d\udd2c #Machine #Learning-Based Methods for Chemical Processes #Optimization Under #Uncertainty \ud83d\udd0d\n\nLeveraging machine learning-based methodologies for chemical process optimization under uncertain conditions can allow experts to enhance efficiency, adapt to complex process models, respond rapidly to changes, and make data-driven decisions; ultimately accelerating drug development and improving operational performance. \ud83d\udca1\ud83d\udcaa\n\nWe would like to share an interesting paper which we recently discovered in the field of chemical process optimization! \ud83d\udcda In this study, we found a machine learning-based methodology that has the potential to improve operations under uncertainty. \ud83c\udf1f\n\nThis paper addresses the intricate challenges encountered in optimizing chemical processes, particularly when dealing with highly nonlinear and black-box models. The authors present an approach which combines statistical techniques, cutting-edge optimization algorithms, and machine learning models. \ud83d\udca1\ud83d\udcc8\n\nWhat makes this methodology interesting is its ability to accurately approximate optimal solutions based on uncertain parameters. By leveraging data-driven models developed offline, the approach enables real-time prediction of optimal solutions, adapting swiftly to changes in uncertain parameters. Moreover, the current methodology reduces computational complexity, resulting in substantial gains in optimization time. \u2699\ufe0f\u23f1\ufe0f\n\nWe extend our appreciation to the authors, Ahmed Shokry Abdelaleem, Sergio Armando Medina Gonz\u00e1lez, PhD, Piero Baraldi, Enrico Zio, eric Moulines, and Antonio Espu\u00f1a, for their exceptional work. \ud83d\udc4f \n\n\ud83d\udd17 Link to paper: https:\/\/lnkd.in\/esbfAuU2\n\n#ChemicalEngineering #ProcessOptimization #MachineLearning #Research #Innovation #Optimization","linkedinURL":"https:\/\/www.linkedin.com\/feed\/update\/urn:li:activity:7077713923809927168","githubURL":null,"paperURL":null,"author":"Antonio Benedetti","createdDate":"06\/22\/2023"},{"title":"The title is: Overcoming Complexities and Parameter Challenges in Crystallization Processes: A New Framework for Optimal Model Reliability","description":"\ud83d\udd2c\ud83d\udd0d Seeking #Optimal #Model #Reliability in #Crystallization Processes: Overcoming Complexities and Parameter Challenges \ud83d\udd0d\ud83d\udd2c\n\nThe development of reliable mathematical models for crystallization processes can be quite challenging. Due to the complexity of the underlying phenomena and the inherent Population Balance Models (PBMs), as well as the large number of parameters that need to be identified from experimental data, it's no easy task. \ud83d\udcca\ud83e\uddea\n\nThe available experimental data often provides limited information, making it challenging to accurately determine the model's structure and the correlations between its parameters. Consequently, the mathematical model may encompass more parameters than can be reliably identified from the available data. However, Dimitrios Fysikopoulos et al proposed a new solution to address this critical issue and ensure optimal model reliability. \ud83d\udca1\ud83d\ude80\n\nThe proposed framework for parameter estimability was validated in a complex crystallization process. It utilized a comprehensive multi-dimensional population balance model within a differential algebraic system, considering the combined influences of crystal growth modifiers and impurities on needle-like crystal size and shape distribution. \ud83d\udc8e\ud83d\udcc8\n\nTwo methods were combined: sequential orthogonalization and Sobol, a variance-based global sensitivity technique, to address parameter estimability. The framework systematically assessed the quality of two parameter sets\u2014one derived from prior knowledge and the other identified through simultaneous optimization. This integration enhanced parameter reliability and model accuracy.\ud83d\udd04\ud83d\udcca\n\nTo determine the optimal subset of model parameters, an incremental least square optimization procedure was implemented. This process identified a cutoff value for both estimability methods, ensuring the selection of the required optimal subset. Despite the use of noisy aspect ratio data, the implemented methodology demonstrated exceptional performance. \ud83d\udcc8\u2728\n\nKudos to Dimitrios Fysikopoulos, Brahim Benyahia, \u00c1kos Borsos, Zoltan Nagy, and Chris Rielly for proposing this innovative approach! \ud83d\udc4f\n\nLink to #Publication: https:\/\/lnkd.in\/g_6eereU\n\n#CrystallizationProcesses #MathematicalModels #ModelReliability #Innovation #data #complexity #processdevelopment ","linkedinURL":"https:\/\/www.linkedin.com\/feed\/update\/urn:li:activity:7077238737679646720","githubURL":null,"paperURL":null,"author":"Antonio Benedetti","createdDate":"06\/20\/2023"},{"title":"The title is: Tackling Uncertainty Head-On! A Data-Driven Approach for Two-Stage Stochastic Programming.","description":"\ud83c\udf1f Data-driven #Scenario #Generation for #TwoStage #Stochastic #Programming: Tackling Uncertainty Head-On! \ud83e\uddec\ud83d\udd2c\n\nIn the field of life science research, optimization problems are vital for unraveling the complexities of biological systems while also maximising their performance. However, effectively addressing these problems becomes a challenge due to inherent uncertainties in various parameters. \n\nExcitingly, a recent paper by Georgios Bounitsis, et al presents a novel approach that combines mathematical programming and copula-based sampling to tackle uncertainty head-on! \ud83d\udcda\ud83d\udd0d\n\nThe paper introduces a data-driven Mixed-Integer Linear Programming (MILP) model specifically designed for the Distribution and Moment Matching Problem (DMP). The DMP is a critical aspect of stochastic programming, aiming to generate scenarios by matching statistical moments and distributions of uncertain parameters. To handle cases with multiple uncertain parameters, the authors employ a copula-based simulation approach to generate initial scenarios. \ud83d\udcca\ud83d\udd2c\n\nBut that's not all! The authors go above and beyond by integrating clustering methods with the DMP to enhance computational performance. By grouping similar scenarios together, the proposed model reduces complexity and improves the efficiency of the optimization process. \ud83d\udcc8\ud83d\udca1\n\nTo validate their approach, the authors compare it with state-of-the-art scenario generation methodologies. Through comprehensive case studies in the field of Process Systems Engineering (PSE), they evaluate the quality of the generated scenario trees by assessing the resulting stochastic solutions. The results speak for themselves, highlighting the superiority of the proposed method in terms of scenario tree quality and corresponding stochastic solutions. \ud83c\udf33\u2728\n\nKudos to Georgios Bounitsis, Lazaros Papageorgiou, and Vassilis Charitopoulos for their outstanding contributions! Some details of the mathematical approach and the code implemented can be found in the supplementary material \ud83c\udf1f\ud83d\udd2c\n\nLink to Publication: https:\/\/lnkd.in\/enen7p2Y\n\n#Optimization #UncertaintyManagement #StochasticProgramming #DataDrivenApproach #ResearchInnovation ","linkedinURL":"https:\/\/www.linkedin.com\/feed\/update\/urn:li:activity:7076911242799378433","githubURL":null,"paperURL":null,"author":"Antonio Benedetti","createdDate":"06\/20\/2023"},{"title":"The title is: Automated High-Throughput Partition Coefficient Determination","description":"\ud83d\udce2 Automated High-Throughput Partition Coefficient Determination \ud83d\udd2c\n\n\ud83d\udca1Automated High-Throughput Partition Coefficient Determination is crucial for #pharmaceutical Drug Substance process development as it enables rapid and accurate assessment of compound distribution between different phases, aiding in the optimization of reaction workup processes processes and ensuring efficient drug substance manufacturing.\n\n\ud83d\udd0e The article titled \"Automated High-Throughput Partition Coefficient Determination with Image Analysis for Rapid Reaction Workup Process Development and Modelling\" introduces a very interesting approach in DS process development.\u00a0Using an image analysis algorithm and a high-throughput automated workflow, the authors extracted partition coefficient measurements and achieved full mass balance from small-scale samples. Their method showed 95% accuracy in determining the volume of aqueous and organic phases.\n\n\ud83d\udcc8 The automated workflow saved up time compared to traditional methods, while enabling the development of thermodynamic models for liquid-liquid equilibrium process steps using small-scale vessels (8 mL). The optimized process conditions increased product recovery from 88% to an impressive 94% theoretical.\n\n\ud83c\udf1f This research provides actionable insights for process development, risk assessment, and quality by design activities. Supplementary information, including the automated protocol, image analysis optimization results, MATLAB code optimization, and NRTL model parameters, can be found here: https:\/\/lnkd.in\/eHucexpw.\n\n\ud83d\udc4f Let's applaud the outstanding work of Sophie Duffield, Luigi Da Vi\u00e0, Amelia Bellman, and Fabio Chiti! Link to the paper: https:\/\/lnkd.in\/e-7sG9E4\n\n#drugsubstance #Automation #ImageAnalysis #HighThroughput #Modelling","linkedinURL":"https:\/\/www.linkedin.com\/feed\/update\/urn:li:activity:7076548962148573184","githubURL":null,"paperURL":null,"author":"Harry Christodoulou","createdDate":"06\/19\/2023"},{"title":"The title is: Combining DEM Simulations and Spray Experiments to Predict Tablet Coating.","description":"\ud83d\udc8a Tablet coating: Combining detailed DEM simulations and Spray experiments! \ud83c\udf1f\n\nModelling #tablet coating is crucial for the pharmaceutical industry as it enables accurate prediction and optimization of coating outcomes, reducing the need for extensive experimental trials and enhancing manufacturing efficiency. \ud83d\udca1\n\nWe recently came across an intriguing paper on tablet coating: \"Tablet Coating in Lab-Scale Drum Coaters: Combining DEM Simulations and Spray Experiments to Predict Tablet Coating.\" \ud83d\udcda This research sheds light on the vital production step of Tablet Coating in the pharmaceutical industry. By integrating Computational Fluid Dynamics (#cfd ), the Discrete Element Method (#DEM), and the Lagrangian Parcel Concept (#LPC), the authors have developed a novel approach to simulate the entire tablet coating process, eliminating the need for time-consuming lab-scale experiments. \ud83e\uddea\n\nThe study highlights the importance of understanding droplet size and velocity distributions in different spray cross-sections. By utilizing Phase #doppler  Anemometry (PDA), the team efficiently characterized the spray droplet properties generated by the two-fluid spray nozzles. Their findings revealed fascinating dynamics, including droplet break-up in the initial spray region and #coalescence downstream. \n\nThis innovative research holds great promise for the #pharmaceuticalindustry  , enabling accurate prediction of tablet coating outcomes without the need for extensive experimental trials. \ud83d\ude80\n\nCongratulations to the authors: Lars Pasternak, Martin Sommerfeld, Pradeep Muramulla, Fei-Liang Yuan, Srikanth Gopireddy, Nora Urbanetz, and Thomas Profitlich from Multiphase Flow Systems (MPS) and Daiichi Sankyo Europe GmbH! \ud83c\udf89\ud83d\udc4f We believe that this outstanding work will continue to highlight the value of advanced modelling in the field of oral solid dosage pharmaceuticals. \n\nLink to the paper: https:\/\/lnkd.in\/eTZEFAxG \ud83d\udcc4\ud83d\udd17\n\n#TabletCoating #PharmaceuticalResearch #Modelling #Innovation #PharmaIndustry","linkedinURL":"https:\/\/www.linkedin.com\/feed\/update\/urn:li:activity:7076166168746553344","githubURL":null,"paperURL":null,"author":"Harry Christodoulou","createdDate":"06\/18\/2023"},{"title":"The title is: A machine learning approach for protein spray drying.","description":"\ud83d\udcbb A machine learning approach for protein spray drying \ud83d\udda5\ufe0f\n\nProtein spray drying is crucial for the pharmaceutical industry as it enables the development of stable, easily transportable, and long-lasting protein-based formulations, ensuring effective delivery of therapeutic proteins to patients. \n\nWe would like to highlight a recent exciting work from Graz University of Technology, University of Graz and the Research Center Pharmaceutical Engineering GmbH. The study, \"Accelerating Pharmaceutical Process Development: A Novel ML Approach,\" enriches the pharma modelling field with a material-efficient multi-step #machinelearning technique for designing protein #spraydrying processes. \ud83d\udcda\n\nTraditionally, creating a Design Space for Spray Drying proteins involved costly and time-consuming experiments. But Fiedler et al. proposed a game-changing alternative. By using a surrogate material (lactose) and ML, they significantly reduced experimental requirements. Their approach was validated through protein-based runs, achieving high yields and low residual moisture. \ud83d\udca1\n\nThis research demonstrates the potential of Machine Learning to streamline pharmaceutical process development. By incorporating changes in spray dryer setup with minimal additional experiments, the team accelerated the implementation of #QualitybyDesign principles. Their work has far-reaching implications for optimizing pharmaceutical processes while maintaining critical quality attributes. \ud83d\udcca\n\nCongratulations to Daniela Fiedler, Elisabeth Fink, Isabella Aigner, Gerd Leitinger, Walter Keller, Eva Roblegg, and Johannes Khinast for their outstanding contribution to the field! \ud83c\udf89\ud83c\udf1f\n\nLink to the paper:  https:\/\/lnkd.in\/eVz3bph2\n\n#ProcessDevelopment #MachineLearning #Pharmaceuticals #QualitybyDesign #SprayDrying","linkedinURL":"https:\/\/www.linkedin.com\/feed\/update\/urn:li:activity:7075842944842227713","githubURL":null,"paperURL":null,"author":"Harry Christodoulou","createdDate":"06\/17\/2023"},{"title":"The title is: The Power of Global Sensitivity Analysis in Modeling: A Case Study from Energy System Models.","description":"The Power of #Global #Sensitivity #Analysis in Modeling: A Case Study from #Energy #System #Models \ud83d\udd2c\ud83d\udcca\n\n\ud83d\udd2c Global sensitivity analysis (GSA) is a powerful technique used by modelers to understand the influence of input parameters on model outputs. It helps identify the most important factors driving system behavior and guides decision-making processes. \u2728\n\n\ud83d\udcda This recent paper from Maria Yliruka et al. explores the importance of considering model detail and uncertainty in energy systems modeling. The authors propose a novel method that quantitatively compares the impact of model detail and uncertainty, aiding in model development and the allocation of computational resources. \ud83c\udf1f\n\n\ud83d\udd0d The method treats modeling choices as additional \"uncertain\" parameters within a global sensitivity analysis framework. By conducting a case study on a heat decarbonization model for the United Kingdom, the authors focus on assessing the importance of spatial resolution in the model's outcomes. \ud83c\udf0d\n\n\ud83d\udcc8 The findings highlight the significance of spatial resolution in determining the capacities of electricity, gas, and heat networks, despite its negligible impact on the optimal total system cost. This emphasizes the importance of considering spatial resolution when designing and optimizing these networks for effective heat decarbonization strategies. \ud83d\udca1\n\n\ud83d\udca1 This research demonstrates the power of global sensitivity analysis in guiding model development and resource allocation. By incorporating modeling choices as uncertain parameters, modellers can quantitatively assess their impact and make informed decisions on system design. \ud83c\udf1f\n\n\ud83d\udcc4 The paper is accessible as #openaccess. Additionally, the authors utilized a Matlab script for conducting the global sensitivity analysis, which was obtained from Khare and Munoz-Carpena, 2014. This script can serve as a valuable resource for those interested in implementing GSA in their own modeling work. (links in the comments) \ud83d\udd17\n\n\ud83c\udf89 Congratulations to Maria Yliruka, Stefano Moret, PhD, and Nilay Shah on this remarkable example of global sensitivity analysis in energy systems modeling! \ud83e\udd73\n\n#GlobalSensitivityAnalysis #ModelDevelopment #DecisionMaking #Optimization #ModelingInsight","linkedinURL":"https:\/\/www.linkedin.com\/feed\/update\/urn:li:activity:7075432872362291200","githubURL":null,"paperURL":null,"author":"Antonio Benedetti","createdDate":"06\/16\/2023"},{"title":"The title is: PharmaPy Does it Again! \ud83d\ude80","description":"#PharmaPy Does it Again! \ud83d\ude80\n\nExciting news in the world of pharma manufacturing #modelling ! \nThe open-source package #PharmaPy has been used to perform a Techno-economic Analysis of dynamic, end-to-end optimal pharmaceutical campaign manufacturing. \ud83d\udcca \n\nCheck out the recent paper by Daniel Casas-Orozco, Ph.D. et al. which addresses the feasibility of batch, hybrid, and continuous manufacturing approaches for small-scale production of an active pharmaceutical ingredient (#API). \ud83e\uddea The team's findings highlight the advantages of the hybrid operating mode, which combines continuous reactors and semi-batch vaporization equipment for intermediate and large production targets. \ud83c\udfaf\n\nAs a community, let's emphasize the value of systematic #digital  evaluation tools like PharmaPy in identifying optimal process configurations while considering technical and economic factors. This work sheds light on the challenges of continuous pharma manufacturing, such as long stabilization times for continuous #crystallization and #thermodynamic  limitations of flash #vaporization, leading to increased costs. \ud83d\udca1\n\nLet's recognize the dedication and achievements of Daniel Casas-Orozco, Ph.D. , Daniel Laky, Vivian Wang, Mesfin Abdi, Xin Feng, Erin Wood, Rex Reklaitis, and Zoltan Nagy, the developers behind PharmaPy and authors of the paper: \"Techno-economic analysis of dynamic, end-to-end optimal pharmaceutical campaign manufacturing using PharmaPy\". \ud83d\ude4c Their contributions in advancing pharmaceutical manufacturing processes through comprehensive analysis and open-source solutions are impressive. This type of work by modelers paves the way for more efficient and cost-effective #pharmaceutical manufacturing processes, ultimately benefiting patients worldwide. \ud83c\udf0d\n\nLink to the paper: https:\/\/lnkd.in\/e6iQyhe7\n\n#PharmaPy #PharmaceuticalManufacturing #ContinuousManufacturing #Research #ProcessOptimization","linkedinURL":"https:\/\/www.linkedin.com\/feed\/update\/urn:li:activity:7075105922867421184","githubURL":null,"paperURL":null,"author":"Harry Christodoulou","createdDate":"06\/15\/2023"},{"title":"The title is: Lethe-DEM: Open-Source Parallel DEM Solver for Granular Material Simulation","description":"\ud83d\udda5\ufe0f Introducing Lethe-DEM: Open-Source Parallel DEM Solver for Granular Material Simulation! \ud83d\udcbb\n\nDiscrete Element Method (#DEM) is of great importance in the pharmaceutical industry as it allows for accurate modelling and simulation of particulate systems, enabling optimization of drug formulations and manufacturing processes. DEM provides valuable insights into #powder  flow, #mixing , #granulation , and other critical factors, contributing to the development of safe and effective #pharmaceutical products.\n\nOn that note, we recently encountered Lethe-DEM, an #opensource  parallel DEM solver which we think can be a valuable tool in the hands of modellers across modalities in the #lifesciences industry \ud83e\uddea. \n\nLethe-DEM can be used to gain advanced insights into particle-scale phenomena, making it a valuable tool for pharma modellers. By tracking the motion and contact of individual particles, Lethe-DEM provides detailed simulations for optimizing processes and enhancing efficiency in the pharma #drugproduct modality, where granular materials constitute a significant portion of raw materials and products.\n\nOne key advantage of the tool lies in its parallel efficiency, achieved through load balancing techniques. This optimization, resulting from the expertise of the development team, leads to computational improvements. Scalability is a priority for Lethe-DEM, and the developers have analysed its performance through strong and weak scaling tests. This ensures Lethe-DEM's ability to handle large-scale simulations effectively. For instance, Lethe-DEM successfully simulated a three-dimensional cylindrical silo with an impressive 4.3 million particles distributed across 320 cores.\n\nThe developers have already conducted thorough validations, comparing Lethe-DEM with existing software and real-world experiments, including flat-bottomed silos, wedge-shaped silos, and rotating drums!\ud83c\udfaf\n\nWe commend the outstanding work of Shahab Golshan, Peter Munch, Rene Gassmoller, Martin Kronbichler, and Bruno Blais in developing Lethe-DEM and offering a practical solution for the industry. \n\nDocumentation: https:\/\/lnkd.in\/ep6SJVyC\nGitHub: https:\/\/lnkd.in\/eyFk_wRc\nArticle: https:\/\/lnkd.in\/eRgYm2cm\u00a0 \n\n\u00a0#GranularMaterialSimulation #OpenSourceSoftware #ChemicalIndustry #Efficiency #Optimization # Pharma","linkedinURL":"https:\/\/www.linkedin.com\/feed\/update\/urn:li:activity:7074745256071553024","githubURL":null,"paperURL":null,"author":"Harry Christodoulou","createdDate":"06\/14\/2023"},{"title":"The title is: Liesel: A Powerful Probabilistic Programming Framework for Semi-parametric Regression","description":"\ud83c\udf1f Introducing #Liesel: A Powerful #Probabilistic #Programming #Framework for #SemiParametric #Regression \ud83c\udf1f\n\nSemi-parametric regression combines the flexibility of nonparametric methods with the interpretability of parametric models, offering a versatile approach to modeling complex relationships. By incorporating both parametric and nonparametric components, this technique captures linear or known functional relationships while also accommodating intricate, potentially nonlinear patterns in the data. \nToday, we are thrilled to share #Liesel, a probabilistic programming framework  focused on semi-parametric regression. Liesel empowers researchers with a comprehensive suite of tools and libraries, enabling efficient and reliable statistical research on complex models and estimation algorithms.\nAt its core, Liesel comprises a graph-based model building library and a flexible Markov chain Monte Carlo (MCMC) library, both implemented in Python. In addition, Liesel offers RLiesel, an intuitive R interface for configuring semi-parametric regression models. The true strength of Liesel lies in its modular design, allowing researchers to seamlessly leverage each component independently or integrate them with third-party model implementations.\nLet's explore some of Liesel's key features:\n\ud83d\udd39 Graph-based Model Building: Construct model graphs using pre-implemented building blocks, seamlessly incorporating new research ideas.\n\ud83d\udd39 Markov Chain Monte Carlo (MCMC): Effortlessly combine kernels and choose from various MCMC procedures, including advanced algorithms like NUTS.\n\ud83d\udd39 Chain Post-processing and Diagnostics: Gain valuable insights into convergence, mixing, and performance with comprehensive tools.\n\ud83d\udd39 JAX Integration: Leverage JAX for automatic differentiation, JIT compilation, and high-performance computing for efficient statistical analysis.\n\nA special acknowledgement goes to Paul Wiemann, Hannes Riebl, and all the contributors for their exceptional work on this #opensource package!  \ud83d\udcc8\ud83d\udca1\n\nLink to #Github: https:\/\/lnkd.in\/eqHTS8XV\nLink to #Paper: https:\/\/lnkd.in\/eviyaw9P\nLink to #Documentation: https:\/\/lnkd.in\/eWTaXCNi\n\n#Liesel #ProbabilisticProgramming #SemiParametricRegression #StatisticalModels #MachineLearning #DataScience #Python #Research #Development #algorithms ","linkedinURL":"https:\/\/www.linkedin.com\/feed\/update\/urn:li:activity:7074339634255650816","githubURL":null,"paperURL":null,"author":"Antonio Benedetti","createdDate":"06\/10\/2023"},{"title":"The title is: MultivariateStats.jl - Your Ultimate Multivariate Analysis Toolkit in Julia!","description":"\ud83d\udd2c Introducing #MultivariateStats.jl: Your Ultimate #Multivariate #Analysis Toolkit in #Julia! \ud83d\udd2c\n\nMultivariate analysis is a statistical technique that involves the simultaneous analysis of multiple variables to understand the relationships and patterns that exist among them. In life science applications, where the complexity of biological systems often involves interactions among numerous factors, multivariate analysis plays a crucial role in uncovering meaningful insights and extracting valuable information from complex datasets.\n\nToday we want to introduce you to MultivariateStats.jl, the ultimate Julia package for multivariate statistics and data analysis.This cutting-edge Julia package empowers you to uncover hidden patterns, explore correlations, and extract valuable information from intricate datasets.\n\ud83e\uddea Discover the Key Functionalities:\nMultivariateStats.jl offers a wide range of powerful functionalities, including:\n\u2705 Linear Least Square Regression\n\u2705 Ridge Regression\n\u2705 Isotonic Regression\n\u2705 Data Whitening\n\u2705 Principal Components Analysis (PCA)\n\u2705 Canonical Correlation Analysis (CCA)\n\u2705 Classical Multidimensional Scaling (MDS)\n\u2705 Metric Multidimensional Scaling (mMDS)\n\u2705 Linear Discriminant Analysis (LDA)\n\u2705 Multi-class LDA\n\u2705 Independent Component Analysis (FastICA)\n\u2705 Probabilistic PCA\n\u2705 Factor Analysis\n\u2705 Kernel PCA\n\ud83d\ude80 But that's not all! MultivariateStats.jl has a dynamic roadmap for the future. The package is continuously evolving to incorporate state-of-the-art techniques, expanding your multivariate analysis capabilities. Future plans include:\n\ud83d\udd1c Partial Least Square (PLS)\n\ud83d\udd1c Other algorithms for ICA (e.g., JADE)\n\nWith MultivariateStats.jl,  you can unlock the full potential of multivariate analysis, gaining deeper insights, detecting patterns, and making informed decisions based on complex datasets. From genetics and genomics to ecology and environmental sciences, this package opens doors to groundbreaking discoveries and advancements across various life science domains.\n\nKudos to Dahua Lin and contributors to build this great capabilities in #Julia #opensource environment!\n\nLink to #Github: https:\/\/lnkd.in\/eUqgUHnA\nLink to #Documentation: https:\/\/lnkd.in\/etVsxadi\n\n\n#MultivariateAnalysis #algorithms #DataAnalysis #LifeSciences #JuliaPackage #Statistics #ResearchTools","linkedinURL":"https:\/\/www.linkedin.com\/feed\/update\/urn:li:activity:7073977244519411712","githubURL":null,"paperURL":null,"author":"Antonio Benedetti","createdDate":"06\/10\/2023"},{"title":"The title is: \"Next-Generation Methodology Harnessing Data Lakes, Natural Language Generation, and Advanced Data Analytics for Cell Line Development\"","description":"Transforming #Cell #Line #Selection: Next-Generation Methodology Harnessing #Data Lakes, #Natural #Language Generation, and #Advanced #Data #Analytics \ud83c\udf10\ud83d\udd2c\ud83e\udda0\n\nCell line development plays a pivotal role in biopharmaceutical advancement, often positioned on the critical path. The failure to fully characterize the lead clone during initial screening can lead to project delays during scale-up, potentially compromising commercial manufacturing success. \ud83e\uddeb\n\nA recent study by Stephen Goldrick et al across UCL and AstraZeneca proposes an innovative methodology called CLD4, which comprises four distinct steps for autonomous data-driven selection of the lead clone. \n1\ufe0f\u20e3The first step involves digitizing the process and storing all available information within a structured data lake. This facilitates comprehensive analysis and exploration.\n2\ufe0f\u20e3In the second step, a new metric called the cell line manufacturability index (MICL) is introduced. It quantifies the performance of each clone based on criteria relevant to productivity, growth, and product quality. This metric enables accurate evaluation of the clones.\n3\ufe0f\u20e3To identify potential risks associated with process operation and critical quality attributes (CQAs), the third step incorporates machine learning (ML). By leveraging ML algorithms, hidden patterns and insights can be uncovered, enabling proactive risk mitigation.\n4\ufe0f\u20e3The final step of CLD4 utilizes available metadata and summarizes the relevant statistics generated in the preceding steps. This is accomplished through an automated report, generated using a natural language generation (NLG) algorithm. The report simplifies communication and facilitates informed decision-making.\n\nThe effectiveness of CLD4 was demonstrated in the selection of a lead clone from a recombinant Chinese hamster ovary (CHO) cell line. The CHO cell line produced high levels of an antibody-peptide fusion, but encountered a known product quality issue related to end-point trisulfide bond (TSB) concentration. CLD4 successfully identified sub-optimal process conditions leading to increased TSB levels, which would have been overlooked by conventional cell line development methodologies.\n\nCLD4 embraces the core principles of Industry 4.0, showcasing the benefits of increased digitalization, integration of data lakes, predictive analytics, and autonomous report generation. These advancements enable more informed decision-making and hold immense potential for optimizing cell line development processes in the biopharmaceutical industry.\n\nCongratulations to Stephen Goldrick, Haneen Alosert, Clare Lovelady, Nick Bond, Tarik Senussi, Diane H., John Klein, Matthew Cheeks PhD, MBA, Richard Turner OBE,\u00a0James Savery\u00a0and\u00a0Suzanne Farid for this tremendous piece of work!\n\n\ud83d\udd17Link to #Publication: https:\/\/lnkd.in\/e8YgrVfQ\n \n#CellLineDevelopment #Biopharmaceuticals #CLD4 #DataDriven #DecisionMaking #Industry40 #DigitalTransformation","linkedinURL":"https:\/\/www.linkedin.com\/feed\/update\/urn:li:activity:7073643754699546624","githubURL":null,"paperURL":null,"author":"Antonio Benedetti","createdDate":"06\/11\/2023"},{"title":"The title is: In-Silico Modeling of a Commercial Biopharmaceutical Downstream Process.","description":"End-to-End #Mechanistic Process #Modeling to In-Silico #Simulate a Commercial #Biopharmaceutical #Downstream #Process\ud83e\udda0\ud83d\udcbb\ud83d\udc89\ud83d\udca1\n\nChromatography and filtration processes are vital in biopharmaceutical downstream manufacturing. They play a crucial role in purifying and separating target biopharmaceutical molecules from complex mixtures, ensuring high product quality and purity. These processes remove impurities and contaminants, meet regulatory standards, and contribute to process efficiency, yield, and consistent product quality. \ud83d\udc69\u200d\ud83d\udd2c\ud83d\udc68\u200d\ud83d\udd2c\n\nWe are excited to share the findings of a recent study that demonstrates the significant contributions of mechanistic modeling to our understanding of chromatography and filtration processes. In this study, a novel approach was taken by connecting mechanistic models to describe an entire downstream process for a Fab fragment throw flowsheet modelling. \ud83d\ude80\n\nFor the capture step, a transport-dispersion model (TDM) combined with an extended Langmuir isotherm was applied. Depth filtration was modeled with a combined pore blocking model. The polishing ion exchange chromatography steps were described by a TDM combined with the colloidal particle adsorption model. The tangential flow filtration model accounts for both the Donnan effects and flow limitations. \ud83d\udca1\n\nImportantly, the presented downstream process model accurately predicted online and offline data recorded at a 12,000 L manufacturing scale. Process variations from 23 manufacturing batches were adequately reproduced by the model, even considering input process parameter variations. \n\nBy optimizing chromatography and filtration with in-silico modeling approaches, biopharmaceutical companies can deliver safe, effective, and compliant products to patients while enhancing productivity and scalability.\n\nA big round of applause and kudos to Federico Rischawy, Till Briskot, Nathalie Hopf, David Saleh, Gang Wang, Simon Kluters, Joey Studts, and J\u00fcrgen Hubbuch for this great piece of work!\ud83d\udc4f\n\n\ud83d\udcc4\ud83d\udca1Link to #Publication: https:\/\/lnkd.in\/ezuMyDkF\n\n#DownstreamProcessModeling #Biopharmaceuticals #InSilicoSimulations #ScientificResearch #Innovation #manufacturing \n","linkedinURL":"https:\/\/www.linkedin.com\/feed\/update\/urn:li:activity:7073313648110137344","githubURL":null,"paperURL":null,"author":"Antonio Benedetti","createdDate":"06\/10\/2023"},{"title":"The title is: Solubility Models for Solvent Selection","description":"\ud83d\udcbb Solubility Models for Solvent Selection \u2705\n\n#Solubility models for solvent selection play a crucial role in the #pharmaceutical industry as they enable researchers to make informed decisions about solvents, ultimately enhancing the development of drug synthesis and formulation processes by optimizing #Yield, impurity rejections, and overall #efficiency . \ud83d\udc8a\n\nOn this important topic, we would like to highlight an insightful paper titled \"Solubility Model to Guide Solvent Selection in Synthetic Process Development\" by Michael Lovette. The article addresses a crucial aspect of crystallization processes for synthetic chemicals: the selection of suitable #solvents  to achieve high yield and impurity rejection.\n\nTo determine solubilities in various solvents and solvent combinations, Lovette developed a model specifically designed for single solvent systems. The model's parameters were trained and fine-tuned, and its performance was validated using a dataset of approximately 500 solubility measurements across different solutes and solvents. \ud83d\udcc8\n\nThrough rigorous training, tuning, and validation, the model successfully captures the solvent landscape and provides performance expectations for solubility predictions based on the number of measurements per solute. The model's cross-validation predictions demonstrate unbiased and accurate results. \n\nFor those interested in diving deeper into the research, the supporting information, including interactive HTML files with the model's source code and results, is available at: https:\/\/lnkd.in\/eqyCyUxP. \ud83d\udcd6\ud83d\udd17\n\nCongratulations to Michael A. Lovette for this important contribution! \n\n#SolubilityModel #SolventSelection #ProcessDevelopment #Crystallization #ChemicalSynthesis","linkedinURL":"https:\/\/www.linkedin.com\/feed\/update\/urn:li:activity:7072973686802149376","githubURL":null,"paperURL":null,"author":"Harry Christodoulou","createdDate":"06\/09\/2023"},{"title":"The title is: Exciting Advances in Microbial Co-Culture Control with Deep Reinforcement Learning!","description":"\ud83d\udd2c Exciting Advances in #Microbial #CoCulture #Control with #Deep #Reinforcement #Learning! \ud83e\udda0\ud83e\uddeb\ud83d\udcbb\n\nMicrobial co-cultures, with their enhanced productivity and reduced metabolic burden, hold great promise for bioprocessing. However, their implementation has been challenging due to the complexities of controlling constituent species.\n\nIn this study by Neythen Treloar et al, the researchers applied cutting-edge techniques from AI, specifically deep reinforcement learning combined with neural networks, to overcome the control complexities of microbial co-cultures. By training a reinforcement learning agent and utilizing feedback mechanisms, they successfully achieved and maintained target population levels. The model-free (or mechanism-free) nature of this approach makes it versatile and widely applicable for applications where the experimental resources are not a constrain.\nWhat's truly remarkable is that the researchers also demonstrated how reinforcement learning can optimize the output of co-culture bioprocesses directly. Moreover, their findings showed that model-free performance with bang-bang control outperformed traditional proportional integral controllers, particularly in scenarios with infrequent sampling.\n\nThis study highlights the growing role of AI in synthetic biology and industrial bioprocessing, with reinforcement learning emerging as a promising technique for optimizing and controlling complex processes.\n\n\ud83d\udc4f Kudos to Neythen Treloar, Alex J H Fedorec, Brian Ingalls, and Chris Barnes for this great piece of work and for their commitment to open science by making the data and code available as #opensource! \ud83d\ude4c\n\nTo explore their research further, check out the links below:\n\ud83d\udd17 Link to #GitHub: https:\/\/lnkd.in\/edZbddXZ \n\ud83d\udd17 Link to #Publication: https:\/\/lnkd.in\/expyf9Tr\n\n\n#ArtificialIntelligence #MicrobialCoCultures #Bioprocessing #SyntheticBiology #ReinforcementLearning #Innovation #Research #Science #Biomanufacturing\n","linkedinURL":"https:\/\/www.linkedin.com\/feed\/update\/urn:li:activity:7072562084047151105","githubURL":null,"paperURL":null,"author":"Antonio Benedetti","createdDate":"06\/08\/2023"},{"title":"The title is: NLsolve.jl: Solving Nonlinear Equations in Julia \ud83d\ude80","description":"\ud83d\udd22 NLsolve.jl: Solving Nonlinear Equations in Julia \ud83d\ude80\n\nIf you're in search of a package to tackle systems of #nonlinear  equations and mixed complementarity problems, then definitely consider NLsolve.jl. This package offers an array of solvers tailored to meet your needs, making it a popular choice among #julialang  users in the #pharmaceutical  industry and other fields. \ud83d\udd2c\n\nThe tool offers versatile solver selection: Benefit from a rich selection of solvers, including Newton's method, Broyden's method, and others, allowing you to employ the most suitable approach for your problem. \ud83d\udcaa\n\nNLsolve.jl is not only powerful, but it also offers a user-friendly experience. It boasts a straightforward API, making it easier to incorporate into our workflows. Say goodbye to steep learning curves, and hello to efficient problem-solving. \ud83c\udfaf\u2728\n\nIf you're seeking a reliable, feature-rich package for nonlinear equations and mixed complementarity problems, NLsolve.jl is a great choice. \ud83c\udf1f\n\nKudos to all the developers: Patrick Kofod Mogensen, Kristoffer Carlsson, S\u00e9bastien Villemot, Spencer Lyon, Matthieu Gomez, Christopher Rackauckas, Tim Holy, David Widmann, Tony Kelman, Daniel Karrasch, Antoine Levitt, Asbj\u00f8rn Nilsen Riseth, Carlo Lucibello, Changhyun Kwon, David Barton, Julia TagBot, Mateusz Baran, Miles Lubin, Sarthak Choudhury, Simon Byrne, Simon Christ, Takafumi Arakaki, Troels Arnfred Bojesen, Miguel Raz Guzm\u00e1n Macedo \ud83d\udc4f and contributors!\n\nDiscover more about NLsolve.jl: https:\/\/lnkd.in\/eTZvEbhR\n\n#JuliaProgramming #NonlinearEquations #ComplementarityProblems #ProblemSolving  \ud83d\udcbb","linkedinURL":"https:\/\/www.linkedin.com\/feed\/update\/urn:li:activity:7072221479156736001","githubURL":null,"paperURL":null,"author":"Harry Christodoulou","createdDate":"06\/07\/2023"},{"title":"The title is: cYield: A tool for the characterization of the bulk flow properties of industrial powders","description":"\ud83c\udf1f cYield: A tool for the characterization of the bulk flow properties of industrial powders \ud83c\udf1f\n\nWe recently came across the interesting work conducted by a team of researchers from UCL Chemical Engineering and Universit\u00e0 degli Studi di Salerno in the field of bulk flow properties analysis. The authors introduce a tool called \"cYield\", developed using MATLAB's App Developer environment.\n\nThe team has made a significant contribution to the field by presenting a clever approach for the evaluation of flow properties in compacted #powders . Note that the proposed approach does not mandate the contact point between the yield locus and the major Mohr circle to coincide with the pre-shear representing point. This divergence from previous approaches demonstrates that innovative thinking makes the most useful tools. \u2728\ud83d\udd2c\n\nThe cYield app, available on #github , offers researchers and engineers an interactive platform to analyse shear data, calculate yield loci, and derive essential bulk flow properties such as principal stresses, cohesion, and angle of friction. This user-friendly tool also provides statistical information and allows for the comparison of different approaches, empowering users to make informed decisions based on reliable data. \ud83d\udcca\ud83d\udd0d\n\nWe extend our sincere congratulations to the authors of the article and developers of cYield: Domenico Macr\u00ec, Roberto Chirone, Hamid Salehi, Daniele Sofia, Massimiliano Materazzi, Diego Barletta, Paola Lettieri FREng, and Massimo Poletto. \ud83c\udf89\ud83d\udc4f\n\nTo learn more about their work, we encourage you to read the full article on: https:\/\/lnkd.in\/ehtVcaic.\n\nDon't forget to check out the cYield app on GitHub to experience it first-hand: https:\/\/lnkd.in\/ezgkShS6\n\n#BulkFlowProperties  #PowderAnalysis #MaterialsScience","linkedinURL":"https:\/\/www.linkedin.com\/feed\/update\/urn:li:activity:7071847112304422912","githubURL":null,"paperURL":null,"author":"Harry Christodoulou","createdDate":"06\/06\/2023"},{"title":"The title is: LaTeXify: Effortless Conversion for Scientific Work!","description":"\ud83d\udd0d\ud83d\udcbb No More #Equation #Formatting with #LaTeXify: Effortless Conversion for Scientific Work! \ud83d\udcdd\u2728\n\nHave you ever found yourself facing the daunting task of documenting your extensive modeling work into a report? The familiar feeling of a cold sweat creeping in might ring a bell. Fear not, for there's a game-changing solution: LaTeXify!\n\nLaTeXify, developed by Google, is a powerful tool that seamlessly converts your Python code into stunning LaTeX equations or expressions. Whether you're tackling complex mathematical models, analyzing data, or documenting your findings, LaTeXify streamlines the process of presenting your work in the elegant and professional format that LaTeX provides.\n\nJust imagine the impact of effortlessly generating publication-quality LaTeX equations directly from your Python scripts. With LaTeXify, you can unlock a whole new level of professionalism and visual appeal for your scientific work. \ud83c\udf1f\ud83d\udcbb\n\nLaTeXify offers an array of compelling features that make it the ultimate tool for scientists and researchers. Firstly, it provides effortless conversion, allowing you to transform your Python mathematical expressions into LaTeX format with remarkable ease, even if you have no prior LaTeX knowledge. Additionally, LaTeXify handles complex expressions automatically, ensuring that your equations are not only accurate but also visually appealing, thereby enhancing the overall readability of your scientific work.\n\nOne of the standout features of LaTeXify is its seamless integration between Python and LaTeX. This remarkable capability enables you to effortlessly incorporate the mathematical expressions generated from your Python code into various scientific papers, presentations, and technical documents. Say goodbye to the tedious process of manual equation formatting!\n\nTime is precious, especially when conducting research. That's why LaTeXify is also a valuable time-saving tool. It eliminates the hassle of manually formatting equations, freeing up your valuable time to focus on the core aspects of your research and accelerate your productivity.\n\n\ud83d\udc49Link to #Github : https:\/\/lnkd.in\/eszguxsR\n\ud83d\udc49Link to #Documentation: https:\/\/lnkd.in\/erzMjTMf\n\n#LaTeXify #Python #LaTeX #ScientificResearch #MathematicalEquations #DataAnalysis #PublicationQuality #ProductivityTools","linkedinURL":"https:\/\/www.linkedin.com\/feed\/update\/urn:li:activity:7071470827115814912","githubURL":null,"paperURL":null,"author":"Antonio Benedetti","createdDate":"06\/05\/2023"},{"title":"The title is: Accelerating #Bioprocess Characterization: Advancements in #iDoE and #Hybrid #Modeling","description":"\ud83d\udd2c\ud83e\udda0Accelerating #Bioprocess Characterization: Advancements in #iDoE and #Hybrid #Modeling \ud83d\udcbb\ud83d\udcc8\n\nThe concept of intensified design of experiments (iDoE) combined with hybrid modeling is emerging as a promising approach to overcome the limitations of traditional methods and efficiently explore design spaces.\n\nIn the biopharmaceutical industry, process characterization traditionally relied on design of experiments (DoE) and process modeling, which often required a significant number of time-consuming and resource-intensive experiments. iDoE overcomes this challenge by incorporating intra-experimental shifts of critical process parameters (CPP), enabling rapid screening of the design space.\n\nIn a recent study by Benjamin Bayer et al., the advantages of this approach were demonstrated using Escherichia coli (E. coli) fed-batch cultivations producing recombinant human superoxide dismutase. Hybrid models trained on iDoE data outperformed models trained on a fractional-factorial design without intra-experimental shifts. The iDoE hybrid model accurately described biomass concentration and product titer for the full-factorial design, surpassing the accuracy of the fractional-factorial approach. Remarkably, the intensified hybrid model required only one-third of the data for model training, significantly reducing experimental effort.\n\nThe hybrid model trained on iDoE data accurately described the biomass concentration and product titer at each time point for the full-factorial design, surpassing the accuracy of the fractional-factorial approach. Additionally, the intensified hybrid model required only one-third of the data for model training compared to the full-factorial approach, resulting in a significant reduction in experimental effort.\n\nThis combination of iDoE and hybrid modeling presents an opportunity to accelerate bioprocess characterization and optimize productivity in the biopharmaceutical industry. By efficiently exploring the design space and accurately predicting outcomes with fewer experiments, this approach can potentially reduce costs and shorten the time required to bring life-saving therapeutics to market.\n\nCongratulations to Benjamin Bayer, Gerald Striedner, and Mark Duerkop on their remarkable contribution to this innovative approach.\n\nLink to #Publication: https:\/\/lnkd.in\/eKUwZJKn\n\n#Biopharmaceuticals #ProcessCharacterization #iDoE #HybridModeling #BioprocessOptimization #Biotechnology #Innovation ","linkedinURL":"https:\/\/www.linkedin.com\/feed\/update\/urn:li:activity:7071124303185895424","githubURL":null,"paperURL":null,"author":"Antonio Benedetti","createdDate":"06\/04\/2023"},{"title":"The title is: Advancing #ControlOriented #Modeling for Optimal Quality in Continuous Pharmaceutical Production: Insights from #TwinScrew #Granulation in ConsiGma\u2122","description":"Advancing #ControlOriented #Modeling for Optimal Quality in Continuous Pharmaceutical Production: Insights from #TwinScrew #Granulation in ConsiGma\u2122\ufe0f-25 \ud83d\udca1\ud83d\udd2c\ud83d\udcca\ud83d\udcbb\n\nContinuous OSD manufacturing has revolutionized the manufacturing paradigm of the pharmaceutical industry, offering seamless tablet production, enhanced process control, and real-time monitoring. It's time to dive deeper into the transformative potential of this cutting-edge technology!\n\n\ud83d\udd0d\ud83d\udd2c\ud83d\udcca In a recent paper by Selma Celikovic et al, effective methods for real-time monitoring and control-oriented modeling of a continuous granulator are proposed. By employing an in-line Process Analytical Technology (PAT) probe based on spatial velocimetry, they monitor the PSD of wet granules and extract valuable insights through an algorithmic evaluation.\n\n \ud83d\udca1\ud83e\udd16The research leverages the local linear model tree (LoLiMoT) approach to create a dynamic process model that predicts PSD characteristics based on granulation parameters. This facilitates process optimization through systematically designed excitation runs and comprehensive data collection, which are rigorously examined and verified.\n\n\ud83d\udd2c\ud83d\udc8e Furthermore, the integration of an in-line PAT probe based on Raman spectroscopy after the granulator allows for the evaluation of API and liquid content of wet granules using chemometric modeling. Through the development and validation of chemometric models using distinct experimental data sets, advanced quality-by-design control concepts, including PSD process control, can be established.\n\n\ud83d\ude80\ud83d\udcc8 By implementing these control-oriented modeling techniques and real-time monitoring approaches, the performance of the ConsiGmaTM-25 process can be significantly enhanced. Robustness against disturbances can be improved, while the quality of intermediate and final products can be optimized.\n\n\ud83c\udf89\ud83d\udc4f A big round of applause for the talented authors Selma Celikovic, Johannes Poms, Johannes Khinast, Martin Horn, and Jakob Rehrl for sharing this remarkable combination of modeling and PAT solutions! Together, they tackle one of the biggest challenges in continuous wet granulation. \n\n\ud83d\udd17\ud83d\udcd1 Read the full research paper here: https:\/\/lnkd.in\/eYw7gPyK\n\n#PharmaceuticalIndustry #ContinuousManufacturing  #ProcessOptimization #ResearchPaper #Innovation #QualityByDesign","linkedinURL":"https:\/\/www.linkedin.com\/feed\/update\/urn:li:activity:7070749046885249026","githubURL":null,"paperURL":null,"author":"Antonio Benedetti","createdDate":"06\/03\/2023"},{"title":"The title is: Unlocking Efficiency: #Differential #Equation #Solutions with DifferentialEquations.jl in #Julia","description":"Unlocking Efficiency: #Differential #Equation #Solutions with DifferentialEquations.jl in #Julia \ud83d\udd13\ud83d\ude80\ud83d\udca1\ud83e\uddee\n\nSolving differential equations is vital in advancing life science research. Mathematical modeling of complex biological processes empowers scientists to uncover the mysteries of living systems. Today, we introduce you to a game-changing tool: #DifferentialEquations.jl, an exceptional Julia package developed by Chris Rackauckas, Qing Nie, and their team. \ud83c\udf1f\n\nDifferentialEquations.jl covers a broad range of differential equation types: discrete equations, ODEs, SDEs, algebraic differential equations, DDEs, hybrid equations, jump diffusions, and (S)PDEs. Leveraging multiple dispatch, metaprogramming, plot recipes, FFI, and call-overloading, this package offers a unified interface for solving and analyzing differential equations without sacrificing performance. It supports modern features like high-precision computations and arithmetic with physical units.\n\nBuilt-in multithreading and parallelism optimize efficiency, while symbolic Jacobian calculations simplify complex equations. The package includes an algorithm testing and benchmarking suite, ensuring accuracy and supporting researchers in developing and sharing their methods. DifferentialEquations.jl is highly extensible, feature-rich, and delivers exceptional performance.\n\nLink to #Github: https:\/\/lnkd.in\/eNn3f9c7 \nLink to #Documentation: https:\/\/lnkd.in\/emyh2NXv\n\n#LifeScienceResearch #DifferentialEquations #ScientificComputing #JuliaLang #DataDrivenDiscovery ","linkedinURL":"https:\/\/www.linkedin.com\/feed\/update\/urn:li:activity:7070396252596654081","githubURL":null,"paperURL":null,"author":"Antonio Benedetti","createdDate":"06\/02\/2023"},{"title":"The title is: PyOD - A Comprehensive Outlier Detection Toolbox!","description":"\ud83d\udd0d #PyOD - A Comprehensive #Outlier #Detection Toolbox! \ud83d\udd0d\n\nOutlier detection, also known as anomaly detection, plays a crucial role in various life science applications by identifying rare items, events, or observations that deviate from the general distribution of a population. In fields that process substantial amounts of unlabelled data and require reliable pattern recognition, dedicated outlier detection algorithms provide immense value. \ud83e\uddec\n\nToday we want to introduce #PyOD, an #opensource #Python toolbox designed for outlier detection on multivariate data! \ud83c\udf89\nPyOD offers an extensive collection of over 40 outlier detection algorithms, including established methods like LOF and state-of-the-art approaches like ECOD. Whether you are a practitioner or a researcher, PyOD provides a unified API and well-documented documentation to facilitate seamless exploration and implementation of various algorithms. \ud83d\udcca\n\nPyOD focuses on robustness, scalability, and best practices. It incorporates essential elements such as unit testing, continuous integration, code coverage, and maintainability checks to ensure reliable results. The toolbox also utilizes JIT and parallelization techniques for optimized performance, enabling faster training and prediction times. \ud83d\udcaa\n\nWith a remarkable track record of over 10 million downloads, PyOD has been widely adopted in both academic research and commercial products. It has received recognition from esteemed platforms such as Analytics Vidhya, KDnuggets, and Towards Data Science, further validating its relevance and value in the machine learning community. \ud83c\udf1f\nPyOD is compatible with Python 2 and 3, making it accessible to a wide range of users. You can easily install PyOD through PyPI or directly from the GitHub repository. Take advantage of the diverse range of outlier detection models offered by PyOD and gain valuable insights from your data. \ud83d\udca1\n\nKudos to Yue Zhao, Zain Nasrullah, Zheng Li, and all contributors! \n\n\ud83d\udd17Link to #Github: https:\/\/lnkd.in\/d3gg6cr\n\ud83d\udcdaLink to #Documentation: https:\/\/lnkd.in\/emGNvNzu\n\ud83d\udcdcLink to #Publication: https:\/\/lnkd.in\/evHqjmsf\n\n #OutlierDetection #MachineLearning #DataScience","linkedinURL":"https:\/\/www.linkedin.com\/feed\/update\/urn:li:activity:7069990982582165505","githubURL":null,"paperURL":null,"author":"Antonio Benedetti","createdDate":"05\/31\/2023"},{"title":"The title is: Machine Learning Educational Resources for Chemical Engineers","description":"#Machine #Learning Educational Resources for #Chemical #Engineers \ud83d\ude80 \ud83c\udf93\u2728\ud83d\udcbb\n\nLooking for top-notch educational resources to dive deep into the intersection of Machine Learning and Chemical Engineering? Look no further! \ud83e\uddea\ud83d\udd2cMachine learning has emerged as a key tool across various engineering domains, and chemical engineers are no exception to this trend.\nIntroducing an exceptional collection of educational materials that will empower you on your machine learning journey in the world of chemical engineering. \ud83d\udcda\ud83d\udca1\n\nCollaboratively curated by the brilliant minds of Edgar Ivan Sanchez Medina, Ehecatl Antonio del Rio Chanona, Caroline Ganzer, and many others, this JupyterBook will change your learning experience! \ud83d\udca1\ud83d\udcbb\n\nInside, you'll find a treasure trove of Python tutorials and captivating case studies that exemplify the practical applications of machine learning in chemical engineering. The best part? All tutorials are designed for seamless integration with Colab, enabling you to experiment and learn hands-on. \ud83d\ude4c\ud83d\udd2c\n\nDive into the world of supervised learning, unsupervised learning, reinforcement learning, hybrid modeling, and data-driven optimization. Each tutorial is crafted to ignite your curiosity and enhance your skills, propelling you towards excellence in your field. \ud83d\ude80\ud83d\udcaa\n\nBut that's not all! This dynamic team is committed to continuous improvement and regularly expanding the JupyterBook with fresh tutorials. So make sure to keep a close eye on the updates. This is exactly the type of resources that our #community loves and that we are committed to host in the upcoming release of our portal (registration link in the comments) \ud83d\udcc8\ud83d\udd0d \n\n\ud83d\udd17 Link: https:\/\/lnkd.in\/ezn-4-qR\n\n#MachineLearning #ChemicalEngineering #JupyterBook #Python #Colab #Education #DataScience ","linkedinURL":"https:\/\/www.linkedin.com\/feed\/update\/urn:li:activity:7069644397369249792","githubURL":null,"paperURL":null,"author":"Antonio Benedetti","createdDate":"05\/31\/2023"},{"title":"The title is: \"Data Science Tools for Thermodynamic Model Selection in HFC\/IL Systems\"","description":"\ud835\uddd8\ud835\ude05\ud835\uddfd\ud835\uddf9\ud835\uddfc\ud835\uddff\ud835\uddf6\ud835\uddfb\ud835\uddf4 \ud835\ude01\ud835\uddf5\ud835\uddf2 \ud835\udde6\ud835\ude06\ud835\uddfb\ud835\uddf2\ud835\uddff\ud835\uddf4\ud835\ude06 \ud835\uddfc\ud835\uddf3 \ud835\uddd7\ud835\uddee\ud835\ude01\ud835\uddee \ud835\udde6\ud835\uddf0\ud835\uddf6\ud835\uddf2\ud835\uddfb\ud835\uddf0\ud835\uddf2 \ud835\uddee\ud835\uddfb\ud835\uddf1 \ud835\udde7\ud835\uddf5\ud835\uddf2\ud835\uddff\ud835\uddfa\ud835\uddfc\ud835\uddf1\ud835\ude06\ud835\uddfb\ud835\uddee\ud835\uddfa\ud835\uddf6\ud835\uddf0 \ud835\udde0\ud835\uddfc\ud835\uddf1\ud835\uddf2\ud835\uddf9\ud835\uddf6\ud835\uddfb\ud835\uddf4: \ud835\uddd4 \ud835\uddd6\ud835\uddee\ud835\ude00\ud835\uddf2 \ud835\udde6\ud835\ude01\ud835\ude02\ud835\uddf1\ud835\ude06 \ud835\uddfc\ud835\uddfb \ud835\udddc\ud835\uddfc\ud835\uddfb\ud835\uddf6\ud835\uddf0 \ud835\udddf\ud835\uddf6\ud835\uddfe\ud835\ude02\ud835\uddf6\ud835\uddf1 \ud835\uddee\ud835\uddfb\ud835\uddf1 \ud835\udddb\ud835\ude06\ud835\uddf1\ud835\uddff\ud835\uddfc\ud835\uddf3\ud835\uddf9\ud835\ude02\ud835\uddfc\ud835\uddff\ud835\uddfc\ud835\uddf0\ud835\uddee\ud835\uddff\ud835\uddef\ud835\uddfc\ud835\uddfb \ud835\udde5\ud835\uddf2\ud835\uddf3\ud835\uddff\ud835\uddf6\ud835\uddf4\ud835\uddf2\ud835\uddff\ud835\uddee\ud835\uddfb\ud835\ude01 \ud835\udde0\ud835\uddf6\ud835\ude05\ud835\ude01\ud835\ude02\ud835\uddff\ud835\uddf2\ud835\ude00\n\ud83c\udf21\ufe0f\ud83d\udcbb\ud83d\udcc8\n\nThe phaseout of high global warming potential hydrofluorocarbon (HFC) refrigerants is a critical global objective. To address this challenge, researchers have explored novel solvents like ionic liquids (ILs) for HFC reuse and recycle technologies. However, selecting the most suitable thermodynamic model for HFC\/IL mixtures remains a complex task. What if data science provides a more principled framework for thermodynamic model selection? \n\nIn a recent study by Bridgette Befort et al, a rigorous workflow harnessing data science tools was proposed to evaluate and analyze sixteen candidate thermodynamic models for HFC\/IL systems. This was achieved by leveraging state-of-the-art data science tools, including visualization, nonlinear regression, Akaike information criteria, Fischer information matrix-based identifiability and uncertainty analyses, and model-based design of experiments methods.\n\nThe open-source #IDAES platform played a key role in this analysis, enabling the training and comparison of sixteen candidate HFC\/IL thermodynamic models. Among these models were well-known equations of state such as Peng-Robinson and Soave-Redlich-Kwong, along with various variations on temperature dependence within a classical van der Waals mixing rule.\nNotably, models incorporating a temperature-dependent mixing rule consistently demonstrated favorable performance based on the Akaike information criteria for model selection. However, it was also observed that these models exhibited significant parameter uncertainty and correlation, suggesting the necessity of data at multiple temperatures.\n\nThese findings challenge the prevailing practice of relying solely on single isotherm datasets for most new HFC\/IL mixtures. Instead, the research suggests that obtaining data at various temperatures is crucial for effectively addressing parameter uncertainty and correlation.\nAdditionally, the study identified valuable experiments to guide optimal data generation. Measurements taken at the composition, temperature boundaries, and pressure levels were found to be particularly informative. These insights offer essential guidance for the regression of thermodynamic models, facilitating multiscale process design efforts.\n\nKudos to Bridgette Befort, Alejandro Garciadiego, Jialu Wang, Ke Wang, Gabriela Franco, Edward Maginn, and Alexander Dowling for this exceptional piece of work and for making the code available as #opensource.\n\nLink to #Github: https:\/\/lnkd.in\/ePz9Xjw7\nLink to #Publication: https:\/\/lnkd.in\/eH97C2_T\n\n #ThermodynamicModels #DataScience #Sustainability","linkedinURL":"https:\/\/www.linkedin.com\/feed\/update\/urn:li:activity:7069289359685869568","githubURL":null,"paperURL":null,"author":"Antonio Benedetti","createdDate":"05\/30\/2023"},{"title":"The title is: Advancing #Antibiofilm #Peptide Screening: Unveiling Insights and Enhancing Efficacy via a #ML #Approach","description":"Advancing #Antibiofilm #Peptide Screening: Unveiling Insights and Enhancing Efficacy via a #ML #Approach \ud83e\udda0\ud83d\udd2c\ud83d\udd0d\ud83e\uddec\n\nBiofilms, which are formed by multicellular colonies of microorganisms, present a significant challenge to public health due to their resilient and protective nature. However, a promising therapeutic solution has emerged in the form of antibiofilm peptides. Screening the right peptide for antibiofilm activity can be resource expensive both in terms of time and lab work required.\nIn a recent study by Hema Chandra Puchakayala et al, a machine learning-aided design framework was proposed to streamline the screening process for antibiofilm peptides. By analyzing the amino acid compositions, sequences, and physicochemical properties of the peptides, the research team developed an SVM-based binary classification model. \nImpressively, the model achieved a notable accuracy rate, surpassing alternative feature representation techniques. This indicates the potential of machine learning algorithms in biofilm research and emphasizes the importance of considering physicochemical properties when designing effective antibiofilm peptides.\nTo enhance the model's interpretability, the researchers employed SHAP analysis, which provided valuable insights into the correlation between specific physicochemical properties and antibiofilm activity. Amphiphilicity, aliphaticity, and cationicity were found to have positive correlations, while steric parameters, length, and volume exhibited negative correlations with antibiofilm activity.\n\nCongratulations to Hema Chandra Puchakayala, Pranshul Bhatnagar, Pranav Nambiar, Arnab Dutta and Debirupa Mitra to build this tool and make it available as a webapp! We would be thrilled to host the code behind such a great work in our upcoming launch of PolyModels Hub.\n\nLink to #WebApp: https:\/\/lnkd.in\/ezcKx5hp\nLink to #OpenAccess  #Publication: https:\/\/lnkd.in\/d_5Ne-Xj\n\n#Biofilms #AntibiofilmPeptides #MachineLearning #SupportVectorMachines","linkedinURL":"https:\/\/www.linkedin.com\/feed\/update\/urn:li:activity:7068957707080216577","githubURL":null,"paperURL":null,"author":"Antonio Benedetti","createdDate":"05\/29\/2023"},{"title":"The title is: Streamlining Tablet Lubrication Design in Oral Solid Dosage Production: Leveraging Model-Based Design of Experiments","description":"\ud83d\ude80 Streamlining Tablet Lubrication Design in Oral Solid Dosage Production: Leveraging Model-Based Design of Experiments \ud83e\uddea\n\n\ud83d\udc8a In the realm of Oral Solid Dosage (#OSD) production, achieving optimal tablet quality and manufacturability without compromising quality properties is paramount. To address this challenge, various #mathematicalmodeling  approaches have been developed. However, some of these models require extensive #experimental campaigns to identify their parameters accurately; or do they? \ud83e\udd14\n\nModel-Based Design of Experiments (#MBDoE) enables efficient process optimization, risk reduction, and data-driven decision making, leading to faster and more cost-effective drug development. By harnessing mathematical models and statistical analysis, MBDoE improves efficiency and enhances the quality and #regulatorycompliance of pharmaceutical processes. \ud83d\udcc8\ud83d\udcaa\n\n\ud83d\udd2c An exciting study conducted by Francesca Cenci et al. at the CAPE-lab Universit\u00e0 degli Studi di Padova and GSK focuses on streamlining tablet lubrication design, significantly reducing the consumption of Active Pharmaceutical Ingredient (API) during experimentation. By applying MBDoE, they minimized the number of experimental blends needed for model calibration, resulting in statistically robust parameter estimates and predictions. \u2705\n\nThe methodology proposed by Cenci and her colleagues reduced the experimental effort by a staggering 60-70% compared to the standard industrial practice. This reduction was achieved consistently across different formulations. \n\nCongratulations to all the authors of the article Francesca Cenci et al., and to the professors at CAPE lab supporting high quality research within the pharma modelling space: Fabrizio Bezzo, Massimiliano Barolo, Pierantonio Facco.\n\nTo learn more about this ground-breaking study check out the article: https:\/\/lnkd.in\/ee-BKBCF \ud83d\udd0d","linkedinURL":"https:\/\/www.linkedin.com\/feed\/update\/urn:li:activity:7068579166933131264","githubURL":null,"paperURL":null,"author":"Harry Christodoulou","createdDate":"05\/28\/2023"},{"title":"The title is: Using Mathematical Modelling to optimally design hybrid distillation-membrane processes!","description":"\u00a0\ud83d\udcbb Using Mathematical Modelling to optimally design hybrid distillation-membrane processes! \ud83e\uddea\ud83d\udd22\n\n#Distillation and membrane processes play a pivotal role in the #Pharma industry by enabling the efficient separation and purification of complex drug compounds, ensuring the production of high-quality pharmaceutical products. \ud83c\udfed\ud83d\udc8a\n\n\"Optimal design of hybrid distillation-membrane processes based on a #superstructure approach\" is a recent publication by Dian Ning Chia and Eva Sorensen from UCL Chemical Engineering. Their work focuses on process intensification for sustainable and energy-efficient processes\u00a0\ud83c\udf31.\u00a0Hybrid distillation-membrane processes are explored as prime examples of intensified processes.\n\nThe authors present strategies to address the complexity of #membrane  networks within hybrids, introducing a superstructure approach for #optimization . The study compares energy consumption and economic performance of hybrid distillation-pervaporation with extractive distillation for separating azeotropic mixtures. Results reveal high energy efficiency of the hybrid process, with low heat duty. \ud83d\udca1\n\nThis high quality article highlights the potential of hybrid distillation-membrane processes to separate challenging azeotropic mixtures. The integration of membranes opens new avenues for efficiency, sustainability, and cost-effectiveness. \ud83d\ude80\n\nCongratulations to the authors for this innovative study! \ud83d\udc4f\n\nLink to the article: https:\/\/lnkd.in\/e8X2rNWG\n\n#ChemicalEngineering #ProcessIntensification #HybridProcesses #Distillation\u00a0#optimization ","linkedinURL":"https:\/\/www.linkedin.com\/feed\/update\/urn:li:activity:7068216778841026560","githubURL":null,"paperURL":null,"author":"Harry Christodoulou","createdDate":"05\/27\/2023"},{"title":"The title is: StateSpaceModels.jl: Empowering Pharma with State-Space Time Series Analysis","description":"\ud83d\udd2c StateSpaceModels.jl: Empowering Pharma with State-Space Time Series Analysis \ud83d\udcca\n\nState Space models are used quite often in the Pharmaceutical and Life Science industries, revolutionizing time series analysis, filtering, smoothing, forecasting, and more. From Drug Substance and Drug Product Process #Monitoring to #Pharmacokinetic modelling, these models find versatile applications.\n\nTherefore, today let's talk about StateSpaceModels.jl! An exciting package out of the Laboratory of Applied Mathematical Programming and Statistics at PUC-Rio. This comprehensive tool enables you to implement and explore state space models in time series analysis, allowing you to fit models, analyse residuals, components, and make accurate forecasts. The package provides pre-defined models and #datasets, continually expanding based on user feedback.\n\nCongratulations to the authors Raphael Saavedra, Guilherme Bodin, Mario Souto, and all contributors for their important work! \ud83d\udc4f\n\n\ud83d\udcca Link to the package: https:\/\/lnkd.in\/eSSwEV2W\n\ud83d\udcda Dive into State Space modelling with \"Time Series Analysis by State Space Methods\" by James Durbin and Siem Jan Koopman: https:\/\/lnkd.in\/eNU4RVCi\u00a0\n\ud83d\udcf0 Check out the article about the package: https:\/\/lnkd.in\/eY-nuZeb\n\n#StateSpaceModels #TimeSeriesAnalysis #PharmaInsights #DataAnalytics #StateSpaceMethods","linkedinURL":"https:\/\/www.linkedin.com\/feed\/update\/urn:li:activity:7067874164082102272","githubURL":null,"paperURL":null,"author":"Harry Christodoulou","createdDate":"05\/26\/2023"},{"title":"The title is: Fluids","description":"\ud83d\udca7 Fluids: An open-source engineering software & lightweight repository of knowledge and utilities relating to fluid dynamics! \ud83d\udcbb\n\nIn the #pharmaceutical industry, modelling tools for #fluiddynamics calculations are crucial for optimizing drug formulation, improving drug delivery systems, and enhancing manufacturing processes for better efficacy, safety, and cost-effectiveness. #optimization\n\nWe recently discovered an #open-source engineering software which can be a powerful tool in the hands of scientists in the Life Sciences field!\n\nFluids offers a comprehensive suite of tools and modules to tackle fluid dynamics challenges, including piping, fittings, pumps, control valves, orifice plates, and more. It empowers engineers with a lightweight, low-overhead #repository of #engineering  knowledge. \ud83d\udee0\ufe0f\n\nDesigned to be versatile and user-friendly, Fluids integrates with #scipy  and #numpy for enhanced functionality. It runs on all major operating systems, ensuring accessibility for engineers.\n\nCongratulations to the developer\/author Caleb Bell and all contributors!\n\nGitHub link: https:\/\/lnkd.in\/e2exwcHe\n\n#Fluids #EngineeringSoftware #FluidDynamics #OpenSource #Python #Engineering\u00a0","linkedinURL":"https:\/\/www.linkedin.com\/feed\/update\/urn:li:activity:7067469354266685441","githubURL":null,"paperURL":null,"author":"Harry Christodoulou","createdDate":"05\/25\/2023"},{"title":"The title is: SynthCity: An open-source package for innovative use cases of synthetic data in different modalities!","description":"\ud83d\udd2c\ud83d\ude80 SynthCity: An open-source package for innovative use cases of synthetic data in different modalities! \ud83d\udcca\ud83d\udca1\n\nSynthetic tabular #data plays a vital role in the development and validation of models, #algorithms, and predictive #analytics  in Life Sciences. By generating synthetic datasets that closely mimic real-world scenarios, researchers can effectively test and refine their models, leading to faster iteration, #optimization, and validation before applying them to real data.\n\nExciting news! Introducing #SynthCity, a robust library- out of University of Cambridge- designed to empower data professionals with advanced synthetic tabular data generation.\n\nSynthCity offers an easy-to-use and extendable architecture, serving as the go-to solution for data modellers seeking realistic synthetic data. With a wide range of evaluation metrics and reference models, it ensures unparalleled accuracy and privacy in data generation. From GAN-based and VAE-based models to time series, survival analysis, and privacy-focused approaches, SynthCity covers diverse domains and use cases. \n\nThis powerful tool enables data analysis and testing, empowering researchers to experiment with algorithms and models in a controlled environment. Additionally, it serves as an invaluable resource for #education and #training in #data #science and #machine #learning.\n\nCongratulations to the talented developers behind SynthCity: Zhaozhi Qian, Bogdan-Constantin Cebere, and Mihaela van der Schaar! \ud83c\udf89\n\n\ud83d\udcc4 Cite the paper: https:\/\/lnkd.in\/ejE8U8xn\n\ud83d\udcbb GitHub link: https:\/\/lnkd.in\/epTiu4qP\n\n#SynthCity #DataGeneration #MachineLearning #DataScience \n","linkedinURL":"https:\/\/www.linkedin.com\/feed\/update\/urn:li:activity:7067106970847064066","githubURL":null,"paperURL":null,"author":"Harry Christodoulou","createdDate":"05\/23\/2023"},{"title":"The title is: Unleashing the Power of #MultiTask #Learning for Accelerated #Chemical #Reaction #Optimization","description":"Unleashing the Power of #MultiTask #Learning for Accelerated #Chemical #Reaction #Optimization \ud83e\uddea\ud83d\udcbb\ud83e\udd16\ud83c\udfaf\n\nPrevious research has shown the effectiveness of #Bayesian #optimization (#BO) in self-optimizing chemical reactions. However, these methods lacked prior knowledge about the specific reactions of interest. In this work by Connor Taylor et al, the researchers explored the potential of multitask Bayesian optimization (#MTBO) by leveraging extensive reaction data collected from historical optimization campaigns in several in silico case studies. \ud83e\uddea\nThe methodology was then applied to real-world applications, where the team successfully optimized the yield of several pharmaceutical intermediates using an autonomous flow-based reactor platform. \ud83d\udca1\nThe results were remarkable, demonstrating the effectiveness of the MTBO algorithm in determining optimal conditions for experimental C\u2013H activation reactions with varying substrates, even in cases where these reactions had not been previously encountered. This breakthrough offers an efficient optimization strategy that can potentially lead to significant cost reductions compared to industry-standard process optimization techniques. \nThese findings highlight the potential of this methodology as an enabling tool in medicinal chemistry workflows. By integrating data-driven approaches and machine learning, researchers can accelerate the drug discovery process and make more informed decisions. \n\nCongratulations to Connor Taylor, Kobi Felton, Daniel Wigh, Mohammed Jeraal, Rachel Grainger, Gianni Chessari, Christopher Johnson, and Alexei Lapkin for this publication. It's also great to see the source code released as #opensource! \n\n\ud83d\udd17Link to\u00a0#Github: https:\/\/lnkd.in\/eKwpCJYB\n\ud83d\udcc4Link to #Publication:https:\/\/lnkd.in\/exw8vRVF\n\n#machinelearning #research #medicinal #chemistry #drugdiscovery #pharmaceutical #data ","linkedinURL":"https:\/\/www.linkedin.com\/feed\/update\/urn:li:activity:7066729492718735361","githubURL":null,"paperURL":null,"author":"Antonio Benedetti","createdDate":"05\/20\/2023"},{"title":"The title is: Open-Sourcing Model Code: A Key to Scientific Innovation and Transparency in Life Sciences","description":"#Modelling is Math, is #Code, and Modelling Code Should be #OpenSource: A Perspective by PolyModels Hub \u2728\ud83d\udd13\ud83c\udf0d\n\nThe topic of opensource code and #AI models has been polarizing political debates on both sides of the Atlantic. On one side, the European Union, with the Cyber Resilience Act (CRA), is proposing a cybersecurity regulation that could pose a threat to open-source developers by enforcing security audits and imposing fines. This has been challenged by several open-source organizations, including Eclipse and Linux Foundation, and the OSI, as it \"poses an unnecessary economic and technological risk to the EU.\" On the other side of the ocean, the recent US Senate hearing with Sam Altman (OpenAI) fueled the debate on the regulation that AI should require to mitigate the risk of technology misuse that could end up very badly. This has been vigorously challenged by Yann LeCun (Meta AI), who instead argued that regulations could have the side effect of increasing the entry barrier for research and innovation in this space, creating black box technologies that would limit transparency, but also creating technological monopolies in this space.\n\nIn this rapidly evolving technological world, whether you are a modeller, data scientist, or working at the interface of data and real-world applications, you must acknowledge the intrinsic nature of Models and Code. Historically, models are defined as mathematical abstractions of physical systems, but computational complexity necessitated translating math into code. Nowadays, we can say that whether you are thinking about a generative AI model, a neural net, or a mechanistic reaction model, you are immediately considering or at least posing the challenge of translating that into some code.\n\nAt PolyModels Hub, we strongly believe that as science is based on open research, scientists who have the desire to drive scientific innovation in this field should consider open-sourcing their model code. Progress is faster when it is open, and this creates a more vibrant, community-driven ecosystem where everyone can contribute. This is even more important in the #lifescience research context where the concepts of transparency, reproducibility, and the translation of research into real-world applications should be the basis of every work. This doesn't mean that software companies or services that revolve around open source should be not-for-profit or free. Developing software and services that can provide real value while basing their libraries of models on open-source building blocks is a challenge but also an opportunity. This will require a step-change in the technology around the models but also an extremely customer-oriented focus on your product solution.\n\nWe are excited to take on this challenge, and we want to start by creating the most vibrant open-source #community in this space. If you want to be part of it from day 1, register now at www.polymodelshub.com to not miss our upcoming launch.","linkedinURL":"https:\/\/www.linkedin.com\/feed\/update\/urn:li:activity:7066367099429871616","githubURL":null,"paperURL":null,"author":"Antonio Benedetti","createdDate":"05\/20\/2023"},{"title":"The title is: Exploring Chromatographic Profile Features for Effective Column Performance Monitoring","description":"Exploring\u00a0#Chromatographic\u00a0#Profile\u00a0#Features\u00a0for Effective\u00a0#Column#Performance\u00a0#Monitoring\ud83d\udd2c\ud83d\udcca\ud83d\udca1\ud83d\udd0d\n\nIn the biopharmaceutical industry, chromatography resins degrade over time, impacting ligand integrity and density. Predicting and validating the condition of chromatography columns is crucial.\u00a0\nThis recent study by Nivetita\u00a0Ravi et al focused on using representative scale-down models and real-time validation during commercial production. Principal Component Analysis (PCA), Partial Least Square (PLS), Similarity Scores, and Single One Point-MultiParameter Technique (SOP-MPT) were employed, along with machine learning principles, to explore the hypothesis of predictive capability in chromatography absorbance profiles.\nThe study involved cycling a MabSelect SuRe\u2122 chromatography column to establish a baseline for process performance and product quality. A harsh NaOH Cleaning in Place (CIP) procedure, exceeding recommended concentrations, was applied to accelerate resin degradation. Analysis of the Wash, Elution, and Strip phases of the chromatography method revealed correlations between mathematical analytical tools and resin degradation, observed through decreasing step yield and binding capacity with each cycle.\nInterestingly, traditional measurements such as height equivalent to a theoretical plate (HETP) and Asymmetry (As) were unable to detect changes in resin integrity. However, utilizing PCA, PLS, Similarity Scores, and SOP-MPT on the absorbance data successfully identified atypical outcomes, allowing for anticipation of issues in the chromatography bed. Notably, changes in monomer, host cell proteins (HCP), and DNA content showed inconsequential correlation with product quality.\nThis study demonstrates the proof-of-concept that innovative analytical tools can effectively measure resin integrity, surpassing the limitations of traditional methods. The findings have significant implications, enabling the development of robust strategies to monitor and maintain chromatography column performance and product quality in the biopharmaceutical industry.\n\nAppreciation goes to the authors of this nice work Nivetita Ravi, Gunnar Malmquist (he\/him), Valentin Stanev, and Gisela M Ferreira!\n\n\ud83d\udd17Link to\u00a0#Publication:\u00a0https:\/\/lnkd.in\/eY4CU4N5\n\n#Biopharmaceuticals\u00a0#Chromatography\u00a0#Research\u00a0#Innovation #ScientificAdvancements\u00a0#machinelearning\u00a0#multivariate\u00a0#analysis","linkedinURL":"https:\/\/www.linkedin.com\/feed\/update\/urn:li:activity:7066004702970163200","githubURL":null,"paperURL":null,"author":"Antonio Benedetti","createdDate":"05\/20\/2023"},{"title":"The title is: Advancing #Chemical #Reaction #Kinetics Modeling: Unveiling the Power of #Semiparametric #Regression in the Absence of Mechanistic Understanding","description":"Advancing #Chemical #Reaction #Kinetics Modeling: Unveiling the Power of #Semiparametric #Regression in the Absence of Mechanistic Understanding \ud83e\uddea\ud83d\udcbb\ud83e\udd16\ud83d\udcca\n\nThe application of mathematical modeling in chemical reaction kinetics has revolutionized the development of new reactions and processes. While it has been widely employed in chemical engineering, pharmaceutical drug development presents unique challenges due to complex reaction mixtures and low-level impurities. In this context, data-driven modeling plays a vital role in understanding the relationship between reaction parameters and profiles.\nRecent advancements in reaction automation technologies have enabled us to gather rich data sets, transforming statistical analysis from end-point analysis to modeling the entire reaction profile using advanced statistical models. This shift is particularly valuable in early-stage development, where limited time and resources make building comprehensive kinetic models difficult.\nTo address this, a rigorous and general modeling workflow, including the application of semiparametric regression, has been developed by Ke Wang and colleagues. By capturing the complexity of pharmaceutical reactions, semiparametric models offer significant advantages in parameter effect estimation, reaction robustness range finding, and reaction optimization and operation window prediction. The semiparemtric regression have been implemented using the R package \"mgcv\" (link below).\nTo demonstrate the effectiveness of this approach, an industrial case study on methyl ester chemoselective hydrolysis reaction is presented. The comparison between traditional kinetic modeling approaches showcases the great performance of semiparametric regression.\n\nHuge congratulations to Ke W., Lu Han, Jason Mustakis, Bryan Li, Javier Magano, David Damon, Am\u00e9lie Dion, Mark Maloney, Ronald Post Sr., and Ruizhi Li for this outstanding piece of work!\n\n\ud83d\udd17Link to #R package for #SPR: https:\/\/lnkd.in\/egjkRPnF\n\ud83d\udcc4Link to #Publication: https:\/\/lnkd.in\/epzVr3-v\n\n\n#ChemicalReactionKinetics #DataDrivenModeling #SemiparametricRegression #PharmaceuticalResearch #InnovationInTheLab","linkedinURL":"https:\/\/www.linkedin.com\/feed\/update\/urn:li:activity:7065687499037143041","githubURL":null,"paperURL":null,"author":"Antonio Benedetti","createdDate":"05\/20\/2023"},{"title":"The title is: Efficient #QualityByDesign (#QbD) Approach to #Tablet Manufacturing Processes: Surrogate #Modelling of #Dissolution Behaviour\ufffd\ufffd\ufffd\ufffd","description":"Efficient #QualityByDesign (#QbD) Approach to #Tablet Manufacturing Processes: Surrogate #Modelling of #Dissolution Behaviour\u2728\ud83d\udcbb\ud83d\udcc8\ud83d\udc8a\n\nDissolution behavior is a crucial quality attribute in the pharmaceutical industry, referring to the time profile of the fraction of dissolved active pharmaceutical ingredients in a solvent from a tablet. Mechanistic models can be used to predict the dissolution profile of the tablets based on the process conditions, but they usually requires some efforts to estimate parameter fitting. Surrogate models have been investigated for some time as viable alternatives to reduce the computational cost.\nToday we want to share with you this recent publication by Kensaku\u00a0Matsunami et al on surrogate models for dissolution behavior, which focuses on identifying the critical input parameters.  By employing mechanistic models fitted by the Weibull model, the research team accurately calculated dissolution behavior. The determination of Weibull model parameters was obtained using random forest regression. Based on the developed surrogate models, case studies were performed for both dry and wet granulation processes, where sensitivity analyses indicated critical input parameters and physical properties of intermediates. This is very nice example of how you can reduce the computational costs of models without losing accuracy.\n\nCongratulations to Kensaku Matsunami, Tomohiro Miura, Keita Yaginuma, Shuichi Tanabe, Sara Badr, and Hirokazu Sugiyama on this great piece of work! It's great to see how this partnership across The University of Tokyo and Daiichi Sankyo, Inc. is contributing to advance research in this field.\n\nLink to Publication: https:\/\/lnkd.in\/edqbakFB\n\n#pharmaceuticalindustry  #models #research  #manufacturing #mechanistic #hybrid ","linkedinURL":"https:\/\/www.linkedin.com\/feed\/update\/urn:li:activity:7065377039603642368","githubURL":null,"paperURL":null,"author":"Antonio Benedetti","createdDate":"05\/19\/2023"},{"title":"The title is: ExplainerDashboard - Simplifying Model Explanation and Interpretability in Life Science Industry","description":"\ud83d\udd0d Simplify #Machine #Learning Model #Interpretation with #ExplainerDashboard! \ud83d\udcca\ud83e\uddea\ud83d\ude80\ud83d\udc68\u200d\ud83d\udcbb\n\nIn the life science industry, explaining the inner workings of machine learning models is becoming increasingly important. Customers and regulators require transparency and accountability. However, this is not always trivial. The assessment of a model cannot just be relegated to the performance metrics, but you must also consider the model structure across inputs and outputs. \nIf you ever faced this challenge at least once, then meet ExplainerDashboard, a powerful package developed by Oege Dijk and contributors, designed to simplify model explanation and enhance transparency. ExplainerDashboard leverages recent advancements in explainable AI, such as SHAP values, to provide clear and intuitive explanations. It offers interactive plots and functionalities, including model performance analysis, feature importances, feature contributions to individual predictions, \"what if\" analysis, partial dependence plots, SHAP (interaction) values, and visualizations of individual decision trees. The modular design empowers you to create custom interactive dashboards using Plotly Dash. Focus on designing layouts and providing project-specific textual explanations, making it interpretable for business users within your organization.\n\nCongratulations to Oege Dijk and all the contributors for releasing this fantastic #opensource work! We would love to feature great project such as this one in the upcoming launch of our #Hub at www.polymodelshub.com (register today)! \n\n\ud83d\udd17 Link to #Github: https:\/\/lnkd.in\/edGJjbJ \n\ud83d\udcc4 Documentation can be found at\u00a0https:\/\/lnkd.in\/eAGpDqjC\n\n#ModelInterpretability #MachineLearning #ExplainerDashboard #LifeScience #Transparency #DataScience #artificialintelligence #opensource #ai ","linkedinURL":"https:\/\/www.linkedin.com\/feed\/update\/urn:li:activity:7064931823956451328","githubURL":null,"paperURL":null,"author":"Antonio Benedetti","createdDate":"05\/18\/2023"},{"title":"The title is: Web-based Models: Expanding the Learning Horizons through Virtual Lab Experiences","description":"Web-based #Models: Expanding the #Learning Horizons\u00a0through #Virtual #Lab #Experiences \ud83e\udd7c\ud83d\udd2c\ud83d\udcbb\ud83c\udf10\n\n#Bioreactors, essential in the #Life #Sciences industry, enable precise cultivation of cells, microorganisms, and other biological entities. They find applications in pharmaceutical production, bioprocessing, and biofuel development. Therefore, it is crucial to provide students with practical training in laboratory work involving bioreactors, ensuring a skilled workforce for the industry. But what if we could use the #power of #models to create a virtual learning experience?\nWe recently came across the work of Stefan Seidel & Team, researchers from ZHAW Zurich University of Applied Sciences, who have introduced a fascinating method to tackle the growing demand for alternative learning resources. By representing real laboratory equipment as web-based models, students can explore the design and operation of stirred bioreactors independently, anytime and anywhere.\nThe web-based bioreactor model provides detailed information on each component and incorporates Computational Fluid Dynamics (#CFD) #OpenFOAM simulations, enabling students to understand the impact of different stirrers on flow behaviour. This online tool prepares students for practical work in the laboratory, bridging the gap between theory and practice.\n\nCongratulations to the authors Stefan Seidel, Regine Eibl and Dieter Eibl !\n\nTell us what you think on these new digital learning approach! Would you like to see more of this #openaccess material in our upcoming platform ( www.polymodelshub.com )?\n\n\ud83d\udc49Link to #Github Web-based tool:\u00a0https:\/\/lnkd.in\/eE4Gcc8H \n\n\ud83d\udc49The bioreactor model is available in several ways. The recommended variant is embedded in the #MOOC (Massive open online course) \"Introduction to Cell Cultivation Techniques\" EdX course:\u00a0https:\/\/lnkd.in\/eTqxeBMY\n\n#Education #OnlineLearning #Biotechnology #Innovation #MOOC #digitaltwins #openaccess ","linkedinURL":"https:\/\/www.linkedin.com\/feed\/update\/urn:li:activity:7064562713141596160","githubURL":null,"paperURL":null,"author":"Antonio Benedetti","createdDate":"05\/17\/2023"},{"title":"The title is: Unleashing Scientific Potential: Introducing #COMBO, an Efficient #Bayesian #Optimization Library for #Materials #Science\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd","description":"Unleashing Scientific Potential: Introducing #COMBO, an Efficient #Bayesian #Optimization Library for #Materials #Science\ud83e\uddea\ud83d\ude80\ud83d\udd2c\ud83c\udfaf\n\nAs discussed in many previous posts, numerous attempts have been made over the past years to accelerate scientific discovery using data-driven experimental design algorithms. Among them, Bayesian optimization has been proven to be an effective tool. However, in these successful applications, the size of the training set was small (i.e., several hundreds at most). For upcoming large-scale problems, the size of the training set may increase to the millions. Existing packages (e.g., scikit-learn) are hopelessly slow in this case.\nTo address this limitation, Tsuyoshi Ueno et al have designed an efficient protocol for Bayesian optimization that employs Thompson sampling, random feature maps, one-rank Cholesky update, and automatic hyperparameter tuning. The authors have implemented this protocol as an open-source Python library called COMBO (COMmon Bayesian Optimization library). COMBO tackles large-scale problems with linear computational time growth, enabling seamless scalability as the number of candidates increases. COMBO empowers materials scientists by providing a user-friendly solution that frees them from the complexities of implementing machine learning algorithms, making it a pivotal tool in the emerging field of materials informatics.\n\nCongratulations to Tsuyoshi Ueno, Trevor David Rhone, Zhufeng Hou, Teruyasu Mizoguchi, and Koji Tsuda, on the development of COMBO! \n\nLink to #Github: https:\/\/lnkd.in\/efb9tRfF\nLink to #Publication: https:\/\/lnkd.in\/ebicNwTv\n\n#materialsscience #computationalmaterialsscience #bayesianoptimization #scientificdiscovery #opensource #research #development #efficiency #scalability #userfriendly #machinelearning #materialsinformatics","linkedinURL":"https:\/\/www.linkedin.com\/feed\/update\/urn:li:activity:7064192775382016000","githubURL":null,"paperURL":null,"author":"Antonio Benedetti","createdDate":"05\/15\/2023"},{"title":"The title is: Open and Extensible Sigma-Profile Database for COSMO-Based Models","description":"Introducing an #Open and #Extensible Sigma-Profile #Database for #COSMO-Based #Models \ud83d\udd0d\ud83d\udcca\ud83d\udcbb\n\nLast week, we discussed the importance of efficient solvent selection for extracting valuable chemicals from food waste using COSMO-based models. COSMO-based activity coefficient models have become an interesting alternative to the prediction of the behavior of substances in mixture. These models depend on the pure substance information known as sigma-profile.\u00a0\nToday, we are excited to share this open sigma-profile database for a wide range of molecules using the GAMESS software. This database is based on the COSMO-SAC model and provides a valuable resource for predicting the behavior of substances in mixtures.\nIn this study, different quantum chemistry theories and basis sets were tested to identify the most accurate and efficient approach for computing sigma-profiles. The Hartree-Fock method with the TZVP basis set was found to be the most effective, providing results that closely matched experimental data while remaining computationally feasible.\n\nCongratulations to Fabr\u00edcio Ferrarini, Guilherme Fl\u00f4res, Andr\u00e9 Muniz, and Rafael Soares on the successful creation and #opensource distribution of the new sigma-profile database!\n\nLink to #Github: https:\/\/lnkd.in\/eiDmVgEq\nLink to #Publication: https:\/\/lnkd.in\/eymMB49P\n","linkedinURL":"https:\/\/www.linkedin.com\/feed\/update\/urn:li:activity:7063830399281451008","githubURL":null,"paperURL":null,"author":"Antonio Benedetti","createdDate":"05\/14\/2023"},{"title":"The title is: Real-Time #Granule #Flowability Measurement: A #SoftSensor Approach to Monitor #Continuous #Dry #Granulation","description":"Real-Time #Granule #Flowability Measurement: A #SoftSensor Approach to Monitor #Continuous #Dry #Granulation \u2699\ufe0f\u2699\ufe0f\ud83d\udcbb\ud83d\udcc8\ud83d\udc8a\n\nIn the #pharmaceutical industry, real-time monitoring and control of powder flowability in continuous lines is essential to ensure the quality of the final tablet products. However, current at-line methods to measure granule flowability can take hours to perform, which is problematic for continuous dry granulation tableting lines. This is where a real-time alternative is needed to measure the flowability of granular products coming out of the roller compactor, the unit operation preceding the tablet press.\nA recent publication by Rexonni Lagare et al. presents a novel real-time approach to measuring granule flowability, utilizing Partial Least Squares (PLS) regression to predict the output of three different types of flowability measurements: rotary drum flow, orifice flow, and tapped density analysis. The PLS regression utilized distributions of size and shape measurements to achieve a coefficient of determination ranging from 0.80 to 0.97, which is reported to be the best performance in the literature. The inclusion of multiple shape characteristics, such as eccentricity, form factor, and elliptical form factor, into the model was instrumental in achieving this result.\nThis highlights the importance of considering shape in addition to size, contrary to the industry's usual perspective, which only focuses on size. The approach is using a PLS regression through the PyPhi package (https:\/\/lnkd.in\/gikjBr2q) to reduce the dimensionality of distribution datasets, instead of the widely used practice of pre-selecting distribution percentiles.\n\nCongratulations to the authors Rexonni Lagare, Yan-Shu Huang, Craig Bush, Katherine Young, Ariana C. Acevedo Rosario\u00a0, Marcial Gonzalez, Paul Mort, Zoltan Nagy, and Gintaras Reklaitis for this great publication! Our #PolyModellers will enjoy the reading!\n\nLink to #Publication: https:\/\/lnkd.in\/e662dRtu\n","linkedinURL":"https:\/\/www.linkedin.com\/feed\/update\/urn:li:activity:7063526535214850049","githubURL":null,"paperURL":null,"author":"Antonio Benedetti","createdDate":"05\/14\/2023"},{"title":"The title is: Unlocking the Potential of Chemical Waste: A Computational Approach to Repurposing for Life Science Applications","description":"Unlocking the Potential of #Chemical #Waste: A #Computational Approach to Repurposing for #Life #Science Applications \ud83d\udcbb\u267b\ufe0f\ud83c\udf31\n\nIn recent years, the chemical and life science industries have been producing significant quantities of waste chemicals, many of which are potentially useful as chemical precursors, but often end up in landfills or are incinerated. To address this challenge, researchers in the field of circular chemistry have been working to develop schemes that can transform waste substrates into valuable products. \nA recent paper by Agnieszka Wo\u0142os offers a potential solution to this challenge. The paper demonstrates how computers equipped with broad synthetic knowledge can help identify and rank potential synthetic routes from waste substrates to valuable products. The researchers used the forward-synthesis #Allchemy platform to generate synthetic networks from approximately 200 waste chemicals recycled on commercial scales. From these networks, they were able to retrieve tens of thousands of routes leading to approximately 300 important drugs and agrochemicals, which they ranked according to sustainable chemistry metrics.\nExperimental validation of several routes was conducted, including an industrially realistic demonstration using a 'pharmacy on demand' flow-chemistry platform (On Demand Pharmaceuticals Inc). Widespread implementation of computerized waste-to-valuable algorithms has the potential to accelerate the reuse of chemicals that would otherwise be costly to store or dispose of and could even pose environmental hazards.\n\nCongratulations to Agnieszka Wo\u0142os, Dominik Koszelewski, Rafal Roszak, Sara Szymku\u0107, Martyna Moskal, Ryszard Ostaszewski, Brenden Herrera, Josef Maier, Gordon Brezicki, Jonathon Samuel, Justin Lummiss, D. Tyler McQuade, Luke Rogers, and Bartosz  Grzybowski on this great work.\n\nLink to #Publication: https:\/\/lnkd.in\/eJ9Wxw7Q\n\n#pharmaceuticals #greenchemistry #sustainability #computerscience ","linkedinURL":"https:\/\/www.linkedin.com\/feed\/update\/urn:li:activity:7063130443679690752","githubURL":null,"paperURL":null,"author":"Antonio Benedetti","createdDate":"05\/13\/2023"},{"title":"The title is: Reinforcement Learning for Solvent Extraction Optimization with GymSolventx","description":"#Reinforcement #Learning for #Solvent #Extraction #Optimization with #GymSolventx \ud83e\uddea\ud83d\udcbb\u2697\ufe0f\ud83d\udca1\ud83c\udfaf\n\nSolvent extraction is a common technique used in various manufacturing industries, including pharmaceuticals, to purify desired products from a mixture. Mathematical models are developed to optimize this process and design more efficient and cost-effective production methods.\nWe recently discovered gym-solventx, a #Python package on GitHub, which uses reinforcement learning to optimize solvent extraction processes. Developed by Blake Richey, Siby Jose Plathottam,\u00a0Greg Curry,\u00a0Joe Cresko and\u00a0Chukwunwike Iloeje the package provides an #OpenAI #Gym environment for simulating solvent extraction processes. The goal is to train a reinforcement learning agent to select the optimal solvent and operating conditions for a given separation problem.\nThis package includes various example scenarios and also allows users to define their custom scenarios. Built on the popular Gym toolkit, it is a useful tool for developing and comparing reinforcement learning algorithms. By implementing a highly configurable learning environment for the solvent design process, the study shows that state-of-the-art deep reinforcement learning agents can successfully predict comparably optimal solvent extraction process designs for varying feed compositions. These results demonstrate the potential of deep reinforcement learning to enhance the performance of conventional optimization strategies in the design of complex hierarchically-structured manufacturing and separations processes.\n\nWe applaud the authors for their innovative work, as we believe it has the potential to not only save time, reduce costs, and enhance the effectiveness of complex solvent extraction processes but also contribute towards designing more sustainable processes.\n\nLink to #Github:\u00a0https:\/\/lnkd.in\/eXrti4nm\nLink to #Publication: https:\/\/lnkd.in\/eDu8z4B9","linkedinURL":"https:\/\/www.linkedin.com\/feed\/update\/urn:li:activity:7062784390220673026","githubURL":null,"paperURL":null,"author":"Antonio Benedetti","createdDate":"05\/12\/2023"},{"title":"The title is: Unlocking the Secrets of Design of Experiments (DoE): Introducing DoEgen!","description":"Unlocking the Secrets of #Design of #Experiments (#DOE): Introducing #DoEgen! \u2728\ud83d\udd11\ud83d\udd2c\ud83e\uddea\n\nIn the world of Life Science, the quality and efficiency of experiments can make all the difference. That's where Design of Experiments (DoE) steps in as a game-changer. By systematically exploring factor combinations, DoE helps uncover crucial insights, optimize resources, and accelerate breakthroughs in fields like pharmaceuticals, biotechnology, genetics, and more. \nThat's why today we are excited to share with you #DoEgen, a powerful #Python library designed to revolutionize the way we generate and evaluate optimized Design of Experiments (DoE). With DoEgen, you can now easily #generate efficient #designs, evaluate their #effectiveness, and #analyze experiment results with utmost precision.\nDoEgen simplifies the process of generating optimized designs by automatically handling any mixture of factor-levels for both numeric and categorical factors. By leveraging the library's capabilities, you'll be able to effortlessly evaluate designs based on the number of experiment runs, allowing you to identify the most efficient options quickly. Moreover, DoEgen supports the import and evaluation of externally generated designs, enabling seamless integration with your existing workflows.\nBut that's not all! DoEgen goes beyond design generation and offers a comprehensive suite of analysis tools to help you derive meaningful insights from your experiment results. You can explore factor importance, identify correlations, and conduct response analysis to make informed decisions when selecting the best parameter space.\n\nCongratulations to the authors and contributors Sebastian Haan, Chris Howden, Danial Azam, Joel Nothman, and Dietmar M\u00fcller for this amazing open-source project!\n\nLink to #Github: https:\/\/lnkd.in\/eBvPx2nc \n\n#DoEgen #DesignofExperiments #OpenSource #PythonLibrary #ExperimentAnalysis #DataScience #Research #Optimization\n","linkedinURL":"https:\/\/www.linkedin.com\/feed\/update\/urn:li:activity:7062392108610932736","githubURL":null,"paperURL":null,"author":"Antonio Benedetti","createdDate":"05\/11\/2023"},{"title":"The title is: Reducing Input Costs in Bayesian Optimization through Pathwise Exploration","description":"#SnAKe: Reducing Input Costs in #Bayesian #Optimization through #Pathwise #Exploration \ud83d\udc0d \ud83e\uddea\ud83d\udd2c \n\nBayesian Optimization is a powerful tool for optimizing black-box functions, but what happens when the expense of evaluating the function increases significantly with large input changes? \ud83e\udd14\nEnter \"Sequential Bayesian Optimization via Adaptive Connecting Samples\" (#SnAKe)! This new algorithm provides a solution for optimizing expensive black-box functions in an asynchronous setting, where new queries must be selected before previous experiments are evaluated.The SnAKe algorithm considers large batches of queries and preemptively builds optimization paths that minimize input costs, resulting in significant reductions in input costs while achieving similar regret to classical Bayesian Optimization algorithms. Additionally, the algorithm is robust to the choice of its single hyper-parameter, and a parameter-free alternative is provided.This paper investigates the problem and provides an innovative solution that could have applications in developing and characterizing reaction chemistry using droplet microfluidic reactors.\u00a0\nCheck out the full paper and the Github repo for more details on the SnAKe algorithm and its impressive results!\u00a0There is also a nice YouTube video that describe the work!\n\nMajor kudos to the great minds behind the #SnAKe algorithm, Jose Pablo Folch, Shiqiang Zhang, Robert Lee, Behrang Shafei, David Walz, Calvin Tsay, Mark van der Wilk, and Ruth Misener! \n\n\ud83d\udd17 Link to #Github: https:\/\/lnkd.in\/exXD9a7a  \n\ud83d\udcc4 Link to Publication:\u00a0https:\/\/lnkd.in\/eaS3Z4sR\n\ud83d\udcfaLink to #Youtube: https:\/\/lnkd.in\/ej3Pingy\n\nWe're thrilled to see research like the SnAKe algorithm and can't wait to bring you more open-source projects that benefit the Life Science industry. Register now at\u00a0www.polymodelshub.com\u00a0to be part of it from day 1! \n\n#BayesianOptimization #OptimizationAlgorithms #MicrofluidicReactors #Research #opensource #lifescience ","linkedinURL":"https:\/\/www.linkedin.com\/feed\/update\/urn:li:activity:7062018447861243904","githubURL":null,"paperURL":null,"author":"Antonio Benedetti","createdDate":"05\/09\/2023"},{"title":"The title is: HybridML: An Open-Source Modelling Platform for Efficient Hybrid Modelling","description":"#HybridML: An #OpenSource Modelling Platform for Efficient #Hybrid #Modelling\n\ud83d\udd27\ud83e\udde9\ud83e\udd16\ud83d\udcbb\n\nHybrid modelling, the combination of #datadriven and #mechanistic modelling, is an increasingly popular approach that can reduce data demand and enable extrapolation of data-driven models. However, the process of #building, #training and #evaluating hybrid models can be challenging and time-consuming with current frameworks.\nFortunately, a group of researchers has developed HybridML, an open-source modelling platform that can train hybrid models using combinations of artificial neural networks, arithmetic expressions, and differential equations. The platform employs #TensorFlow for artificial neural network training and #Casadi to integrate ordinary differential equations and provide gradients of differential model equations, allowing for #continuous #time #representations. Additionally, HybridML offers a JSON interface for model development, making it user-friendly for researchers and practitioners.\nIn a recent study, the researchers applied HybridML to an industrial case study to predict drug concentrations over time based on patient physiological information. They also demonstrated the versatility of HybridML by modelling the spread of COVID-19 in German federal states based on socio-economic attributes.\n\nCongratulations to Kilian Merkelbach, Artur Schweidtmann, Younes M\u00fcller, Patrick Schwoebel, Adel Mhamdi, Alexander Mitsos, Andreas Schuppert, Thomas Mrziglod, and Sebastian Schneckener on the development of HybridML! \ud83d\udc4f\n\n\ud83d\udd17Link to #Github: https:\/\/lnkd.in\/gxWimEvG\n\ud83d\udcc3Link to #Publication: https:\/\/lnkd.in\/gWAQpGPr\n","linkedinURL":"https:\/\/www.linkedin.com\/feed\/update\/urn:li:activity:7061656065720926208","githubURL":null,"paperURL":null,"author":"Antonio Benedetti","createdDate":"05\/08\/2023"},{"title":"The title is: Revolutionizing Chemical Reaction Optimization: A Review on the Advantages of Algorithm-Based and Miniaturized High-Throughput Techniques","description":"Revolutionizing #Chemical #Reaction Optimization: A Review on the Advantages of #Algorithm-#Based and #Miniaturized #HighThroughput #Techniques \ud83e\uddea\ud83d\udcbb\ud83d\udd2c\ud83d\udd01\n\nFor years, synthetic chemists have relied on recipes and intuition to achieve clean reaction outcomes. While this method has proven effective, new research shows that model-based techniques outperform human intuition and achieve optimization in a much more time- and material-efficient manner.\nUnfortunately, many chemists are not exposed to these cutting-edge techniques during their undergraduate training, leaving them unaware of their existence or unable to use them to optimize their reactions. \nIn this  new paper by Connor Taylor et al, the advantages of algorithm-based and miniaturized high-throughput techniques for optimizing chemical reactions are explored. \nThis paper serves as a reference for inspired scientists, highlighting the basics and cutting-edge of modern chemical reaction optimization, as well as its relation to process scale-up. This includes a very interesting overview of approaches such as #Design of #Experiments (#DOE), #kinetic #modelling, #selfoptimization and #datadriven #optimization. The authors detail several applications of these techniques and hope to inspire a new wave of innovation in the field of synthetic chemistry.\n\nHats off to Connor Taylor and the rest of the team - Alexander P., Kobi Felton, Rachel Grainger, Magda H. Barecka, Thomas Chamberlain, Richard Bourne, Christopher Johnson, and Alexei Lapkin - for their fantastic work on this paper!\n\n\ud83d\udd17Link to #Publication: https:\/\/lnkd.in\/gzeZC7zQ\n\nRegister today at www.polymodelshub.com to be the first to upload your open-source collaboration repos on this topic through our Hub!\n\n#research #chemistry #innovation #lifescience \n","linkedinURL":"https:\/\/www.linkedin.com\/feed\/update\/urn:li:activity:7061348250020163584","githubURL":null,"paperURL":null,"author":"Antonio Benedetti","createdDate":"05\/08\/2023"},{"title":"The title is: PolyModels Hub: A Collaborative Platform for Democratizing Access to Modeling in the Life Sciences Industry","description":"Hello again, #PolyModellers! As we get closer to the launch of our platform, we want to give you a sneak peek at some of the exciting features we're working on.\n\nPolyModels Hub is a collaborative platform that aims to democratize access to #modeling and build the most advanced #opensource library of models for the #Life #Sciences industry. Here are some of the key features you can look forward to:\n   \ud83d\udcc1 Publish your model #codes in version control repositories\n   \ud83d\ude80 Deploy demo #apps to showcase your work\n   \ud83e\udd1d #Connect with peers across academia and the Life Science industry\n   \ud83c\udf1f Create, discover and better #collaborate on the most exciting open-source projects\n\nWe're excited to launch PolyModels Hub soon, and we can't wait to see what kind of amazing projects our #community will create. As always, we welcome your feedback and ideas. Don't forget to register on our landing page to be the first to know when we launch, and stay tuned for more updates!\n\n\ud83d\udc49#Register now at www.polymodelshub.com","linkedinURL":"https:\/\/www.linkedin.com\/feed\/update\/urn:li:activity:7060931279130611712","githubURL":null,"paperURL":null,"author":"Antonio Benedetti","createdDate":"05\/06\/2023"},{"title":"The title is: Innovative Solvent Selection for Antioxidant Extraction from Food Waste: A Computational Screening Approach","description":"Unlocking the Hidden Value of #Food #Waste: Innovative #Solvent Selection via #Computational Screening for #Antioxidant #Extraction \ud83c\udf31\u267b\ufe0f\ud83e\udd6d\ud83c\udf4a\ud83c\udf4c\n\nEvery year, a staggering 1.3 billion tons of global food production end up in landfills and composting, resulting in significant anthropogenic greenhouse gas (GHG) emissions. A promising solution to this issue is extracting antioxidant and antimicrobial chemicals such as flavonoids and phenolic acids from food waste. However, one of the major challenges in this process is identifying efficient solvents for extraction.\nA recent study by Yagya Gupta et al has identified over 100 high-performing solvents for extracting antioxidants and antimicrobial chemicals from food waste, presenting an economically lucrative valorization strategy. The study, which utilized in silico high throughput screening, found that the traditionally used solvents, ethanol and methanol, were outperformed by these newly identified solvents.\nThe solubilities of nine of the most promising solvents were measured and found to be in reasonable agreement with the model predictions. By analyzing the Conductor like Screening Model for Real Solvents (COSMO-RS) \u03c3-profiles and Hansen Solubility Parameters, the researchers were able to pinpoint polarity and hydrogen bonding as the factors that make dimethylformamide (DMF) an excellent single solvent.\nWhat makes this finding even more exciting is that it also showcases a move away from toxic solvents towards green mixtures, as demonstrated in their approach to potato peel waste. The implications of this study go beyond just finding a more efficient method of extraction but also present a blueprint for solvent selection and generate new insights into extraction from food waste.\n\nCongratulations to Yagya Gupta,\u00a0Souryadeep Bhattacharyya and\u00a0Dion Vlachos for this excellent publication!\n\nLink to #Publication: https:\/\/lnkd.in\/ek47n229\n\n#inSilico #highthroughput #computationalchemistry #COSMORS #HansenSolubilityParameters #modelling #mathematicalmodeling  \n#foodwaste #sustainability #innovativesolutions #greenextraction  #solventselection #foodindustry #environmentallyfriendly #circulareconomy #zerowaste\n","linkedinURL":"https:\/\/www.linkedin.com\/feed\/update\/urn:li:activity:7060611938581389312","githubURL":null,"paperURL":null,"author":"Antonio Benedetti","createdDate":"05\/06\/2023"},{"title":"The title is: pyPESTO: New Open-Source Toolbox for Parameter Estimation.","description":"#pyPESTO: New #Preprint of this Powerful #Toolbox for #Parameter #Estimation \ud83c\udf3f\ud83c\udfaf\u00a0\ud83d\udcc3\n\nWe have already discussed the challenges related to parameter estimations in some of our past posts. Today we want to bring the attention to a new tool that Yannik Sch\u00e4lte et al. just published called pyPESTO. pyPESTO is a recent #opensource #parameter #estimation toolbox that can help with the challenging task of estimating unknown parameters in mechanistic models. This is particularly interesting for complex biological systems, but we believe pyPESTO has applications pretty much anywhere in the modelling world.\n\nWhat's impressive about pyPESTO is its modular framework, which provides scalable algorithms for optimization and uncertainty quantification in systematic parameter estimation. The open source toolbox has various algorithms and a unified interface to popular simulation and inference methods. pyPESTO supports efficient ODE simulations, has a Julia interface #UserFriendly, and can work with the PEtab format to simplify problem definition #PEtab.\n\nMoreover, pyPESTO offers a range of local and global, derivative-based and derivative-free optimizers, and a multi-start globalization scheme. It can also quantify uncertainties using multiple samplers and approximate profile calculation. That is exceptionally important in #pharmaceutical #process #development #modelling work!\u00a0\nThe developers have done an excellent job, and if you're interested in learning more, we encourage you to check it out!\n\n\ud83d\udd17 Link to #GitHub :\u00a0https:\/\/lnkd.in\/ec9ZKVen \n \ud83d\udcdc\u00a0Link to Preprint:\u00a0https:\/\/lnkd.in\/eDEE2wvV\n\ud83d\udcc3 Link to Documentation:\u00a0https:\/\/lnkd.in\/ebk8-awZ\n\nHopefully, you will see pyPESTO and the next releases on our upcoming Hub at\u00a0www.polymodelshub.com!\nCheck our page out to learn more! \n","linkedinURL":"https:\/\/www.linkedin.com\/feed\/update\/urn:li:activity:7060286513112051713","githubURL":null,"paperURL":null,"author":"Antonio Benedetti","createdDate":"05\/05\/2023"},{"title":"The title is: Optimizing #Reactor and #Tube Simulations with #Multi-#Fidelity #Bayesian #Optimization","description":"Optimizing #Reactor and #Tube Simulations with #Multi-#Fidelity #Bayesian #Optimization \ud83e\uddea\ud83d\udcbb\ud83d\udd2c\n\nDesigning highly parameterized chemical reactors can be a challenging and expensive task, but a new study by Tom Savage et al has presented a promising solution. By formulating the design of a helical-tube reactor as a multi-fidelity black-box optimization problem, researchers were able to create a framework that takes advantage of different quality #simulations to enhance #optimization via #MultiFidelity #Bayesian #optimization. They derived a new criterion for monitoring progress and dictating termination of the optimization, ensuring a high-fidelity solution is returned before the computational budget is exhausted. The team successfully applied this framework to optimize a helical-tube reactor geometry and operating conditions, which were then #3D #printed and #experimentally #validated for performance. This study demonstrates the potential of 3D printing and simulation-based optimization in advancing the design of highly parameterized chemical reactors. Future work will investigate alternative reactor parameterizations and longer classes of reactors, as well as optimizing different performance indicators. This approach is extensible to a wide range of simulation-based design problems, offering new opportunities for rapid prototyping and optimization in chemical engineering.\n\nCongratulations to Tom Savage, Nausheen Basha, Jonathan McDonough, Omar Matar, and Ehecatl Antonio del Rio Chanona on this innovative piece of work! \n\n\ud83d\udd17Link to #Github: https:\/\/lnkd.in\/eyXsAiCe\nLink to Publication: https:\/\/lnkd.in\/eEZmPjT6\n","linkedinURL":"https:\/\/www.linkedin.com\/feed\/update\/urn:li:activity:7059851023263092737","githubURL":null,"paperURL":null,"author":"Antonio Benedetti","createdDate":"05\/04\/2023"},{"title":"The title is: PyPhi 3.0: A New Release of the Powerful OpenSource Tool for Multivariate Analysis","description":"#PyPhi 3.0: A New Release of the Powerful #OpenSource Tool for #Multivariate #Analysis \ud83c\udfaf\ud83d\udd2c\ud83d\udcca\ud83d\udcbb\n\nThe PyPhi toolbox for multivariate analysis has released its latest version, PyPhi 3.0, which includes several exciting new features. Developed by Salvador Garc\u00eda Mu\u00f1oz , PyPhi is a comprehensive tool for researchers working with complex datasets and seeking to extract meaningful insights from them.\n\nPyPhi 2.0 already included several powerful tools such as Principal Components Analysis (PCA), Projection to Latent Structures (PLS), Locally Weighted PLS (LWPLS), Savitzy-Golay derivative and Standard Normal Variate pre-processing for spectra. But PyPhi 3.0 takes this a step further by including the LPLS model by Muteki, as well as the JRPLS and TPLS models. These new models allow researchers to analyze materials, processes, and products in even greater detail.\n\nOne of the most exciting additions to the suite of tools is the Batch Analysis. This new feature makes it much easier to analyze large datasets by aligning batch data using an indicator variable, generating batch descriptors, and calculating relative times. Researchers can also plot batch contributions to gain insights into how individual batches contribute to overall results.\n\nOverall, PyPhi is a powerful tool for researchers and practitioners interested in multivariate analysis. With its advanced features and intuitive interface, PyPhi makes it easier than ever to explore complex datasets and uncover meaningful insights from your process and product data.\n\nThank you Salvador for developing and making PyPhi available on #Github:\u00a0https:\/\/lnkd.in\/gikjBr2q \nHopefully, you will see this and the next releases on our upcoming Hub at www.polymodelshub.com ! Check our page out to learn more! #dataanalysis #datascience #models #chemometrics #researchtools","linkedinURL":"https:\/\/www.linkedin.com\/feed\/update\/urn:li:activity:7059552655433465857","githubURL":null,"paperURL":null,"author":"Antonio Benedetti","createdDate":"05\/03\/2023"},{"title":"The title is: PolyModels Hub","description":"\ud83d\ude80Building the Most Advanced #OpenSource Library of #Models for #Life #Sciences: #Register Now for PolyModels Hub! \ud83d\udcbb\ud83e\uddec\ud83e\udda0\ud83e\uddea\n\nPolyModels Hub started almost 6 months ago as a community for digital design and smart manufacturing. With almost 2000 followers and growing, we're excited to be building one of the most vibrant communities in this field.\nThrough our interactions with our PolyModellers, we've come to realize that there's a significant gap in the development of #opensource #models for the #LifeSciences industry. This has inspired us to develop something more than just a LinkedIn page.\n\nWe're thrilled to announce the #upcoming #launch of PolyModels Hub - a cutting-edge #community #platform that aims to drive #innovation in the Life Sciences industry through the power of #collaboration. Our mission is to democratize access to modeling and build the most advanced open-source library of models, facilitating the design, scale-up, transfer, and manufacturing of products and processes.\nBy bringing together industry and academic experts to collaborate on these challenges,  we're confident that we can help accelerate innovation and change the face of the life sciences industry.\n\nTo stay up-to-date with the latest news and be the first to know when we launch, be sure to register on our new landing page today! Visit https:\/\/lnkd.in\/gM-TRds7 to learn more and join our community.\n\n\ud83d\udd17#Register here: https:\/\/lnkd.in\/gM-TRds7\n\n#OpenSource #Models #LifeSciences #Gap #Community #Upcoming #Launch #Innovation #Collaboration #DemocratizeAccess #DigitalDesign #SmartManufacturing #PolyModelsHub #RegisterNow","linkedinURL":"https:\/\/www.linkedin.com\/feed\/update\/urn:li:activity:7059176511173509122","githubURL":null,"paperURL":null,"author":"Antonio Benedetti","createdDate":"05\/02\/2023"},{"title":"The title is: Accelerating Drug Development: An Efficient Computational Approach for API Coformer Screening.","description":"Accelerating Drug Development: An Efficient #Computational #Approach for #API #Coformer Screening\ud83d\udc8a\u2744\ufe0f\ud83d\udcbb\ud83d\udd2c\n\nCocrystallization is an essential aspect of drug product development, but the current state-of-the-art involves expensive and time-consuming experimental screening. A recent paper by Isaac Sugden et al proposes a systematic, high-throughput computational approach to identify API\/coformer pairs that are unlikely to form cocrystals. This new approach, which builds on a well-established crystal structure prediction methodology, could significantly reduce the experimental effort required.\nThe researchers tested their approach on 30 potential multicomponent systems, involving three active pharmaceutical ingredients and nine coformers. The approach accurately predicted five new cocrystals and a polymorphic example, which were then experimentally verified. This is excellent news for the industry as it suggests that a significant proportion of potential API\/coformer pairs can be quickly and efficiently eliminated, saving considerable experimental effort.\nThis paper demonstrates the power of computational approaches to accelerate drug development, especially in the early stages when API material is limited. By identifying unlikely pairs early on, researchers can focus on the most promising candidates, ultimately speeding up the drug development process. \n\nCongratulations and kudos to the authors of the paper Isaac Sugden, Doris Braun, David Bowskill, Claire Adjiman, and Costas Pantelides! We look forward to seeing further advancements in this area and the impact it will have on the pharmaceutical industry.\n\nLink to #Publication: https:\/\/lnkd.in\/enysqXpX\n#pharmaceuticalindustry #drugdevelopment #cocrystallization #modelling #screening #crystal #structure #prediction ","linkedinURL":"https:\/\/www.linkedin.com\/feed\/update\/urn:li:activity:7058754130403569665","githubURL":null,"paperURL":null,"author":"Antonio Benedetti","createdDate":"05\/01\/2023"},{"title":"The title is: Development of a Hybrid Deterministic Stochastic Model for Loss-in-Weight Feeder Dynamics in Continuous Drug Manufacturing Processes.","description":"Development of a #Hybrid #DeterministicStochastic #Model for #LossInWeight #Feeder #Dynamics in Continuous Drug Manufacturing Processes \ud83e\uddd1\ud83c\udffc\u200d\ud83d\udd2c\u2699\ufe0f\ud83d\udc8a\n\nLoss-in-weight (#LIW) feeders play a crucial role in #continuous #drug #product #manufacturing, ensuring accurate and consistent feeding of raw materials into the production process. These feeders operate on a loss of weight principle, which allows for precise control over the amount of material delivered, improving product quality and reducing waste. To design better processes and controllers, it's essential to have a computationally efficient #flowsheet #model that can accurately simulate the #stochastic behavior of a screw feeder in real-time.\nThis paper addresses this gap by proposing a model that leverages time series analysis and an Autoregressive Moving Average (#ARMA) model to simulate the observed non-random variation in feeder powder flow. The model was able to examine the deterministic model errors of three different volumetrically fed excipients, demonstrating that the errors are leptokurtic, heavy-tailed, and display a linear dependence on their prior two seconds of state. These errors are all reasonably modeled by an ARMA(2,1) model and are parametrically distinct from each other.\nOne of the key benefits of this approach is that it allows for improved process and controller design while being quick-to-solve, high-variance, and having a low experimental overhead. Additionally, the paper shows that refilling the feeder online significantly alters the error distribution, autocorrelation structure, and ARMA parameters.\nOverall, this research lays the groundwork necessary to model and predict the realistic feeder dynamics of a much broader range of powders and operating conditions. The findings have the potential to be a valuable tool for improving continuous drug manufacturing processes and ensuring consistent product quality.\n\nCongratulations to Brad Johnson, Maitraye Sen, Joshua Hanson, P.E.,\u00a0Salvador Garc\u00eda Mu\u00f1oz and\u00a0Nick Sahinidis for the results of this great collaboration!\n\nLink to #Publication: https:\/\/lnkd.in\/eE4CzXK5 ","linkedinURL":"https:\/\/www.linkedin.com\/feed\/update\/urn:li:activity:7058410813270695936","githubURL":null,"paperURL":null,"author":"Antonio Benedetti","createdDate":"04\/30\/2023"},{"title":"The title is: Learning to Love Machine Learning: A Personal Perspective on its Impact in Process Systems Engineering","description":"Learning to Love\u00a0#MachineLearning: A Personal Perspective on its Impact in\u00a0#Process\u00a0#Systems\u00a0#Engineering\u00a0\ud83e\udd16\ud83d\udcbb\ud83d\udc99\n\nIf you come from a traditional Process Systems Engineering (PSE) background, you have likely faced the dilemma of understanding the role of Machine Learning (ML) in the field over the last year. The hype surrounding the ML wave has stimulated innovation and excitement among neophytes, while also putting many conservatives on the defensive. The reality is that, like any new technology, it takes time to understand how to incorporate the best aspects of ML to maximize research or industrial application outcomes.\nIn his thought-provoking paper, Professor\u00a0Victor M Zavala\u00a0shares his personal journey and experiences with machine learning (ML) and explores how this rapidly evolving field is transforming process systems engineering (PSE). Zavala delves into the ways in which PSE can contribute to and benefit from the ML revolution while also emphasizing the importance of continuing to teach fundamental mathematical principles. Through anecdotes and insights, Zavala provides a fascinating glimpse into the impact of ML on PSE and the opportunities and challenges presented by this exciting field.\u00a0\nWhether you are a PSE researcher or simply curious about the intersection of ML and engineering, you won't regret reading this paper!\n\nLink to\u00a0#Paper:\u00a0https:\/\/lnkd.in\/g9q2cbyT\n\n#learning #technology #technology #innovation #ml # #research ","linkedinURL":"https:\/\/www.linkedin.com\/feed\/update\/urn:li:activity:7058052110524768256","githubURL":null,"paperURL":null,"author":"Antonio Benedetti","createdDate":"04\/29\/2023"},{"title":"The title is: Building Accurate and Interpretable Models with Sparse Linear Regression","description":"Building #Accurate and #Interpretable #Models with #Sparse #Linear #Regression \ud83d\udcca\ud83d\udcc8\ud83d\udcbb\n\nSparse estimators are essential in linear regression, as they help select a small subset of critical variables from a larger set of potential predictors. The goal is to build models that are both precise and understandable, making them easier to interpret.\nThere are numerous methods for building linear regression models, and none is guaranteed to perform well for any given problem. The article \"A Discussion on Practical Considerations with Sparse Regression Methodologies\" provides more information on the benefits and drawbacks of major methods.\nIt is a very interesting review article comparing benefits and drawbacks of major methodologies. The authors also provide an easy framework to build and compare linear regression models using various exciting methods such as Orthogonal Matching Pursuit and Elastic-Net. \n\n#Kudos to Owais Sarwar,\u00a0Benjamin Sauk and\u00a0Nick Sahinidis for publishing this great review article and making the tool available as #opensource package!\n\n\ud83d\udd17Link to #Github:\u00a0https:\/\/lnkd.in\/eKhtG8Q4\n\ud83d\udd17Link to #Publication:\u00a0https:\/\/lnkd.in\/e3dTJACT","linkedinURL":"https:\/\/www.linkedin.com\/feed\/update\/urn:li:activity:7057315437029535745","githubURL":null,"paperURL":null,"author":"Antonio Benedetti","createdDate":"04\/27\/2023"},{"title":"The title is: eQuilibrator 3.0: A Database Solution for Estimating Thermodynamic Constants of Biochemicals","description":"#eQuilibrator 3.0: A #Database #Solution for Estimating #Thermodynamic #Constants of #Biochemicals \ud83e\udda0\u2194\ufe0f\ud83d\udff0\ud83e\uddd9\u200d\u2642\ufe0f\n\nBiochemical systems are very complex with a large number of parameters and interactions. However, they are - like all of us - governed by a set of rules that make them amenable to modelling and simulation: The laws of thermodynamics!\neQuilibrator is a user-friendly web interface which facilitates thermodynamic analysis of biochemical systems.\nThe platform by the #Milo #Lab at the Weizmann Institute of Science in partnership with Novo Nordisk, ETH Z\u00fcrich, Northwestern University and Caltech allows users to search for compounds and reactions by name, and provides thermodynamic estimates for these compounds and reactions under different conditions.\neQuilibrator uses a group contribution approximation method to estimate the free energy of formation of compounds, which enables thermodynamic analysis of many biochemical reactions and pathways. It currently provides estimates for many compounds in the KEGG database and allows users to manipulate the conditions of a reaction to explore its thermodynamic landscape.\neQuilibrator 3.0 is out! Check it out at:\u00a0https:\/\/lnkd.in\/e-BrWfiA\n\nWe believe that tools like eQuilibrator make thermodynamic modelling more accessible to scientists. Kudos to all the contributors by Avi Flamholz, Elad Noor, Arren Bar-Even, Ron Milo, Moritz Beber,\u00a0Mattia Gollub,\u00a0Dana Mozaffari,\u00a0Kevin Shebek!\n\nLink to #GitLab:\u00a0https:\/\/lnkd.in\/efHkEn2V\nLink to #Publication:\u00a0https:\/\/lnkd.in\/eQhudBHW\n","linkedinURL":"https:\/\/www.linkedin.com\/feed\/update\/urn:li:activity:7056945020636913664","githubURL":null,"paperURL":null,"author":"Antonio Benedetti","createdDate":"04\/25\/2023"},{"title":"The title is: Open Reaction Database: A Centralized Schema and Infrastructure for Structuring and Sharing Organic Reaction Data","description":"Breaking Barriers in\u00a0#Chemical\u00a0#Reaction\u00a0#Data\u00a0#Management\u00a0and\u00a0#Sharing: Introducing the\u00a0#Open\u00a0#Reaction\u00a0#Database \ud83d\udcbe\ud83d\uddc2\ufe0f\ud83e\uddea\ud83d\udcbb\ud83d\udcbd\n\nHave you ever wondered how chemical reaction data is stored and shared among researchers? Well, it turns out that this data is often stored in various formats, making it unstructured and difficult to use in downstream applications like training machine-learning models. That's why a group of scientists has created the Open Reaction Database (#ORD), an\u00a0#openaccess\u00a0schema and infrastructure for structuring and sharing organic reaction data.\nThe ORD schema supports both conventional and emerging technologies, from benchtop reactions to automated high-throughput experiments and flow chemistry. By providing a centralized data repository, researchers can more easily access and share valuable information. Plus, all the data, schema, supporting code, and web-based user interfaces are publicly available on GitHub.\nThe\u00a0#goal\u00a0of the ORD is to enable downstream applications that will improve\u00a0#computer-aided\u00a0#synthesis\u00a0#planning,\u00a0#reaction\u00a0#prediction, and other\u00a0#predictive\u00a0#chemistry\u00a0tasks. With a consistent data representation and infrastructure to support data sharing, researchers can collaborate more effectively and train machine-learning models more accurately.\n\nThis is the result of a cross-industry effort across\u00a0Merck,\u00a0Pfizer,\u00a0Relay Therapeutics,\u00a0Google,\u00a0Massachusetts Institute of Technology,\u00a0UCLA\u00a0and\u00a0Caltech! Huge congrats to\u00a0Steven Kearnes,\u00a0Michael Maser,\u00a0Michael Wleklinski,\u00a0Anton Kast,\u00a0Abigail Doyle,\u00a0spencer dreher,\u00a0Joel Hawkins,\u00a0Klavs Jensen,\u00a0and\u00a0Connor W. Coley\u00a0for this excellent contribution. Our community will love this work !\n\nLink to\u00a0#Github:\u00a0https:\/\/lnkd.in\/eyjXmnsE\nLink to\u00a0#publication:\u00a0https:\/\/lnkd.in\/eKy5fBNr\n\n#technology\u00a0#datamining\u00a0#datamodeling\u00a0#infrastructure\u00a0#share","linkedinURL":"https:\/\/www.linkedin.com\/feed\/update\/urn:li:activity:7056587878889345024","githubURL":null,"paperURL":null,"author":"Antonio Benedetti","createdDate":"04\/25\/2023"},{"title":"The title is: Bayesian Approaches to Design Space Characterization in Drug Development: Embedding Uncertainty to Process Models\ud83d\udcbb\ud83d\udc8a\ud83c\udfaf","description":"#Bayesian Approaches to #Design #Space Characterization in #Drug Development: Embedding #Uncertainty to Process #Models\ud83d\udcbb\ud83d\udc8a\ud83c\udfaf\n\nThe #pharmaceuticalindustry is constantly seeking ways to improve drug development and manufacturing practices. One key aspect of this is ensuring Quality by Design (#QbD), which relies on accurate and reliable design space characterization. This is where Bayesian approaches come into play.\nWe recently came across an engaging collaborative work by researchers from Imperial College London, Slovak University of Technology, and Eli Lilly and Company. The paper, authored by Kennedy Putra Kusumo and colleagues, explores Bayesian approaches to design space characterization in pharma manufacturing.\nThe authors propose using #Nested #Sampling, a Monte Carlo technique, to determine the feasibility probability of a design space, allowing practitioners to assess reliability and risk. The algorithm maintains a set of live points through regions with increasing probability feasibility until reaching a desired reliability level. It also leverages efficient strategies from Bayesian statistics for generating replacement proposals during the search.\nThe paper goes on to discuss practical aspects of exploiting the sampled design space and illustrates the effectiveness of nested sampling on higher-dimensional problems. The industrial case studies mentioned in the article are particularly interesting, showcasing the potential of Bayesian approaches for design space characterization. The source code of the algorithm used for nested sampling is available as #opensource package. If you're involved in technical risk assessments of pharmaceutical products or simply want to learn more about Bayesian approaches to design space characterization, this paper is definitely worth a read.\n\nWe want to give a big kudos to the authors - Kennedy Putra Kusumo, Lucian Gomoescu, Radoslav Paulen, Salvador Garc\u00eda Mu\u00f1oz, Costas Pantelides, Nilay Shah, and Benoit Chachuat - for their excellent work. \n\nLink to #GitHub: https:\/\/lnkd.in\/e3c6_zjR \nLink to #Publication: https:\/\/lnkd.in\/eXE-ySKy\n\n#pharma #qualitybydesign #processsystemsengineering #montecarlo #nestedsampling #reliability #riskassessment #pharmaceutical #drugdevelopment ","linkedinURL":"https:\/\/www.linkedin.com\/feed\/update\/urn:li:activity:7056220244935073792","githubURL":null,"paperURL":null,"author":"Antonio Benedetti","createdDate":"04\/23\/2023"},{"title":"The title is: \"Rethinking Viral Production: How Computational Modelling Strategies are Transforming Biotechnology and Medicine\"","description":"Rethinking #Viral #Particle #Production: How #Computational #Modelling #Strategies are Transforming #Biotechnology and #Medicine \ud83e\udda0\ud83e\uddec\ud83d\udcbb\n\nViral systems, including wild-type viruses, viral vectors, and virus-like particles, are crucial components of modern medicine and biotechnology. However, current production methods are highly inefficient, making it challenging to develop new therapies and vaccines. A recent review by Christopher Canova et al has highlighted the potential of computational modelling strategies in improving the commercial-scale production of viral systems. \nImportantly, this review shows that computational strategies can offer a promising avenue for improving the development, optimization, and control of viral system production. The paper explores the use of mechanistic modeling strategies at the cellular and bioreactor scales to create suitable process models. The resulting models can then be used to test novel process operating strategies and advanced process control, all while minimizing the need for costly and time-consuming experiments.\nThe authors of the paper also emphasize the potential for adapting techniques and models from adjacent fields, such as epidemiology and wild-type viral infection kinetics. By taking an interdisciplinary approach, researchers can improve the efficiency of viral system production, ultimately leading to more effective therapies and vaccines.\n\n#Kudos to Christopher Canova, Pavan Inguva and Richard D. Braatz for this holistic view of the state-of-the-art of modelling applied to viral production processes. Our Polymodellers will enjoy the deep-dive!\n\nLink to #Publication: https:\/\/lnkd.in\/eTYMsugW","linkedinURL":"https:\/\/www.linkedin.com\/feed\/update\/urn:li:activity:7055905627742556160","githubURL":null,"paperURL":null,"author":"Antonio Benedetti","createdDate":"04\/23\/2023"},{"title":"The title is: Customizing #Metabolic #Models: Guidelines for Context-Specific Modeling using #Gene #Expression #Data","description":"Customizing #Metabolic #Models: Guidelines for Context-Specific Modeling using #Gene #Expression #Data \ud83e\uddec\ud83d\udcc8\ud83d\udd2c\ud83c\udf10\n\nGenome-scale metabolic models provide a comprehensive description of an organism's metabolism and can be customized using #omics data to model condition-specific physiology. However, the quality of context-specific models can be affected by both the choice of algorithm and parameters, as well as the existence of alternate context-specific models that equally explain the -omics data.\nThis paper by Saratram Gopalakrishnan et al. provides valuable insights into the impact of algorithm choice and topological properties on the extraction of context-specific metabolic models.\nThe study, which evaluated the performance of four different extraction algorithms, found that the scope of alternate models is strongly influenced by these factors. Interestingly, fatty acid metabolism and intracellular metabolite transport were identified as significant contributors to alternate solutions in all models.\nThe researchers also discovered that the metabolic tasks defining an organism's phenotype must be explicitly and quantitatively protected to ensure the quality of context-specific models. This highlights the importance of benchmarking -omics integration algorithms and the need for a systematic workflow to extract biologically relevant models.\nFurthermore, the study revealed that GIMME generated the best-performing models in E. coli, while mCADRE was better suited for complex mammalian models. \n\nCongratulations to Saratram Gopalakrishnan,\u00a0Chintan Joshi,\u00a0Miguel \u00c1. Valderrama-G\u00f3mez,\u00a0Elcin Icten-Gencer,\u00a0Pablo Rolandi,\u00a0Will Johnson,\u00a0Cleo Kontoravdi and\u00a0Nathan Lewis on this groundbreaking work! \n\nLink to #Publication: https:\/\/lnkd.in\/eaqrvXac\n\n#metabolicmodeling #genomescalemodels #omicsintegration #biologyresearch #algorithmchoice #researchinsights","linkedinURL":"https:\/\/www.linkedin.com\/feed\/update\/urn:li:activity:7055533208427229184","githubURL":null,"paperURL":null,"author":"Antonio Benedetti","createdDate":"04\/22\/2023"},{"title":"The title is: Combining Preprocessing and Regression for Chemometric Modeling: A Single Optimization Framework","description":"A Single #Optimization \ud83e\udd47 Combining #Preprocessing and #Regression for #Chemometric #Modelling \ud83d\ude80\n \nChemometric methods play a crucial role in the #chemical and #biochemical sectors. #Chemometrics can support monitoring and control of complex systems, and regression models based on dimensionality reduction techniques (e.g., projection to latent structures, #PLS, regression) can be built starting from chemometric data. The effectiveness of these models generally depends heavily on the preprocessing of #data, which can significantly influence the regression model and its predictive ability. Data preprocessing can also play a crucial role on the interpretability and explainability of a chemometric model. This is particularly important in the modern (bio)#pharmaceutical sector, with the advent of process analytical technology (#PAT) framework and quality by design (#QbD) paradigms.\n \nIn this context, Chryssa Kappatou et al. recently presented an approach consisting of coupling preprocessing decisions and model parameter estimation in a single optimization step. The proposed framework enables the simultaneous optimization of both accuracy and robustness properties in chemometric models. The optimization problem allows to get optimal decision variables when it comes to data pretreatment, while an optimal number of latent components is selected concerning the underlying latent variable regression model (PLS). Model accuracy was evaluated based on the difference between model predictions and observed values for the response variable (output), while the authors introduced a novel metric for quantifying robustness to known data variability (i.e., towards overfitting). Chryssa and co-workers validated the proposed approach in a simulated case as well as in an #industrial case study.\n \nMany congratulations to the authors for their innovative work, which offers a promising new direction for chemometric modeling research!\n \nChryssa Kappatou, James Odgers, Salvador Garc\u00eda Mu\u00f1oz, and Ruth Misener\n \nLink to #GitHub: https:\/\/buff.ly\/3UXwKuX \nLink to Publication: https:\/\/buff.ly\/3UXwKLt","linkedinURL":"https:\/\/www.linkedin.com\/feed\/update\/urn:li:activity:7055164643580813312","githubURL":null,"paperURL":null,"author":"Alberto Marchetto","createdDate":"04\/21\/2023"},{"title":"The title is:\n\n\"Generating #MachineLearning-ready Benchmarking #Datasets \ud83d\udcc2\ud83c\udf10 for #Network #Biology #Research \ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd","description":"Generating #MachineLearning-ready Benchmarking #Datasets \ud83d\udcc2\ud83c\udf10 for #Network #Biology #Research \ud83e\uddec\ud83e\uddeb with #nleval \n\n#Graph representation learning (GRL) methods have revolutionized many real-world applications, such as #DrugDiscovery and molecular property prediction. In particular, graph machine-learning approaches are used in network biology. Network biology is a discipline that has proven to be promising in understanding the relations between #genes and human #diseases. However, working with biological networks is challenging due to a lack of #standardisation and #transparency in the preprocessing steps required to set up machine learning-ready benchmarking #datasets. Popular benchmarking graph databases lack such accessibility in the exact processing pipelines.\n\nIn a recent breakthrough, Renming Liu and Arjun Krishnan have recently released nleval (name that stands for (biological) network learning evaluation), a #Python package which provides unified data (pre-)processing tools in order to prepare network biology datasets for ML-based models, comprising standardized data splitting strategies. Thanks to nleval it is possible to build a reproducible and transparent data processing pipeline, where each processing step is accessible and open to the users.\n\nCongratulations to the authors of this study for developing this package and for their contributions to advancing the field of network biology!\n\nLink to #GitHub: https:\/\/lnkd.in\/dcMVVHxy\nLink to Publication: https:\/\/lnkd.in\/dzFjhNjB\n","linkedinURL":"https:\/\/www.linkedin.com\/feed\/update\/urn:li:activity:7054819852909223936","githubURL":null,"paperURL":null,"author":"Alberto Marchetto","createdDate":"04\/20\/2023"},{"title":"The title is: Construct, Simulate and Calibrate Dynamical Systems Efficiently \u23f1\ufe0f in #Python \ud83d\udc0d with #pySODM \ud83d\udcbb\ud83d\ude80","description":"Construct, Simulate and Calibrate Dynamical Systems Efficiently \u23f1\ufe0f in #Python \ud83d\udc0d with #pySODM \ud83d\udcbb\ud83d\ude80\n\nIf you work with differential equations to model and simulate complex dynamical systems, you will want to check out pySODM. This powerful tool was recently presented by Tijs Alleman et al. and it makes it easier than ever to implement, simulate, and calibrate a dynamical system with n-dimensional states represented by coupled ordinary differential equations (#ODEs) in Python.\nWith pySODM, you can quickly and easily translate real-world phenomena into a set of differential equations, analyze their structural identifiability, and implement them using a programming language. You can then use calibrate some of the model parameters (even time-dependent ones) from a set of experimental data, verify the goodness-of-fit, and analyze the distributions of the resulting model parameters. pySODM also allows you to gain further insights into the process or make robust projections beyond the calibrated range. \n\nThe authors showcased pySODM features and capabilities through two case studies from different research domains. In the first case study, the reaction rate of the esterification of D-Glucose and Lauric acid using an immobilized #enzyme is calibrated from eight #batch experimental data, taken at different conditions. The calibrated kinetic model is therefore used to predict the product yields in a tubular, continuous-flow reactor packed with the enzyme. The second case study concerned the calibration of a stochastic, age-stratified model for #Influenza to data collected in the period 2017-2018 in Belgium. \n\nBy reducing the time needed to go through this workflow, pySODM enables #scientists and #engineers to focus on what really matters: solving complex problems and gaining new insights from them. So why not give pySODM a try and see how it can make your dynamical system modelling more productive and efficient?\n\nKudos to Tijs Alleman, Christian Stevens\u00a0and Jan Baetens\n\nLink to #GitHub: https:\/\/lnkd.in\/d_pawDZj\nLink to Publication: https:\/\/lnkd.in\/dhre7Hyw","linkedinURL":"https:\/\/www.linkedin.com\/feed\/update\/urn:li:activity:7054495413147492352","githubURL":null,"paperURL":null,"author":"Alberto Marchetto","createdDate":"04\/19\/2023"},{"title":"The title is: UQLab: Make Uncertainty Quantification Available for Anybody, in Any Field of Applied Science and Engineering","description":"#UQLab: \u201cMake #Uncertainty Quantification Available for Anybody, in Any Field of Applied #Science and #Engineering\u201d\n\nQuantifying uncertainty is a crucial aspect in countless applications and it involves several #modelling elements. To guarantee a broad accessibility of uncertainty quantification tools to researchers and scientists across different disciplines, a research team at Eidgen\u00f6ssische Technische Hochschule Z\u00fcrich, composed by Prof. Bruno Sudret et al., developed UQLab. UQLab is a general purpose framework written in #Matlab that connects #opensource scientific modules with the aim to carry out different types of uncertainty quantification analyses. Among them, UQLab allows users to perform Monte Carlo simulations, sensitivity analyses, reliability analyses (i.e., computations of rare event probabilities), surrogate modelling (such as polynomial chaos expansions, #Kriging, etc.), #Bayesian inversion\/calibration, etc. The huge potential of UQLab was confirmed by the fact that, as of October 2021, 4,000 users had registered to it.\n\nThe idea behind UQLab was to \u201cMake uncertainty quantification available for anybody, in any field of applied science and engineering\u201d. That is why Prof. Sudret\u2019s team decided to allow users who do not use Matlab to access the functionalities of UQLab. In particular, they realised UQCloud, a #cloud-based web API that allowed them to introduce language-specific bindings to a wide range of programming languages. The first of them was UQ[Py]lab, a\u00a0#Python\u00a0cloud-based version of UQLab, currently under beta testing since 2021. The result is the possibility to use all UQLab functionalities in any Python environment of choice! \n\nCheck it out at\u00a0https:\/\/lnkd.in\/dtgG3jky\nLink to #Jupyter notebook examples of UQ[Py]Lab: https:\/\/lnkd.in\/db6D6KAX","linkedinURL":"https:\/\/www.linkedin.com\/feed\/update\/urn:li:activity:7054117121752018945","githubURL":null,"paperURL":null,"author":"Alberto Marchetto","createdDate":"04\/18\/2023"},{"title":"The title is: Efficient Process Development in Biopharmaceutical Manufacturing: A Novel Model-based Framework","description":"\ud83d\ude80 Efficient Process Development in #Biopharmaceutical #Manufacturing \ud83e\uddec\ud83d\udc8a. A Novel Model-based Framework \ud83d\udcbb\ud83d\udd0e Developed at Imperial College London \n\n(Bio)pharmaceutical manufacturing involves complex and critical processes that require extensive experimentation for the identification of optimal operating conditions. Process development is typically associated with lengthy wet-lab experiments, which can be time-consuming and costly. #QualitybyDesign (#QbD) initiatives can come to help: one of the key advantages offered by QbD is the possibility to identify a process operating space \u2013 the design space \u2013 defined by sets of \u201cgood\u201d process conditions, i.e., conditions within which the process is guaranteed to meet the target product specifications. That is not all: computer-aided tools can be combined with the QbD principles, leading to the so-called Quality by Digital Design (#QbDD). In QbDD process design and the choice of operating conditions are supported by computational models and tools that also guide wet-lab validation and testing.\n\nWithin that framework, Steven Sachio and co-workers recently introduced a model-based framework to assist #QbDD by identifying and assessing process design spaces. The proposed framework comprises three main steps: model development and problem formulation, design space identification, and design space analysis. The proposed framework allows to rapidly identify and visualise the design space, and compare operating alternatives based on their performance, flexibility and robustness. The authors applied the framework to a Protein A #chromatography separation of #antibody-based #therapeutics from cell-derived impurities, demonstrating its potential in the biopharmaceutical manufacturing industry. \n\nThis work is a perfect example of how research and innovation can lead to more efficient, quicker and cost-effective process development in the (bio)pharmaceutical sector!\n\nCongratulations to: Steven Sachio, Cleo Kontoravdi, and Maria Papathanasiou \n\nLink to associated #GitHub repo (dside): https:\/\/lnkd.in\/dS3aGp7d\nLink to Publication: https:\/\/lnkd.in\/dEKws7jU","linkedinURL":"https:\/\/www.linkedin.com\/feed\/update\/urn:li:activity:7053783894428459008","githubURL":null,"paperURL":null,"author":"Alberto Marchetto","createdDate":"04\/17\/2023"},{"title":"The title is: Developing Efficient Hybrid Models and Sorption Discovery Models for Complex Systems: A Scientific Machine Learning Study using Julia.","description":"Developing Efficient #Hybrid #Models and #Sorption #Discovery #Models for Complex Systems: A Scientific Machine Learning Study using #Julia \ud83d\udcbb\ud83d\udd0d\ud83d\udcc8\ud83d\ude80\n\nIn this post, we're sharing a new study conducted using Julia. If you miss one of our previous episodes, Julia is a high-performance programming language created by a #community of researchers, scientists, and developers to address the need for a language that could handle #complex #numerical and #scientific #computing tasks. It combines the simplicity and syntax of dynamic languages like Python with the speed of compiled languages like C++. Julia is known for its ability to solve large-scale mathematical problems and has become increasingly popular in the scientific computing community due to its impressive performance and ease of use.\n\nIn this recent study by Vinicius Santana et al., they introduced a systematic machine learning approach for developing efficient hybrid models and discovering sorption uptake models in non-linear advection-diffusion-sorption systems. This approach utilizes gradient-based optimizers, adjoint sensitivity analysis, and JIT-compiled vector Jacobian products, along with spatial discretization and adaptive integrators.\nSparse and symbolic regression techniques were employed to identify missing functions in the artificial neural network, and the proposed method was tested on an in-silico data set of noisy breakthrough curve observations of fixed-bed adsorption. The results looks exciting, as the study successfully reconstructed sorption uptake kinetics and accurately predicted breakthrough curves using identified polynomials.\n\nThis study has highlighted the potential of the proposed framework for identifying sorption kinetic law structures, and it is a significant step forward in the development of efficient hybrid models in complex systems. Kudos to Vinicius Santana,\u00a0Erbet Costa,\u00a0Carine Rebello,\u00a0Ana Mafalda Ribeiro,\u00a0Chris Rackauckas and\u00a0Idelfonso B. R. Nogueira for their groundbreaking research! \n\nLink to Publication: https:\/\/lnkd.in\/eTuSpbtw\n\n#machinelearning #hybridmodels #sorptionkinetics #research #science\n","linkedinURL":"https:\/\/www.linkedin.com\/feed\/update\/urn:li:activity:7053309043154546688","githubURL":null,"paperURL":null,"author":"Antonio Benedetti","createdDate":"04\/16\/2023"},{"title":"The title is: A Novel Two-Stage Shelf Temperature #Optimization Approach for #FreezeDrying","description":"A Novel Two-Stage Shelf Temperature #Optimization Approach for #FreezeDrying \ud83d\udc8a\ud83c\udf21\ufe0f\u2744\ufe0f \n\nFreeze-drying (also called #lyophilization) is a critical step in the manufacturing of #biopharmaceuticals, but it is also known for being time and cost-intensive. One of the most challenging aspects of freeze-drying is the primary #drying phase, which is also a highly energetically demanding step. During primary drying it is important to keep the process advantageous from a time perspective, while avoiding an excessive temperature increase in the system. Indeed, this would lead to the collapse of the product, due to the critical temperature of the formulation being exceeded.\n\nRecently, Brecht Vanbillemont et al. proposed a novel two-stage shelf temperature #optimization approach that maximizes sublimation during primary drying without risking product collapse. Experiments were conducted to obtain high-resolution variability data of process parameters such as the heat transfer coefficient, vial dimensions, and dried layer resistance, which were then incorporated into an uncertainty analysis.\n\nThe authors verified the methodology using two formulations, allowing for either aggressive or conservative freeze-drying conditions, with very satisfactory results. This research is a significant step forward in freeze-drying process optimization, ensuring that the #biopharmaceutical industry can manufacture products that are both effective and economical!\n\nCongratulations to the team: Brecht Vanbillemont, Anna-Lena Greiner, Vanessa Ehrl, Tim Menzen, Wolfgang Friess, Andrea Hawe\n\nLink to Publication: https:\/\/lnkd.in\/erJzjY45","linkedinURL":"https:\/\/www.linkedin.com\/feed\/update\/urn:li:activity:7052981158321516544","githubURL":null,"paperURL":null,"author":"Alberto Marchetto","createdDate":"04\/15\/2023"},{"title":"The title is: Boosting Property Predictions for Short Peptides through a Serverless System","description":"\ud83d\ude80 Boosting Property Predictions \ud83d\udd2e for Short #Peptides \ud83e\uddec\ud83d\udc8a\ud83d\udd2c through a #Serverless System \ud83d\udca1\n\nAre you working with peptides and you are struggling to predict important peptide properties you need? Mehrad Ansari and Andrew White at University of Rochester have developed three novel #deeplearning models that predicts short peptide properties such as hemolysis, solubility, and resistance to nonspecific interactions. Among them, a sequence-based solubility predictor, named #MahLooL, outperforms the current state-of-the-art methods for short peptides. The models have been implemented as a static website without needing to rely on a dedicated #server or #cloud #computing service. In particular, the trained models are built using #JavaScript and are loaded to a user\u2019s web browser. This means that the models included in this package are easily accessible, reproducible, and can be used on a wide range of devices such as local machines and even mobile phones. This serverless system means that you do not need to worry about any limitations associated with third-party servers, such as their upkeep and maintenance, as well as any dependence on cloud providers. The code and models are open source and available on #GitHub for anyone to use!\n\nKudos to Mehrad and Andrew!\n\nLink to GitHub:\u00a0https:\/\/lnkd.in\/eSkmY9tk\nCheck out the demo at:\u00a0https:\/\/peptide.bio\/","linkedinURL":"https:\/\/www.linkedin.com\/feed\/update\/urn:li:activity:7052580728810692608","githubURL":null,"paperURL":null,"author":"Alberto Marchetto","createdDate":"04\/14\/2023"},{"title":"The title is: Unlocking the Power of Digital Process #Kinetics Modelling: Introducing the Reaction Mechanism Generator (#RMG) for Accurate Chemical Property \ufffd\ufffd\ufffd\ufffd\ufffd\ufffd","description":"Unlocking the Power of Digital Process #Kinetics Modelling: Introducing the Reaction Mechanism Generator (#RMG) for Accurate Chemical Property \ud83e\uddea\u2697\ufe0f Prediction \ud83d\udd2e\n\nModelling the kinetics of a reactive system is of paramount importance in many industrial applications, including #combustion, #pyrolysis and complex #pharmaceutical product syntheses. Often, these processes involve complex reactions between many intermediate species, and both #thermodynamics and transport phenomena must be carefully accounted for. Especially combustion models can become very difficult to build manually, due to the very high number of species involved. This makes digital tools, such as automatic reaction mechanism generation codes, particularly important for this task. \n\nThe #opensource #Python package RMG-Py (Reaction\u00a0Mechanism\u00a0Generator) was developed by Prof. William Green\u2019s research group at Massachusetts Institute of Technology and Prof. Richard West's group at Northeastern University to help chemists and engineers model kinetic mechanisms through an automatic chemical mechanism generation. RMG works by considering thermochemistry properties estimated through Benson group additivity method and a collection of known kinetic rate rules and reaction templates. RMG can also generate heterogeneous #catalysis models, and methods for local and global uncertainty analysis have been recently implemented in addition to the previous features. The RMG database of thermochemical and kinetic parameters has undergone significant expansions and can now cover many types of chemistry. Parallelization has also been made possible to allow for faster computational modelling. In addition to the open-source #GitHub repository, all the information and properties that RMG can provide are easily accessible through a graphical user interface (#GUI) (link below). \n\nWith RMG, constructing complex chemical kinetic mechanisms has never been easier. Stay ahead of the curve by incorporating this powerful tool into your research today!\n\nLink to GitHub: https:\/\/lnkd.in\/eQ3Q3hBj\nLink to GUI: https:\/\/rmg.mit.edu\/\n","linkedinURL":"https:\/\/www.linkedin.com\/feed\/update\/urn:li:activity:7052291191073050624","githubURL":null,"paperURL":null,"author":"Alberto Marchetto","createdDate":"04\/13\/2023"},{"title":"The title is: bletl - A Python Package for Streamlined Data Analysis of High-Throughput Microbioreactor Data","description":"\ud83d\ude80 Empowering #Microbiologists and #Bioprocess #Engineers: Introducing #bletl - A Python Package for Streamlined #Data #Analysis of #HighThroughput  #Microbioreactor Data  \ud83d\udcbb\ud83e\uddec\ud83d\udd2c\ud83c\udf31\ud83d\udcca\n\n#Microbioreactor (MBR) devices have become popular for #microbial phenotyping and bioprocess characterization, as they provide a wealth of online process #data in a highly parallelized manner. However, interpreting such datasets can be a tedious and time-consuming task for manual workflows.\n\nIn this study, we present #bletl, an #opensource #Python package that makes data analysis and machine learning techniques accessible without the need for extensive data parsing and preprocessing. With bletl, users can easily read raw result files from BioLector I, II, and Pro devices, and apply standard tooling from the Python scientific computing ecosystem. The package also provides interactive visualizations and spline-based derivative calculations, making it a powerful tool for time series analysis.\nIn addition, the study presents a new method for unbiased quantification of time-variable specific growth rate based on unsupervised switchpoint detection with Student-t distributed random walks. With an adequate calibration model, this method enables practitioners to quantify time-variable growth rate with Bayesian uncertainty quantification and automatically detect switch-points that indicate relevant metabolic changes.\nFinally, the study demonstrates how time series feature extraction enables the application of machine learning methods to MBR data, resulting in unsupervised phenotype characterization. As an example, Neighbor Embedding (t-SNE) is performed to visualize datasets comprising a variety of growth\/DO\/pH phenotypes.\n\nCongratulations to Michael Osthege ,\u00a0Niklas Tenhaef,\u00a0Rebecca Zyla,\u00a0Carolin M\u00fcller,\u00a0Johannes Hemmerich,\u00a0Wolfgang Wiechert,\u00a0Stephan Noack and\u00a0Marco Oldiges. This is a wonderful and well structure package that can have numerous applications in the #bioprocess industry. Our Community will love it \ud83d\udc99\n\n\ud83d\udc49Link to #Github: https:\/\/lnkd.in\/euTeqhHU \n\ud83d\udc49Link to #OpenAccess Publication: https:\/\/lnkd.in\/ex4Hc2DA \n\n#dataanalysis #machinelearning #community #bioengineering #modeling #dataandanalytics ","linkedinURL":"https:\/\/www.linkedin.com\/feed\/update\/urn:li:activity:7051887048760152064","githubURL":null,"paperURL":null,"author":"Antonio Benedetti","createdDate":"04\/12\/2023"},{"title":"The title is: Chemotools","description":"Crack Open This Easter Egg-straordinary Gift: #Chemotools, a Spectral Preprocessing #python Package!\" \ud83d\udc30\ud83c\udf81\ud83e\udd5a\ud83d\udcc9\n\nToday we are excited to share with you #Chemotools, an #opensource  #Python package for spectral preprocessing techniques. This package is the result of spectacular Easter project by Pau Caba\u00f1eros L\u00f3pez! \nThe package integrates with scikit-learn API and includes various preprocessing algorithms such as baseline correction, derivative, smoothing, scaling, and scatter correction. You can find more details about the algorithms and the content in the Github Doc page below.\nWe share the hope of the author that this project will serve as a useful resource for anyone interested in learning more about spectral preprocessing and machine learning. We also encourage contributions from the community, whether through bug reports, feature requests, or pull requests, to help us make this project even better.\nCheck out the link below for more information, and feel free to share with your network!\n\nHuge congratulations to Pau Caba\u00f1eros L\u00f3pez for this outstanding work. We hope that it will be greatly appreciated by our Polymodellers \ud83d\ude09 \n\n\ud83d\udc49Link to #Github Package: https:\/\/lnkd.in\/eMiMJZM8 \n\ud83d\udc49Link to Github Doc Page:  https:\/\/lnkd.in\/ejKg5yVx\n\n#python #spectralpreprocessing #scikitlearn #datascience #chemometrics #opensource #spectroscopy  ","linkedinURL":"https:\/\/www.linkedin.com\/feed\/update\/urn:li:activity:7051522775496167425","githubURL":null,"paperURL":null,"author":"Antonio Benedetti","createdDate":"04\/11\/2023"},{"title":"The title is: Accelerating #DrugDiscovery with #DeepDock: A collaboration between The Janssen Pharmaceutical Companies of Johnson & Johnson and Imperial College London","description":"Accelerating #DrugDiscovery with #DeepDock: A collaboration between The Janssen Pharmaceutical Companies of Johnson & Johnson and Imperial College London\n\nWe have already seen how big the chemical space of drug-like molecules is (remember? 10^60 feasible species have been estimated to exist!). This makes the development of new drugs an extremely complex and costly process that requires an in-depth understanding of the interactions between ligands and their molecular targets, as these are recognised to be driving forces of drug potency and selectivity. \n\nRecently, Oscar M\u00e9ndez-Lucio and co-workers released DeepDock, a methodology based on geometric deep learning that aims to predict the binding conformation of ligands to #protein targets. DeepDock works by learning a statistical potential using a distance likelihood and is tailored to each ligand-target complex. This potential can then be coupled with global optimization algorithms to reproduce the experimental binding conformations of ligands. \nTo achieve that, DeepDock was trained using experimental data of ligands binding to protein targets taken from a free database (PDBbind). The model represents the protein target as a polygon mesh, embedding the target molecular surface. Four properties are encoded in each node of the mesh: electrostatics, hydropathy, hydrogen-bond donor\/acceptor and a shape index. On the other hand, in the mesh edges connectivity information between nodes is encoded. The ligand is instead represented through a common molecular graph, where atoms correspond to nodes and bonds to graph edges.\n\nThis research shows that the method performs similarly or better than well-established scoring functions for #docking and #screening tasks. This is a significant improvement in the field of structure-based drug design and represents a promising avenue for future drug discovery. The use of #ArtificialIntelligence (#AI) in drug design has the potential to revolutionize the field and accelerate the development of new drugs. \n\nCongrats to the authors for their important contribution to the field of drug design and their use of innovative techniques to address this critical issue!\n\nOscar M\u00e9ndez-Lucio, Mazen Ahmad, Ehecatl Antonio del Rio Chanona and Joerg Kurt Wegner\n\nLink to #GitHub: https:\/\/lnkd.in\/eKzm572m\nLink to #Nature Publication: https:\/\/lnkd.in\/eQ9z4CyB","linkedinURL":"https:\/\/www.linkedin.com\/feed\/update\/urn:li:activity:7051130356086759424","githubURL":null,"paperURL":null,"author":"Alberto Marchetto","createdDate":"04\/10\/2023"},{"title":"The title is: How Computational Fluid Dynamics, Thin Film Flow Simulations, and the Mixture Model Can Assist Oral Solid Dosage Form Manufacturing?","description":"How can Computational Fluid Dynamics #CFD, thin film flow #simulations, or the mixture #model for multiphase flow be used to assist Oral Solid Dosage Forms #OSD manufacture? \ud83d\udc8a \ud83c\udfed \n\nFor a sneak peak to the answer, do not miss out on this article by Harry Christodoulou, Eva Sorensen, A.S Khair, Salvador Garc\u00eda Mu\u00f1oz and Luca Mazzei. A great collaboration among UCL, Carnegie Mellon University and Eli Lilly and Company. \n\nManufacturing oral solid dosage forms, such as tablets, poses various challenges including achieving uniform drug content, developing a uniform coating layer, ensuring consistent release profiles, addressing issues related to solubility and bioavailability, and maintaining the integrity of the dosage form during storage. These challenges require careful formulation design, process optimization, and quality control measures to ensure safe and effective drug products for patients. It sounds like advanced modelling techniques need to be utilized!\n\nOn this topic, the team has developed a comprehensive model that simulates the behaviour of a liquid-particle suspension on the surface of a tablet during the pharmaceutical coating process. The model employs the mixture modelling approach and the lubrication approximation method to precisely capture how the coating suspension moves and dries on the tablet surface, considering important physical properties such as density and viscosity that change as the carrier fluid evaporates. This provides valuable insights into the underlying mechanisms at play. \n\nAdditionally, Christodoulou et al.'s work accounts for the absorption of the coating suspension inside the core of the porous tablet, which yields the tablet water content, a key quantity that characterizes the coating process. \n\nCongrats to the authors! Their comprehensive approach adds a crucial dimension to our understanding of the #pharmaceutical #coating process.\n\nLink to the publication: https:\/\/lnkd.in\/euaunM_8","linkedinURL":"https:\/\/www.linkedin.com\/feed\/update\/urn:li:activity:7050785322023968769","githubURL":null,"paperURL":null,"author":"Harry Christodoulou","createdDate":"04\/09\/2023"},{"title":"The title is: Optimizing Evaporation Processes in Pharmaceuticals: Exploring Advanced Model Predictive Control Strategies","description":"Optimizing #Evaporation Processes in #Pharmaceuticals: Exploring Advanced #Model #Predictive #Control Strategies\u2697\ufe0f\ud83d\udca7\ud83d\udcbb\ud83d\udd01\n\nDespite the advancements in technology and automation, the pharmaceutical industry still relies on basic process control systems. This has resulted in inefficiencies and increased costs, highlighting the need for more advanced control techniques in order to stay competitive, become more sustainable and meeting supply chain variation in demand.\nOn this topic, a recent paper has been published on the development of #advanced #control strategies for the control of #concentration inside a #continuous Evaporation process at Eli Lilly and Company. The paper describes the design and implementation of three different control strategies, including PID control, MPC Control - EPSAC, and multi-parametric model predictive control (mp-MPC).\nTo test the performance of the designed controllers, the researchers used the #model developed in their previous work and tested for reference tracking, step changes in references, and disturbances on the input concentration. The controllers were designed for a mixture of fenofibrate, ethanol, and water, where the concentration of H2O and API are the outputs that the researchers aimed to control.\nThe results showed that the PI controller and the mp-MPC controller performed well, showing no significant overshoot or undershoot, fast settling time, even when tested on different mixtures than the one it was initially designed on.\nThe researchers also explored ways to improve the performance of the designed controllers, including implementing advanced control structures such as cascade, feedforward or ratio control, static decoupling for the PID control, and tuning different parameters for the model predictive controllers, such as different prediction horizon and different values for lambda.\nOverall, the paper represents the first step towards the development of advanced model predictive controllers that can work with different #molecules and different thermodynamics scenarios without redoing the process design and process control steps. The user only needs to give the controller the corresponding #thermodynamic #properties of the new molecule to be used, as well as the target setpoint values and possible constraints.\n\nThis research has exciting potential to improve process control systems in the pharmaceutical industry. Huge congratulations to the authoring team Ioana Nascu, Nikolaos Diangelakis, Salvador Garc\u00eda Mu\u00f1oz and Stratos Pistikopoulos\u00a0for pushing the boundaries in this field.\n\nLink to #Publication: https:\/\/lnkd.in\/eqffcWv9\n\n#pharmaceuticalindustry #research #development #MPC #digital #modelling ","linkedinURL":"https:\/\/www.linkedin.com\/feed\/update\/urn:li:activity:7050438118444789760","githubURL":null,"paperURL":null,"author":"Antonio Benedetti","createdDate":"04\/08\/2023"},{"title":"The title is: Optimizing #VOC Abatement in #Pharmaceutical Manufacturing: A #Dynamic #Modeling and #Theoretical #Performance Analysis Approach","description":"Optimizing #VOC Abatement in #Pharmaceutical Manufacturing: A #Dynamic #Modeling and #Theoretical #Performance Analysis Approach \ud83c\udfed\ud83c\udf43\u267b\ufe0f \n\n#Sustainability is increasingly becoming a critical priority for manufacturing companies worldwide. Protecting the #environment and society should be a top priority for all, but it is particularly crucial for the #healthcare industry to lead the way in this effort given its mission-driven focus on creating value for society. For example, GSK decided to set new environmental goals of #NetZero impact on climate and net positive impact on nature by #2030.\nThe use of volatile organic compounds (VOCs) in the pharmaceutical industry is widespread and poses significant risks to the environment and human health if not managed properly. Can modelling contribute to this objective?\n\nIn this recent paper by ,  use of activated carbon (AC) beds for selectively removing VOCs from gas effluent streams.\nThe paper presents a dynamic, non-isothermal adsorption model used to study binary VOC mixture adsorption on industrial AC beds for various structural and operating conditions. The model enables a scenario-based investigation of binary mixture behavior and examines the effect of key parameter changes on bed performance through multiple dynamic simulations, experimental corroboration, and predictive formulas.\nThe paper also employs theoretical bed performance analysis using Glueckauf hodographs to provide valuable insights into nonisothermal VOC capture bed operation, both for clean and used beds. By understanding how AC beds behave under different conditions, it is possible to optimize their performance and minimize the risks associated with VOC use.\n\n#Kudos to Vasiliki Tzanakopoulou,\u00a0Mike Pollitt,\u00a0Daniel\u00a0Castro-Rodriguez,\u00a0Alexandra Costa and Dimitrios I. Gerogiorgis.\n\nLink to Publication: https:\/\/lnkd.in\/etjXgS2P","linkedinURL":"https:\/\/www.linkedin.com\/feed\/update\/urn:li:activity:7050121848897843200","githubURL":null,"paperURL":null,"author":"Antonio Benedetti","createdDate":"04\/07\/2023"},{"title":"The title is: glyXtoolMS","description":"Introducing #glyXtoolMS: A Versatile Software Suite \ud83d\udcbb for #Glycoproteomic Analysis \ud83e\uddeb\ud83d\udd0e\n\u00a0\nThe goal of #glycoproteomics is to understand how #glycosylation, i.e., the attachment of #carbohydrates to #proteins, influences biological processes by analyzing #peptide sequences, glycan structures and modification sites. Glycoproteomic analysis can be highly time-consuming and error-prone, especially when it comes to manually analyzing spectra and identifying #glycopeptides. Over the years, several web tools and packages have been introduced to support this process, but they often come with limitations. Existing products are usually tailored to a specific fragmentation technique and only present the final analysis results, which makes them more like black-box tools. This makes difficult or even impossible to manually inspect and correct intermediate results.\n\u00a0\nToday we would like to introduce you glyXtoolMS, an open-source glycopeptide analysis toolbox written in #Python that allows for the analysis, interpretation, and visualization of #glycopeptide #spectra. By dividing the analysis tasks into modular tools \u2013 each associated with given functions \u2013\u00a0glyXtoolMS gives users maximum flexibility and control over the progress of gylcoproteomic analyses. The glyXtoolMS toolbox includes filtering of fragment spectra, #insilico screening of #protein sequences to individuate glycopeptide candidates, precursor matching to possible glycan compositions and peptide sequences, and an annotation tool for glycopeptide fragment ions. The resulting analysis file can be visualized thanks to glyXtoolMSEvaluator, a tool that enables inspection, verification, and validation of results from the analysis pipeline (including results of each intermediate step). To demonstrate the effectiveness of glyXtoolMS, the authors used it to analyze N-glycopeptides derived from human immunoglobulin \u03b3 (IgG) and O-glycopeptide samples from human fibrinogen, with great results.\n\u00a0\nglyXtoolMS is a valuable addition to the glycoproteomic analysis toolbox, enabling researchers to analyze glycopeptides more efficiently and accurately. You can find the software suite on #GitHub and give it a try (link below)!\n\u00a0\nKudos to: Markus Pioch, Marcus Hoffmann, Alexander Pralow, Udo Reichl and Erdmann Rapp, Dr.\n\u00a0\nLink to GitHub: https:\/\/lnkd.in\/ee59hYV6\nLink to Publication: https:\/\/lnkd.in\/ekrFPvNd\n","linkedinURL":"https:\/\/www.linkedin.com\/feed\/update\/urn:li:activity:7049745644718043136","githubURL":null,"paperURL":null,"author":"Alberto Marchetto","createdDate":"04\/06\/2023"},{"title":"The title is: BioVL - An Online Educational Platform for Industry 4.0","description":"\ud83c\udf93\ud83c\udf10\ud83d\udcbb Revolutionizing #Engineering #Education: Introducing #BioVL, an Online Educational Platform for Industry 4.0 \ud83d\ude80\ud83d\udd2c\n\nIndustry 4.0 is no longer a distant concept but an ongoing paradigm shift. It's essential to prepare future engineers by fine-tuning our current educational approach. Advanced modelling, programming, and data analysis are now becoming fundamental skills. Therefore, it's crucial to integrate these elements\/subjects into the graduate and undergraduate curriculums.\nTo make the learning experience dynamic and active, educational computer-aided tools could be an excellent platform to teach fundamental engineering concepts and other essential tools for digitalization. \n\nToday we want to talk about #BioVL, an online and #opensource educational computer-aided platform\/simulator which has been developed with the purpose of filling this educational gap.\nBioVL is built upon a three-pillar strategy that includes identifying learning requirements, a learning design, and a motivation strategy that includes gaming elements and an agile microlearning approach. Currently, BioVL is in its prototype stage and under continuous development and refinement.\nOngoing and future steps include implementing AI-powered adaptive learning so that the students can receive immediate feedback and prevent error propagation. The pillars of a successful transition towards a digitalized industry can be built upon by upgrading the curriculum and integrating online educational computer-aided tools to prepare future engineers to be fluent in data analysis and process modelling.\n\nThis is a very exciting educational initiative so some big kudos to Carina Lira Gargalo,\u00a0Simoneta Ca\u00f1o de las Heras,\u00a0Fiammetta Caccavale,\u00a0Krist Gernaey and Ulrich Kr\u00fchne for bringing education in this space to a total new level.\nShare your thoughts and ideas about this initiative in the comments section.\n\n#Industry40 #EngineeringEducation #BioVL #Digitalization #FutureReady #OnlineLearning #learning \n\nLink to Github: https:\/\/lnkd.in\/eH9a9VzW \nLink to Publication: https:\/\/lnkd.in\/edBuqf6B\nLink to Website: www.biovl.com \n","linkedinURL":"https:\/\/www.linkedin.com\/feed\/update\/urn:li:activity:7049418669239480320","githubURL":null,"paperURL":null,"author":"Antonio Benedetti","createdDate":"04\/05\/2023"},{"title":"The title is: SGTPy - A Python Open-Source Code for Accurate Calculation of Interfacial Properties","description":"Introducing #SGTPy: A #Python #opensource code for accurate calculation of interfacial properties in pure #fluids and #fluid #mixtures. \ud83d\udcbb\ud83e\uddea\u2697\ufe0f\n\nInterfacial properties play a crucial role in the behavior of fluids and their mixtures, particularly in processes like oil extraction, chemical synthesis, and material science. However, calculating these properties accurately remains a significant challenge, in part due to the inhomogeneity of interfacial regions. \n\nThat's where SGTPy comes in. SGTPy is a Python open-source code that combines the Square Gradient Theory (#SGT) with the Statistical Associating Fluid Theory of Variable Range #EoS employing a Mie potential (#SAFT-VR-Mie), to calculate interfacial properties for both pure fluid species and fluid mixtures. SGTPy is written in Python and uses standard packages like NumPy and SciPy. Additionally, some of its features are presented through examples written on Jupyter Notebook, thus providing an interactive environment for coding, computing, and plotting. Features of SGTPy include the calculation of phase stability, phase equilibria, interfacial properties, and optimization of the SGT and SAFT parameters for vapor\u2013liquid, liquid\u2013liquid, and vapor\u2013liquid\u2013liquid equilibria. \n\nSGTPy has the potential to significantly advance research in fields where interfacial properties play a critical role. Its accuracy and ease of use make it an essential tool for #scientists and #engineers working in various areas of fluid science. We believe that SGTPy will be of great benefit to the research community, and we invite you to explore this open-source code and see how it can help you in your work!\n\nCongratulations to Andr\u00e9s Mej\u00eda, Erich M\u00fcller, and Gustavo Chaparro Maldonado for their excellent contribution.\n\nLink to #GitHub: https:\/\/lnkd.in\/eX6DKHYu\nLink to Publication: https:\/\/lnkd.in\/eWCSna8j","linkedinURL":"https:\/\/www.linkedin.com\/feed\/update\/urn:li:activity:7049035607599149056","githubURL":null,"paperURL":null,"author":"Alberto Marchetto","createdDate":"04\/04\/2023"},{"title":"The title is: Building a community in mass #spectrometry-based #proteomics #research with #ProteomicsML","description":"Building a community in mass #spectrometry-based #proteomics #research with #ProteomicsML \ud83e\uddec\ud83d\udcbb\n\nIf you are working on the field of proteomics, you will probably know that the acquisition and curation of liquid #chromatography-mass spectrometry (LC-MS) data is one of the most challenging parts of the projects. This has become particularly an issue ever since #machinelearning (#ML) approaches entered the scene and ML-based models were introduced in proteomics. In proteomics-based liquid chromatography coupled to mass spectrometry data sets, a significant amount of data reduction can occur between raw data and machine learning-ready data. One of the main hurdles here is lab-to-lab heterogeneity, which limits data reproducibility and compatibility. \n\nIn response to that, Tobias Greisager Rehfeldt and co-workers introduced ProteomicsML, an #opensource collection of proteomics-based data sets and tutorial ML models. ProteomicsML aims to facilitate the application of ML techniques within the field of MS-based proteomics, by promoting the dissemination of \u201cready-to-use\u201d data sets for ML-based research, and encouraging new contributors thanks to expert-driven tutorials. Data sets present in the web platform contain information such as peptide retention times (with data sets including up to 1 million observations) and fragmentation intensity data. Additionally, ML models aimed at predicting peptide collisional cross section and detect proteins encoded in the proteome of given species are available.\n\nKudos to the whole team: Tobias Greisager Rehfeldt,\u00a0Ralf Gabriels,\u00a0Robbin Bouwmeester,\u00a0Siegfried Gessulat,\u00a0Benjamin Neely,\u00a0Magnus Palmblad,\u00a0Yasset Perez-Riverol,\u00a0Tobias Schmidt,\u00a0Juan Antonio Vizcaino,\u00a0and\u00a0Eric Deutsch \n\nLink to #GitHub: https:\/\/lnkd.in\/eWqUFtkn\nLink to Publication: https:\/\/lnkd.in\/efSybjpt\n\nThe platform is also available at https:\/\/lnkd.in\/e3zQEX_u. Check it out and contribute to enhance the field of ML-based proteomics!","linkedinURL":"https:\/\/www.linkedin.com\/feed\/update\/urn:li:activity:7048653860122353666","githubURL":null,"paperURL":null,"author":"Alberto Marchetto","createdDate":"04\/03\/2023"},{"title":"The title is: Monitoring and Optimizing Anaerobic Digestion Processes with Multi-Block Data Analysis","description":"Struggling to handle #multiple #data sources (off\/on\/in\/at-line) from your #bioprocess? #MultiBlock Data Analysis an be the Solution\ud83d\udd2c\ud83d\udcbb\ud83d\udcca\ud83e\udda0\n\nBioprocess #control and #monitoring is becoming more and more complex thanks to the availability of measurement systems of different natures that goes behind traditional lab test or standard sensors. This creates a great opportunity from a data analytics perspective since data have never been so abundant. However, this comes with the challenge of how to handle and process data of different nature and frequency to solve problems like process #optimization or monitoring. \nThis recent study by  has investigated the use of #sequential and #orthogonalized partial least squares (#SO-#PLS) regression to monitor the process and maximize #biogas production. The study utilized data from near-infrared spectroscopy, chemical routine analysis, and kinetics of biogas production to develop models that extract relevant information and discard redundancies.\nTo meet the needs of biogas plant operators, variable selection was performed on the infrared blocks using a recent method called SO-CovSel. This method couples SO-PLS and Covariance Selection (CovSel) to provide suitable multi-response calibration with infrared calibration. The study demonstrated that the models produced were able to predict and monitor the relevant parameters of stability in anaerobic co-digestion with good accuracy.\nThe current monitoring strategies and methods used in anaerobic digestion have lacked sensitivity and robustness when taken individually. Therefore, the use of SO-PLS and SO-CovSel in this study provides a promising solution for improving the monitoring and optimization of anaerobic digestion.\n\nWell done to Lorraine A.,\u00a0Ryad BENDOULA,\u00a0jean-michel roger and\u00a0Fabrice B\u00e8line\u00a0! This is a great example of how this #datanalysis tool can be used in #biogas production.\n\nLink to #Publication: https:\/\/lnkd.in\/e7NqubbG ","linkedinURL":"https:\/\/www.linkedin.com\/feed\/update\/urn:li:activity:7048294055461416960","githubURL":null,"paperURL":null,"author":"Antonio Benedetti","createdDate":"04\/02\/2023"},{"title":"The title is: Advancing #Pharmaceutical #Opensource #Model #Libraries: Insights from a Case Study on #Reaction Kinetics and Uncertainty Analysis with #PharmaPy","description":"Advancing #Pharmaceutical #Opensource #Model #Libraries: Insights from a Case Study on #Reaction Kinetics and Uncertainty Analysis with #PharmaPy \ud83e\uddea\ud83d\udc8a\ud83d\udcbb\ud83d\udcc8\n\nOver the last months, we reposted some of the great work initiated by Prof. Zoltan Nagy and his team at Purdue University to develop a fully open-source #python-based modelling for pharmaceutical manufacturing systems design and optimization. This is one of the most exciting projects out there that really inspired us to start our #community and we are really excited to share today some more spoilers on the capability of this upcoming platform.\nIn this paper by Daniel Casas-Orozco, Ph.D. et al, the authors focus on the synthesis of the drug lomustine and the use of a parameter estimation framework built into the PharmaPy library to determine rate parameters and uncertainty regions of different kinetic expressions. Through identifiability analysis, the researchers simplified the reaction mechanisms and gained insights into the drug manufacturing process.\nThe study emphasizes the importance of considering parameter uncertainty in process #design, particularly in the first steps of a multi-step process where parametric sensitivity can propagate along the #manufacturing line. This can compromise process feasible operations and the positive achievement of critical #quality attributes of the product.\n\nOverall, this paper provides a fantastic snapshot of the utility of such applications for our #Polymodellers in the pharmaceutical domain and it increases exponentially our hype for the upcoming release of the platform \ud83e\udd13 \nKudos to Daniel Casas-Orozco, Ph.D.,\u00a0Daniel Laky,\u00a0Jaron Mackey,\u00a0Gintaras\u00a0Reklaitis and\u00a0Zoltan Nagy !!! \n\nLink to #Publication: https:\/\/lnkd.in\/eWsh4BQE","linkedinURL":"https:\/\/www.linkedin.com\/feed\/update\/urn:li:activity:7047916238559174656","githubURL":null,"paperURL":null,"author":"Antonio Benedetti","createdDate":"04\/01\/2023"},{"title":"The title is: FelooPy - A Hyper-Optimization Interface for Automated Operations Research in Python","description":"#Optimization \ud83d\udcbb\ud83d\udcc8 is a critical element of many fields, and it is of special interest in #Pharma \ud83d\udc8a. However, writing optimization codes can be a challenging and time-consuming \u23f1\ufe0f\u23f3 process, which can take away from the more analytical and decision-making aspects of research and development. This is where FelooPy comes in.\n\nFelooPy is a hyper-optimization interface and integrated optimization environment conceived for automated operations research in #Python. How should that be helpful for you? The way FelooPy is designed will allow you to focus more on #modeling and #analytics instead of #coding, which can save you a ton of time and energy! Indeed, the name FelooPy stands for feasible, logical, optimal, and Python, and that's exactly what it is about.\u00a0It also refers to memory efficiency, as Feloopy resembles the word Floppy, well known for having very low available memory.\n\nUsing FelooPy, you can automate all kinds of tedious tasks, like optimization model development, debugging, and implementation. It's also really user-friendly, with the possibility to switch between optimization interfaces and algorithms with no need of code changes.\nThe best part is that FelooPy supports a whopping 259 single-objective heuristic and exact optimization algorithms, and it is all in Python! Plus, it has all kinds of cool features like sensitivity analysis, automated encoding and decoding for heuristic optimization, timers, etc.\n\nFelooPy is a real game-changer for anyone who is involved in automated operations research. It simplifies the optimization process and provides you with practical and applicable solutions that you can actually use in your work. And if that's not enough, it could even support multi-objective optimization and multi-criteria decision making in the near future! How cool is that?\n\nCongratulations to Keivan Tafakkori for this #opensource contribution, ad maiora!\n\nLink to #GitHub: https:\/\/lnkd.in\/e4cW5ikD","linkedinURL":"https:\/\/www.linkedin.com\/feed\/update\/urn:li:activity:7047480586885562368","githubURL":null,"paperURL":null,"author":"Alberto Marchetto","createdDate":"03\/31\/2023"},{"title":"The title is: \"Transformer for Peptide Retention Time Prediction in Mass Spectrometry-Based Proteomics\"","description":"Using the #Transformer \ud83e\udd16\ud83d\udcbb to improve spectral analysis in #proteomics \ud83e\uddeb\ud83d\udd2c\ud83e\uddec\n \nThe retention time (RT) of a #peptide in a chromatographic column is defined as the time the peptide takes to move through the column. Accurately predicting the RT of peptides in liquid #chromatography is a crucial task in mass #spectrometry-based proteomics. Such information is indeed an integral part in spectral libraries, and can be used to improve peptide identification confidence to control false discovery rate and to identify chimeric fragmentation spectra. Approaches based on #deeplearning (DL) have proven to be highly effective in this regard, but there is always room for improvement... A research published by Thang Pham et al. takes peptide RT prediction a step further by using the Transformer architecture, which has demonstrated state-of-the-art performance in many other fields such as natural language processing (#NLP), computer vision, and #biology. The model developed by the authors converts peptide sequences into vector representations. Therefore, the vector representations are transformed by an encoder, which allows for the model to characterise the dependency among amino acids in the peptide sequence. The learned representation is then used as input for the prediction layer. The authors benchmarked the Transformer using datasets from five published DL models, and the proposed approach outperformed the traditional methods and allowed for an overall outstanding accuracy in peptide RT prediction. \n \nThe best news? The data and software code are publicly available! So, if you are interested in applying the Transformer to predict peptide RT in your mass spectrometry study with unprecedented precision, go and check them out!!\n \nKudos to Thang Pham, Vinh V. Nguyen, Duong Vu, Alex Henneman, Robin Richardson, Sander Piersma and Connie Jimenez for this remarkable contribution.\n \nLink to\u00a0#Github:\u00a0https:\/\/buff.ly\/3JRVS13\nLink to Publication:\u00a0https:\/\/buff.ly\/40o4LXl","linkedinURL":"https:\/\/www.linkedin.com\/feed\/update\/urn:li:activity:7047108701060567040","githubURL":null,"paperURL":null,"author":"Alberto Marchetto","createdDate":"03\/30\/2023"},{"title":"The title is: Optimizing Bioreactor Processes with In-Situ Product Removal: A Modeling Approach","description":"#Optimizing #Bioreactor Processes with #InSitu #Product #Removal: A #Modeling Approach\ud83e\udda0\ud83d\udcbb\ud83d\udcc8\n\nBioreactor processes can have varied degrees of complexity based on the type of #microorganisms, culture #media, and #process conditions used. However, in many cases, the presence of inhibitory #byproducts can significantly limit the yield and productivity of bioreactor processes. In-situ product removal (#ISPR) is a promising approach to overcome this limitation by continuously or periodically removing the product from the reaction mixture. ISPR has been shown to improve the yield and productivity of many bioreactor processes, but designing and operating ISPR systems can be challenging, particularly in discontinuous systems. \nThis recently published paper by Lucas Van der Hauwaert et al explores the use of mathematical models to optimize the process, using a co-culture #batch #fermentation with #electrodialysis as the ISPR system for #propionate production.\nThe research team developed a model that was calibrated using datasets from monoculture experiments and validated on an independent dataset that described the entire process. Optimization problems were implemented using single objective optimization, multi-objective optimization, and stochastic optimization to find several operational strategies related to the ISPR and feeding.\nThe results showed that the #yield and #productivity could be #improved compared to the base case, and the identified strategies could be adapted by ISPR designers. The paper concludes that future studies should verify the implementation of these strategies and further fine-tune the model with collected data.\n\nWell done to Lucas Van der Hauwaert,\u00a0Alberte Regueira L\u00f3pez,\u00a0Dr.-Ing. Ludwig Selder,\u00a0An Ping\u00a0Zeng and\u00a0Miguel Mauricio Iglesias! This paper is extremely interesting and our community loves to have access to the code as #opensource!!!\n\nLink to #Github: https:\/\/lnkd.in\/epNsh5Tn\nLink to #Publication: https:\/\/lnkd.in\/eedEFw-9 ","linkedinURL":"https:\/\/www.linkedin.com\/feed\/update\/urn:li:activity:7046767978364686336","githubURL":null,"paperURL":null,"author":"Antonio Benedetti","createdDate":"03\/28\/2023"},{"title":"The title is: AI-based Co-crystal Density Prediction: A Promising Approach for Experimental Investigations","description":"We have already seen how much helpful artificial intelligence (#AI) can be in fields like #drugdiscovery and organic functional materials. We also already showed you that graph neural networks (#GNNs) are very promising techniques in molecular property prediction tasks. \n\nIn today\u2019s post we want to introduce you a further, astonishing success: let us see how #AI can be used to support co-crystal engineering research.\n\nA recent academic study carried out by Jiali Guo et al. (Sichuan University) has explored this very topic, and the results are very interesting. The authors used a message passing graph neural network (#GNN)-based #deeplearning framework to accurately predict co-crystal density from structural information about molecules, including atomic donors, atomic acceptors, ring properties etc.  \n\nThe study found that different stoichiometric ratios of molecules in co-crystals can significantly influence prediction performance, emphasising the importance of having high-quality data available in machine learning (#ML) modelling. Additionally, the authors noticed that redundancy in the molecular information included in the #GNNs worsened #GNN predictive capabilities. Therefore, they demonstrated the importance of adding extra molecular features only if they sufficiently supplement the lacked information in the original molecular representation (i.e., the molecular graph!). The #GNN was trained from experimental co-crystal data, and global #attention was introduced to optimise the feature space and identify important atoms in the co-crystals to allow for a greater model interpretability. Overall, the results showed that the #GNN-based approach significantly outperformed three competitive models and exhibited high prediction accuracy for unseen co-crystals, demonstrating its robustness and generalisation capabilities. \n\nNot only does this study provide a general co-crystal density prediction tool for experimental investigations, but it also offers useful guidelines for #ML applications in the field of molecular property predictions. Ad maiora!!\n\nKudos to: Jiali Guo, Ming Sun, Xueyan Zhao, Chaojie Shi, Haoming Su, Yanzhi Guo, and Xuemei Pu \n\nLink to #GitHub: https:\/\/lnkd.in\/eP2nei4j\nLink to #Pubblication: https:\/\/lnkd.in\/eaPcHusr","linkedinURL":"https:\/\/www.linkedin.com\/feed\/update\/urn:li:activity:7046441337629351937","githubURL":null,"paperURL":null,"author":"Alberto Marchetto","createdDate":"03\/28\/2023"},{"title":"The title is: \"How #Pyomo Simplifies #Reactive #Distillation\"","description":"From ChemEng Students' Nightmare to Elegant Code: How #Pyomo Simplifies #Reactive #Distillation \ud83e\uddea\u2697\ufe0f\ud83d\udcc8\n\nIf you studied Chemical Engineering, you may still recall the challenges of modeling reactive distillation.\nReactive distillation is a challenging process to model due to the combined chemical reaction and distillation that takes place. However, the Pyomo optimization modeling language makes it easier to define and solve the reactor and distillation column models and constraints.\nToday we just want to share this great example of how to go around modelling a Fischer\u2013Tropsch reactive distillation\u00a0using\u00a0Pyomo. The package includes a range of capabilities to support this task, including a model archive for compatibility, a global sets module for shared parameters, a saved solutions module for file storage, and a utility module with helper functions for data gathering, debugging, analysis, and visualization. The data module contains all the physical parameters for the model, while the physics module serves as the first level physics block with fundamental equations that will be used in higher level model structures. By using this package, users can streamline the process of reactive distillation modeling and that is a great add on.\n\nKudos to Naien He, Yanyan Hu, Cornelius Mduduzi Masuku\u00a0and\u00a0Lorenz Biegler for sharing this fantastic piece of work, including the code!\n\nLink to #Github: https:\/\/lnkd.in\/gii8ezSk\nLink to #Publication: https:\/\/lnkd.in\/eqN-GEbP","linkedinURL":"https:\/\/www.linkedin.com\/feed\/update\/urn:li:activity:7046120478368788480","githubURL":null,"paperURL":null,"author":"Antonio Benedetti","createdDate":"03\/27\/2023"},{"title":"The title is: Advancing Thermokinetic Analysis: New Calorimetric Technique to Simultaneously Characterize Reaction Kinetics and Enthalpy","description":"Advancing #Thermokinetic #Analysis: New Calorimetric Technique to Simultaneously Characterize #Reaction #Kinetics and #Enthalpy \ud83c\udf21\ufe0f\u2194\ufe0f\ud83e\uddea\n\nFlow reactions are gaining popularity in the #pharmaceuticalindustry due to their efficiency, scalability, and ability to synthesize complex molecules that are difficult to produce using conventional methods.\nA recent study has developed a new calorimetric reaction-characterization technique that can determine the Gibbs energy of activation and the enthalpy of reactions simultaneously in a #flow #reactor. The method was verified and compared to conventional analytical methods using a family of peptide syntheses as model reactions. The results showed that the #thermal #model equation closely fitted the acquired temperature profile, and the calculated Gibbs energies of activation agreed closely with the values determined from #product #yield-time trends obtained using several reactants at different temperatures. Additionally, the calculated reaction enthalpy was similar to the values obtained from quantum chemical calculations. The findings suggest that spatial regression calorimetry can simultaneously extract more reaction characteristics than conventional calorimetry, which could have important implications for the field of thermokinetic analysis.\n\nWell done to Yusuke Imamura,\u00a0Jun-ichi Ogawa,\u00a0Yuma Otake,\u00a0and\u00a0Hidenosuke Itoh, PhD for publishing this very interesting work. \n\nLink to #Publication: https:\/\/lnkd.in\/eEtjzUYw","linkedinURL":"https:\/\/www.linkedin.com\/feed\/update\/urn:li:activity:7045751094047559680","githubURL":null,"paperURL":null,"author":"Antonio Benedetti","createdDate":"03\/26\/2023"},{"title":"The title is: Optimizing #Batch #Scheduling: Importance of Quality-Based Changeovers (#QBC) and Comparison of Modelling Frameworks","description":"#Optimizing #Batch #Scheduling: Importance of Quality-Based Changeovers (#QBC) and Comparison of Modelling Frameworks \n\nIn process systems engineering, batch scheduling is a crucial task that involves determining the timing and size of batches for plants.\nA recent study by Braulio Brunaud et al highlights the importance of quality-based changeovers (QBC) in batch scheduling models. QBC enables equipment cleaning operations to be skipped between batches if enough batches of the second product are performed in a row, but it has been ignored in scheduling models until now.\nThe study compares four main modelling frameworks for batch scheduling and extends them to include QBC: State-Task Network (STN), Maximal State-Task Network (m-STN), Resource-Task Network (RTN), and Unit-Operation-Port-State-Superstructure (UOPSS). The authors find that STN and m-STN formulations are limited for large-scale problems, while RTN is difficult to extend but performs better as the number of changeovers increases. The UOPSS framework is intuitive and performs well for large-scale problems. Lazy constraints were also investigated for changeovers, but they did not significantly improve computational efficiency. Furthermore, including QBC in the models does not add significant computational burden to the four frameworks.\nThis study is a must-read for process systems engineering professionals who need to solve large-scale batch scheduling problems that involve QBC. \n\nKudos to Braulio Brunaud, Hector Perez, Satyajith Amaran, Scott Bury, John Wassick, and Ignacio Grossmann!  We hope that this work can help our community of modellers to select an appropriate modelling framework for batch scheduling problems in industries that use QBC.\n\nLink to #Publication: https:\/\/lnkd.in\/ewgV9KU2\n","linkedinURL":"https:\/\/www.linkedin.com\/feed\/update\/urn:li:activity:7045399521039675392","githubURL":null,"paperURL":null,"author":"Antonio Benedetti","createdDate":"03\/25\/2023"},{"title":"The title is: PyParse: Automated analysis of LCMS data for high throughput chemistry experiments","description":"#PyParse: Automated analysis of #LCMS data for #high #throughput #chemistry experiments \ud83d\udd2c\ud83e\uddea\ud83e\udd16\ud83e\uddbe\n\nAre you tired of spending countless hours analyzing LCMS #data for your high throughput chemistry experiments? Look no further than PyParse, a #python-based script designed to automate the analysis process!\nPyParse is a powerful tool that reads LCMS data in the Waters Corporation OpenLynx\u2122 browser report (.rpt) file format, assigns peaks to compounds specified in a .csv platemap, and generates heatmaps and other visualizations to compare and contrast different LCMS runs. It's perfect for reaction optimizations, parallel synthesis, and library validation experiments.\nWhat's great about PyParse is its ability to automate the analysis process, saving you time and effort. You can quickly and easily analyze LCMS data and generate valuable insights into your experiments. And because it's #opensource, you can customize and adapt the script to fit your specific needs.\n\nThank you, Joe Mason, Francesco Rianjongdee, Harry Wilders, and David Fallon, for sharing PyParse with the scientific community. It's an excellent resource for anyone interested in high throughput chemistry experiments.\n\nLink to #Github: https:\/\/lnkd.in\/gadhFWA5\n\n#PyParse #LCMS #HighThroughputChemistry #OpenSource #DataAnalysis #GitHub ","linkedinURL":"https:\/\/www.linkedin.com\/feed\/update\/urn:li:activity:7045001305555169280","githubURL":null,"paperURL":null,"author":"Antonio Benedetti","createdDate":"03\/23\/2023"},{"title":"The title is: Harnessing the #Unknown: \ud83e\uddee\ud83d\udd2c #Modeling #Physical Governing Equations with #LaSDI \ud83e\udd16\ud83d\udca5","description":"\ud83d\ude80 Harnessing the #Unknown: \ud83e\uddee\ud83d\udd2c #Modeling #Physical Governing Equations with #LaSDI \ud83e\udd16\ud83d\udca5\n\nAre you tired of slow and inaccurate simulations? Say hello to #Latent #Space #Dynamics #Identification (LaSDI), the latest #opensource tool that can enhance your work and save you time and resources.\nLaSDI is a data-driven framework that compresses high-dimensional time-dependent data into a reduced latent space data, making it easier to handle limited memory and storage issues. But the real magic happens when the SINDy-type method is applied to identify the unknown governing equations for the latent space dynamics. This identification leads to efficient surrogate modeling, accurately accelerating computationally expensive physical simulations.\n\nReally well done to Youngsoo Choi, Xiaolong He & William (Bill) Fries ! This is brilliant work and highly valuable for our community! \n\nLink to #GitHub: https:\/\/lnkd.in\/eZuNJeQg\nLink to Publication: https:\/\/lnkd.in\/ervu98zU\n \n#surrogate\u00a0#modeling\u00a0#mathematics\u00a0#machinelearning\u00a0#ml #reducedordermodel\u00a0#fast\u00a0#accurate\u00a0\u00a0#software\u00a0#python #pytorch\u00a0#repository\u00a0#physics\u00a0#science","linkedinURL":"https:\/\/www.linkedin.com\/feed\/update\/urn:li:activity:7044638919266574336","githubURL":null,"paperURL":null,"author":"Antonio Benedetti","createdDate":"03\/22\/2023"},{"title":"The title is: Discover the Power of #pyABC: A Likelihood-Free Inference Framework for BlackBox Models","description":"Discover the Power of #pyABC: A Likelihood-Free Inference Framework for BlackBox Models \ud83d\udd0d\ud83d\udd01\ud83d\udcbb\u03c0\n\nToday we wanted to share this fantastic #opensource #Python package called \"#pyABC\". This package is all about helping you solve the problem of parameter inference when all you can do is simulate from a black-box model, but no further analysis is possible.\nIn other words, if you have a forward simulator and need to do the backward parameter inference step, pyABC is the tool for you. All you need is some kind of experimentally observed or synthetically generated data and a parametrized stochastic simulator that can potentially explain the data (such as a function that uses a random number generator).\nWith pyABC, you no longer need to worry about calculating the likelihood function because it \"inverts\" the model for you and tells you which parameters are well-matching and which ones are not. This allows you to approximate the posterior distribution over the model parameters and understand which parameters are the most likely to explain your observed data.\nNot only is pyABC easy to use, but it also runs efficiently on multi-core machines and distributed cluster setups, making it ideal for large-scale projects. Plus, since it's an open-source package, it's flexible and extensible, allowing you to tailor it to your specific needs.\nIf you're interested in learning more about pyABC and how it can help you with your parameter inference problems, be sure to check out their website and give it a try. Trust us, you won't be disappointed!\n\nKudos to Yannik Sch\u00e4lte, Emmanuel Klinger, Dennis Rickert, Emad Alamoudi and\u00a0Jan Hasenauer! \n\nLink to #Github: https:\/\/lnkd.in\/e6Fj27ag \nLink to Publication: https:\/\/lnkd.in\/e5BKKF2z\n\n#ParameterInference #BlackBoxModel #StochasticSimulator #LikelihoodFreeInference #DataScience #MachineLearning #Statistics","linkedinURL":"https:\/\/www.linkedin.com\/feed\/update\/urn:li:activity:7044293011991588864","githubURL":null,"paperURL":null,"author":"Antonio Benedetti","createdDate":"03\/22\/2023"},{"title":"The title is: Examples of Numerical Calculations with Python for Chemical Technology and Biotechnology","description":"#Modeling in #Chemical #Technology:\u00a0Examples of Numerical Calculations with #Python \ud83e\uddea\ud83d\udd22\ud83d\udcbb\ud83d\udc0d\n\nIt's been a while since we've shared some #educational resources, and we believe that continuing to promote #development is crucial. That's why we're excited to share this fantastic collection of solved problems and exercises in Python for chemical technology and biotechnology.\nThese examples demonstrate how numerical calculations can be used to create models of complex chemical systems and processes, starting from simple calculations of mass balances and moving up to much more complex bioreactor systems. By sharing educational resources like these, we can help others develop their skills and knowledge in areas that are crucial to the success of our industries.\nEven the more seasoned modellers of our #community can benefit from resources like this to learn a new programming language or to support new colleagues or friends who are taking their first steps into this area. Therefore, don't hesitate to share additional resources like this with us.\n\nA big thank you to Szczepan Bednarz for sharing this great collection of code and the well-explained book!\n\nLink to #Github: https:\/\/lnkd.in\/eHcn_k_p\n","linkedinURL":"https:\/\/www.linkedin.com\/feed\/update\/urn:li:activity:7044020080665317376","githubURL":null,"paperURL":null,"author":"Antonio Benedetti","createdDate":"03\/21\/2023"},{"title":"The title is: Reaktoro - An Open-Source Unified Framework for Modeling Chemically Reactive Systems","description":"#Reaktoro: An #opensource unified framework for modeling #chemically #reactive #systems \ud83e\uddea\u2194\ufe0f\ud83d\udcc8\n\nOver the past few months, we have introduced several modeling frameworks to tackle the complexities of chemical reactions. Chemical reactions can be highly intricate systems that require sophisticated modeling solutions, depending on the complexity of the reactive phases involved (such as bi-phasic or tri-phasic). \nToday we are excited to share about the amazing open source computational framework - Reaktoro! Developed in #C++ and #Python, Reaktoro enables simulation of chemically reactive processes with features such as support for several thermochemical databases (PHREEQC, SUPCRT, NASA, and more), chemical equilibrium and kinetics calculations with general constraints, and efficient numerical algorithms. With the ability to model chemical systems with any number of phases and species, Reaktoro uses automatic differentiation to compute derivatives with respect to virtually any variable or parameter.\n\nKudos to Allan Leal & contributors to create such an interesting open-source project!\n\nLink to #Github: https:\/\/lnkd.in\/eztZsehk \nLink to Reactoro Project Page: https:\/\/lnkd.in\/ey2XT7cQ\n\n #computationalchemistry #opensource #chemicalsimulation","linkedinURL":"https:\/\/www.linkedin.com\/feed\/update\/urn:li:activity:7043585568009543680","githubURL":null,"paperURL":null,"author":"Antonio Benedetti","createdDate":"03\/20\/2023"},{"title":"The title is: \"Mapping Morphological Distributions to Understand Pharmaceutical Processing Behavior\"","description":"#Morphological Distribution #Mapping: #Modelling Whole #Particle #Distributions to Understand Pharmaceutical Processing Behavior \ud83d\udd0d\ud83d\udcc8\ud83d\udc68\u200d\ud83d\udd2c\ud83d\udc8a\ud83d\udca1\n\nThe last two decades have seen a focus on making better measurements on particles to understand formulation research issues. With thousands of batches of API examined and sophisticated data analysis in place, researchers are beginning to understand what makes a successful API and where problem materials live. For instance, examination of direct compression API's has revealed a characteristic not previously considered, leading to new insights from the database.This recent paper by John Gamble et al. shows how whole particle distributions can be used to map the full range of particle properties in a curated dataset. This approach may enable a more complete understanding of the particle landscape, improving the link between particle properties and processing behavior.The paper describes the application of a 1-dimensional principal component analysis (PCA) approach to create a \u2018morphological distribution landscape\u2019 using a curated dataset of imaged APIs, intermediates, and excipients encompassing particle size, particle shape (elongation, length, and width), and distribution shape between 2008 and 2022. The curated dataset encompassed over 200 different materials, including over 150 different APIs, and approximately 3500 unique samples.The morphological landscape enables differentiation of materials of equivalent size but varying shape and vice versa. This type of approach can be utilized to better understand the influence of particle properties on pharmaceutical processing behavior and thereby enable scientists to leverage historical knowledge to highlight and mitigate risks associated with materials of similar morphological nature.\n\nKudos to the whole team at Bristol Myers Squibb: John Gamble, Ilgaz Akseli, Ph.D., MBA, Ana Patricia Ferreira, Michael Leane,\u00a0Stephen Thomas, Mike Tobyn, Robert Wadams \n\nLink to Publication: https:\/\/lnkd.in\/er5xNVcy","linkedinURL":"https:\/\/www.linkedin.com\/feed\/update\/urn:li:activity:7043226108665679872","githubURL":null,"paperURL":null,"author":"Antonio Benedetti","createdDate":"03\/19\/2023"},{"title":"The title is: Model-Based Analysis of Solvent Selection for Heterogeneous Hydrogenation Syntheses","description":"#ModelBased analysis of #solvent selection on #batch and #flow #syntheses using heterogeneous hydrogenation \ud83e\uddea\ud83d\udcbb\ud83d\udd2c\ud83d\udca7\ud83d\udcb9\n\nThe pharmaceutical industry has a keen interest in flow synthesis and #continuous production. Solvent selection is usually based on solubility and reactivity\/selectivity, but in heterogeneous reactions, the #properties of the #solvent related to mass transfer can affect reaction performance. This study by Junu Kim et al. presents a model-based analysis of the impact of solvent selection in batch and flow syntheses for heterogeneous hydrogenation, with #simulations of reaction conversions conducted under different conditions. The individual solvent properties were examined, and a guideline for solvent selection was proposed to reduce experimental burden and enable more deliberate and selective solvent selection, potentially aiding in solvent design through computer-aided molecular design.\n\nThat's a very interesting work! Kudos to the authors Junu Kim,\u00a0Yusuke Hayashi,\u00a0Sara Badr,\u00a0Hayao\u00a0Nakanishi and\u00a0Hirokazu\u00a0Sugiyama from PSE@UTokyo !\n\nLink to Publication: https:\/\/lnkd.in\/gF543aWR ","linkedinURL":"https:\/\/www.linkedin.com\/feed\/update\/urn:li:activity:7042905236562223104","githubURL":null,"paperURL":null,"author":"Antonio Benedetti","createdDate":"03\/18\/2023"},{"title":"The title is: Ersilia Model Hub - Revolutionising AI-based Drug Discovery and Disease Research","description":"Making AI-based drug discovery and disease research available to everyone! \ud83d\udc8a\ud83e\uddec\ud83e\uddeb\ud83e\udda0\ud83d\udcbb\ud83c\udf0d\n\nAt PolyModels Hub, we understand the importance of creating an open and collaborative community to boost research and development in the digital design of processes and computer-aided product manufacturing. We have often shared with you outstanding contributions in the AI-driven drug design and development, but today we want to take a step further. \n\nWe are delighted to present you Ersilia Model Hub, a cutting-edge platform that is revolutionising the way #AI models can be used for #Drugdiscovery and infectious disease research. Ersilia is a hub that hosts a wide range of free and #opensource AI \/ #machinelearning models and codes taken from scientific publications, code repositories etc., often built by exploiting publicly available data. Within it, developers can share and access pre-trained models for various drug design and disease research applications, and models can be adapted to everyone\u2019s needs, thanks to the collaborative environment that characterises the hub. \n\nAs an example, Ersilia has partnered with the Holistic Drug Discovery and Development Centre (H3D) at the University of Cape Town, South Africa, to increase the efficiency of virtual screening to contrast malaria, tuberculosis and antimicrobial resistance through ZairaChem, a #Python library of quantitative structure activity relationships (#QSAR) models. \n\nThe efforts put on the development of Ersilia can allow scientists and clinicians to employ models and run predictions without requiring any prior coding knowledge, and with no need to pay for expensive software licenses. Additionally, models do not need to be built from scratch, which further saves time and reduces costs, something that low-resourced countries can particularly benefit from. \n\nIf you are interested in drug design and disease research, then make sure you have look at the Ersilia Open Source Initiative. In addition to ZairaChem, you will find a lot of other outstanding projects!\n\nErsilia #GitHub repository: https:\/\/lnkd.in\/eu9_ZXNX\nErsilia website: https:\/\/www.ersilia.io\/\n\nZairaChem #GitHub repository: https:\/\/lnkd.in\/ebJm7ZYg\nZairaChem #preprint publication: https:\/\/lnkd.in\/ewDU3uDX\u00a0\n(Credit to: Gemma Turon, Jason Hlozek, John Woodland, Kelly Chibale, Miquel Duran-Frigola)\n\nVery well done to the team who made Ersilia possible: Gemma Turon, Miquel Duran-Frigola, Edoardo Gaude\n\n#AIdevelopment #Modelhub #AIcommunity #Drugdesign\u00a0#Ersilia","linkedinURL":"https:\/\/www.linkedin.com\/feed\/update\/urn:li:activity:7042506914034835456","githubURL":null,"paperURL":null,"author":"Alberto Marchetto","createdDate":"03\/17\/2023"},{"title":"The title is: Unlocking #Sustainable Alternatives: #Reinforcement #Learning for Batch #Bioprocess Optimization","description":"Unlocking #Sustainable Alternatives: #Reinforcement #Learning for Batch #Bioprocess Optimization \ud83e\udda0 \ud83d\udcbb\ud83d\udd01 \ud83c\udf31 \n\nBioprocesses are extensively used in the #pharmaceutical industry to produce a wide range of therapeutic proteins, vaccines, and other biologic products. The industry is focused on developing bioprocesses that are scalable, robust, and sustainable.\u00a0However, designing and optimizing these processes can be challenging due to their unsteady-state operation modes and stochastic behaviors. Not to mention the complexity of biological systems, which often leads to plant-model mismatch. To tackle these challenges Panagiotis Petsagkourakis, PhD et al. propose a novel reinforcement learning-based optimization strategy for batch processes. The study applied the \"#Policy #Gradient\" method from batch-to-batch to update a control policy parametrized by a recurrent neural network. A preliminary process model was used to obtain a preliminary optimal control policy. Then, this policy was updated based on measurements from a true plant. The new capability was tested on 3 different case studies. The results showed that their approach significantly improved the performance of the batch process, demonstrating the effectiveness of reinforcement learning-based optimization strategy. We recommend that you try this approach on your own case studies! \n\nWell done Panagiotis Petsagkourakis, PhD,\u00a0Ilya Orson Sandoval,\u00a0Eric Bradford,\u00a0DONGDA ZHANG,\u00a0Ehecatl Antonio del Rio Chanona!! Thanks for embodying the spirit of #opensource and scientific sharing that is one of the core values of our #community.\n\nLink to #Github:\u00a0https:\/\/lnkd.in\/eEBzkHiG\nLink to Publication:\u00a0https:\/\/lnkd.in\/eJA4khUs & https:\/\/lnkd.in\/ekKKU-W7 ","linkedinURL":"https:\/\/www.linkedin.com\/feed\/update\/urn:li:activity:7042127127646756864","githubURL":null,"paperURL":null,"author":"Antonio Benedetti","createdDate":"03\/16\/2023"},{"title":"The title is: PyEquion - An Open-Source Python Library for Calculating Aqueous Electrolyte Equilibrium","description":"Are you looking to add #Electrolytes #Chemical #Equilibrium to your model?  Then have a look at #PyEquion ! \u2795\ud83d\udca7 \u2796\n\nToday we wanted to bring your attention on the importance of understanding and modelling #aqueous #electrolyte #solutions. This might be useful in various applications, such as #pharmaceutical crystallization. Having an accurate understanding of these solutions is crucial for #designing and #optimizing processes.\nThis is wher #PyEquion comes in!\u00a0PyEquion is an #opensource python library developed specifically for calculating aqueous electrolyte #equilibrium.\u00a0With PyEqulon you can input the feed components of a solution and the package will automatically identify the composing ions as well as the chemical reactions involved to calculate equilibrium conditions. What makes this tool even more facinating is that the built-in activity coefficient models are structured in a modular approach, allowing users to perform non-ideality calculations with their own provided function\/code. This package is a great tool for modellers who want to readily identify the equilibrium reactions and possible solid phases in a user-friendly way.\nGive it a try of this open-source library and let us know what you think!\n\nCongrats to the developers Caio Curitiba Marcellos, Danilo Naiff, Gerson Francisco da Silva Junior, Elvis do Amaral Soares, Fabio Ramos, Amaro Barreto Jr\n\nLink to #Github: https:\/\/lnkd.in\/etNqJnND \nSimplified Web-GUI: https:\/\/lnkd.in\/eNGUvZVa ","linkedinURL":"https:\/\/www.linkedin.com\/feed\/update\/urn:li:activity:7041828664782540800","githubURL":null,"paperURL":null,"author":"Antonio Benedetti","createdDate":"03\/15\/2023"},{"title":"The title is: Predicting #hydrogen bond strength to support #drugdiscovery and #drugdesign! \ud83d\udd17\ud83d\udc8a\ud83d\udc68\u200d\ud83d\udd2c\ud83d\udc69","description":"Predicting #hydrogen bond strength to support #drugdiscovery and #drugdesign! \ud83d\udd17\ud83d\udc8a\ud83d\udc68\u200d\ud83d\udd2c\ud83d\udc69\u200d\ud83d\udd2c\n\nHydrogen bonding is a type of intermolecular interaction that results from the attraction between a hydrogen atom bonded to a highly electronegative atom (nitrogen, oxygen, etc.) in a first #molecule and another, highly electronegative atom in a second molecule. Apart from making water as we know it, hydrogen bonds are of fundamental importance in many drug discovery and development applications: Hydrogen bonding affects the interactions of small molecules at multiple levels of complexity, which in turn has a strong impact on the biological activity, #pharmacokinetics, and physicochemical properties of drugs. Despite its importance, characterising hydrogen bond interactions and predicting its properties is far from being well established. \n\nGian Marco Ghiandoni and Eike Caldeweyher\u00a0recently proposed Jazzy, an #opensource tool for calculating hydrogen bond strengths and molecular free energy of hydration from atomic partial charges and Van der Waals radii. Hydrogen bond strengths and free energies can be then used for drug screening purposes, or as starting properties for more complex molecular modelling. In addition, Jazzy enables the visualisation of hydrogen bond donors and acceptors, which are highlighted with different colour gradients, allowing for a clear, easy interpretation of existing data.\n\nThe tool was validated against two data sets of experimental hydration free energies, showing promising results. Jazzy also proved to be useful in understanding structure\u2013activity relationships of #bioactive components. Overall, Jazzy can be used for interactive drug design, compound screening, as well as #machinelearning modelling. \n\nWell done Gian Marco and Eike, and many thanks for making your work accessible to the community!\n\n#GitHub:\u00a0https:\/\/lnkd.in\/eQtt5MFT\n#opensource publication: https:\/\/lnkd.in\/eb5Hnmsz","linkedinURL":"https:\/\/www.linkedin.com\/feed\/update\/urn:li:activity:7041409446396231680","githubURL":null,"paperURL":null,"author":"Alberto Marchetto","createdDate":"03\/14\/2023"},{"title":"The title is: Optimizing #Experimental #Design in #Stochastic Systems Using Model-Based DoE (#SMBDoE)","description":"Optimizing #Experimental #Design in #Stochastic Systems Using Model-Based DoE (#SMBDoE) \ud83e\uddea\ud83d\udd2c: A New Method for Simultaneously Identifying Optimal Operating Conditions and Sampling Strategies \ud83c\udfaf\ud83d\udcc8\ud83d\udd70\ufe0f\n\nIn this paper, authors Chunbing Huang, Federica Cattani, and Federico Galvanin present a new method for SMBDoE that simultaneously identifies optimal operating conditions and allocation of sampling points in time. The method uses two sampling strategies to select sampling intervals based on the average and the uncertainty of Fisher information, ensuring that the experimental data is informative and precise in estimating model parameters.\nThis publication highlights the importance of systematic model-based DoE in maximizing the information gained from an experimental campaign, particularly in stochastic systems where intrinsic uncertainty can significantly impact the experimental design.\n\nIt's great to see how this collaboration between UCL and Syngenta contributes to the advancements of Model-Based Design of Experiments.\n\nLink to #Publication: https:\/\/lnkd.in\/eNhj7ee6 ","linkedinURL":"https:\/\/www.linkedin.com\/feed\/update\/urn:li:activity:7040667880320860160","githubURL":null,"paperURL":null,"author":"Antonio Benedetti","createdDate":"03\/12\/2023"},{"title":"The title is: Estimating Ice Nucleation Kinetics in Biopharmaceutical Vials","description":"Advances in Model-Based #Freezing Process Design: Estimating Ice #Nucleation #Kinetics in Biopharmaceutical Vials \ud83c\udf21\ufe0f\u2744\ufe0f\ud83d\udc89\n\nThis recent paper by Leif-Thore Deck and Marco Mazzotti presented a new method for estimating nucleation kinetic parameters and their uncertainty from experimental data generated in a parallelized mid-throughput batch-crystallizer. This method aims to improve the #modelbased freezing process design, which is essential for the freezing and freeze-drying processes of biopharmaceuticals in vials.\nIce nucleation is inherently stochastic, and nucleation events occur in the vials of a batch at different times and temperatures, making it a major challenge for these processes. The methodology presented in this paper considers the #stochasticity and the #variability in heterogeneous nucleation sites among vials, which extends the conventional stochastic description of ice nucleation.\nThe model was validated with experimental data, and the results showed a nearly quantitative agreement for the predictions of the extended model with experimental data, and a qualitative one for the conventional model. While the focus of the work is on ice nucleation kinetics, the rigorous analysis of the experimental uncertainty may also be of relevance for nucleation studies in related fields, such as industrial crystallization.\nThe new method for estimating nucleation kinetic parameters is a step forward in the right direction for the biopharmaceutical industry. \n\nImproved process control, increased efficiency, and reduced costs are some of the potential benefits of the model-based freezing process design. Well done Leif-Thore and Marco!\n\nLink to #Publication: https:\/\/lnkd.in\/eX6eedPi\n\n#biopharmaceuticals #freezingprocessdesign #nucleationkinetics #crystallization","linkedinURL":"https:\/\/www.linkedin.com\/feed\/update\/urn:li:activity:7040304979848364032","githubURL":null,"paperURL":null,"author":"Antonio Benedetti","createdDate":"03\/11\/2023"},{"title":"The title is: Can Artificial Intelligence (AI) Help Optimizing Drug Tableting Processes?","description":"Can artificial intelligence (#AI) help optimizing drug tableting processes? \ud83d\udc8a\ud83d\udcbb\ud83d\udc68\u200d\ud83d\udd2c\n\nPowder flowability is a key parameter in the manufacturing of solid dosage forms, as it informs the choice of tableting methods. Traditionally, flowability measurements require large quantities of materials, significant time and human investments, and repeat testing due to a lack of reproducible results when taking experimental measurements. This process is particularly challenging during the early-stage development of a new formulation, when the amount of material is limited. Additionally, it contributes to the overall long time required for #pharmaceuticals to reach the market. \n\nTo overcome these challenges, Matthew Wilkinson and coworkers have developed a new method that uses #DeepLearning (#DL) to predict powder flow from images of bulk powder particles. Using this approach, the need for experimental powder flow characterization is reduced as the DL predictions derive from prior experience. By reducing the material demand and measurement times, this data-driven approach can be better applied to early-stage drug development, which is by nature a highly iterative process. This technology can help new pharmaceutical products be developed faster with less material, reducing costs, limiting material waste, and resulting in a more efficient, sustainable manufacturing process. With a validation accuracy of 98.9%, the method proposed by the authors has the potential to significantly improve the pharmaceutical industry's manufacturing process.\n\nKudos to the authors for their work! Matthew Wilkinson, Laura Pereira D\u00edaz, Antony D. Vassileiou, John Armstrong, Cameron Brown, Bernardo Castro Dominguez, Alastair Florence \n\nLink to #GitHub: https:\/\/lnkd.in\/eMWcrWFC\nLink to #OpenAccess Publication: https:\/\/lnkd.in\/e3Y8gHJF","linkedinURL":"https:\/\/www.linkedin.com\/feed\/update\/urn:li:activity:7039916390643851264","githubURL":null,"paperURL":null,"author":"Alberto Marchetto","createdDate":"03\/10\/2023"},{"title":"The title is: Modelling Batch Distillation: Dynamic Parameter Estimation and Optimization to improve Efficiency and Sustainability","description":"Modelling Batch Distillation: Dynamic Parameter Estimation and Optimization to improve Efficiency and Sustainability \u2697\ufe0f \ud83c\udf43 \ud83d\udcb9 \n \nDistillation columns are a crucial part of many industries, from oil and gas to pharmaceuticals, and there are approximately 40,000 of them in the US alone. However, these columns consume a significant amount of energy, accounting for 6% of the yearly US energy demand. While continuous distillation columns have been the focus of optimization efforts, batch columns have often been overlooked due to their transient nature.\n \nIn this recent study by Seyed Mostafa Safdarnejad et al., a new methodology was used to model, estimate, and optimize a simple batch column with a binary methanol-ethanol mixture. Nonlinear statistics and sensitivity analysis were used to refine the model and find the best parameter estimates for dynamic optimization implementation. \n \nThis study highlights the importance of embedding modelling to optimize basic unit operations such as batch distillation, which are often used for specialty and smaller-use items, but also for energy demanding pharmaceuticals product. By doing that, we can improve the efficiency and sustainability of these processes. \n \nWell done to Mostafa Safdarnejad, Jonathan Gallacher, John Hedengren and thanks for sharing the code as #opensource.\n \nLink to #Github: https:\/\/lnkd.in\/eKUeac6P \nLink to Publication: https:\/\/lnkd.in\/eTRnNUga","linkedinURL":"https:\/\/www.linkedin.com\/feed\/update\/urn:li:activity:7039578015751634945","githubURL":null,"paperURL":null,"author":"Antonio Benedetti","createdDate":"03\/09\/2023"},{"title":"The title is: Sensitivity Analysis Library (SALib)","description":"Exploring #Model #Behavior: A tool to #Sensitivity #Analysis \ud83d\udd0d \ud83e\uddee \ud83d\udcca \n\nSensitivity analysis is a technique for quantifying how much the output of a model changes in response to changes in its input parameters. By examining the sensitivity of a model to different input parameters, we can gain insight into how the model works and identify areas where improvements can be made. It can also be helpful to identify the variables that impact the most the response of interest and enhance process understanding.\nIn this context, we want to share with you #SALib (Sensitivity Analysis Library), an easy-to-use #Python #opensource package for sensitivity analysis!\nSALib contains implementations of commonly used Global Sensitivity Analysis methods including: Sobol, Morris, Delta Moment-Independent Measure, Derivative-based Global Sensitivity Measure (DGSM), and Fractional Factorial Sensitivity Analysis.\u00a0\nWith SALib, global sensitivity analysis can be seamlessly integrated into a variety of modelling workflows, regardless of the specific application \n\nWe love this package and we want to share this with our #Polymodellers. Really well done to Takuya Iwanaga, Will Usher, Jon Herman and the numerous contributors!\n\nLink to #Github:\u00a0https:\/\/lnkd.in\/eY6Wd6MG\u00a0\nLink to Publication: 10.21105\/joss.00097\nLink to SALib documentation: https:\/\/lnkd.in\/eBH2CwHs","linkedinURL":"https:\/\/www.linkedin.com\/feed\/update\/urn:li:activity:7039216198021980160","githubURL":null,"paperURL":null,"author":"Antonio Benedetti","createdDate":"03\/08\/2023"},{"title":"The title is: Reagent Prediction with a Molecular Transformer to Improve Reaction Data Quality","description":"#Transformers Revolution: Reagent Prediction with a #Molecular #Transformer to Improve #Reaction Data Quality - Pfizer & Co recent #opensource release \ud83e\udd16\u269b\ufe0f\ud83e\uddea\n\nExciting news in the world of generative chemistry! The key to success in this field is automated synthesis planning, but traditional methods have fallen short due to a lack of recommendations for reaction conditions. However, a new study published today in Chemical Science by Mikhail Andronov et al. has introduced a game-changing solution to this problem. By utilizing a cutting-edge Transformer model, this state-of-the-art approach for reaction prediction and single-step retrosynthesis has been trained on the US patents dataset and tested on Reaxys, demonstrating impressive out-of-distribution generalization capabilities.\nThanks to this breakthrough technology, arbitrary reactions can now be accurately predicted with the identification of the most suitable reagents. Notably, this model outperforms those trained solely on USPTO data, marking a significant advancement for the field of generative chemistry.\n\nThe success of this study is a result of the collaborative efforts between Swiss AI Lab IDSIA USI-SUPSI and Pfizer's joint PhD student in the AIDD-ITN IMI PhD Program. It is an excellent example of the power of partnerships in driving innovation and achieving groundbreaking results while also contributing to foster innovation through #opensource sharing. Kudos to Mikhail Andronov, Varvara Voinarovska, Natalia Andronova, Michael Wand, Djork-Arn\u00e9 Clevert and J\u00fcrgen Schmidhuber\n\nLink to #Github: https:\/\/lnkd.in\/esynWunz\nLink to #OpenAccess Publication: https:\/\/lnkd.in\/e66-9rKZ","linkedinURL":"https:\/\/www.linkedin.com\/feed\/update\/urn:li:activity:7038659521535176704","githubURL":null,"paperURL":null,"author":"Antonio Benedetti","createdDate":"03\/06\/2023"},{"title":"The title is: Porchlight","description":"Introducing #Porchlight: A Python-based Application for #Spectroscopic #Preprocessing and Student Learning \ud83d\udcbb\ud83d\udcc8\ud83d\udc68\u200d\ud83d\udd2c\n\nPreprocessing is a critical step in the analysis pipeline of spectroscopic data, yet it is rarely introduced in laboratory courses. This can delay students' progress in the field and limit their understanding of the analysis process. \nA new Python-based application has been developed to support student learning in the field of spectroscopic analysis. The application, called #Porchlight, aims to provide an easy-to-use platform for students to apply common spectral preprocessing techniques with instantaneous results. Porchlight aims to fill this educational and good practice gap and make spectroscopic analysis widely available to students, trainees, and users in general, without the need for costly commercial software.\nCheck out Porchlight and the supplied Jupyter notebooks today to learn more about this innovative application. \n\nWell done Jakub Konkol\u00a0and\u00a0George Tsilomelekis from Rutgers University for sharing this #opensource tool with the academic community!\n\nLink to #Github: https:\/\/lnkd.in\/ePyNkGJM\nLink to Publication:  https:\/\/lnkd.in\/eSvGWaTK\n\n#spectroscopy #python #preprocessing #scienceeducation","linkedinURL":"https:\/\/www.linkedin.com\/feed\/update\/urn:li:activity:7038483882693787649","githubURL":null,"paperURL":null,"author":"Antonio Benedetti","createdDate":"03\/06\/2023"},{"title":"The title is: Efficient and Sustainable Solvent Selection Tool","description":"A Holistic and Data-Driven Approach to #Efficient and #Sustainable #Solvent #Selection \ud83d\udc69\u200d\ud83d\udd2c\ud83c\udf31\ud83d\udcbb\n\nToday we want to share this tool developed by the AstraZeneca team to consider multiple factors including chemical functionality, physical properties, regulatory concerns, and safety\/health\/environmental (SHE) impact to identify appropriate solvents for use in experiments.\nBy utilizing this tool, chemists can save time and reduce costs by identifying suitable solvents before conducting screening experiments. Established processes can also be improved by replacing less desirable solvents with more appropriate alternatives, benefiting both the bottom line and the environment.\nBut the value of this tool doesn't stop there. Once a shortlist of solvents has been identified, the data can be used to define experimental programs or exported to a molecular properties prediction tool to further assess suitability. As the chemistry industry continues to evolve, this tool remains an essential resource for ensuring the safe and effective use of solvents in experiments.\nSo if you haven't yet tried out this interactive solvent selection tool, now is the time to give it a go and streamline your workflow while making more environmentally conscious decisions.\n\nKudos to the authors: Louis Diorazio,\u00a0David Hose,\u00a0and\u00a0Neil Adlington\n\nLink to #OpenAccess Publication: https:\/\/lnkd.in\/eU9ttiiu\nLink to Web Tool: https:\/\/lnkd.in\/eKHx_rsa\n\n#GreenChemistry #Sustainability #ChemicalResearch ","linkedinURL":"https:\/\/www.linkedin.com\/feed\/update\/urn:li:activity:7038149668731539456","githubURL":null,"paperURL":null,"author":"Antonio Benedetti","createdDate":"03\/05\/2023"},{"title":"The title is: Continuous Bioprocessing: Revolutionizing the Manufacturing of Biologics Using Modelling, Real-time PAT and In-Process Control","description":"#Continuous #Bioprocessing: Revolutionizing the Manufacturing of Biologics Using #Modelling, Real-time #PAT and In-Process #Control \ud83c\udf9b\ufe0f \u2194\ufe0f \ud83e\udda0 \n\nContinuous bioprocessing is revolutionizing the manufacturing of biologics, including protein-based drug molecules such as monoclonal antibodies (mAbs). This promising technology has the potential to enhance product quality, process stability, and overall profitability, much like advanced manufacturing processes did for small molecule drugs over the past decade.\nDespite the benefits, the implementation of continuous manufacturing for biological processes producing mAbs faces numerous challenges. The barriers can, however, be surmounted through better predictive capabilities, facilitated by hybrid modeling that can lead to robust process control, resulting in improved process understanding.\u00a0\nIn this insightful review, the recent advances and ongoing obstacles encountered during the use of advanced process analytical technologies (PAT), process modeling, and control strategies to enable continuous manufacturing of mAbs are summarized. The review also highlights the process strategies and future directions of advanced continuous manufacturing approaches adapted by other industries that could soon be implemented for mAbs production. \n\nCongratulations to Viki Chopda, \u00c1ron Gyorgypal, Ou Yang, Dr. Ravendra Singh, Rohit Ramachandran, Haoran Zhang, George Tsilomelekis, Shishir P S Chundawat, and Marianthi Ierapetritou  for their excellent work in summarizing the recent advances and ongoing obstacles faced during the use of advanced process analytical technologies, process modeling, and control strategies to enable continuous manufacturing of mAbs. \n\nLink to Publication: https:\/\/lnkd.in\/gghmiaRD ","linkedinURL":"https:\/\/www.linkedin.com\/feed\/update\/urn:li:activity:7037773403784712192","githubURL":null,"paperURL":null,"author":"Antonio Benedetti","createdDate":"03\/04\/2023"},{"title":"The title is: Cultured Meat Production: Overcoming Cell Cultivation Challenges in Bioreactors","description":"Helping scaling up cell cultivation for cultured meat production \ud83e\udd69\ud83c\udf56\ud83e\uddeb\ud83e\uddec\n\nCultured meat is one of the most promising solutions to end animal slaughtering (and dramatically reduce the CO2 emissions associated with farming) while still being able to enjoy a delicious beef steak. \n\nIn order to culture meat, it is necessary to combine state-of-the-art #TissueEngineering techniques and #BioprocessEngineering expertise for cell cultivation in #bioreactors. There are, however, a variety of issues linked to bulk cell growth in bioreactors: Metabolic inefficiency, low cell growth rate and cell growth inhibition, as well as cell damage caused by turbulent flows and\/or bubble formation. As a result, these criticalities hinder the scale of the process units used and the attainable cell density. \n\nTo make cultured meat possible at a large scale, it is of paramount importance for researchers to collaborate and help each other to overcome the issues associated with cell cultivation in bioreactors. On that note, we would like to share with you the first release of a #Python based technical analysis workflow for cultivated meat yield prediction and optimisation. The package is released by Simon Hubbard, and is derived from models and approaches available in literature to describe bioreactor performance and media characterisation. A method for bioreactor process optimisation is also included in the package!\n\nKudos to Simon, and thank you for your contribution to make cultured meat production possible in the future!\n\nLink to #GitHub:\u00a0https:\/\/lnkd.in\/dbebERZs","linkedinURL":"https:\/\/www.linkedin.com\/feed\/update\/urn:li:activity:7037413307753861120","githubURL":null,"paperURL":null,"author":"Alberto Marchetto","createdDate":"03\/03\/2023"},{"title":"The title is: Predicting Retention Indices of Structurally Unknown Chemicals Using Machine Learning","description":"Studying and discovering potentially threatening chemicals \ud83d\udd2c\ud83e\uddea\ud83d\udd0e\n\nMeasuring the possible exposures of an individual in a lifetime and how those exposures relate to health is fundamental to understand the potential health impact of the chemical species we may get in contact with in our life. \n\nThe human and environmental #exposome contains countless chemicals of several different nature. These chemicals cover a wide range of molecular weights, functional groups or compound classes, physiochemical properties, and #toxicity. Most of them, moreover, are structurally unknown and therefore we do not know much about their potential health impact. \n\nTo help solving such issues, Jim Boelrijk et al. have developed a novel #MachineLearning algorithm that can predict the retention indices (RI) of chemicals in non-target analysis (NTA) combined with high-resolution #MassSpectrometry (HRMS). This breakthrough is significant because RI values are used in non-target analysis experiments to help identify unknown chemicals and their potential impact on human and environmental health. In general, predictions of RI require the exact structure of the chemicals, but the methodology proposed by the authors allows for the prediction of RI for structurally unknown species. \n\nThe model was validated using both experimental RI values and descriptor-based predicted RI values, and showed comparable accuracy to conventional molecular descriptor-based models.\nThis breakthrough has great potential to unravel the human and environmental exposome via non-target analysis assays and can help identify chemicals of emerging concern. \n\nCongratulations to the whole group on this innovative research!\n\nJim Boelrijk,\u00a0Denice van Herwerden,\u00a0Bernd Ensing,\u00a0Patrick Forr\u00e9\u00a0&\u00a0Saer Samanipour \n\nLink to #GitHub: https:\/\/lnkd.in\/ewsbnDvT\nLink to Publication: https:\/\/lnkd.in\/eR9HtpRy","linkedinURL":"https:\/\/www.linkedin.com\/feed\/update\/urn:li:activity:7037081129157316609","githubURL":null,"paperURL":null,"author":"Alberto Marchetto","createdDate":"03\/02\/2023"},{"title":"The title is: Bayesian Optimization Tutorial Series on BoTorch","description":"Do you want to learn #Bayesian #Optimization but don't know where to start? \ud83e\uddee \ud83d\udcbb \ud83c\udfaf \n\nOver the last few months, we've shared some great works showcasing the power of Bayesian Optimization, from optimizing chemical reactions to tuning machine learning hyperparameters. It's a powerful technique for optimizing costly-to-evaluate black-box functions and can be applied to a wide range of scientific and engineering problems. \n\nToday, we're excited to share an excellent educational resource: Eduardo C\u00e9sar Garrido Merch\u00e1n's Jupyter notebook tutorial series on #BoTorch. BoTorch is an #opensource software library developed by Facebook AI Research (FAIR) that provides tools and algorithms for Bayesian Optimization of machine learning models. With BoTorch, you can optimize hyperparameters, perform active learning, and tune experimental setups, all while leveraging #PyTorch's automatic differentiation capabilities for efficient optimization. It also supports parallel evaluation of objective functions and integrates with popular optimization libraries.\n\nWhether you're a seasoned machine learning practitioner or just getting started, Eduardo's tutorial series on BoTorch is an excellent way to dive into Bayesian Optimization. Check it out today! \n\nLink to #Github: https:\/\/lnkd.in\/eWqZpMCt","linkedinURL":"https:\/\/www.linkedin.com\/feed\/update\/urn:li:activity:7036666577248743424","githubURL":null,"paperURL":null,"author":"Antonio Benedetti","createdDate":"03\/01\/2023"},{"title":"The title is: SDEGen: learning to evolve molecular conformations from thermodynamic noise for conformation generation","description":"#SDEGen: learning to evolve molecular conformations from thermodynamic noise for conformation generation\n\u269b\ufe0f\ud83d\udc69\u200d\ud83d\udd2c\n\n#Chemistry101: The conformation of a molecule represents the 3D coordinates of all the atoms in a molecule.\nWhy should that be of interest for us? From statistical dynamics, we know that everything about a macroscopic system can be inferred if we get all the corresponding system geometries. Analogously, if we obtain all the possible 3D conformations of a molecule, we can get access to molecular information that can be crucial in drug discovery studies. \n\nBearing that in mind, Haotian Zhang and coworkers have developed a novel conformation generation model based on stochastic differential equations (differential equations whose coefficients are random numbers or random functions of the independent variable(s)), called SDEGen. SDEGen is aimed at tackling the challenge of generating all possible conformations for studied systems in complicated biomolecule-involved problems such as structure-based drug design. Their research demonstrates that SDEGen can outperform existing methods in different tasks, e.g., conformation generation, interatomic distance distribution prediction, and thermodynamic property estimation, showing great potential for real-world applications.\n\nSDEGen enjoys many advantages, including high model capacity to capture multimodal conformation distributions, possibility to generate molecular conformations efficiently, and a clear physical interpretation. Compared to existing methods, SDEGen can generate not only one energetically favourable conformation but also a series of locally optimal conformations, thus being consistent with real thermodynamic environments.\n\nCongratulations to the whole team for sharing this powerful tool with the scientific community through #GitHub. Their contribution will undoubtedly benefit researchers in #cheminformatics and computer-aided drug discovery, leading to more effective drug design and development.\n\nHaotian Zhang, Shengming Li, Jintu Zhang, Zhe Wang, Jike Wang, Dejun Jiang, Zhiwen Bian, Yixue Zhang, Yafeng Deng, Jianfei Song, Yu Kang and Tingjun Hou\n\nLink to GitHub: https:\/\/buff.ly\/3ICVeE9\n\nLink to Publication: https:\/\/buff.ly\/3kxjxeA","linkedinURL":"https:\/\/www.linkedin.com\/feed\/update\/urn:li:activity:7036304311173152770","githubURL":null,"paperURL":null,"author":"Antonio Benedetti","createdDate":"02\/28\/2023"},{"title":"The title is: \"Janssen Pharmaceutical Companies of Johnson & Johnson Release Open-Source Package for Reaction Yield Prediction Using BERT Enriched Embedding\"","description":"#Transformers\u00a0Revolution Series ! It's\u00a0#Drug\u00a0#Development\u00a0time:\u00a0The Janssen Pharmaceutical Companies of Johnson & Johnson Released an #OpenSource Package to Predict #Reaction #Yield \ud83e\udd16 \ud83e\uddea \ud83d\udc8a \n\nAs a new episode of our #TranformersRevolution series, we want to share today an exciting work published by the n-Silico Discovery and External Innovation team at J&J.  The pharmaceutical industry is seeing exciting developments thanks to the application of Artificial Intelligence (#AI), particularly #DeepLearning models. One area with unrealized potential is reaction yield prediction, where one fifth of synthesis attempts result in yields that are too low. To address this, a team developed a #BERT Enriched Embedding (#BEE) model that was pre-trained on 16 million reactions from four data sources. The model demonstrated a near 20-point improvement in R2 score compared to state-of-the-art models and was tested on an internal company data benchmark, reducing the number of negative reactions ran by at least 34%. The model was also used successfully as a reagent recommender in an ongoing drug discovery project, highlighting its potential for industry application. \n\nCongratulations to the authors for their tremendous work! It's great to see that another model has been published as open-source on #Github. This will undoubtedly benefit the scientific community and further advance research in this important field. It's also great to see how Pharma already leverages #transformers beyond #chatGPT bots. Kudos to Paulo Neves,\u00a0Kelly McClure,\u00a0Jonas Verhoeven,\u00a0Natalia Dyubankova,\u00a0Ramil Nugmanov,\u00a0Andrey Gedich,\u00a0Sairam Menon,\u00a0Zhicai Shi\u00a0&\u00a0Joerg Kurt Wegner \n\nLink to Github: https:\/\/buff.ly\/3m8OJBi \nLink to Publication: https:\/\/buff.ly\/3Z4tMG3\n\n#aiml #chatgpt #drugdevelopment #drugdiscovery ","linkedinURL":"https:\/\/www.linkedin.com\/feed\/update\/urn:li:activity:7035941793951051778","githubURL":null,"paperURL":null,"author":"Antonio Benedetti","createdDate":"02\/27\/2023"},{"title":"The title is: Realistic interplays between #Data #Science and #Chemical #Engineering","description":"\"Realistic interplays between #Data #Science and #Chemical #Engineering\" \ud83d\udcbb \u2697\ufe0f \ud83c\udfed \n\nToday we want to share this very interesting review by Patrick Piccione on the current moderate uptake of digital technologies in the chemical and process industries despite the steady stream of value statements and promises. It provides method recommendations for successful digital transformation in the industry, covering strategy development, organisational mobilisation, and project delivery. The paper emphasises the importance of assembling a skilled team, understanding data science and digital transformation, and focusing on real needs in strategy development. Mobilising an organisation is equally critical and requires enabling project identification, setting up a supportive organisational structure, and forming valuable partnerships to access external resources. Effective collaborations and a diverse portfolio are needed to deliver valuable projects, and the use of software best practices is beneficial. The paper concludes by highlighting future trends in data science beyond traditional analytics and the need to encourage individuals interested in disruptive currents to stay ahead of the curve. \n\nThis is a very insightful paper! Thank you Patrick Piccione for sharing this with the scientific and industrial community \ud83d\udc4f \n\nLink to Publication: https:\/\/buff.ly\/3Z64tDG \n\n#DigitalTransformation #ChemicalIndustry #DataScience #SmartManufacturing #Industry4_0 #ProjectDelivery #OrganisationalMobilisation #SoftwareBestPractices #Collaboration  #TeamEmpowerment #ExternalPartnerships #PortfolioDiversity  #BusinessStrategy #ValueCreation #Innovation #Productivity #Efficiency #Leadership","linkedinURL":"https:\/\/www.linkedin.com\/feed\/update\/urn:li:activity:7035596758583758848","githubURL":null,"paperURL":null,"author":"Antonio Benedetti","createdDate":"02\/26\/2023"},{"title":"The title is: Integrating Mechanistic and Empirical Constraints to Improve Predictive Power in Flux Balance Analysis","description":"Going #Hybrid for #GenomeScale Modelling \ud83d\udd00 \ud83e\uddec  : Integrating #Mechanistic and #Empirical Constraints to Improve Predictive Power in Flux Balance Analysis (#FBA) \ud83d\udd0d \ud83e\udda0 \n\nToday we reccomend this great new paper by Jo\u00e3o Ramos et al. in which the authors suggest that integrating mechanistic-level constraints with empirical constraints in the same linear program can significantly improve the predictive power of Flux Balance Analysis (FBA) methods.FBA is currently the standard method for computing metabolic fluxes in genome-scale networks. However, there have been several FBA extensions employing diverse objective functions and\/or constraints published. The proposed hybrid semi-parametric FBA extension combines mechanistic-level constraints (parametric) with empirical constraints (non-parametric) in the same linear program. The authors of the paper used a CHO dataset with 27 measured exchange fluxes obtained from 21 reactor experiments to evaluate the method. The mechanistic constraints were deduced from a reduced CHO-K1 genome-scale network with 686 metabolites, 788 reactions and 210 degrees of freedom. The non-parametric constraints were obtained by principal component analysis of the flux dataset.The authors found that integrating parametric and nonparametric constraints in the same linear program reduced the solution space and improved the specific growth rate prediction under different constraints scenarios. Moreover, a metabolically efficient cell growth feed targeting minimal byproducts accumulation was designed by hybrid FBA. The proposed method is an efficient approach to improve the predictive power of FBA methods when critical mechanistic information is missing. \n\nWe congratulate Jo\u00e3o Ramos,\u00a0Gil P.,\u00a0Patrick Dumas\u00a0& Rui Oliveira on their groundbreaking work and look forward to seeing how this new approach will be applied in the the pharmaceutical design of new mAbs therapies. \n\nLink to Publication: https:\/\/rdcu.be\/c6mXh","linkedinURL":"https:\/\/www.linkedin.com\/feed\/update\/urn:li:activity:7035240285383094272","githubURL":null,"paperURL":null,"author":"Antonio Benedetti","createdDate":"02\/25\/2023"},{"title":"The title is: Quantifying Uncertainty in Partial Least Squares using Bootstrapping","description":"Wondering how to Quantify #Uncertainty in Partial Least Squares (#PLS)? #Bootstrapping is the solution! \ud83d\udd22\ud83c\udfaf  \ud83d\udd03 \u2705 \n\nThe quantification of uncertainty in the parameters of a model is critical for assessing the reliability and generalizability of its predictions. For example, high uncertainty in the parameters of a PAT model that is used for Real-time Release can results in a high percentage of invalid predictions for the product.\nIn this collaboration by Eli Lilly and Company and Imperial College London, James Odgers et al published a new approach for modeling uncertainty in Partial Least Squares (PLS) that accounts for the non-linear effects of observed data on the latent space. The approach, based on #bootstrapping, enables accurate representation of confidence intervals for points near or far from the latent space.The paper demonstrates the benefits of the method in two applications: determining the Design Space for industrial processes and modeling the uncertainty of spectroscopy data. Results show that this approach is effective for accounting for uncertainty far from the latent space in Design Space identification, while also matching the performance of established methods for spectroscopy data.The code for this approach is available on the authors' Github repository. We hope this method will help researchers and practitioners better understand the uncertainty in their PLS models. \n\nReally excellent work James Odgers, Chryssa Kappatou ,\u00a0Ruth Misener,\u00a0Salvador Garc\u00eda Mu\u00f1oz and Sarah Filippi ! It's inspiring to witness academia and industry collaborating to advance scientific transparency by openly sharing the package as open-source. \n\nLink to #Github: https:\/\/buff.ly\/3IuVx3A \nLink to Publication: https:\/\/buff.ly\/3SpoN0a","linkedinURL":"https:\/\/www.linkedin.com\/feed\/update\/urn:li:activity:7034854554038886400","githubURL":null,"paperURL":null,"author":"Antonio Benedetti","createdDate":"02\/24\/2023"},{"title":"The title is: SKiMpy - A Python Package for Intuitive and Efficient Modeling of Large-Scale Biochemical Reaction Networks","description":"Biological organisms are complex systems, whose response to environmental or #genetic perturbations are difficult to model. Within such framework, large-scale kinetic models become fundamental to understand how the underlying biochemical reaction networks are affected by such perturbations. However, the development and application of these models is limited by the availability of computational tools that can be applied to build and analyse them properly. \n\nDaniel Weilandt and coworkers recently developed the SKiMpy #Python package, which can help implementing, parameterising and analysing these models intuitively and efficiently. Their work is an invaluable tool for understanding the dynamic and adaptive responses of biological systems, and it bridges the gap between the availability of computational tools and the need for large-scale modelling.\nSKiMpy can be used in various biological domains, including signaling, gene expression, and metabolism. The #toolbox can be used to parameterise kinetic models around a steady-state reference and to implement multispecies bioreactor simulations for assessing biotechnological processes.\n\nThe authors' decision to make SKiMpy available as a Python package on #GitHub is commendable, as it makes the software accessible to a wider community and encourages collaboration and further development.\n\nKudos to all the team's member for their work, and for sharing it with the community!\nDaniel Weilandt, Pierre Salvy, Maria Masid Barcon, Georgios Fengos, Robin Denhardt-Eriksson, Zhaleh Hosseini and Vassily Hatzimanikatis\n\nLink to GitHub: https:\/\/lnkd.in\/eFUeArRe\nLink to the Publication: https:\/\/lnkd.in\/esmfzcBC","linkedinURL":"https:\/\/www.linkedin.com\/feed\/update\/urn:li:activity:7034499920640270336","githubURL":null,"paperURL":null,"author":"Alberto Marchetto","createdDate":"02\/23\/2023"},{"title":"The title is: IDAES Integrated Platform for Sustainable Energy Systems","description":"\ud83d\udd0b Revolutionizing #Energy Industry #Sustainability with #OpenSource #Process #System #Engineering \u26a1 \n\nToday we want to share this massive #opensource project by The Institute for Design of Advanced Energy Systems (#IDAES) .\nTherefore, will just limit ourselves to quote their description: \"Transforming and decarbonizing the world\u2019s energy systems to make them environmentally sustainable while maintaining high reliability and low cost is a task that requires the very best computational and simulation capabilities to examine a complete range of technology options, ensure that the best choices are made, and to support their rapid and effective implementation.The Institute for Design of Advanced Energy Systems (#IDAES) was originated to bring the most advanced modeling and optimization capabilities to these challenges. The resulting IDAES integrated platform utilizes the most advanced computational algorithms to enable the design and optimization of complex, interacting energy and process systems from individual plant components to the entire electrical grid.A team of the world leading scientists and engineers continues to advance the platform to address new challenges, enhance usability, and to assist the broad range of stakeholders who are adopting IDAES tools to deliver more sustainable, reliable, and affordable energy and process systems as well as related infrastructure and supply chains. \" \n\nThis is a perfect example of what an opensource project can achieve thanks to the power of the community! Kudos to some of the key contributors of this initiative: Andrew Lee,\u00a0Jaffer Ghouse,\u00a0John  Eslick,\u00a0Carl Laird,\u00a0John Siirola,\u00a0Miguel Zamarripa,\u00a0Dan Gunter,\u00a0John Shinn,\u00a0Alexander Dowling,\u00a0Debangsu Bhattacharyya,\u00a0Lorenz Biegler,\u00a0Anthony Burgard,\u00a0David Miller  \n\nLink to #Github: https:\/\/buff.ly\/3IHvhEA \nLink to #Website: https:\/\/buff.ly\/3YSZczl \nLink to #Publication: https:\/\/buff.ly\/3lSxwMi","linkedinURL":"https:\/\/www.linkedin.com\/feed\/update\/urn:li:activity:7034144767533805568","githubURL":null,"paperURL":null,"author":"Antonio Benedetti","createdDate":"02\/22\/2023"},{"title":"The title is: Model-based dynamic optimization to design monoclonal antibodies with a QbD approach: a step forward in the right direction.","description":"Model-based dynamic #optimization to design monoclonal antibodies (#mAbs) with a #QbD approach: a step forward in the right direction  \ud83e\udda0\n \nWe already spoke few times about monoclonal antibodies (mAb) models and that's because there is still a lot to unpack in order to be able to model this complex system to the level of accuracy required for different applications.  This very interesting article by Chryssa Kappatou , A. Ehsani, S. Niedenf\u00fchr, Adel Mhamdi ,  Andreas Schuppert , and Alexander Mitsos is a must-read! The authors utilize a mechanistic model for monoclonal antibodies production to derive optimal supplementation profiles of nutrients and nucleotide sugars, and incorporate constraints for acceptable glycosylation ranges into the dynamic optimization problem. The study highlights how model-based dynamic optimization can be used to implement the Quality by Design (QbD) approach in biopharmaceuticals, which is still a major challenge for the industry.\n \nLink to the Publication: https:\/\/lnkd.in\/ekEp7jZz","linkedinURL":"https:\/\/www.linkedin.com\/feed\/update\/urn:li:activity:7033782258964549633","githubURL":null,"paperURL":null,"author":"Antonio Benedetti","createdDate":"02\/21\/2023"},{"title":"The title is: Integrating #molecular and #process #design approach by leveraging a machine-readable #graphbased #molecular #representation \u269b\ufe0f \ud83e\uddea","description":"Integrating\u00a0#molecular\u00a0and\u00a0#process\u00a0#design\u00a0approach by leveraging a machine-readable #graphbased #molecular #representation \u269b\ufe0f \ud83e\uddea\n\nPhilipp Rehner and coworkers have recently published a research paper that presents a new approach to computer-aided molecular and process design (#CAMPD). In brief, a CAMPD is aimed at optimizing the process degrees of freedom simultaneously with the molecular degrees of freedom, thus resulting in a single\u00a0#optimization\u00a0problem. In this work, the integrated molecular and process design approach leverages a machine-readable graph-based molecular representation (molecule superstructure) that captures the full structural information about a molecular entity. The molecule superstructure implemented by the authors allows for molecular integer variable relaxation, thus making possible to use fast gradient-based optimization algorithms.\n\nThe proposed molecular design method was demonstrated by the authors in a case study to identify the optimal working fluid for a small-scale high-temperature organic Rankine cycle. Since the molecule superstructure consists of a fully informative structural representation of the molecule, it can be interfaced with more sophisticated property prediction methods than simple group contribution models. In the case study considered here, the heterosegmented gc-PC-SAFT equation of state (#EoS) was used as a property prediction model, and the results obtained by the authors demonstrated how the proposed molecular superstructure representation enables the efficient integration of advanced property models into molecular design.\n\nThis innovative research is a significant step forward in the field of molecular and process design, and we look forward to seeing how it can be further applied to other chemical engineering applications.\n\nCongratulations to the whole team for their contribution: Philipp Rehner, Johannes Schilling and\u00a0Andr\u00e9 Bardow\n\nLink to CAMPD framework (#GitHub):\u00a0https:\/\/lnkd.in\/eQkMe-A3 \nLink to Publication:\u00a0https:\/\/buff.ly\/3kcov03\n\n\n#Superstructure\u00a0#ChemicalEngineering\u00a0#OpenSource","linkedinURL":"https:\/\/www.linkedin.com\/feed\/update\/urn:li:activity:7033414365886205952","githubURL":null,"paperURL":null,"author":"Antonio Benedetti","createdDate":"02\/20\/2023"},{"title":"The title is: Nonlinear Model Predictive Control (NMPC) in Pharma: A Mean to Achieve Quality-by-Control (QbC)","description":"#AdvanceProcessControl in Pharma: Nonlinear Model Predictive Control (#MPC) as a mean to achieve Quality-by-Control (#QbC) \ud83c\udfaf\n\nThe implementation of nonlinear model predictive control (NMPC) has been proven to be an effective solution for highly sensitive variations and nonlinear multiple-input-multiple-output (MIMO) systems, which can be crucial for the highly regulated pharmaceutical manufacturing industry.\nThis #openaccess paper showcases the development and implementation of Nonlinear Model Predictive Control (NMPC) in continuous manufacturing of solid dosage forms in the pharmaceutical industry. To ensure control accuracy and effectiveness, the authors used a Moving Horizon Estimation (MHE) approach to estimate state variables and monitor real-time data. The paper presents a series of examples demonstrating the practical applicability and effectiveness of the approach, including for scenarios of plant-model mismatch and glidant effects. The adaptive NMPC implementation allowed for compensation of process uncertainties and reduced plant-model mismatch effects.\n\nWe look forward to seeing the continued impact of QbC and NMPC approaches in pharmaceutical manufacturing. Kudos to Yan-Shu Huang, Ziyan Sheriff, Ph.D., @Sunidhi Bachawala, @Marcial Gonzalez, Zoltan Nagy, @Gintaras Reklaitis\n\nLink to publication: https:\/\/lnkd.in\/ex8jhMmu\n","linkedinURL":"https:\/\/www.linkedin.com\/feed\/update\/urn:li:activity:7033117055897718785","githubURL":null,"paperURL":null,"author":"Antonio Benedetti","createdDate":"02\/19\/2023"},{"title":"The title is: Fluid Bed Granulation: Challenges and Approaches for Optimization","description":"Hey PolyModelers!\n\nToday, let's talk about Fluid Bed #granulation . A process that poses many questions to scientists in #pharmaindustry :\n\n- Can we pinpoint the key process parameters which need to be controlled during fluid bed granulation? \n- How can the granule moisture content be monitored and controlled (MPC anyone?) during fluid bed granulation, and how does this impact the #quality ?\n- Can the risk of agglomeration and particle breakage during fluid bed granulation be optimized?\n- What are the most common challenges encountered during scale-up?\n- What are the #regulatory requirements for fluid bed granulation processes in OSD manufacture, and how can compliance be demonstrated?\n\nCan you think of other questions\/open problems? Do you think modelling can be used to get actionable insight into the process? \n\nWe recommend going through the article by\u00a0Maryam Askarishahi,\u00a0Mohamed-Sadegh Salehi,\u00a0and\u00a0Stefan Radl\u00a0[https:\/\/lnkd.in\/ek3ycTFB]. The article discusses the complexity around fluid bed granulation and the importance of investigating particle-particle interactions to understand the process.\nIt summarizes numerical approaches used for modeling drying and agglomeration . Overall, this thorough review provides a useful overview of the challenges and approaches related to drying in fluid bed granulation. Kudos to the authors!\n\nLink to the paper: https:\/\/lnkd.in\/eiB-HNRg","linkedinURL":"https:\/\/www.linkedin.com\/feed\/update\/urn:li:activity:7032739144581697536","githubURL":null,"paperURL":null,"author":"Harry Christodoulou","createdDate":"02\/18\/2023"},{"title":"The title is: \"Feeding Modelling for Continuous OSD Manufacturing: A More Holistic Approach\"","description":"\"#Feeding #Modelling for Continuous #OSD Manufacturing: A More Holistic Approach\" \ud83d\udc68\u200d\ud83d\udd2c \ud83d\udca1\ud83d\udc8a \n\nIf you work in continuous OSD pharmaceutical manufacturing, you know the importance of characterizing your powder. This great research from Theresa R. H\u00f6rmann-Kincses  et al. focuses on the critical importance of powder feeding in continuous manufacturing and presents a new, holistic approach to predicting feeding issues and feed rate space for raw materials. The study introduces statistical models and novel equipment descriptors that capture the effect of different geometries and performance indicators, such as the end fill level, to predict potential feeding issues and to assess the \"feedability\" of raw materials.The workflow was demonstrated for a simple formulation, and model validation was successfully performed for an additional powder that was not contained in the original dataset. Additionally, the most relevant material attributes were identified, and reduced material characterization data sets were investigated in terms of effects on the model's prediction performance.\n\nOverall, this research presents a promising tool for initial process assessment in early-phase development! Kudos to the author team: Theresa R. H\u00f6rmann-Kincses, Michela Beretta, @Julia Kruisza, Fanny Stauffer, Gudrun Birk, Patrick Piccione, Jim Holman, Johannes Khinast \n\n #pharmaceuticalmanufacturing #continuousmanufacturing #materialcharacterization #flowability #powderfeeding \n\nLink to Publication: https:\/\/lnkd.in\/eSGJBrDi ","linkedinURL":"https:\/\/www.linkedin.com\/feed\/update\/urn:li:activity:7032321528956379137","githubURL":null,"paperURL":null,"author":"Antonio Benedetti","createdDate":"02\/17\/2023"},{"title":"The title is: Developing New Formulations That Can Overcome Limitations of Current Formulations Using a \"Bridge\" Design of Experiments Methodology.","description":"We may not know you, but we are pretty sure you use formulated products every day! Liquid #formulations are at the basis of countless daily products, including #pharmaceuticals, food, #cosmetics, and detergents. Although fundamental in our lives, many formulated products are toxic to the environment, cause pollution, require high ingredient concentrations to produce a desired effect, etc. Nevertheless, developing new formulations that can overcome these (and other) limitations is challenging and often associated with long and expensive trial-and-error campaigns. Approaches based on theoretical modelling might be seen as a solution, but first principles predictions of emergent properties of multi-component mixtures might not be accurate enough yet to justify their use. \n\nIn a recent study, Liwei Cao et al. introduced a \u201cbridge\u201d design of experiments (#DoE) methodology starting from one of their recent works. In a nutshell, the idea is to use an algorithmic design of experiments approach, coupling statistical modelling with robot-assisted experiments, to efficiently select a sub-set of formulation ingredients from an initial, available pool. Peculiarly, this was done in the absence of available physical models. \n\nThe developed methodology was applied to a commercial formulation to simultaneously meet specific customer-defined targets, i.e., formulation stability and viscosity. The authors thus demonstrated that the developed methodology can optimize two responses for a real detergent, allowing to select a subset of ingredients from an initial pool while using a relatively small number of experiments, generated by exploiting a robotic platform. \n\nCheck out their R package, available in #GitHub (link below)! \n\nCongratulations to the whole team for this great achievement, and thank you for sharing this with the research community: Liwei Cao, Danilo Russo, Emily Matthews, Alexei Lapkin, David Woods\n\nLink to GitHub: https:\/\/buff.ly\/3Yqg1Bu \nLink to Publication: https:\/\/buff.ly\/3K5NCMC","linkedinURL":"https:\/\/www.linkedin.com\/feed\/update\/urn:li:activity:7031955433326014464","githubURL":null,"paperURL":null,"author":"Antonio Benedetti","createdDate":"02\/16\/2023"},{"title":"The title is: MVMOO: A Powerful and Efficient Optimization Tool for Chemical and Pharmaceutical Processes","description":"#ProcessOptimisation is of massive interest for the pharmaceutical industry, as it helps delivering life-saving medicine in the shortest time possible and with the lowest associated expense. No surprise then if a lot of effort has been recently put into the development of powerful and efficient optimisation tools.\n \nOne of such tools is the mixed variable multi-objective optimisation (MVMOO) algorithm implemented by Jamie Manson et al., which is capable of optimising both continuous and discrete bounded variables in an efficient manner. MVMOO is based on #GaussianProcesses (GPs) as surrogates, which are coupled with a distance metric based upon Gower similarity (which is capable of properly determining distances between coordinates based on mixed data). \n \nAlthough been suited for general optimisation purposes, MVMOO has recently been applied by Oliver Kershaw et al. for the self-optimization of chemical reactions. By coupling the MVMOO algorithm with an automated continuous flow platform, the authors were able to optimise both continuous and discrete process variables in two systems used as a case study, i.e., SNAr reaction with solvent dependent regioselectivity and a Sonogashira reaction (within the synthesis of a TRPV1 receptor antagonist), thus overcoming massive limitations associated with the optimisation of chemical (and pharmaceutical) spaces based on mixed variables. \n \nContributions like these are what really makes a difference, and they pave the way to a better future for the chemical and pharmaceutical sectors! \n \nWell done to all:\n \nOliver Kershaw, Adam Clayton, Jamie Manson, Alexandre Barthelme, John Pavey, Phil Peach, Jason Mustakis, Roger Howard, Thomas Chamberlain, Nick Warren, Richard Bourne \n \n(MVMOO): Jamie Manson, Thomas Chamberlain, Richard Bourne \n \nLink to #GitHub (MVMOO): https:\/\/lnkd.in\/eYQB4N2e\nLink to Publication (Kershaw et al.): https:\/\/lnkd.in\/esNbCiJP\nLink to Publication (Manson et al.): https:\/\/lnkd.in\/eFPqyPgi","linkedinURL":"https:\/\/www.linkedin.com\/feed\/update\/urn:li:activity:7031589059198119936","githubURL":null,"paperURL":null,"author":"Alberto Marchetto","createdDate":"02\/15\/2023"},{"title":"The title is: MOCCA - Multivariate Online Contextual Chromatographic Analysis","description":"Looking for an #opensource solution for your #chromatographic #data analysis? \ud83e\uddea \ud83d\udcbb \n\nConventional chromatographic data analysis systems are limited by hardware and software components, making it challenging to implement automated workflows and potentially not aligning with FAIR data principles. \n#MOCCA, or Multivariate Online Contextual Chromatographic Analysis, is an open-source #Python project that offers a comprehensive set of data analysis features, including a peak deconvolution routine. This enables automated deconvolution of known signals, even in the presence of unexpected impurities or side products. Try MOCCA and and don't miss the chance to contribute to such an exciting project! \n\nKudos to Christian Haas,\u00a0Maximilian Lubbesmeyer,\u00a0Edward Jin,\u00a0Matthew McDonald,\u00a0Brent Koscher,\u00a0Nicolas Guimond, Laura Di Rocco, Henning Kayser, Samuel Leweke, \u00a0Sebastian Niedenf\u00fchr, Rachel Nicholls, Emily Greeves,\u00a0David Barber,\u00a0Julius Hillenbrand,\u00a0Giulio Volpin,\u00a0and Klavs Jensen\n\nLink to #Github: https:\/\/lnkd.in\/eCYjzHiC   \nLink to #openaccess Publication: https:\/\/buff.ly\/3HVZApt ","linkedinURL":"https:\/\/www.linkedin.com\/feed\/update\/urn:li:activity:7031230586287489025","githubURL":null,"paperURL":null,"author":"Antonio Benedetti","createdDate":"02\/14\/2023"},{"title":"The title is: 1000 Followers","description":"Hey Polymodellers, we've hit a huge milestone! Our community here on LinkedIn has reached 1000 followers and we couldn't be more grateful. Thank you for being a part of this platform where we share git projects, publications, and knowledge for the benefit of us all. Here's to continued growth and even more opportunities to learn and connect with each other! #1000Followers #PolyModelsHub","linkedinURL":"https:\/\/www.linkedin.com\/feed\/update\/urn:li:activity:7031170294069284865","githubURL":null,"paperURL":null,"author":"Antonio Benedetti","createdDate":"02\/14\/2023"},{"title":"The title is: Phasepy - A Powerful and Versatile Python Package for Calculating Fluid Phase Equilibria and Interfacial Properties","description":"Have you ever faced the challenge of calculating #fluid #phase #equilibria and #interfacial #properties for your chemical engineering projects? \u2697\ufe0f If yes, then #Phasepy is here to help!\n\nPhasepy is a powerful and versatile #opensource #Python-based package for the calculation of fluid phase equilibria and interfacial properties from equation of state (EoS). This tool integrates several popular Python libraries such as NumPy, SciPy, Pandas, and Matplotlib, making it easily accessible through Jupyter Notebooks. With Phasepy, you can model phase equilibria using both \u03d5\u2013\u03b3 and \u03d5\u2013\u03d5 approaches. The fugacity coefficient (\u03d5) can be modeled as a perfect gas, virial gas, or EoS fluid, while the activity coefficient (\u03b3) can be described by conventional models such as NRTL, Wilson, Redlich-Kister expansion, and the group contribution modified-UNIFAC. Interfacial properties are calculated using the square gradient theory coupled with the \u03d5\u2013\u03d5 approach.Phasepy offers a variety of EoSs including the cubic EoS family extended to mixtures through the quadratic, modified-Huron-Vidal, and Wong-Sandler mixing rules. With this package, you can analyze phase stability, compute phase equilibria, interfacial properties, and optimize their parameters for vapor\u2013liquid, liquid\u2013liquid, and vapor\u2013liquid\u2013liquid equilibria for multicomponent mixtures. Give it a try!\n\nThat's a fantastic accomplishment! A big shoutout to Gustavo Chaparro Maldonado and @Andr\u00e9s Mej\u00eda. \n\nLink to #Github: https:\/\/buff.ly\/3jQlG4K \nLink to Publication: https:\/\/buff.ly\/3RPzpFw","linkedinURL":"https:\/\/www.linkedin.com\/feed\/update\/urn:li:activity:7030868219477286912","githubURL":null,"paperURL":null,"author":"Antonio Benedetti","createdDate":"02\/13\/2023"},{"title":"The title is: Optimizing Primary Lyophilization Models in an Industrial Environment","description":"Wondering how can you use primary #lyophilization #models in an industrial environment with limited availability of equipment sensors? \ud83c\udf21\ufe0f \n\nA recent study by Margherita Geremia, Gabriele Bano,\u00a0Emanuele Tomba,\u00a0Massimiliano Barolo and\u00a0Fabrizio Bezzo has explored the potential for optimizing the primary drying process through the use of mathematical models. While traditional parameter estimation methods often require invasive experiments and sensors, the study has successfully developed a calibration protocol using limited industrial data - pressure measurements and gravimetric tests - to obtain statistically meaningful estimates. The results show that optimal inputs and outputs can be predicted without the need for product temperature measurements, a major advancement in transferring lyophilization recipes and scaling up the process. \n\nLink to Publication: https:\/\/buff.ly\/3xyMg5L","linkedinURL":"https:\/\/www.linkedin.com\/feed\/update\/urn:li:activity:7030505890730409985","githubURL":null,"paperURL":null,"author":"Antonio Benedetti","createdDate":"02\/12\/2023"},{"title":"The title is: Could Advance Process Control (#APC) be the missing lynchpin in the chain of your Quality-by-Design (#QbD) strategy?","description":"Could Advance Process Control (#APC) be the missing lynchpin in the chain of your Quality-by-Design (#QbD) strategy? \ud83d\udd17\n\nPAT has been a widely debated topic for the past 20 years, with some emphasizing its massive potential and crucial role in #pharmaceutical continuous manufacturing, while others call for stronger methods or remain skeptical of its industrialization.\nIn this paper, Heribert Helgers et al discuss the need for a more sophisticated process control strategy in continuous manufacturing of biopharmaceutical. They evaluate the use of a combination of spectroscopic methods, such as #Raman, #FTIR, #fluorescence, and #UVVis spectroscopy, for Advanced Process Control (#APC) in biologics antibody manufacturing. The results show that Raman spectroscopy is the most versatile and robust method for titer and purity prediction in upstream processing, aqueous two-phase extraction, and precipitation. The combination of UV\/Vis and fluorescence spectroscopy was effective in later stages of the process. The authors conclude by proposing a PAT development workflow for holistic process development.\nThis paper highlights the importance of choosing the right technology to chase advanced process control in continuous manufacturing.\n\nKudos to the authors for contextualising APC and PAT into the Process Development Workflow of a Biopharmaceutical Heribert Helgers, Axel Schmidt , Lara Julia Lohmann , @Florian Lukas Vetter, Alex Juckers, Christoph Jensch, Mourad Mouellef, @Steffen Zobel-Roos and @Jochen Strube\n\nLink to #openaccess Publication: https:\/\/lnkd.in\/ex6EdScH ","linkedinURL":"https:\/\/www.linkedin.com\/feed\/update\/urn:li:activity:7030175269772525568","githubURL":null,"paperURL":null,"author":"Antonio Benedetti","createdDate":"02\/11\/2023"},{"title":"The title is: Graphs are attracting an ever increasing attention in the machine learning (#ML) community","description":"#Graphs are attracting an ever increasing attention in the machine learning (#ML) community, thanks to their great capability of representing structural data. This is why they are being extensively used for molecular property predictions in a wider and wider range of applications. \n\nSo-called graph neural networks (#GNNs) \u2013 which use graphs as input information \u2013 have shown superior performances to descriptor-based approaches in a multitude of tasks. To support this field, Alexander Kensert et al. recently released MolGraph, a new GNN package aiimed a creating GNNs highly compatible with the TensorFlow and Keras application programming interface (API). They also provided the package with a chemistry module, in order to accommodate the generation of small molecular graphs \u2014 which could then be inputted to the GNNs for molecular ML. The GNNs generated from MolGraph were benchmarked by the authors against the datasets of MoleculeNet, as well as three chromatographic retention time datasets. The best news? MolGraph is easily accessible by anyone who might be interested through #GitHub! \n\nLet us know what are your thougths regarding GNN and graph-based molecular property predictions!\n\nWell done to the authors: Alexander Kensert, Gert Desmet and Deirdre Cabooter \n\nLink to GitHub: https:\/\/buff.ly\/40GLnoR \nLink to the Publication: https:\/\/buff.ly\/3jLwjFT","linkedinURL":"https:\/\/www.linkedin.com\/feed\/update\/urn:li:activity:7029781286915342337","githubURL":null,"paperURL":null,"author":"Antonio Benedetti","createdDate":"02\/10\/2023"},{"title":"The title is: AstraZeneca Released an Open-Source Package to Aid Molecule Optimization","description":"#Transformers Revolution ! It's #Drug #Discovery time: AstraZeneca Released an Open-Source Package to Aid Molecule Optimization\n\nOne of the common challenges in drug discovery is finding molecules with the right balance of multiple properties. Challenging properties can be a potential issue for both drug efficacy and development. For example, properties such as solubility, stability, and bioavailability can impact a drug's ability to effectively target a specific therapeutic area and its overall efficacy. Additionally, properties such as molecular size and structure can also impact the feasibility of synthesizing, manufacturing, and commercializing the drug. This package from focuses on molecular optimization, where the goal is to optimize a given molecule to have desired properties. The task is framed as a machine translation problem in NLP, where the molecule is translated into a molecule with optimized properties. The Transformer model and a sequence-to-sequence model with attention mechanism are employed to generate molecules with desirable properties. As a proof of concept, the package optimizes three important drug properties simultaneously: logD, solubility, and clearance. The user-specified desirable properties are incorporated into the input, allowing the models to generate molecules that satisfy these conditions. The Transformer model outperforms the graph-to-graph translation model, HierG2G, in generating more molecules with desirable properties by making small modifications to the starting molecules. An ensemble of models can further enrich the diversity of molecules generated. \n\nThis is a very nice piece of work that really shows how much work was happening on these algorthms even before #ChatGPT! Kudos to Jiazhen He  \u00a0, @Huifang you\u00a0, @emil Sandstr\u00f6m, Eva Nittinger \u00a0,Esben Jannik Bjerrum\u00a0,Christian Tyrchan \u00a0, Werngard Czechtizky and Ola Engkvist  \n\nLink to #Github: https:\/\/buff.ly\/3YifIZf \nLink to Publication: https:\/\/buff.ly\/3YgASqK","linkedinURL":"https:\/\/www.linkedin.com\/feed\/update\/urn:li:activity:7029418634959552512","githubURL":null,"paperURL":null,"author":"Antonio Benedetti","createdDate":"02\/09\/2023"},{"title":"The title is: Modelling of Bioprocesses: Where Should You Start?","description":"#Modelling of #Bioprocesses:  where should you start?\n\nBiotechnological upstream production processes require the determination of key performance indicators such as titer, rate and yield to design and optimize you process. Unlike fully data-driven models, bioprocess #mechanistic or #hybrid models offer a comprehensive and deeper understanding of the process by starting from the known phenomena at the cell level. These models are usually based on Ordinary Differential Equation systems (#ODEs). In this post, we present the recently launched #pyFOOMB package which offers a convenient and flexible implementation of ODEs in bioprocess modeling. Based on Python, pyFOOMB is an #opensource package that enables the modular design, reusability, and extensibility of bioprocess models. The package integrates seamlessly with other available Python packages, allowing for easy analysis of experimental data. PyFOOMB also supports the description of multi-stage processes and optimization problems, making it a valuable tool for bioprocess engineers. Get a better understanding of the strengths and capabilities of pyFOOMB through its collection of examples!!!\n\nThank you very much Johannes Hemmerich, Niklas Tenhaef \u00a0Wolfgang Wiechert and\u00a0@Stephan Noack for making this work available! \n\nLink to #GitHub: https:\/\/lnkd.in\/e9SmK4cQ \nLink to #OpenAccess Publication: https:\/\/lnkd.in\/eazjWcxi","linkedinURL":"https:\/\/www.linkedin.com\/feed\/update\/urn:li:activity:7029056483711451136","githubURL":null,"paperURL":null,"author":"Antonio Benedetti","createdDate":"02\/08\/2023"},{"title":"The title is: A Novel Method for Autocomplete Chemical Flowsheets Using State-of-the-Art Technology","description":"#ChatGPT to aid process #flowsheet design. Crazy, isn't? \n\nThe #tranformer algorithm technology behind the most popular #AI tool is pushing the boundaries in many fields and chemical process design is not excluded. A novel method proposed by Gabriel Vogel ,\u00a0 Lukas Schulze Balhorn ,\u00a0Artur Schweidtmann  has the potential to autocomplete chemical flowsheets using state-of-the-art technology. This approach represents flowsheets as strings using SFILES 2.0 (see #GitHub for SMILES 2.0 #opensource code) notation and leverages a transformer-based language model to learn the grammatical structure and common patterns. Through pre-training on synthetic data and fine-tuning on real flowsheet topologies, the trained model provides recommendations during interactive flowsheet synthesis. The results demonstrate a high potential for future AI-assisted process synthesis while also highlighting limitations and next steps for real-world deployment. \n\n#ChemicalEngineering #AI #ProcessSynthesis   \n\nLink to Github for SFILES 2.0: https:\/\/buff.ly\/3jCDnoe \nLink to Publication: https:\/\/buff.ly\/3RFYwKH","linkedinURL":"https:\/\/www.linkedin.com\/feed\/update\/urn:li:activity:7028694123259822080","githubURL":null,"paperURL":null,"author":"Antonio Benedetti","createdDate":"02\/07\/2023"},{"title":"The title is: Modelling Requires Data, But Good Modelling Requires the Right Data","description":"Modelling Requires Data, But Good Modelling Requires the Right Data \ud83d\udd0d\n\n#GCMS (Gas Chromatography-Mass Spectrometry) is a powerful analytical technique widely used in various industries for sample analysis, e.g. reaction monitoring, impurities quantification and many more applications. Despite its many benefits, GC-MS data analysis often presents challenges such as large sample sets, complex data, and the need for robust and reproducible methods. \nThis is where #PARADISe comes in! Developed by the group of research of Prof. Rasmus Bro , PARADISe is a user-friendly #opensource new tool designed to simplify the process of transforming large sample sets into peak tables. This software seems to offer a simple, robust, and reproducible method for analyzing untargeted GC-MS data so it is worthy a try. \ud83d\udcbb \n\nLink to Software: https:\/\/buff.ly\/3HyMXQX \nLink to Publication: https:\/\/buff.ly\/40vzsdC","linkedinURL":"https:\/\/www.linkedin.com\/feed\/update\/urn:li:activity:7028331462114332672","githubURL":null,"paperURL":null,"author":"Antonio Benedetti","createdDate":"02\/06\/2023"},{"title":"The title is: Automated #Bioprocess Development & Machine Learning (#ML): where are we?","description":"#Automated #Bioprocess Development  & Machine Learning (#ML): where are we?\n\nThe use of machine learning (ML) is growing in importance across various fields of engineering, but its potential has yet to be fully realized in bioprocess engineering. While lab automation has improved experimental speed, human intervention is still needed for experimental planning and data modeling. ML can automate the entire experimental cycle and allow experts to focus on more complex tasks. This review by Nghia Duong-Trung et al. covers ML-based automation in bioprocess development, including the use of probabilistic programming for autonomous model building and ML-assisted experiment planning based on model predictions. It highlights the potential and limitations of existing ML solutions, and identifies missing links for easy implementation in biotechnology and biopharma. The goal is to combine biotechnology knowledge and ML methods to address the reproducibility crisis in bioprocess development. \n\nGreat job to all the authors: @Stefan\u00a0Born,\u00a0Jong Woo Kim,\u00a0Marie-Therese Schermeyer,\u00a0Katharina Paulick,\u00a0Maxim Borisyak,\u00a0M. Nicolas Cruz B.,\u00a0@Thorben\u00a0Werner,\u00a0@Randolf\u00a0Scholz,\u00a0@Lars\u00a0Schmidt-Thieme,\u00a0Peter Neubauer,\u00a0@Ernesto\u00a0Martinez \n\nLink to Publication: https:\/\/buff.ly\/3X5d6fR","linkedinURL":"https:\/\/www.linkedin.com\/feed\/update\/urn:li:activity:7027969145254117376","githubURL":null,"paperURL":null,"author":"Antonio Benedetti","createdDate":"02\/05\/2023"},{"title":"The title is: \"Considering Random Effects in Biopharmaceutical Process Control: A Case Study\"","description":"\"If there is no #randomness in the universe, then what do we mean by chaos?\"\n\nThe control strategy for a biopharmaceutical process often fails to consider #random effects. This can cause a lot of issue in supply chain manufacturing down the line.\nIn this #openaccess article, Thomas Oberleitner,\u00a0Thomas Zahel,\u00a0Marco Kunzelmann,\u00a0Judith Thoma & Christoph Herwig present a case study that highlights the importance of considering the variance introduced by random effects in the calculation of proven acceptable ranges (PAR), which form the basis of the control strategy.\n\nLink to Publication: https:\/\/lnkd.in\/eJBBP_dQ","linkedinURL":"https:\/\/www.linkedin.com\/feed\/update\/urn:li:activity:7027590583753822208","githubURL":null,"paperURL":null,"author":"Antonio Benedetti","createdDate":"02\/04\/2023"},{"title":"The title is: Modelling the Evolution of Pore Structure during the Disintegration of Pharmaceutical Tablets.","description":"\"Modelling the Evolution of Pore Structure during the Disintegration of Pharmaceutical Tablets:\"\n\nModelling tablet performance is a key enabler to fully understand your process and product. It requires a combination of several modelling and Process Analytical Technologies (PAT), but once the knowledge is there, it can really boost your digital design. This #openaccess study recently presented by a cross academia-industry team combined the discrete element method and a single-particle swelling model with experimental data from terahertz-pulsed imaging to uncover new insights into the changes in tablet pore structure during the disintegration process. The findings show that pores shrink in both wetted and dry volume during the process, slowing down the overall swelling process. Understanding these changes in porosity and formulation is crucial for improving tablet performance and can bring your manufacturing design next level up. \n\nVery well done to Majid Hassanizadeh,\u00a0Thomas Sweijen, @J Axel Zeitler,\u00a0Prince Bawuah,\u00a0\u00a0Mohammed D. Al-Sharabi,\u00a0Kendal Pitt,\u00a0Mithushan Soundaranathan,\u00a0Blair Johnston and Daniel Markl.\n\nLink to  Publication: https:\/\/lnkd.in\/eBGhyigp ","linkedinURL":"https:\/\/www.linkedin.com\/feed\/update\/urn:li:activity:7027291945030844418","githubURL":null,"paperURL":null,"author":"Antonio Benedetti","createdDate":"02\/03\/2023"},{"title":"The title is: #DataDriven #Synthetic #Chemistry: Revolutionizing the Discovery and Design of Pharmaceutical Drugs","description":"#DataDriven #Synthetic #Chemistry: Revolutionizing the Discovery and Design of Pharmaceutical Drugs\n\nIf you are looking at some exciting novel approaches to power your data-driven synthetic chemistry workflow, check #AutoQChem. Auto-QChem is another fantastic #opensource tool developed by Princeton University and Bristol Myers Squibb. It streamlines DFT calculations for organic molecules by performing initial conformational searches, managing DFT calculations on local HPC clusters, and facilitating cloud data storage and access through a web interface, starting from string representations of molecules.\n\nWell done to Andrzej \u017bura\u0144ski, @Jason Wang, Benjamin Shields and Abigail Doyle\n\nLink to Github: https:\/\/lnkd.in\/e7sPqiNu\nLink to Publication: https:\/\/lnkd.in\/ez_5hjW4","linkedinURL":"https:\/\/www.linkedin.com\/feed\/update\/urn:li:activity:7027005059603300354","githubURL":null,"paperURL":null,"author":"Antonio Benedetti","createdDate":"02\/02\/2023"},{"title":"The title is: Can #ML modelling accelerate the design of #Long #Acting #Injectables (#LAI)?","description":"Can #ML modelling accelerate the design of #Long #Acting #Injectables (#LAI)?\n\nLong-acting injectables are a promising treatment for chronic diseases because they offer improved efficacy, safety, and patient compliance. However, the interplay between drug and polymer properties in such systems makes it difficult to predict their performance. This study published in Nature by Pauric Bannigan et al. shows that machine learning algorithms can be used to predict drug release from these systems and guide the design of new long-acting injectables, reducing time and cost in drug formulation development. \n\nIt's fantastic to see such a detailed paper with open-source access to all the approaches presented! Kudos to the whole team Pauric Bannigan,  Zeqing Bao,\u00a0Riley Hickman,\u00a0Matteo Aldeghi,\u00a0Florian H\u00e4se,\u00a0Al\u00e1n Aspuru-Guzik\u00a0&\u00a0Dr. Christine Allen! Our community will love the publication and all the resources that you made available!\n\nLink to #GitHub: https:\/\/lnkd.in\/gVEVBBax\nLink to Publication: https:\/\/lnkd.in\/gq_bcZCu\n","linkedinURL":"https:\/\/www.linkedin.com\/feed\/update\/urn:li:activity:7026590036011745280","githubURL":null,"paperURL":null,"author":"Antonio Benedetti","createdDate":"02\/01\/2023"},{"title":"The title is: Model-Based Design of Experiments for Calibrating Nonlinear Process Models","description":"We are very excited to share one of the latest research on model-based design of experiments (#MBDoE) for calibrating nonlinear process models! A key challenge in maximizing the effectiveness of experiments is accurately predicting information from each of them. Kennedy Putra Kusumo et al. recently developed a novel methodology using prior probability distributions in a bi-objective optimization approach, considering a conditional-value-at-risk (CVaR) criterion as well as an average information criterion. \n\nCase studies of increasing complexity, including dynamic experiments, demonstrate the effectiveness and tractability of the proposed methodology. The results the authors obtained show significant improvement in worst-case scenarios and optimal experimental campaigns regardless of risk attitude. \n\nCheck out their open-source implementation, the package Pydex available in #Python! \n\nWell done to the team: Kennedy Putra Kusumo, Kamal Kuriyan, Shankarraman\u00a0Vaidyaraman, Salvador Garc\u00eda Mu\u00f1oz, Nilay Shah, Benoit Chachuat\n\nLink to #GitHub: https:\/\/lnkd.in\/eF9_xtK8\nLink to Publication: https:\/\/lnkd.in\/e2j_u_W8","linkedinURL":"https:\/\/www.linkedin.com\/feed\/update\/urn:li:activity:7026167708664659969","githubURL":null,"paperURL":null,"author":"Alberto Marchetto","createdDate":"01\/31\/2023"},{"title":"The title is: Is Modelling Continuous #HighShear #Wet #Granulation (#HSWG) Hard to Achieve?","description":"Is modelling Continuous #HighShear #Wet #Granulation (#HSWG) hard to achieve?\"\nYou should definitely read this work by The University of Sheffield and AstraZeneca!\nSpoiler: While challenging, it is achievable. \ud83d\ude04 \n\nKudos to Daniele Monaco, Gavin Reynolds, Pirjo Tajarobi, Jim Litster and Agba Salman \n\nLink to Publication: https:\/\/lnkd.in\/eqqFHK-z ","linkedinURL":"https:\/\/www.linkedin.com\/feed\/update\/urn:li:activity:7025936066368937984","githubURL":null,"paperURL":null,"author":"Antonio Benedetti","createdDate":"01\/30\/2023"},{"title":"The title is: \"Development of a Predictive, Mechanistic Model for Monoclonal Antibody (mAb) Process Simulation\"","description":"Are you familiar with the challenges of obtaining an accurate #dynamic #metabolic #model for monoclonal antibody (#mAb) process simulation? \n\nThe development of new biologics is becoming more complex due to increased competition and regulatory requirements. This is why predictive, mechanistic process models are crucial in reducing resources and time in process development. In a recent study, the development of such a model for mAb production was illustrated and key factors influencing product formation were identified to support the #QbD design of the process. Read on to learn more about this great piece of work by Heribert Helgers, Axel Schmidt and @Jochen Strube\n\nLink to #OpenAccess Paper: https:\/\/lnkd.in\/eR7i9jew ","linkedinURL":"https:\/\/www.linkedin.com\/feed\/update\/urn:li:activity:7025515803181469697","githubURL":null,"paperURL":null,"author":"Antonio Benedetti","createdDate":"01\/29\/2023"},{"title":"The title is: Exciting news in scientific machine learning!","description":"Exciting news in scientific machine learning! The concept of Universal Differential Equations (UDE) combines the power of the universal approximation theorem \u2013 in brief, the capability of artificial neural networks (#ANNs) to approximate any function with an arbitrary non-zero error \u2013 with physical knowledge of a given system. \n\nCreating this level of #hybridization within a stiff partial differential equation system can be challenging. That's where adsorption phenomenological models come in - they use sink\/source terms to describe #adsorptionequilibrium through simplified models like Langmuir, Sips, and BET. However, these assumptions are a simplification of the system phenomenology, limiting the resulting model. \n\nEnter universal ordinary differential equations (UODE) - an approach implemented by Idelfonso Bessa dos Reis Nogueira et al., that conciliates the potential of artificial neural networks to learn given phenomena without conceptual simplifications, all while considering the system physics. This work proposes a UODE system to solve multicomponent separation by adsorption in a fixed bed adsorptive column. And the best part? The hybrid model can use a few data points to precisely describe the system, and represents competitive adsorption with higher precision than the Langmuir model. \n\nWell done to the whole team: Idelfonso B. R. Nogueira,\u00a0Vinicius Santana, Ana M. Ribeiro and Alirio Rodrigues\n\nLink to Publication: https:\/\/lnkd.in\/ezk8sSJg","linkedinURL":"https:\/\/www.linkedin.com\/feed\/update\/urn:li:activity:7025096771986976768","githubURL":null,"paperURL":null,"author":"Alberto Marchetto","createdDate":"01\/28\/2023"},{"title":"The title is: Leveraging the Power of #Modeling & #Simulation for #Pharmaceutical Development : How the FDA is Ahead of the Game and How You Can Be Too","description":"Leveraging the Power of #Modeling & #Simulation  for #Pharmaceutical Development : How the FDA is Ahead of the Game and How You Can Be Too\n\nWorried about facing penalties from FDA for using computer #modeling and #simulation (CM&S)?  Rest easy, the FDA encourages and supports its appropriate use.\nThe FDA has long encouraged the use of computer modeling and simulation (CM&S) in product areas under its jurisdiction. In 2011, the FDA outlined goals for using simulation models in product life cycles, risk assessment, and other regulatory science uses. They have continued to issue guidance and other forms of communication supporting CM&S over the past decade. Recently in November 2022, FDA released a report titled \"Successes and Opportunities in Modeling and Simulation for FDA\" which explains how and where CM&S is used across the FDA, the types and purposes of CM&S used, and presents case studies of how CM&S is playing a tangible role in the FDA fulfilling its mission. Additionally, the report identifies opportunities for the FDA to better harness CM&S in upcoming years by embracing computational advances and new data streams to develop improved public health solutions.\n\nLink to FDA latest Guidance : https:\/\/lnkd.in\/e2DYS3AN","linkedinURL":"https:\/\/www.linkedin.com\/feed\/update\/urn:li:activity:7024804965407711232","githubURL":null,"paperURL":null,"author":"Antonio Benedetti","createdDate":"01\/27\/2023"},{"title":"The title is: \"Introducing #sbml2hyb: A Python Tool for Converting Mechanistic Models into Hybrid Semiparametric Models\"","description":"Are you tired of using solely mechanistic models for your biological systems? Look no further than #sbml2hyb, a new Python tool that allows for the conversion of mechanistic models in #SBML format into #hybrid semiparametric models. By combining mechanistic functions with machine learning, these hybrid models can provide a more comprehensive understanding of biological systems. Not only that, but the tool also includes a user-friendly export interface and supports a new model format called HMOD that facilitates building hybrid models.\n\nWell done to Prof Rui Oliveira and team!\n\n\nLink to Github:\u00a0https:\/\/lnkd.in\/eMUPAib9\nLink to Paper:\u00a0https:\/\/lnkd.in\/e57EC2m2","linkedinURL":"https:\/\/www.linkedin.com\/feed\/update\/urn:li:activity:7024446888963633152","githubURL":null,"paperURL":null,"author":"Antonio Benedetti","createdDate":"01\/26\/2023"},{"title":"The title is: Data-Driven Engineering Python Course","description":"So far we have been posting quite a lot of process systems engineering (#PSE) models that are written in #Python. \n\nPython is becoming one of the favourite programming languages for the PSE community, also thanks to it being an #opensource tool, which allows people to easily share models and codes with others (as we are doing!). Using Python, however, is not always trivial, especially for those who lack a proper language knowledge and experience. Many courses are out there, but how many of them focus on the application of Python to solve Engineering issues? \n\nJohn Hedengren has recently released a Data-Driven Engineering Python course, that allows you to get a proper understanding of how to use Python for your Engineering-related applications. Topics covered include data collection and analysis, predictive analytics, data visualisation, with practical examples.\n\nGo check it out! We are sure you will find it very useful, no matter if you are a beginner or an already experienced Python user.\n\nVery well done John!!\n\nhttps:\/\/apmonitor.com\/dde\/","linkedinURL":"https:\/\/www.linkedin.com\/feed\/update\/urn:li:activity:7024110018174046208","githubURL":null,"paperURL":null,"author":"Alberto Marchetto","createdDate":"01\/25\/2023"},{"title":"The title is: Reaction Experts vs Machine Learning: A Game to Test Chemical Reaction Optimization","description":"Let's play a #Game : Reaction #Experts vs #MachineLearning !\nYou might think we are joking, but that is not the case \ud83d\ude03 \n\n#EvML is a game designed to test the decisions made by automated machine learning systems and chemists of various backgrounds and levels of experience. In this game, you'll take on the role of a chemist, using your personal knowledge and data gained from running experiments to optimize reactions. Meanwhile, the machine learning algorithms will be working with no prior knowledge and will also be running experiments to gain data.\nThis game is based on a fixed experimental budget, meaning that you'll have to make strategic decisions on how to spend your resources. But here's the catch - the data generated in the game is real! Each experiment you run will return the result of the corresponding experiment in the lab.\nThink you have what it takes to outsmart the machine learning algorithms and optimize reactions better than they can? Then download the game now on Github and put your skills to the test. But before you begin, be sure to read the rules carefully for a fair and exciting experience.\n\nThe work is just a tiny part of a publication in Nature that we will share soon !\n\nHuge #Kudos to Benjamin Shields and Jun Li, @Jay Stevens, and Jake Janey. That is a tremendous idea! Our community will love it \ud83d\ude09 \n\nLink to #Github: https:\/\/lnkd.in\/epGVd5Bx\n","linkedinURL":"https:\/\/www.linkedin.com\/feed\/update\/urn:li:activity:7023725440326365185","githubURL":null,"paperURL":null,"author":"Antonio Benedetti","createdDate":"01\/24\/2023"},{"title":"The title is: Predicting Molecular Properties from Molecular Structure: A Revolutionary Approach","description":"Predicting molecular properties from molecular structure is a research field of increasing interest in #drugdiscovery, material design, process optimisation, among many other applications. The chemical space is huge (as we have already seen in one of our recent posts), so relying on supervised learning techniques (e.g., graph neural networks, #GNNs, that learn from graph topological information) for molecular property prediction can be challenging. No worries, though, because there is a lot going on to solve such limitations. One excellent contribution comes from Jerret Ross et al., and is called MolFormer. Specifically, MolFormer is a #transformer encoder model which learns spatial relationships between atoms within a molecule from the molecule #SMILES string representation.\n\nTheir results show how MolFormer representations can accurately capture chemical and structural information to predict a wide range of chemical properties, with performances that are either better than or comparable with state-of-the-art GNNs. It is also thanks to such precious contributions that drug discovery and material design can allow for a brighter future for our society!\n\nVery well done to the whole team: Jerret Ross, Brian Belgodere, Vijil Chenthamarakshan, Inkit Padhi, Youssef MROUEH, Payel Das\n\nLink to Publication: https:\/\/lnkd.in\/erKTEdMP","linkedinURL":"https:\/\/www.linkedin.com\/feed\/update\/urn:li:activity:7023326168875466752","githubURL":null,"paperURL":null,"author":"Alberto Marchetto","createdDate":"01\/23\/2023"},{"title":"The title is: \"Tube-based distributionally robust Model Predictive Control (#MPC) for nonlinear process systems via linearization\"","description":"Check out this fascinating repost on \"Tube-based distributionally robust Model Predictive Control (#MPC) for nonlinear process systems via linearization\" by Panagiotis Petsagkourakis, PhD\n\n\"Model predictive control is an effective (amazing!) approach to control multivariable dynamic systems. However, uncertainty in the form of noise or plant-model mismatch can lead to closed-loop performance deterioration and constraint violations. In this work we propose a novel data-driven distributionally robust MPC scheme for nonlinear systems, which does not require the exact disturbance distribution and decides the control action with respect to the expectation on the worst distribution from an ambiguity set. This results in an approach that is less conservative then robust MPC, but performs better than stochastic MPC when the distribution is not known exactly.\"\n\nLink to GitHub: https:\/\/lnkd.in\/e-sYwQ82 \nFull paper:\u00a0https:\/\/lnkd.in\/e8PCXqDr\n\nKudos to the authors team\u00a0Zhengang Z., Ehecatl Antonio del Rio Chanona . Grateful for the availability of your work through #opensource\n\n\u00a0#Datadriven\u00a0#PSE\u00a0#ChemicalProcesses\u00a0#ProcessControl\u00a0#MPC","linkedinURL":"https:\/\/www.linkedin.com\/feed\/update\/urn:li:activity:7022947349601648640","githubURL":null,"paperURL":null,"author":"Antonio Benedetti","createdDate":"01\/22\/2023"},{"title":"The title is: Assessing Critical Quality Attributes and Implementing Quality by Design for RNA-Based Products in Global Vaccination and Infectious Disease Control.","description":"We all witnessed how vital it is for the modern society to rapidly respond to disease outbreaks and guarantee a fast #vaccine development at a global scale.\u00a0\n\nA recent paper by Simon Daniel et al. has shed light on the potential of #RNA-based products in global #vaccination and infectious disease control. The paper highlights the importance of assessing critical quality attributes (#CQAs), understanding product-process interactions, and utilising relevant process analytical technologies (#PATs) and process modelling capabilities in order to implement a robust Quality by Design (#QbD) framework for the development and control of RNA platform production processes. This is a crucial time for RNA technology enhancement and we really look forward to seeing the progress that will be made in this field in the coming years.\n\nMany congratulations to Simon Daniel, Zolt\u00e1n Kis, Cleo Kontoravdi and Nilay Shah for their extremely valuable contribution to this field! If you are interested in learning more about RNA technology and its potential applications, be sure to check out the paper at the link below.\u00a0\n\nLink to Publication: https:\/\/lnkd.in\/eg2p4KJa","linkedinURL":"https:\/\/www.linkedin.com\/feed\/update\/urn:li:activity:7022611684204666880","githubURL":null,"paperURL":null,"author":"Alberto Marchetto","createdDate":"01\/21\/2023"},{"title":"The title is: \"Estimating the number of feasible 'drug-like' components in chemical space: 10^60! | LinkedIn\"","description":"Do you know how many feasible \"drug-like\" components have been estimated to exist in the chemical space? 10^60!! Crazy, right? So far, the number of prepared organic molecules is \"only\" over one hundred million or so, which is why it is fundamental for researchers to develop innovative tools in field of the #DrugDiscovery. \n\nOne of such tools is definitely given by the Molecular Transformer introduced by Philippe Schwaller et al., a fully attention-based model that can accurately predict subtle and selective chemical transformations from molecular #SMILES representations. Molecular Transformer infers correlations between the presence and absence of chemical motifs in the reactant, reagent, and product, and it has shown the capability to outperform all algorithms available in the reaction prediction literature. \n\nThe availability of such tools if of great importance to boost chemical #reaction predictions, and it gives an immense contribution to the drug discovery field. Thank you for sharing this with the community!\n\nVery well done to the whole team: Philippe Schwaller, Teodoro Laino, Th\u00e9ophile \u269b\ufe0f Gaudin, Peter Bolgar, Christopher A. Hunter, Costas Bekas and Alpha Lee!\n\nLink to #GitHub: https:\/\/lnkd.in\/e-4EVwhy\nLink to Publication: https:\/\/lnkd.in\/e85Ef_Tc","linkedinURL":"https:\/\/www.linkedin.com\/feed\/update\/urn:li:activity:7022248882172489728","githubURL":null,"paperURL":null,"author":"Alberto Marchetto","createdDate":"01\/20\/2023"},{"title":"The title is: Lyophilization: A Critical Step in Preserving Perishable Materials","description":"#Lyophilization, also known as freeze-drying, is a process that removes water or other solvents from a product while preserving its integrity, making it an ideal method for preserving perishable materials. It is a critical step in many processes, including preservation of biologics, such as vaccines and therapeutics or preservation of food and agricultural products.\n\nIn this context, a tool like #LyoPRONTO, which is user-friendly and #openaccess, can greatly enhance your capabilities in simulation and process optimization. The tool comprises of freezing and primary drying calculators, a design-space generator, and a primary drying optimizer. The freezing calculator utilizes 0D lumped capacitance modeling to predict product temperature variation with time and has shown good agreement with experimental measurements. The primary drying calculator uses 1D heat and mass transfer analysis to predict drying time. Additionally, the tool can generate a design space to determine the most optimal setpoints for operation. The optimizer provides varying chamber pressure and shelf temperature profiles to minimize primary drying time and operational cost with impressive results during testing.\n\nKudos to Gayathri Shivkumar, Petr Kazarin,@Andrew Strongrich and Alina Alexeenko for this great piece of work!\n\nLink to Website: https:\/\/lnkd.in\/ey6hUnfM \nLink to Publication: https:\/\/lnkd.in\/egyJTWg5","linkedinURL":"https:\/\/www.linkedin.com\/feed\/update\/urn:li:activity:7021922326120157184","githubURL":null,"paperURL":null,"author":"Antonio Benedetti","createdDate":"01\/19\/2023"},{"title":"The title is: Overcoming Multi-Scale Integration Challenges in Digital Twin Development for Pharmaceutical Manufacturing","description":"How do we overcome #MultiScale #Integration Challenges in the development of #DigitalTwins ? \n\nThis challenge is particularly obvious when we look for example at continuous manufacturing for pharmaceuticals.  Despite some progress in creating data integration frameworks and models, the development of a comprehensive digital twin for continuous pharmaceutical manufacturing that enables real-time process monitoring, control, and optimization remains a challenge. From a modelling perspective, multi-scale models that can characterize powder properties and describe process flows need to be integrated, which is a challenging task.\n\nThis proposed framework by Pooja Bhalode, Yingjie Chen and Marianthi Ierapetritou addresses the challenges of integrating multi-scale information, such as powder properties and process flowsheets, through the use of hybrid multizonal compartment models and adaptive models. These computationally efficient and self-adaptive models are proposed as a valuable solution to overcome the multi-scale integration challenges. This research is a great example of how the modelling community should start to address the current technical challenges of developing digital twins by proposing great innovative solutions! \n\nLink to Publication: https:\/\/lnkd.in\/gDZDHvnx\n\n#digitaltwins #pharmaceuticalmanufacturing #industry40","linkedinURL":"https:\/\/www.linkedin.com\/feed\/update\/urn:li:activity:7021522803606646785","githubURL":null,"paperURL":null,"author":"Antonio Benedetti","createdDate":"01\/18\/2023"},{"title":"The title is: GEKKO","description":"Today we want to introduce another great #opensource package for #optimization : #GEKKO!\n\nMachine learning (ML) has become a must-have technology across all industries, while dynamic optimization has emerged as a valuable tool for a wide range of applications. From chemical production planning to energy storage systems, dynamic optimization has proven its worth in various industries.\nGEKKO is not only an algebraic modeling language (AML) for posing optimization problems in simple object-oriented equation-based models to interface with powerful built-in optimization solvers but is also a package with the built-in ability to run model predictive control, dynamic parameter estimation, real-time optimization, and parameter update for dynamic models on real-time applications. The development of GEKKO places it in a unique position among other optimization packages, making it a powerful tool for those who are looking to improve the performance of their process modeling problems.\n\nI highly recommend our community to check out John Hedengren's LinkedIn page, as he and his research team are the creators of Gekko. There you can find a plethora of useful examples of its applications in various fields.\n\nLink to Github: https:\/\/lnkd.in\/ehMigdiV \nLink to Paper: https:\/\/lnkd.in\/eAVmvuNC\n\n#machinelearning #artificialintelligence ","linkedinURL":"https:\/\/www.linkedin.com\/feed\/update\/urn:li:activity:7021194789328973825","githubURL":null,"paperURL":null,"author":"Antonio Benedetti","createdDate":"01\/17\/2023"},{"title":"The title is: KIPET - A Python Package for Chemical Reaction Simulation and Parameter Estimation","description":"We are thrilled to share with you one of the latest developments in the field of chemical reaction simulation and parameter estimation.\u00a0\n\nSalvador Garc\u00eda Mu\u00f1oz et al. have recently released KIPET, a #Python package that is designed to simulate and estimate parameters from chemical reaction systems using maximum likelihood principles, large-scale nonlinear programming, and discretisation methods. This package is a game changer in the field as it offers a wide range of functionalities, such as the ability to simulate reactive systems described with #DAEs, estimate noise variance from the model and measurements, estimate kinetic parameters from #spectra or concentration data (including their confidence intervals), among many others. KIPET also includes a tool for data pre-processing.\u00a0\n\nThis package is a true testament to the KIPET team's expertise and dedication to the field and it is so exciting to have access to such a powerful tool. We encourage you all to check it out and see the benefits it can bring to your research.\u00a0\n\nCongratulation to Kevin McBride, Kuan-Han Lin , Dr. Christina Schenk, Michael Short, Jose Santiago Rodriguez, David M. Thierry, Salvador Garc\u00eda Mu\u00f1oz, Lorenz Biegler for this great achievement, and for sharing it with the community!\u00a0\n\n#ChemicalReactionSimulation #OpenSource\n\nLink to #Github: https:\/\/lnkd.in\/ePNhmVBm\n\nLink to Publications:\u00a0\nhttps:\/\/lnkd.in\/e8gT8T4H\nhttps:\/\/lnkd.in\/eA9Qb5mD","linkedinURL":"https:\/\/www.linkedin.com\/feed\/update\/urn:li:activity:7020725307372367872","githubURL":null,"paperURL":null,"author":"Alberto Marchetto","createdDate":"01\/16\/2023"},{"title":"The title is: Simplifying Complexity: Utilizing #DataDriven Reduced-Order Modeling for Efficient Simulation of Multicomponent Reacting Flows","description":"Simplifying Complexity: Utilizing #DataDriven Reduced-Order Modeling for Efficient Simulation of Multicomponent Reacting Flows\n\nData-driven modeling of #complex #dynamical #systems is becoming increasingly popular across various domains of science and engineering. This is thanks to advances in numerical computing, which provides high fidelity data, and to algorithm development in data science and machine learning. One area that is particularly benefiting from these developments is the simulation of multicomponent reacting flows. The traditional approach of using coupled partial differential equations can be computationally expensive, due to the high number of chemical species involved. However, data-driven reduced-order modeling (ROM) can now be used to identify and parameterize low-dimensional manifolds (LDMs) within these datasets. This allows for substantial model reduction and cost savings in computation. This #openaccess article reviews recent advances in ROM of turbulent reacting flows, including the use of data science and machine learning techniques such as dimensionality reduction and nonlinear regression. The article also provides practical examples using the newly developed #opensource Python software, #PCAfold. \n\nPolyModellers, don't miss this chance to expand your knowledge on data-driven reduced-order modeling for efficient simulation of multicomponent reacting flows. We're eager to hear your insights on how this approach can be adapted to other complex reaction systems!\n\nKudos to the author team: Kamila Zdyba\u0142, Rafi Malik, Axel Coussement, James Sutherland, Alessandro Parente\n\nLink to #Github : https:\/\/lnkd.in\/em9tX5Xy\nLink to open access book chapter: https:\/\/lnkd.in\/ejvRjXTG ","linkedinURL":"https:\/\/www.linkedin.com\/feed\/update\/urn:li:activity:7020414902955597824","githubURL":null,"paperURL":null,"author":"Antonio Benedetti","createdDate":"01\/15\/2023"},{"title":"The title is: Overcoming Industry-Specific Barriers to Adopt Continuous Production Processes in Biologics Manufacturing","description":"Are you curious about why #Batch processing still dominates the #Biologics landscape? \n\nThe transition to continuous processes has been a slow one for traditional Small Molecule pharmaceuticals, but the path for Biologics seems even harder. In this open access paper, Ashish Kumar, Isuru A. Udugama, Carina Lira Gargalo and Krist Gernaey delve into the industry-specific barriers hindering the adoption of continuous production processes in biopharmaceutical manufacturing. Discover how process systems engineering (#PSE), process analytical technologies (#PAT), and process #modeling and #simulation can help overcome these barriers and pave the way for a more efficient future in biologics production. \n\nLink to Publication: https:\/\/lnkd.in\/ezgr_8Gp \n \n#biologics #pharmaceuticals #continuousprocesses\"","linkedinURL":"https:\/\/www.linkedin.com\/feed\/update\/urn:li:activity:7020065356446625792","githubURL":null,"paperURL":null,"author":"Antonio Benedetti","createdDate":"01\/14\/2023"},{"title":"The title is: Unleashing the Power of #Tensors","description":"Unleashing the Power of #Tensors: would that help us to understand more about our process development and manufacturing data?\n\nTensorial data analytics is a field of data analysis that deals with multi-dimensional arrays, also known as tensors. Tensors are a generalization of matrices and can represent data with more than two dimensions, such as images, videos, and audio. Tensorial data analytics techniques can be used to extract information and insights from these types of data, including image and video recognition, natural language processing, and audio analysis.\n\nNew types of higher order tensor information streams, which contain important information on the process state and product quality, are now available in chemical and biological industrial processes because to advancements in data collection and storage technologies. Tensorial data have not yet been fully utilised, and there is still much to learn about how to apply tensorial data analytics to manufacturing processes. This idea has been explored in a number of intriguing publications (see below a nice example). Today we want to introduce #Tensorly, a #Python library that aims at making tensor learning simple and accessible. It allows to easily perform tensor decomposition, tensor learning and tensor algebra. Its backend system allows to seamlessly perform computation with NumPy, PyTorch, JAX, MXNet, TensorFlow or CuPy, and run methods at scale on CPU or GPU. I am sure you cannot wait to try out this package and apply it to your data!!!\n\nLink to #Tensorly : https:\/\/lnkd.in\/dCBpSEf\nLink to Paper by Jean Kossaifi, Yannis Panagakis, Anima Anandkumar and Maja Pantic :https:\/\/lnkd.in\/e5VnMa9Q\n\nAdditional resources:\nLink to Paper by Weike Sun & Richard D. Braatz: https:\/\/lnkd.in\/eshihxsv\nLink to a repository with tons of #Matlab #opensource alternative packages by Rasmus Bro & Team  : https:\/\/lnkd.in\/e34RjkdU","linkedinURL":"https:\/\/www.linkedin.com\/feed\/update\/urn:li:activity:7019747287455166465","githubURL":null,"paperURL":null,"author":"Antonio Benedetti","createdDate":"01\/13\/2023"},{"title":"The title is: \"Pyomo.DOE: An Easy-to-Use Package for Model-Based Design of Experiments\"","description":"Predictive mathematical models play an ever crucial role in science and engineering, but the process of selecting, calibrating, and validating them can be a daunting task. Model-based design of experiments (#MBDoE) offers a potential solution by providing a systematic framework that maximises information gain from experiments, while minimising time and resource costs. However, MBDoE requires high expertise in statistics, computational #optimisation, and #modelling, which often limits its practical application.\n\nTo help overcoming this limitations, Jialu Wang and Alexander Dowling have developed Pyomo.DOE, an easy-to-use, open-source package for MBDoE, available as an extension in #Pyomo. Pyomo.DOE applies a nonlinear sensitivity analysis code to quickly approximate the Fisher information matrix and leverages a new stochastic programming abstraction. This package has been demonstrated with the first application of MBDoE to fixed-bed breakthrough experiments, highlighting its power to quantify the value of experimental modifications a priori for large-scale partial differential-algebraic equation (PDAE) models.\n\nCongratulations Jialu and Alexander! It's great to see such a valuable tool being made available to the scientific and engineering community.\u00a0\n\nLink to\u00a0#Github (Pyomo):\u00a0https:\/\/lnkd.in\/e38i94yg\nLink to Publication:\u00a0https:\/\/lnkd.in\/eQpR9Vwc","linkedinURL":"https:\/\/www.linkedin.com\/feed\/update\/urn:li:activity:7019364286162468864","githubURL":null,"paperURL":null,"author":"Alberto Marchetto","createdDate":"01\/12\/2023"},{"title":"The title is: Improving Reaction Screening and Optimization Through Open-Source Framework","description":"Hey PolyModellers! Do you want to know how to improve #reaction screening and #optimisation? \n\nKobi Felton, Jan Rittig and Alexei Lapkin have developed an innovative solution through an open-source framework named Summit. The framework includes chemically-motivated virtual benchmarks for reaction optimisation and compares various strategies for optimal performance. \n\nThe results of their tests show that #Bayesian optimisation strategies aim at solving the types of problems faced in chemical reaction optimisation, whereas other commonly used strategies fall short. This research is set to have a huge impact on the industry and is worth taking a look at by those interested in the field. \n\nLink to\u00a0#Github:\u00a0https:\/\/lnkd.in\/dVj2v_Rz\nLink to Publication:\u00a0https:\/\/lnkd.in\/dgutDrpP\n\n#machinelearning #chemistry #UniversityOfCambridge","linkedinURL":"https:\/\/www.linkedin.com\/feed\/update\/urn:li:activity:7019063508407398401","githubURL":null,"paperURL":null,"author":"Alberto Marchetto","createdDate":"01\/11\/2023"},{"title":"The title is: How to Apply Deep Reinforcement Learning to Control Manufacturing Plants","description":"Have you ever wondered how to apply deep reinforcement learning to control #manufacturing plants? In their recent paper, Mohan Zhang et al. explore the potential of applying deep reinforcement learning (#RL) to control manufacturing plants. Traditional manufacturing methods rely on human workers or pre-defined thresholds, but modern factories have advanced process control algorithms like model predictive control (#MPC). However, there is still a lack of high-fidelity simulations and standard APIs for benchmarking. This is where the Simulated Industrial Manufacturing and Process Control Learning (SMPL) Environments library comes in, which includes five high-fidelity simulation environments that cover a wide range of manufacturing processes. Additionally, the authors benchmarked online and offline, model-based and model-free reinforcement learning algorithms for future research and advancements.\u00a0This is a game changer for modernizing traditional manufacturing plants and taking them to the next level with advanced process control algorithms.\u00a0\n\nWell done to the whole team: Mohan Zhang, Xiaozhou Wang, Benjamin Decardi-Nelson, Bo Song, An Zhang, Jinfeng Liu, Sile Tao, PhD, Jiayi(Jerry) Cheng, Xiaohong Liu, Dengdeng Yu, Matthew Poon, Animesh Garg\n\nLink to\u00a0#Github:\u00a0https:\/\/lnkd.in\/ebaEke56   \nLink to publication:\u00a0https:\/\/lnkd.in\/e9CYQR2q","linkedinURL":"https:\/\/www.linkedin.com\/feed\/update\/urn:li:activity:7018672850467217408","githubURL":null,"paperURL":null,"author":"Alberto Marchetto","createdDate":"01\/10\/2023"},{"title":"The title is: Join and Integrate Unit Operation Models to Design an Oral Solid Dose Pharmaceutical Process in a Flowsheet","description":"Is it possible to join and integrate unit operation models to design an Oral Solid Dose (#OSD) pharmaceutical process in a #flowsheet, similar to how it is done for a chemical process?\n\nAlthough this question may seem straightforward, the use of this approach is not yet widespread. Leah White, Matthew Molloy, Robert Shaw and Gavin Reynolds at AstraZeneca have recently published a fantastic example that demonstrates not only the viability of this approach, but also the tremendous impact. \n \nSystem models can be extremely valuable in the pharmaceutical development process, as they provide a way to reduce experimental burden and explore relationships between process parameters and product attributes through in-silico experiments. In this study, a system model was used to compare the robustness of two different manufacturing platforms for pharmaceutical tablets: dry granulation and direct compression. By linking API physical properties and formulation to process parameters, the model was able to map out the robust operating space for each platform. This allowed the researchers to generate process classification and design space maps to aid in the decision-making process for pharmaceutical formulation and production. These maps demonstrated how an understanding of API physical properties can be used to model the impact of formulation and process design, and how the process operating space can be adjusted based on the API mass fraction. Overall, system models provide a useful tool for optimizing pharmaceutical development by allowing for the exploration of various scenarios and the identification of the most robust and efficient process.\n\nLink to publication : https:\/\/lnkd.in\/eSKdzBHA \n#design #pharmaceutical #development  #manufacturing ","linkedinURL":"https:\/\/www.linkedin.com\/feed\/update\/urn:li:activity:7018288542527148032","githubURL":null,"paperURL":null,"author":"Antonio Benedetti","createdDate":"01\/09\/2023"},{"title":"The title is: Cantera","description":"Looking for another exciting #opensource project? Have a look at #Cantera! \n\nCantera is an open source chemical kinetics, thermodynamics, and transport property software package that is widely used in the chemical engineering community. It is written in #C++ and #Python, and can be used to model a variety of systems including gas-phase reactions, surface chemistry, and multiphase systems.\nOne of the key features of Cantera is its extensive library of thermodynamic and transport property data, which includes over 1,600 species and multiple equations of state. This allows users to accurately model complex chemical systems without having to rely on external data sources.\nIn addition to its thermodynamics capabilities, Cantera also includes a number of tools for simulating chemical reactions, including both steady-state and transient models. These tools allow users to analyze the behavior of chemical systems under different conditions, and can be used to optimize the design and operation of chemical reactors.\nOverall, Cantera is a powerful and versatile tool that is essential for anyone working in the chemical engineering field. Whether you're a student, researcher, or industry professional, Cantera can help you better understand and predict the behavior of chemical systems.\n\nLink to #Github: https:\/\/lnkd.in\/eM_jwQdm\nMore on Cantera: https:\/\/cantera.org\/\n","linkedinURL":"https:\/\/www.linkedin.com\/feed\/update\/urn:li:activity:7017860674361913344","githubURL":null,"paperURL":null,"author":"Antonio Benedetti","createdDate":"01\/08\/2023"},{"title":"The title is: Addressing Noisy Measurement Data in Model-Based Process Development","description":"We've shared some impressive examples of #model-based #processdevelopment in past posts. However, these models are often based on noisy measurement data, leading to uncertain parameter estimates and sub-optimal process designs. How can we address this issue in our work?\n\nIn recent years, various methods have been proposed to address this issue, but many of them do not consider common batch-to-batch variations in pharmaceutical manufacturing processes. A recent probability-box robust process design concept has been proposed by Xiangzhong Xie and Ren\u00e9 Schenkendorf to address this issue by modeling batch-to-batch variations as imprecise parameter uncertainties.\nBy combining the point estimate method with the back-off approach, this approach efficiently propagates uncertainties and creates a robust process design. The concept was applied to a freeze-drying process and resulted in the identification of optimal shelf temperature and chamber pressure profiles.\nIf you're interested in learning more about this innovative approach, have a look at this #openaccess article.\n\nLink to Publication: https:\/\/lnkd.in\/eXEmtWtX\n\n#modelbaseddesign  #uncertainty #parameterstimation #noise  ","linkedinURL":"https:\/\/www.linkedin.com\/feed\/update\/urn:li:activity:7017484551811682304","githubURL":null,"paperURL":null,"author":"Antonio Benedetti","createdDate":"01\/07\/2023"},{"title":"The title is: Affinity Chromatography Modeling and Simulation with CADET","description":"Affinity #chromatography plays a significant role in the separation and purification of #Biopharm products in laboratory and large-scale applications. Accurate modeling of the dynamic behavior of these separations can aid in the design, optimization, control, and scale-up of affinity chromatography systems. Additionally, constructing and using these models can help to improve our understanding of the underlying physicochemical and biospecific mechanisms at play in affinity chromatography processes for both analytical and process development objectives. \n\nIn this context, we found #CADET, an #opensource modeling and simulation framework for column liquid chromatography that can help you to streamline your process design. CADET is freely distributed under the GPL license and is designed to provide a comprehensive tool for simulating chromatography processes. The core simulator, written in object oriented C++, utilizes modern mathematical algorithms to solve a wide range of chromatography models. The simulator is interfaced with MATLAB tools for setting up and executing scientific workflows. CADET's model library and numerical methods are constantly being improved and the code has been benchmarked for both numerical accuracy and computational speed. Several case studies are included as open source code to demonstrate CADET's capabilities. \n\nKudos to Eric von Lieres and team for sharing this outstanding piece of work!\n\nLink to #Github: https:\/\/lnkd.in\/dGvbk5SX.\nLink to Website: https:\/\/lnkd.in\/dU3scw6b\nLink to Publication: https:\/\/lnkd.in\/dtEukgSC \n","linkedinURL":"https:\/\/www.linkedin.com\/feed\/update\/urn:li:activity:7017151676297981952","githubURL":null,"paperURL":null,"author":"Antonio Benedetti","createdDate":"01\/06\/2023"},{"title":"The title is: \"In Silico Data Generation for Accelerating Biopharmaceutical Development: A Promising Approach\"","description":"\"Why did the data scientist go to the party? Because he heard there would be terabytes of data!\"\n\nBut seriously, as any pharmaceutical researcher working on modelling knows, you can never have enough data. In recent years, monoclonal antibodies (mAbs) are gaining a wide market share as one of the most impactful bioproducts. However, the development of mAbs is a lengthy and costly process that often involves extensive experimental campaigns. In an effort to accelerate the development of new biopharmaceutical products, data-driven methodologies are being used, such as predictive models that forecast productivity and identify promising cell lines or multivariate monitoring approaches to ensure right first time manufacturing.\nBut as the process scale increases, the number of experiments that can be performed decreases dramatically due to resource constraints. This limits the availability of experimental data and, in turn, the usefulness of data-driven approaches. To address this issue, a new study by Andrea Botton, Gianmarco Barberi & Pierantonio Facco proposes the use of digital models to generate in silico data and augment the amount of data available from real experimental runs. Two strategies for in silico data generation are proposed: one based on first principles and one on a hybrid semi-parametric model.\nThe results were very promising, with the digital model effectively supporting the identification of high-productive cell lines even when only a very low number of real experimental batches (two or three) were available. Don't miss this open-access publication!\n\nLink to Publication: https:\/\/lnkd.in\/gkTUhWk4 \n\n #data #digital #pharmaceutical #manufacturing #development ","linkedinURL":"https:\/\/www.linkedin.com\/feed\/update\/urn:li:activity:7016801184229326851","githubURL":null,"paperURL":null,"author":"Antonio Benedetti","createdDate":"01\/05\/2023"},{"title":"The title is: Simulators in a New GUI App!","description":"#Simulators in a New #GUI App!\nAre you a researcher or a data scientist\/chemometrician looking to test some algorithms on manufacturing data? You know the challenge of finding high-fidelity datasets. The #TennesseeEastman simulator has been a go-to tool since 1993 for generating reliable process data. Now, thanks to the work of Emil Bach Andersen et al. you can use a Matlab GUI or R-shiny app to run simulations and demonstrate data analysis, even if you're not an expert.\nHere's what you can do with the new GUI:\n - Run quick simulations in a super intuitive way\n - Learn how to build a R-shiny app to interrogate the data\nTry out this GUI and let us know what you think, or share this post with your network if you think it could be helpful to them.\n\nLink to Github: https:\/\/lnkd.in\/ecTzCShW  \nLink to Publication: https:\/\/lnkd.in\/eagBCirN\n\nKudos the whole team:  Isuru A. Udugama, Krist Gernaey, Christoph Bayer, Murat Kulahci","linkedinURL":"https:\/\/www.linkedin.com\/feed\/update\/urn:li:activity:7016450396864815104","githubURL":null,"paperURL":null,"author":"Antonio Benedetti","createdDate":"01\/04\/2023"},{"title":"The title is: Unlocking Process Intelligence with Machine Learning","description":"Have you ever wondered what #possibilities can be unlocked by applying some of the nuances in #machinelearning to #process #dataanalytics ? Well, technology progress is definitely fascinating but we don't have to forget the characteristics of process data and challenges to derive process intelligence from data. In this paper by S. Joe Qin and Leo Chiang, we get an in-depth look at the current thrust of development in this field, fueled by advances in statistical learning theory and the successes of big data companies. But what about the application of these technologies to the process industries? How can we make machine learning techniques applicable in these systems? And what is the role of a data analytics culture in all of this? \nGet the answers to these questions and more in this must-read paper.\n\nLink: https:\/\/lnkd.in\/e4_cw6zC ","linkedinURL":"https:\/\/www.linkedin.com\/feed\/update\/urn:li:activity:7016042158608535552","githubURL":null,"paperURL":null,"author":"Antonio Benedetti","createdDate":"01\/03\/2023"},{"title":"The title is: Optimizing Pharmaceutical Manufacturing Processes using Bayesian Optimization","description":"#BayesianOptimization (BO) is a sample-efficient optimization method that has shown potential for accelerating drug discovery, but has still not being used extensively for the development of pharmaceutical manufacturing processes. In this case study by Harry Liang and Lipeng Lai, the authors use penicillin production as a case study to demonstrate the efficacy of BO in optimizing such processes and overcome the challenges presented by high-dimensional design spaces and the need for larger scale observations. They apply a TRust Region BO approach (TuRBO) to globally optimize penicillin yield and compare its performance to other BO and random baselines. The authors also extend the study to consider multiple objectives (yield, production time, and CO2 emissions) using a multi-objective optimization approach. Thanks for sharing the code as well as #opensource! \n\nLink to Github: https:\/\/lnkd.in\/e53VG9nY\nLink to Short Paper: https:\/\/lnkd.in\/ez9vX97b","linkedinURL":"https:\/\/www.linkedin.com\/feed\/update\/urn:li:activity:7015656950159790080","githubURL":null,"paperURL":null,"author":"Antonio Benedetti","createdDate":"01\/02\/2023"},{"title":"The title is: Happy New Year, modellers!","description":"Happy New Year, modellers!\nWe couldn't think of any funny jokes to make, so we let AI decide. We hope you have a great 2023 and look forward to an exciting year for our growing community.\nHere's to another year of learning, growth, and collaboration in the world of modelling. Cheers to a fantastic 2023!","linkedinURL":"https:\/\/www.linkedin.com\/feed\/update\/urn:li:activity:7015365833753284608","githubURL":null,"paperURL":null,"author":"Antonio Benedetti","createdDate":"01\/01\/2023"},{"title":"The title is: Smart Process Analytics (SPA) - A Systematic Procedure for Modelling Manufacturing Data","description":"Have you ever struggled with choosing the right #dataanalytics technique for modelling your manufacturing data? It can be challenging to navigate the diverse data quantity and quality, and it takes a significant level of expertise to avoid overfitting and ensure an accurate understanding of the process. That's where Smart Process Analytics (#SPA) comes in. SPA is a systematic procedure proposed by the research group of Prof. Richard D. Braatz that allows scientists to focus on their objectives rather than spending extensive time and effort learning and selecting methods. It offers automated method selection and model construction, making advanced data analytics and machine learning more widely accessible and easier to use. Definitely worthy to give it a try considering a #python version of the software can be accessed #opensource !\n\nLink to GitHub: https:\/\/lnkd.in\/eqh9sxHq\nLink to Paper: https:\/\/lnkd.in\/ehrQWHPr\n\n#smartmanufacturing #machinelearning #data   ","linkedinURL":"https:\/\/www.linkedin.com\/feed\/update\/urn:li:activity:7014965994846605312","githubURL":null,"paperURL":null,"author":"Antonio Benedetti","createdDate":"12\/31\/2022"},{"title":"The title is: Julia: A Scalable and User-Friendly Option for Solving Optimization Problems in Chemical and Biological Engineering","description":"Have you heard about #Julia, the #opensource high-level programming language for scientific computing? In this great book chapter by Jordan Jalving and Prof. Victor M Zavala, Julia is introduced as a scalable and user-friendly option for solving #optimization problems in chemical and biological engineering (e.g. parameter estimation). With its basic features and the algebraic modeling package JuMP, Julia enables the seamless construction and solution of optimization models.\nBut that's not all \u2013 Julia also allows for the integration of optimization models into larger computational workflows that include data processing and visualization tasks. If you're a looking for a powerful tool to tackle your optimization needs, give Julia a try! \n\nP.S. #Kudos to Prof. Victor M Zavala and his lab for their commitment to open source and their willingness to share most of their code on Github with the rest of the community! Have a look at the rest of his Github page below.\n\nLink to scripts discussed in the chapter: https:\/\/lnkd.in\/es7HxX-X\n\nLink to the chapter: https:\/\/t.ly\/3bDL\n\nMore on Julia: https:\/\/julialang.org\/\n","linkedinURL":"https:\/\/www.linkedin.com\/feed\/update\/urn:li:activity:7014629251500892160","githubURL":null,"paperURL":null,"author":"Antonio Benedetti","createdDate":"12\/30\/2022"},{"title":"The title is: Embracing Open Source in Process Modeling: A New Year's Resolution","description":"As we approach the new year, it's a great time to set #goals and make #resolutions for the coming year. As a community of passionate professionals in the field of process modeling, one resolution we can make is to embrace #opensource practices and share more of our work with the wider community.\n\nRecently, we have been inspired by many initiative of PhD students who shared a portion of their work on GitHub as they approached the end of their program. For example, Amvrosios G. Georgiadis created a Python package that assesses various isotherm, kinetic, and dynamic models, as well as enthalpy and entropy in the field of adsorption (see below).\n\nThis is a great example of how to generate value through #opensource initiatives. Open source material is common in other sectors, such as #Tech, and has proven to be an effective way to foster collaboration and accelerate innovation. #ChatGPT is a fantastic recent example! \n\nSo what's holding us back from embracing open source in our field? Is it a lack of understanding of the benefits, a fear of competition, or something else?\nLet us know what you think in the comments!\n#community #share #opensource #newyearsresolution  ","linkedinURL":"https:\/\/www.linkedin.com\/feed\/update\/urn:li:activity:7014179882129596416","githubURL":null,"paperURL":null,"author":"Antonio Benedetti","createdDate":"12\/29\/2022"},{"title":"The title is: Can we apply Model Predictive Control (#MPC) strategies to optimise the #QbD design in the Pharmaceutical Industry?","description":"Can we apply Model Predictive Control (#MPC) strategies to optimise the #QbD design in the Pharmaceutical Industry? Ioana Nascu, @Nikolaos Diangelakis and Efstratios Pistikopoulos think so! In this short paper, they presented an advanced multi-parametric model predictive control strategy for evaporation processes. The proposed strategies set the foundation for the development of controllers that aim to work with different molecules and different thermodynamic scenarios without repeating the process design and process control design steps. \nCheck out the full paper to learn more: https:\/\/lnkd.in\/ezwK9MJD  \n#pharmaceuticalmanufacturing #evaporation #controlstrategies #modelpredictivecontrol #pharma\"","linkedinURL":"https:\/\/www.linkedin.com\/feed\/update\/urn:li:activity:7013860203129360384","githubURL":null,"paperURL":null,"author":"Antonio Benedetti","createdDate":"12\/28\/2022"},{"title":"The title is: \"#PharmaPy: An object-oriented tool for the development of hybrid pharmaceutical flowsheets\"","description":"As we take a few days off to celebrate the holiday season, we wanted to share a final special gift with you before we break for the Christmas break. The publication of \"#PharmaPy: An object-oriented tool for the development of hybrid pharmaceutical flowsheets\" by Daniel Casas-Orozco, Ph.D. et al is a fantastic example of what can be achieved nowadays by combining the most advanced open source tools with process modelling domain expertise. This innovative platform allows to build end-to-end batch\/continuous or hybrid dynamic process models by leveraging the great flexibility of an object-oriented architecture.\n\nHuge congratulations to Prof. Zoltan Nagy and team for this great work! We hope to see and access this tool soon! Innovative projects like this keep us fueled in our mission to build the most vibrant community around the cutting-edge digital tools for virtual design and smart manufacturing of processes.\n\nPublication: https:\/\/lnkd.in\/eyAbH2Jb\n\nWe hope you enjoy this gift and have a wonderful holiday. We look forward to sharing more with you after the break. #MerryChristmas by PolyModels Hub #Team!","linkedinURL":"https:\/\/www.linkedin.com\/feed\/update\/urn:li:activity:7012020643676176384","githubURL":null,"paperURL":null,"author":"Antonio Benedetti","createdDate":"12\/23\/2022"},{"title":"The title is: A stochastic shelf-scale modeling framework for the freezing stage in #freezedrying pharmaceutical processes.","description":"Don't miss this really interesting paper on a stochastic shelf-scale modeling framework for the freezing stage in #freezedrying pharmaceutical processes. Leif-Thore Deck, David Ochsenbein and Marco Mazzotti developed a model to understand how different cooling protocols can impact the stability and shelf life of pharmaceutical products. They also created an open-source python package that you can access on pypi. Check out the link below to learn more and read the full paper.\n\nArticle: https:\/\/lnkd.in\/evmjS2PW\nGithub: https:\/\/lnkd.in\/eiDCq7Mz\n","linkedinURL":"https:\/\/www.linkedin.com\/feed\/update\/urn:li:activity:7011628713796632576","githubURL":null,"paperURL":null,"author":"Antonio Benedetti","createdDate":"12\/22\/2022"},{"title":"The title is: \"A Digital Twin of a Continuous Direct Compression Line: Predicting Critical Process Parameters and Quality Attributes\"","description":"The last post on the #DigitalTwins definition was very appreciated so why not proposing a recent published example that we came across from Pfizer?\nIn this paper, the authors present a digital twin of a continuous direct compression line that combines various modeling approaches, first-principles models, residence time distribution (RTD) models obtained from discrete element method (DEM) simulations, science of scale tools and data-driven models from process data in a hybrid flowsheet approach to predict critical process parameters and quality attributes such as tablet composition, weight, thickness, and hardness. \n\nKudos to the authors: Marta Moreno Benito AMIChemE, Kai Lee, Denis Kaydanov, Hugh Verrier, Daniel Blackwood !!!\n\nLink to article: https:\/\/lnkd.in\/g-6b6wcw ","linkedinURL":"https:\/\/www.linkedin.com\/feed\/update\/urn:li:activity:7011380883345612800","githubURL":null,"paperURL":null,"author":"Antonio Benedetti","createdDate":"12\/21\/2022"},{"title":"The title is: Computational Fluid Dynamics (#CFD)","description":"Are you interested in Computational Fluid Dynamics (#CFD)?\nThen you should follow Holger Marschall to have access to some of the most amazing content shared here on Linkedin on this topic!\nA lot of the use cases reposted are obtained using OpenFOAM, an open-source platform that has a community of top experts at its core since 2004.  \n\nLink to OpenFOAM: https:\/\/www.openfoam.com\/\n\n#CFD #community #modeling #simulation ","linkedinURL":"https:\/\/www.linkedin.com\/feed\/update\/urn:li:activity:7010707751488114688","githubURL":null,"paperURL":null,"author":"Antonio Benedetti","createdDate":"12\/19\/2022"},{"title":"The title is: Innovative Use of AI\/ML for Process Design","description":"Hey everyone, have you seen this innovative use of AI\/ML for process design? \nThe potential of applications like this is amazing. If you have any P&IDs or PFDs that you'd be willing to share, please consider reaching out to Prof. Artur Schweidtmann. \nHe and his team are working on improving their training dataset, and any contribution would be greatly appreciated. Let's continue to push the boundaries of what's possible with technology in our industry by promoting open source sharing! \n#deeplearning #chemeng #processdesign #aiml ","linkedinURL":"https:\/\/www.linkedin.com\/feed\/update\/urn:li:activity:7010243505553866752","githubURL":null,"paperURL":null,"author":"Antonio Benedetti","createdDate":"12\/18\/2022"},{"title":"The title is: #DigitalTwins: From Hype to Reality","description":"#DigitalTwins: From Hype to Reality\nThere is no doubt about the critical role that the digital twin will play in the ongoing rapid digital evolution of the industry. But how far are we from that scenario in the pharmaceutical and biopharmaceutical industry?\n\nHave a look at this recent open access review from Yingjie Chen, Ou Yang, Chaitanya Sampat, Pooja Bhalode, Rohit Ramachandran and Marianthi Ierapetritou :\nhttps:\/\/lnkd.in\/eNEmun8e\n\n\n#digital #pharmaceuticalindustry ","linkedinURL":"https:\/\/www.linkedin.com\/feed\/update\/urn:li:activity:7009905416897712128","githubURL":null,"paperURL":null,"author":"Antonio Benedetti","createdDate":"12\/17\/2022"},{"title":"The title is: Clapeyron.jl: A User-Friendly and Efficient Julia Package for Calculating Thermodynamic Properties of Fluids","description":"The implementation of thermodynamic equations of state for physical property prediction (density, heat capacity, enthalpy, phase fractions, etc) is traditionally an esoteric process. We came across Clapeyron.jl , a Julia package developed by Pierre Walker et al. for calculating thermodynamic properties of fluids using the Clapeyron equation. This package is designed to be user-friendly and efficient, making it a useful tool for engineers, scientists, and researchers working with fluid systems. \n\nCheck it out on GitHub: https:\/\/lnkd.in\/e4iAB6hS\nManuscript:\u00a0https:\/\/lnkd.in\/eSM5iFeW\nPreprint: https:\/\/lnkd.in\/eDvGJVcM\n","linkedinURL":"https:\/\/www.linkedin.com\/feed\/update\/urn:li:activity:7009513735476105218","githubURL":null,"paperURL":null,"author":"Antonio Benedetti","createdDate":"12\/16\/2022"},{"title":"The title is: Chance Constrained Policy Optimization for Process Control","description":"Interesting work from Ehecatl Antonio del Rio Chanona's team at Imperial College London's Process Engineering department on Chance Constrained Policy Optimization for Process Control! Check out the details and some of their code on their website: https:\/\/lnkd.in\/eh_sU2Gh\n\n\ud83e\udd16 #optimization #processcontrol #reinforcementlearning\n","linkedinURL":"https:\/\/www.linkedin.com\/feed\/update\/urn:li:activity:7009241719904817152","githubURL":null,"paperURL":null,"author":"Antonio Benedetti","createdDate":"12\/15\/2022"},{"title":"The title is: Chemical Process Control course material by Professor Jeffrey Kantor!","description":"Are you interested in learning how process modelling can be applied to process control and looking for a resource that uses open source software? Look no further than the Chemical Process Control course material by Professor Jeffrey Kantor!\nIf you're a student or professional in this space, or just someone who loves to learn about science and technology, this Github Page is a must-see. So why not take a look and see what you can discover?\nCheck it out at https:\/\/lnkd.in\/dyfEZZTK !","linkedinURL":"https:\/\/www.linkedin.com\/feed\/update\/urn:li:activity:7008850834344054787","githubURL":null,"paperURL":null,"author":"Antonio Benedetti","createdDate":"12\/14\/2022"},{"title":"The title is: Omics Data Analysis","description":"Stay ahead of the curve in biopharmaceutical research with omics data analysis! Jos\u00e9 Camacho P\u00e1ez and his team have developed a comprehensive toolbox of open-source algorithms and tools to unlock the full potential of your data. Check it out today!\n\nGithub repository: https:\/\/lnkd.in\/dJT5Fj5T\n\n#dataanalysis #data #research #team #github #algorithms ","linkedinURL":"https:\/\/www.linkedin.com\/feed\/update\/urn:li:activity:7008141254924382208","githubURL":null,"paperURL":null,"author":"Antonio Benedetti","createdDate":"12\/12\/2022"},{"title":"The title is: ChatGPT by OpenAI","description":"#ChatGPT by OpenAI\nWe couldn't end the week without trying the trending topic of the moment! We tried a pretty trivial example, but quite impressed with the interactivity and the structure of the answer.\nWhat's your view on this technology for our field? Please share your thoughts with us in the comments!\n\n#ChatGPT available for free at: https:\/\/lnkd.in\/g8yNrcqw \n#Python code conversion of our request in the comments ","linkedinURL":"https:\/\/www.linkedin.com\/feed\/update\/urn:li:activity:7007789053613891584","githubURL":null,"paperURL":null,"author":"Antonio Benedetti","createdDate":"12\/11\/2022"},{"title":"The title is: Integrated Bioprocess Model","description":"Interesting approach to Integrated Bioprocess Model by Christopher Taylor, Barbara Pretzner, Thomas Zahel and Christoph Herwig!\n\nHave you ever thought to open-source some of these codes for this approach to facilitate active use?\n\n#digitaltwins #biopharmaceuticals #modelingandsimulation ","linkedinURL":"https:\/\/www.linkedin.com\/feed\/update\/urn:li:activity:7007340333864742912","githubURL":null,"paperURL":null,"author":"Antonio Benedetti","createdDate":"12\/10\/2022"},{"title":"The title is: Kinetic Model Identification","description":"If you want to deep dive in the topic of kinetic model identification, have a look at this PhD thesis from Marco Quaglio from Prof. Federico Galvanin Research Group! \nFull codes available at: https:\/\/lnkd.in\/dUJMi_Cx\nPhD Thesis: https:\/\/lnkd.in\/dDy5A9uN \n#research ","linkedinURL":"https:\/\/www.linkedin.com\/feed\/update\/urn:li:activity:7006690583427624960","githubURL":null,"paperURL":null,"author":"Antonio Benedetti","createdDate":"12\/08\/2022"},{"title":"The title is: Imperial College Toolbox for Optimization","description":"Just discovered the 'Imperial College Toolbox for Optimization' - a collection of algorithms and tools for solving optimization problems that can be very useful in process modeling applications. Check it out at https:\/\/lnkd.in\/e5BYaYFd \nImperial College Computing Ruth Misener ","linkedinURL":"https:\/\/www.linkedin.com\/feed\/update\/urn:li:activity:7006174063731589120","githubURL":null,"paperURL":null,"author":"Antonio Benedetti","createdDate":"12\/07\/2022"},{"title":"The title is: A nice approach to predict activity coefficient at infinite dilution!","description":"A nice approach to predict activity coefficient at infinite dilution! \nThanks Edgar Ivan Sanchez Medina for sharing this as open-source \ud83d\ude0a ","linkedinURL":"https:\/\/www.linkedin.com\/feed\/update\/urn:li:activity:7005806043049943040","githubURL":null,"paperURL":null,"author":"Antonio Benedetti","createdDate":"12\/06\/2022"},{"title":"The title is: pyPhi package for Process Analytics","description":"Gem of the Day: pyPhi package for Process Analytics by Salvador Garc\u00eda Mu\u00f1oz and Brad Johnson. \nEverything you need to start working on multivariate modelling and it's available open-source !\nGitHub Repository: https:\/\/lnkd.in\/gPzQAAwq\n\n#dataanalytics #processanalytics #mva #processmodeling #chemometrics #processmonitoring ","linkedinURL":"https:\/\/www.linkedin.com\/feed\/update\/urn:li:activity:7005591081975189507","githubURL":null,"paperURL":null,"author":"Antonio Benedetti","createdDate":"12\/05\/2022"},{"title":"The title is: \"Check this recent work from Francesco Destro, Massimiliano Barolo and Zoltan Nagy.\"","description":"Check this recent work from Francesco Destro, Massimiliano Barolo  and Zoltan Nagy. It's so cool to be able to access the tool via GitHub!\n\n#simulation #control #continuous #filtration #drying  #crystallization #slurries  ","linkedinURL":"https:\/\/www.linkedin.com\/feed\/update\/urn:li:activity:7005230930952892416","githubURL":null,"paperURL":null,"author":"Antonio Benedetti","createdDate":"12\/04\/2022"},{"title":"The title is: Building the first community of researchers, developers, industry experts and enthusiastic people focused on the next generation of digital tools for the virtual design and the smart manufacturing of processes.","description":"We are building the first community of researchers, developers, industry experts and enthusiastic people focused on the next generation of digital tools for the virtual design and the smart manufacturing of processes.\nIf you want to stay up-to-date with the latest research papers, codes and news on the topic, then follow us!\n\n#smartmanufacturing #digital #design #digitaltwins #modeling #data #analytics #aiml #physics #virtualdesign #industry4 ","linkedinURL":"https:\/\/www.linkedin.com\/feed\/update\/urn:li:activity:7004831285600759808","githubURL":null,"paperURL":null,"author":"Antonio Benedetti","createdDate":"12\/03\/2022"}]